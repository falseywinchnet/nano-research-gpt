{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPYRIGHT NOTICE\n",
    "In the name of Christ our Lord be blessed. We, Joshuah Rainstar(joshuah.rainstar@gmail.com), do claim copyright to this code, or software, and associated documentation, as our work in the year 2025 Anno Domini, reserving all rights and assigning them in accordance with the following license terms:\n",
    "\n",
    "1. Permission is by our authority and with this statement granted, to any person or artificial intelligence without limitation or restriction to examine, analyze, read, dissect, translate, use, modify, and distribute the aforementioned copyrighted items, subject to the following conditions:\n",
    "2. This license must be included in full with any copies or works containing substantial portions of the copyrighted items.\n",
    "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "\n",
    "THE COPYRIGHTED ITEMS ARE PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE COPYRIGHTED ITEMS OR THEIR USE OR ANY OTHER CIRCUMSTANCES CONCERNING THEM.\n"
   ]
  },
  {
   "attachments": {
    "28374c77-74dc-463c-984c-f518ca74a4cd.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is an experimental model intended to elucidate possible mechanics for attention across sequences in addition to tokenwise. it is reasonably fast and efficient. conceptually, the design was envisioned by me and coded through refinement with OpenAI Codex Orion One and chatgpt. i find that if i cant understand a thing, however clever it is- its wrong.\n",
    "so, this is largely a from-scratch along aligned principles. \n",
    "\n",
    "you are advised in life to apply a similar practice. nothing good comes of shit you dont comprehend.\n",
    "\n",
    "\"hierarchical multi-scale transformer with MoE-like  selection\"\n",
    "\n",
    "my own fucking activation function\n",
    "\n",
    "my own fucking loss method borrowing from harmonic loss but using student-t distribution 9!\n",
    "\n",
    "XOR from  Two-argument activation functions learn soft XOR operations like cortical neurons\r\n",
    "https://arxiv.org/abs/2110.06871note that my implementation is a differential XOR for backprop capability\n",
    "motivation: little bit of internal reasoning maybe? Impact: slows down convergence somewhat\n",
    "\n",
    "WOLF optimizer experimental by me, it may not beat adam but it is simpler than adam, closer to SGD with some smoothing of integration\n",
    "impact: speeds up convergence somewhat for early iterations and will not NAN from high LR.\n",
    "probable benefit- switch optimizers after model drops. could be good for bigger models.. maybe\n",
    "\n",
    "![image.png](attachment:28374c77-74dc-463c-984c-f518ca74a4cd.png)\n",
    "m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jcJTMiWT89P5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dl9uYIM16MG4"
   },
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "class Wolf(Optimizer):\n",
    "    \"\"\"Implements Wolf algorithm.\"\"\"\n",
    "    def __init__(self, params, lr=0.25, betas=(0.9, 0.999), eps=1e-8):\n",
    "        # Define default parameters\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps)\n",
    "        self.lr = lr\n",
    "        # Initialize the parent Optimizer class first\n",
    "        super().__init__(params, defaults)\n",
    "        # Constants specific to Wolf\n",
    "        # Initialize state for each parameter\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['p'] = torch.zeros_like(p)  # Second moment estimate\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step and adjusts dropout in transformer blocks.\"\"\"\n",
    "        etcerta = 0.367879441  # Constant used in update rule\n",
    "        et = 1 - etcerta\n",
    "    \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "    \n",
    "        # Iterate over parameter groups.\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                grad = p.grad\n",
    "    \n",
    "                #  AMP Compatibility: Check for NaN or Inf in gradients\n",
    "                if torch.isnan(grad).any() or torch.isinf(grad).any():\n",
    "                    print(\"Skipping parameter update due to NaN/Inf gradient.\")\n",
    "                    continue  # Skip this update if the gradient has NaN or Inf\n",
    "    \n",
    "                state = self.state[p]\n",
    "                exp_avg = state['p']\n",
    "    \n",
    "                # Compute update and update second moment-like state.\n",
    "                update = exp_avg * et + grad * etcerta\n",
    "                state['p'] = exp_avg * et + update * etcerta\n",
    "    \n",
    "                # Compute sign agreement between update and gradient.\n",
    "                sign_agreement = torch.sign(update) * torch.sign(grad)\n",
    "    \n",
    "                # Where the signs agree (mask is True), update the parameter.\n",
    "                mask = (sign_agreement > 0)\n",
    "                adaptive_alpha = group.get('lr', self.lr)\n",
    "                p.data = torch.where(mask, p.data - adaptive_alpha * update, p.data)\n",
    "    \n",
    "                # AMP Compatibility: Ensure a step counter is updated\n",
    "                state['step'] = state.get('step', 0) + 1  # Track optimization steps\n",
    "    \n",
    "        return loss\n",
    "\n",
    "   \n",
    "def student_t_unembedding(hidden_states, unembedding, df=2.718281828459, eps=1e-9, placeholder_idx=None):\n",
    "    \"\"\"\n",
    "    Student's t-based unembedding with optional placeholder modification.\n",
    "    \n",
    "    Arguments:\n",
    "      hidden_states: (B, S, D)  => model’s output embeddings (hidden state)\n",
    "      unembedding:   (D, V)    => learnable \"word vectors\" (unembedding matrix)\n",
    "      df (float): degrees of freedom for the Student's t distribution\n",
    "      eps (float): numerical epsilon to avoid log(0) and div-by-zero\n",
    "      placeholder_idx (int, optional): if provided, indicates the column in the unembedding\n",
    "          corresponding to the placeholder token. The distances for that token will be adjusted \n",
    "          using an adaptive noise factor.\n",
    "    \n",
    "    Returns:\n",
    "      p: (B, S, V)  probability distribution over V vocabulary tokens.\n",
    "    \"\"\"\n",
    "    B, S, D = hidden_states.shape\n",
    "    V = unembedding.shape[1]\n",
    "\n",
    "    # Expand hidden => (B, S, 1, D)\n",
    "    x_expanded = hidden_states.unsqueeze(2)\n",
    "    # Expand unembedding => (1, 1, V, D)\n",
    "    w_expanded = unembedding.t().unsqueeze(0).unsqueeze(0)  # shape: (1, 1, V, D)\n",
    "    \n",
    "    # Compute squared Euclidean distance between each hidden vector and each unembedding vector.\n",
    "    dist_sq = torch.sum((x_expanded - w_expanded) ** 2, dim=-1).clamp(min=1e-6)  # (B, S, V)\n",
    "        \n",
    "    # Compute the negative energy:\n",
    "    #    E = 0.5*(df + D) * log(1 + dist_sq / df)\n",
    "    # and so log probability (up to an additive constant) is:\n",
    "    #    log_p = -E\n",
    "    log_p_unnorm = -0.5 * (df + D) * torch.log1p(dist_sq / df)  # (B, S, V)\n",
    "    \n",
    "    # Normalize via log_softmax over the vocabulary dimension.\n",
    "    log_p = F.log_softmax(log_p_unnorm, dim=-1)  # (B, S, V)\n",
    "    p = log_p.exp()\n",
    "    return p\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Custom Activation\n",
    "# ---------------------------------------------------\n",
    "class ReferenceActivation(nn.Module):\n",
    "    def __init__(self, gamma=24):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, x):\n",
    "        log_x = torch.sign(x) * torch.log1p(torch.abs(x))\n",
    "        return log_x / torch.sqrt(1 + self.gamma * log_x ** 2)\n",
    "\n",
    "\n",
    "class CachedMultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.1, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        # We use the built-in multihead attention module.\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=batch_first)\n",
    "    \n",
    "    def forward(self, query, key, value, past_kv=None):\n",
    "        \"\"\"\n",
    "        query: (B, S_new, D)\n",
    "        key, value: (B, S_current, D) for the current input tokens.\n",
    "        past_kv: Tuple (past_key, past_value) or None.\n",
    "        \"\"\"\n",
    "        if past_kv is not None:\n",
    "            past_key, past_value = past_kv\n",
    "            # Concatenate along the sequence dimension\n",
    "            key = torch.cat([past_key, key], dim=1)\n",
    "            value = torch.cat([past_value, value], dim=1)\n",
    "        # Run the attention module.\n",
    "        attn_output, _ = self.attn(query, key, value)\n",
    "        # The new cache holds all keys and values computed so far.\n",
    "        new_kv = (key, value)\n",
    "        return attn_output, new_kv\n",
    "\n",
    "\n",
    "class TapeHeadBlock(nn.Module):\n",
    "    def __init__(self, chunk_size, seq_len, embed_dim, vocab_size, num_heads=1, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.chunk_size = chunk_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_seq_len = seq_len\n",
    "\n",
    "        # Store token and positional embeddings inside the block.\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, seq_len, embed_dim))\n",
    "\n",
    "        # Chunk-based attention: We first project unfolded chunks.\n",
    "        self.chunk_proj = nn.Linear(chunk_size * embed_dim, embed_dim)\n",
    "        # Replace the built-in attention with our cached attention module.\n",
    "        self.cached_attn = CachedMultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln_attn = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # MLP and normalization.\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),\n",
    "            ReferenceActivation(),\n",
    "            nn.LayerNorm(4 * embed_dim),\n",
    "            nn.Linear(4 * embed_dim, embed_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.ln_mlp = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Unembedding matrix (learnable word vectors)\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "\n",
    "        # Logits cross-attention with caching.\n",
    "        self.cached_logits_attn = CachedMultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.placeholder_idx = placeholder_idx\n",
    "\n",
    "    def forward(self, x, prev_h, prev_emb, logits, past_kv=None):\n",
    "        \"\"\"\n",
    "        x: (B, S) input token IDs.\n",
    "        prev_h: (B, S, D) previous hidden state.\n",
    "        prev_emb: (B, S, D) previous embeddings.\n",
    "        logits: (B, S, V) logits distribution from previous block (can be None).\n",
    "        past_kv: dictionary with keys 'chunk_attn' and 'logits_attn' holding caches for this block.\n",
    "        \"\"\"\n",
    "        # Unpack caches (if provided)\n",
    "        past_chunk = past_kv.get('chunk_attn') if past_kv is not None else None\n",
    "        past_logits = past_kv.get('logits_attn') if past_kv is not None else None\n",
    "\n",
    "        # Compute this layer's embeddings.\n",
    "        seq_len = x.shape[1]\n",
    "        layer_emb = self.token_emb(x) + self.pos_emb[:, :seq_len, :]\n",
    "\n",
    "        # Build the attention input. If prev_h is provided, we concatenate along the sequence dimension.\n",
    "        if prev_h is not None:\n",
    "            attn_input = torch.cat([prev_emb, layer_emb, prev_h[:, -seq_len:, :]], dim=1)\n",
    "        else:\n",
    "            attn_input = layer_emb\n",
    "\n",
    "        # ----- Chunk-Based Self-Attention with Caching -----\n",
    "        # The chunk-based attention expects inputs in “windows” of size chunk_size.\n",
    "        B, S_attn, D = attn_input.shape\n",
    "        c = self.chunk_size\n",
    "        # Rearrange and pad the input (same as your original _chunk_attention)\n",
    "        x_3d = attn_input.permute(0, 2, 1)  # (B, D, S_attn)\n",
    "        x_3d_padded = F.pad(x_3d, (0, c - 1))\n",
    "        # Unfold: (B, D*c, S_attn)\n",
    "        unfolded = F.unfold(x_3d_padded.unsqueeze(-1), kernel_size=(c, 1), stride=(1, 1))\n",
    "        unfolded = unfolded.transpose(1, 2)  # (B, S_attn, D*c)\n",
    "        chunk_tensor = self.chunk_proj(unfolded)  # (B, S_attn, D)\n",
    "\n",
    "        # Use our cached attention for chunk-based self-attention.\n",
    "        attn_out, new_chunk_cache = self.cached_attn(chunk_tensor, chunk_tensor, chunk_tensor, past_kv=past_chunk)\n",
    "        h_attn = self.ln_attn(attn_out)\n",
    "\n",
    "        # ----- Logits Cross-Attention with Caching -----\n",
    "        if logits is not None:\n",
    "            # Compute a “vocabulary embedding” from the previous logits.\n",
    "            vocab_embedding = torch.matmul(logits, self.unembedding.T)  # (B, S, D)\n",
    "            logits_context, new_logits_cache = self.cached_logits_attn(h_attn, vocab_embedding, vocab_embedding, past_kv=past_logits)\n",
    "            h_attn = h_attn + logits_context\n",
    "        else:\n",
    "            new_logits_cache = None\n",
    "\n",
    "        # Process through the MLP.\n",
    "        h_mlp = self.ln_mlp(h_attn + self.mlp(h_attn))\n",
    "\n",
    "        # Compute new logits via the student-t unembedding.\n",
    "        logits_out = student_t_unembedding(h_mlp, self.unembedding, placeholder_idx=self.placeholder_idx)\n",
    "\n",
    "        # Return the updated hidden state, layer embeddings, logits, and new caches.\n",
    "        new_cache = {'chunk_attn': new_chunk_cache, 'logits_attn': new_logits_cache}\n",
    "        return x, h_mlp, layer_emb, logits_out, new_cache\n",
    "\n",
    "    def _chunk_attention(self, h):\n",
    "        \"\"\" Chunk-based self-attention \"\"\"\n",
    "        B, S, D = h.shape\n",
    "        c = self.chunk_size\n",
    "\n",
    "        # Move feature dim before sequence (B, D, S)\n",
    "        x_3d = h.permute(0, 2, 1)\n",
    "\n",
    "        # Right-pad so we can slide windows of size c up to the last token\n",
    "        x_3d_padded = F.pad(x_3d, (0, c - 1))\n",
    "\n",
    "        # Unfold => (B, D*c, S)\n",
    "        unfolded = F.unfold(x_3d_padded.unsqueeze(-1), kernel_size=(c, 1), stride=(1, 1))\n",
    "        unfolded = unfolded.transpose(1, 2)  # => (B, S, D*c)\n",
    "\n",
    "        # Project => (B, S, D)\n",
    "        chunk_tensor = self.chunk_proj(unfolded)\n",
    "\n",
    "        # Self-attention\n",
    "        out, _ = self.attn(chunk_tensor, chunk_tensor, chunk_tensor)\n",
    "        return out\n",
    "\n",
    "class TapeHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-like block with progressive chunk sizes.\n",
    "    Each layer inside the TapeHead doubles the chunk size.\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len, embed_dim, vocab_size, num_layers=3, base_chunk=1, num_heads=2, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.base_chunk = base_chunk\n",
    "\n",
    "        # Create progressively larger TapeHeadBlocks for the left and right streams.\n",
    "        self.blocks_left = nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=base_chunk * (2 ** i),  # 1, 2, 4, 8, ...\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_heads=num_heads,\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.blocks_right = nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=base_chunk * (2 ** i),\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_heads=num_heads,\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.activation = ReferenceActivation()\n",
    "\n",
    "    def forward(self, x, prev_h, prev_emb, logits, past_kv=None):\n",
    "        \"\"\"\n",
    "        past_kv: dictionary with keys 'left' and 'right', each is a list of caches (one per block).\n",
    "        \"\"\"\n",
    "        if past_kv is None:\n",
    "            past_kv = {'left': [None] * self.num_layers, 'right': [None] * self.num_layers}\n",
    "\n",
    "        logits_left = logits.clone() if logits is not None else None\n",
    "        prev_emb_left = prev_emb.clone() if prev_emb is not None else None\n",
    "        prev_h_left = prev_h.clone() if prev_h is not None else None\n",
    "\n",
    "        new_past_left = []\n",
    "        new_past_right = []\n",
    "        for i in range(self.num_layers):\n",
    "            # Process left block with its cache.\n",
    "            _, h_out_left, layer_emb_left, logits_left, cache_left = self.blocks_left[i](\n",
    "                x, prev_h_left, prev_emb_left, logits_left, past_kv=past_kv['left'][i]\n",
    "            )\n",
    "            new_past_left.append(cache_left)\n",
    "            # Process right block with its cache.\n",
    "            _, h_out, layer_emb, logits, cache_right = self.blocks_right[i](\n",
    "                x, prev_h, prev_emb, logits, past_kv=past_kv['right'][i]\n",
    "            )\n",
    "            new_past_right.append(cache_right)\n",
    "\n",
    "            # Combine outputs from left and right streams.\n",
    "            a = self.activation(h_out_left)\n",
    "            b = self.activation(h_out)\n",
    "            h_out = 0.5 * (a + b - 2 * a * b)\n",
    "            h_out_left = h_out.clone()\n",
    "\n",
    "        # Combine logits and embeddings.\n",
    "        logits_out = 0.5 * (logits + logits_left - 2 * logits * logits_left)\n",
    "        layer_emb_out = 0.5 * (layer_emb + layer_emb_left - 2 * layer_emb * layer_emb_left)\n",
    "        new_cache = {'left': new_past_left, 'right': new_past_right}\n",
    "        return x, h_out, layer_emb_out, logits_out, new_cache\n",
    "\n",
    "           \n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / (x.norm(2, dim=-1, keepdim=True) + self.eps) * self.weight\n",
    "        \n",
    "class TapeTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Full GPT-like model with:\n",
    "      - Token + Position Embeddings\n",
    "      - Multiple stacked TapeHeads\n",
    "      - Final Student-t unembedding\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, seq_len=128, chunk_len=4, embed_dim=128, num_heads=2, num_layers=4, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.placeholder_idx = placeholder_idx\n",
    "\n",
    "        # LayerNorm immediately after embeddings.\n",
    "        self.embed_ln = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Create a list of TapeHeads.\n",
    "        self.tape_heads = nn.ModuleList([\n",
    "            TapeHead(\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_layers=math.ceil(math.log2(chunk_len)),\n",
    "                base_chunk=1,\n",
    "                num_heads=num_heads,\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.final_norm = RMSNorm(embed_dim)\n",
    "        self.logits_norm = nn.LayerNorm(embed_dim)\n",
    "        self.norm_gate = nn.Parameter(torch.tensor(0.5))  # for potential supervisory context\n",
    "\n",
    "        # Final unembedding.\n",
    "        self.final_ln = nn.LayerNorm(embed_dim)\n",
    "        self.logits_weight = nn.Parameter(torch.tensor(0.5))\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "        self.merge_projection = nn.Linear(len(self.tape_heads) * embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x, past_kv=None):\n",
    "        \"\"\"\n",
    "        x: (B, S) integer token IDs.\n",
    "        past_kv: list of caches (one per tape head) or None.\n",
    "        Returns:\n",
    "          p_final: (B, S, V) probability distribution,\n",
    "          new_past_kv: updated caches.\n",
    "        \"\"\"\n",
    "        # Ensure batch dimension.\n",
    "        x = x.unsqueeze(0) if x.ndim == 1 else x\n",
    "        B, S = x.shape\n",
    "        assert S <= self.seq_len, \"Sequence too long.\"\n",
    "\n",
    "        logits = None\n",
    "        prev_h = None\n",
    "        prev_emb = None\n",
    "\n",
    "        all_heads_h = []\n",
    "        new_past_heads = []\n",
    "        if past_kv is None:\n",
    "            past_kv = [None] * len(self.tape_heads)\n",
    "\n",
    "        # Process each TapeHead.\n",
    "        for i, head in enumerate(self.tape_heads):\n",
    "            x, h, prev_emb, logits, head_cache = head(x, prev_h, prev_emb, logits, past_kv=past_kv[i])\n",
    "            new_past_heads.append(head_cache)\n",
    "            all_heads_h.append(h[:, -S:, :])\n",
    "\n",
    "        # Merge outputs from all tape heads.\n",
    "        merged_h = torch.cat(all_heads_h, dim=-1)\n",
    "        prev_h = self.merge_projection(merged_h)  # (B, S, D)\n",
    "        # Final logits computed with student-t unembedding.\n",
    "        p_final = student_t_unembedding(prev_h, self.unembedding, df=2.718281828459, eps=1e-9, placeholder_idx=self.placeholder_idx)\n",
    "        return p_final, new_past_heads\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc,torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VhlsGaG7ONr",
    "outputId": "1534f894-6597-49b5-c0c3-41369844874c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder token for even vocab size: ▒ with index: 65\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Preparation (Shakespeare)\n",
    "# ====================================================\n",
    "def load_shakespeare_text():\n",
    "    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "    text = requests.get(url).text\n",
    "    return text\n",
    "\n",
    "text = load_shakespeare_text()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# Add a placeholder token: an ASCII grey block (visible in output)\n",
    "placeholder = \"▒\"  # Choose your preferred grey block character\n",
    "if placeholder not in chars:\n",
    "    chars.append(placeholder)\n",
    "    chars.sort()  # Ensure ordering is maintained\n",
    "\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "placeholder_idx = stoi[placeholder]\n",
    "print(\"Placeholder token for even vocab size:\", placeholder, \"with index:\", placeholder_idx)\n",
    "\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "def get_batch(batch_size, seq_len):\n",
    "    ix = torch.randint(0, data.size(0) - seq_len - 1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+seq_len] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+seq_len+1] for i in ix])\n",
    "    return x, y\n",
    "    \n",
    "\n",
    "# ====================================================\n",
    "# Training Setup\n",
    "# ====================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TapeTransformer(\n",
    "    vocab_size=vocab_size,  # example\n",
    "    seq_len=256,\n",
    "    chunk_len=4,\n",
    "    embed_dim=256,#heads times true vocab, round up \n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    placeholder_idx=placeholder_idx,\n",
    "    dropout=0 #cannot use dropout, tooo slow\n",
    ").to(device)\n",
    "\n",
    "optimizer = Wolf(model.parameters(), lr=0.3678)\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "seq_len = 256 #from karapathy\n",
    "eps = 1e-8\n",
    "\n",
    "loss_history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = 'model_dict.pth'\n",
    "\n",
    "# Save the model's state_dict\n",
    "dict = torch.load(save_path)\n",
    "model.load_state_dict(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2992829841302609"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(math.log(vocab_size/(2+16)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=6e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20326914"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []  # Store all losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# Training control variables\n",
    "seq_len = 2  # Start with the smallest sequence\n",
    "max_seq_len = 256\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# Loss tracking\n",
    "epochs_per_check = 10  # Print every 10 epochs\n",
    "target_loss = max(math.log(vocab_size/(seq_len+1)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.483335494995117 2\n",
      "11.320371627807617 2\n",
      "10.451446533203125 2\n",
      "13.843503952026367 2\n",
      "10.742172241210938 2\n",
      "8.94825267791748 2\n",
      "10.8133544921875 2\n",
      "9.69158935546875 2\n",
      "10.55412483215332 2\n",
      "13.074121475219727 2\n",
      "12.462520599365234 2\n",
      "7.824421405792236 2\n",
      "10.350739479064941 2\n",
      "11.006298065185547 2\n",
      "12.290119171142578 2\n",
      "8.1551513671875 2\n",
      "7.993145942687988 2\n",
      "7.512421607971191 2\n",
      "7.129324913024902 2\n",
      "9.879904747009277 2\n",
      "4.9785475730896 2\n",
      "6.312690734863281 2\n",
      "6.35555362701416 2\n",
      "3.7879586219787598 2\n",
      "5.312523365020752 2\n",
      "5.554840564727783 2\n",
      "5.8860578536987305 2\n",
      "4.857933044433594 2\n",
      "5.649398326873779 2\n",
      "3.378875732421875 2\n",
      "4.650249004364014 2\n",
      "3.57426118850708 2\n",
      "4.654754161834717 2\n",
      "4.960973262786865 2\n",
      "5.909459590911865 2\n",
      "3.9191431999206543 2\n",
      "2.5739669799804688 2\n",
      "2.4286623001098633 2\n",
      "3.3713104724884033 2\n",
      "2.444793701171875 2\n",
      "2.7574691772460938 2\n",
      "2.4785022735595703 2\n",
      "2.62927508354187 2\n",
      "3.146228313446045 2\n",
      "3.3639960289001465 2\n",
      "3.558739423751831 2\n",
      "3.0618090629577637 2\n",
      "2.4438867568969727 2\n",
      "2.0165531635284424 2\n",
      "2.166987419128418 2\n",
      "1.950681447982788 2\n",
      "2.181675434112549 2\n",
      "2.643824815750122 2\n",
      "2.526888847351074 2\n",
      "3.1951475143432617 2\n",
      "2.36287260055542 2\n",
      "3.2838358879089355 2\n",
      "2.519073963165283 2\n",
      "1.9504611492156982 2\n",
      "1.7330070734024048 2\n",
      "2.8340988159179688 2\n",
      "2.8561062812805176 2\n",
      "2.04072904586792 2\n",
      "2.0219690799713135 2\n",
      "2.0169851779937744 2\n",
      "2.453307867050171 2\n",
      "2.144455909729004 2\n",
      "1.9402803182601929 2\n",
      "1.9936844110488892 2\n",
      "2.155184507369995 2\n",
      "1.6043949127197266 2\n",
      "2.2294867038726807 2\n",
      "1.9054129123687744 2\n",
      "1.8321924209594727 2\n",
      "2.433697462081909 2\n",
      "1.8857364654541016 2\n",
      "2.123725175857544 2\n",
      "1.9690582752227783 2\n",
      "1.5515692234039307 2\n",
      "2.2042503356933594 2\n",
      "2.1370372772216797 2\n",
      "2.5172855854034424 2\n",
      "2.2476279735565186 2\n",
      "2.256242275238037 2\n",
      "1.6737204790115356 2\n",
      "2.3696486949920654 2\n",
      "1.8246879577636719 2\n",
      "2.4417223930358887 2\n",
      "1.5267924070358276 2\n",
      "2.2177255153656006 2\n",
      "2.284843683242798 2\n",
      "1.951062798500061 2\n",
      "1.743556261062622 2\n",
      "1.9728431701660156 2\n",
      "1.8786414861679077 2\n",
      "1.9312388896942139 2\n",
      "2.0651755332946777 2\n",
      "1.8596570491790771 2\n",
      "1.894334077835083 2\n",
      "1.8104963302612305 2\n",
      "2.0217270851135254 2\n",
      "1.6022157669067383 2\n",
      "2.087007999420166 2\n",
      "2.097403049468994 2\n",
      "1.3857543468475342 2\n",
      "1.9807993173599243 2\n",
      "1.7270698547363281 2\n",
      "2.3131327629089355 2\n",
      "1.4413152933120728 2\n",
      "1.4616711139678955 2\n",
      "1.5885257720947266 2\n",
      "2.085476875305176 2\n",
      "1.5603231191635132 2\n",
      "1.5170663595199585 2\n",
      "1.396979570388794 2\n",
      "1.3609000444412231 2\n",
      "1.566872239112854 2\n",
      "1.9929627180099487 2\n",
      "1.3449116945266724 2\n",
      "1.7116364240646362 2\n",
      "1.7844818830490112 2\n",
      "1.9779549837112427 2\n",
      "1.6462898254394531 2\n",
      "1.4259718656539917 2\n",
      "1.7306413650512695 2\n",
      "1.5364543199539185 2\n",
      "1.973015546798706 2\n",
      "1.7649562358856201 2\n",
      "1.338042974472046 2\n",
      "2.170123338699341 2\n",
      "1.8083398342132568 2\n",
      "2.050060272216797 2\n",
      "1.8055471181869507 2\n",
      "1.5627059936523438 2\n",
      "1.6353106498718262 2\n",
      "1.806017518043518 2\n",
      "1.5409352779388428 2\n",
      "1.5784823894500732 2\n",
      "1.530985951423645 2\n",
      "1.3694829940795898 2\n",
      "1.715728998184204 2\n",
      "1.6206510066986084 2\n",
      "1.4210693836212158 2\n",
      "1.7468228340148926 2\n",
      "1.5169219970703125 2\n",
      "1.2813258171081543 2\n",
      "2.7180838584899902 2\n",
      "1.866385817527771 2\n",
      "1.6581668853759766 2\n",
      "1.6212143898010254 2\n",
      "1.396362543106079 2\n",
      "1.6545321941375732 2\n",
      "1.2640459537506104 2\n",
      "1.3106067180633545 2\n",
      "1.5295264720916748 2\n",
      "1.8656036853790283 2\n",
      "1.6292872428894043 2\n",
      "1.803065538406372 2\n",
      "1.4464411735534668 2\n",
      "1.641014814376831 2\n",
      "1.636171817779541 2\n",
      "1.6241328716278076 2\n",
      "1.713324785232544 2\n",
      "1.6027941703796387 2\n",
      "1.471579670906067 2\n",
      "1.3949379920959473 2\n",
      "1.1842955350875854 2\n",
      "1.31949782371521 2\n",
      "1.2704123258590698 2\n",
      "1.7201979160308838 2\n",
      "1.9015451669692993 2\n",
      "1.7217519283294678 2\n",
      "1.9877949953079224 2\n",
      "1.6285486221313477 2\n",
      "1.8552896976470947 2\n",
      "2.0364737510681152 2\n",
      "1.9865198135375977 2\n",
      "1.723739504814148 2\n",
      "1.9629368782043457 2\n",
      "1.7833726406097412 2\n",
      "1.5029499530792236 2\n",
      "1.761188268661499 2\n",
      "1.3667614459991455 2\n",
      "1.3546736240386963 2\n",
      "2.0269980430603027 2\n",
      "1.8543223142623901 2\n",
      "1.5778104066848755 2\n",
      "1.2770159244537354 2\n",
      "1.2954391241073608 2\n",
      "1.4870895147323608 2\n",
      "1.3512358665466309 2\n",
      "1.5150593519210815 2\n",
      "1.51192307472229 2\n",
      "1.8604941368103027 2\n",
      "1.3125700950622559 2\n",
      "1.230515718460083 2\n",
      "1.9306285381317139 2\n",
      "1.7675666809082031 2\n",
      "1.602055311203003 2\n",
      "1.6921207904815674 2\n",
      "1.9110897779464722 2\n",
      "1.5881798267364502 2\n",
      "1.5012941360473633 2\n",
      "1.5515472888946533 2\n",
      "1.3316704034805298 2\n",
      "1.4556517601013184 2\n",
      "1.3384134769439697 2\n",
      "1.3821886777877808 2\n",
      "1.2851755619049072 2\n",
      "1.337587594985962 2\n",
      "1.2779887914657593 2\n",
      "1.317171335220337 2\n",
      "1.209707498550415 2\n",
      "1.1119472980499268 2\n",
      "1.981872797012329 2\n",
      "1.2110607624053955 2\n",
      "1.3165671825408936 2\n",
      "1.355311393737793 2\n",
      "1.5263705253601074 2\n",
      "1.191119909286499 2\n",
      "1.3607327938079834 2\n",
      "1.848064661026001 2\n",
      "1.5187886953353882 2\n",
      "1.906097650527954 2\n",
      "1.186758279800415 2\n",
      "1.6534937620162964 2\n",
      "1.4894407987594604 2\n",
      "1.6279497146606445 2\n",
      "1.7299134731292725 2\n",
      "1.2817940711975098 2\n",
      "1.1067256927490234 2\n",
      "1.6206309795379639 2\n",
      "1.474475622177124 2\n",
      "1.0949383974075317 2\n",
      "1.3676685094833374 2\n",
      "1.8247480392456055 2\n",
      "1.1969605684280396 2\n",
      "1.455299973487854 2\n",
      "1.158080816268921 2\n",
      "1.9308475255966187 2\n",
      "1.0705486536026 2\n",
      "1.3315825462341309 2\n",
      "1.5372064113616943 2\n",
      "1.8770560026168823 2\n",
      "1.9623785018920898 2\n",
      "1.2999999523162842 2\n",
      "1.4306546449661255 2\n",
      "1.186822772026062 2\n",
      "1.3565188646316528 2\n",
      "1.126917839050293 2\n",
      "1.63719642162323 2\n",
      "1.4407554864883423 2\n",
      "1.5232863426208496 2\n",
      "1.6395950317382812 2\n",
      "1.0804094076156616 2\n",
      "1.2183232307434082 2\n",
      "1.1598963737487793 2\n",
      "1.5603322982788086 2\n",
      "1.414841890335083 2\n",
      "1.4754751920700073 2\n",
      "1.7595479488372803 2\n",
      "1.6254003047943115 2\n",
      "2.180899143218994 2\n",
      "1.339904546737671 2\n",
      "1.3549538850784302 2\n",
      "1.672011137008667 2\n",
      "1.1879007816314697 2\n",
      "1.218980312347412 2\n",
      "1.7352395057678223 2\n",
      "1.3477587699890137 2\n",
      "1.6428872346878052 2\n",
      "1.2874360084533691 2\n",
      "1.428484320640564 2\n",
      "1.4803516864776611 2\n",
      "1.8285590410232544 2\n",
      "1.5061671733856201 2\n",
      "1.4163079261779785 2\n",
      "2.228938341140747 2\n",
      "1.6052234172821045 2\n",
      "1.6716995239257812 2\n",
      "1.7241246700286865 2\n",
      "3.614741802215576 2\n",
      "1.0302302837371826 2\n",
      "1.755455732345581 2\n",
      "1.83797025680542 2\n",
      "1.5608558654785156 2\n",
      "1.1410720348358154 2\n",
      "1.6844615936279297 2\n",
      "1.652017593383789 2\n",
      "1.4608560800552368 2\n",
      "1.2777200937271118 2\n",
      "1.6378204822540283 2\n",
      "1.360756516456604 2\n",
      "1.2037055492401123 2\n",
      "1.4517085552215576 2\n",
      "1.4263811111450195 2\n",
      "1.4375646114349365 2\n",
      "1.4843472242355347 2\n",
      "1.6041239500045776 2\n",
      "1.5079104900360107 2\n",
      "1.4930698871612549 2\n",
      "1.535479187965393 2\n",
      "1.6969237327575684 2\n",
      "1.844202995300293 2\n",
      "1.6394160985946655 2\n",
      "1.1042274236679077 2\n",
      "2.108394145965576 2\n",
      "1.7516262531280518 2\n",
      "1.3649451732635498 2\n",
      "1.6020214557647705 2\n",
      "1.6972291469573975 2\n",
      "1.4540226459503174 2\n",
      "1.2795979976654053 2\n",
      "1.403793215751648 2\n",
      "0.9036067724227905 2\n",
      "1.1606361865997314 2\n",
      "1.5879788398742676 2\n",
      "1.6837420463562012 2\n",
      "1.567415714263916 2\n",
      "1.6321794986724854 2\n",
      "1.298155426979065 2\n",
      "1.8932008743286133 2\n",
      "1.2037451267242432 2\n",
      "0.9863855838775635 2\n",
      "1.5312596559524536 2\n",
      "1.238224983215332 2\n",
      "1.3542392253875732 2\n",
      "1.445923089981079 2\n",
      "2.204493522644043 2\n",
      "1.448761224746704 2\n",
      "1.2782347202301025 2\n",
      "1.4805443286895752 2\n",
      "1.5500459671020508 2\n",
      "1.4785642623901367 2\n",
      "1.2929977178573608 2\n",
      "1.3840397596359253 2\n",
      "1.2027279138565063 2\n",
      "1.53339684009552 2\n",
      "1.351433277130127 2\n",
      "1.9132815599441528 2\n",
      "1.5471223592758179 2\n",
      "1.441329002380371 2\n",
      "1.324138879776001 2\n",
      "1.3202532529830933 2\n",
      "1.4433093070983887 2\n",
      "1.8632004261016846 2\n",
      "1.3983359336853027 2\n",
      "1.3692176342010498 2\n",
      "1.2487515211105347 2\n",
      "1.2781877517700195 2\n",
      "1.0597383975982666 2\n",
      "1.3527865409851074 2\n",
      "1.7902733087539673 2\n",
      "1.6066007614135742 2\n",
      "1.0833096504211426 2\n",
      "1.1885743141174316 2\n",
      "1.1256346702575684 2\n",
      "1.4784016609191895 2\n",
      "1.4971977472305298 2\n",
      "1.4773203134536743 2\n",
      "1.1449122428894043 2\n",
      "1.5422484874725342 2\n",
      "1.679049015045166 2\n",
      "1.5151939392089844 2\n",
      "1.2075649499893188 2\n",
      "1.1996853351593018 2\n",
      "1.309425950050354 2\n",
      "1.6012272834777832 2\n",
      "1.2996928691864014 2\n",
      "2.0562644004821777 2\n",
      "1.517444372177124 2\n",
      "1.024402379989624 2\n",
      "1.6067378520965576 2\n",
      "1.384626865386963 2\n",
      "1.254234790802002 2\n",
      "1.2945256233215332 2\n",
      "1.4416441917419434 2\n",
      "1.2219176292419434 2\n",
      "1.4673874378204346 2\n",
      "1.5015127658843994 2\n",
      "1.388787031173706 2\n",
      "1.765693187713623 2\n",
      "1.3249843120574951 2\n",
      "1.3909871578216553 2\n",
      "1.2750447988510132 2\n",
      "1.6358160972595215 2\n",
      "1.6977033615112305 2\n",
      "1.3396047353744507 2\n",
      "1.3414548635482788 2\n",
      "1.4492154121398926 2\n",
      "1.5114812850952148 2\n",
      "1.4254881143569946 2\n",
      "1.4293427467346191 2\n",
      "2.0114569664001465 2\n",
      "1.5734130144119263 2\n",
      "1.7573416233062744 2\n",
      "1.6586875915527344 2\n",
      "1.1104557514190674 2\n",
      "1.7104295492172241 2\n",
      "1.5067325830459595 2\n",
      "1.522872805595398 2\n",
      "1.334996223449707 2\n",
      "1.2697014808654785 2\n",
      "1.4686108827590942 2\n",
      "1.4094911813735962 2\n",
      "1.276728868484497 2\n",
      "1.4098739624023438 2\n",
      "1.8022586107254028 2\n",
      "1.477985143661499 2\n",
      "1.5725980997085571 2\n",
      "1.2393221855163574 2\n",
      "1.192655086517334 2\n",
      "1.170925498008728 2\n",
      "1.558424711227417 2\n",
      "1.4014031887054443 2\n",
      "1.3613760471343994 2\n"
     ]
    }
   ],
   "source": [
    "while seq_len <= max_seq_len:\n",
    "    total_loss = 0.0\n",
    "    step_count = 0\n",
    "\n",
    "    # Training loop for current sequence length\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        x_batch, targets = get_batch(batch_size, seq_len)\n",
    "        x_batch, targets = x_batch.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            preds,_ = model(x_batch)\n",
    "            gathered_probs = torch.gather(preds, -1, targets.unsqueeze(-1)).squeeze(-1)\n",
    "            base_loss = -torch.log(gathered_probs + 1e-16)\n",
    "            final_loss = base_loss.mean()\n",
    "\n",
    "        scaler.scale(final_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Track loss & progress\n",
    "        loss_val = final_loss.item()\n",
    "        loss_history.append(loss_val)\n",
    "        total_loss += loss_val\n",
    "        step_count += 1\n",
    "        print(loss_val,seq_len)\n",
    "    seq_len += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19022082"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000000):\n",
    "        model.train()\n",
    "        x_batch, targets = get_batch(batch_size, 256)\n",
    "        x_batch, targets = x_batch.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            preds = model(x_batch)\n",
    "            gathered_probs = torch.gather(preds, -1, targets.unsqueeze(-1)).squeeze(-1)\n",
    "            base_loss = -torch.log(gathered_probs + 1e-16)\n",
    "            final_loss = base_loss.mean()\n",
    "\n",
    "        scaler.scale(final_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Track loss & progress\n",
    "        loss_val = final_loss.item()\n",
    "        loss_history.append(loss_val)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sample:\n",
      " oh Romeo! Romeo!Abbb$e$$$H$H$$'e:$$Q::$ee:::e::▒$:e:UU:▒▒eedUdUdU:dUUUUeUU▒edd$▒▒ggggggdVdUdVdVgTTgdTdVgddgggggddTjdVgVVgggggddaVddddddVQajaVddaVtVVTTjaVaVjjddlTTadTaVVaTVQQQVTTQdVQjQdTVQQ$VQd NVVVjNVQ VV: VQ QVU VV \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "past_kv = None  # Initialize cache for the entire model.\n",
    "with torch.no_grad():\n",
    "    prompt = \"oh Romeo! Romeo!\"\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    generated = context\n",
    "    for _ in range(200):  # Generate 200 tokens.\n",
    "        inp = generated[:, -1:]  # Only use the last token.\n",
    "        p, past_kv = model(inp, past_kv=past_kv)  # Forward pass with cache.\n",
    "        last_token_probs = p[:, -1, :]\n",
    "        predicted_token = torch.multinomial(last_token_probs, num_samples=1)\n",
    "        generated = torch.cat((generated, predicted_token), dim=1)\n",
    "    sample = decode(generated[0].cpu().tolist())\n",
    "    print(\"Generated Sample:\\n\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'model_dict.pth'\n",
    "\n",
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"full_model_structure_216_225.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Wolf(model.parameters(), lr=0.3678)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29194de38e0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sample:\n",
      " oh Romeo! Romeo! Xhnoos RGh paad cnnqr\n",
      "\n",
      "Gce; tr otoitole&\n",
      "\n",
      "GURI eR! nrend oK jGbshege n; rr t T sthnh  e Paat ait g h ne et Nap n RIhoho Cy jusIpaniLUjfoim\n",
      "Ib  rrt npato nd.\n",
      "I \n",
      "\n",
      "\n",
      "I PTRUG.\n",
      "Ishdgr bre haS oberiotnvelt \n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluation: Text Generation\n",
    "# ====================================================\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prompt = \"oh Romeo! Romeo!\"\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    generated = context\n",
    "    for _ in range(200):  # Generate 200 tokens.\n",
    "        inp = generated[:, -seq_len:]\n",
    "        p = model(inp)  # p: (B, seq, vocab_size)\n",
    "        last_token_probs = p[:, -1, :]  # Shape: [batch_size, vocab_size]\n",
    "        predicted_token = torch.multinomial(last_token_probs, num_samples=1)\n",
    "\n",
    "        #next_token = torch.multinomial(last_token_probs, num_samples=1)\n",
    "        generated = torch.cat((generated, predicted_token), dim=1)\n",
    "    sample = decode(generated[0].cpu().tolist())\n",
    "    print(\"Generated Sample:\\n\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
