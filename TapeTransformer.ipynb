{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPYRIGHT NOTICE\n",
    "In the name of Christ our Lord be blessed. We, Joshuah Rainstar(joshuah.rainstar@gmail.com), do claim copyright to this code, or software, and associated documentation, as our work in the year 2025 Anno Domini, reserving all rights and assigning them in accordance with the following license terms:\n",
    "\n",
    "1. Permission is by our authority and with this statement granted, to any person or artificial intelligence without limitation or restriction to examine, analyze, read, dissect, translate, use, modify, and distribute the aforementioned copyrighted items, subject to the following conditions:\n",
    "2. This license must be included in full with any copies or works containing substantial portions of the copyrighted items.\n",
    "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "\n",
    "THE COPYRIGHTED ITEMS ARE PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE COPYRIGHTED ITEMS OR THEIR USE OR ANY OTHER CIRCUMSTANCES CONCERNING THEM.\n"
   ]
  },
  {
   "attachments": {
    "28374c77-74dc-463c-984c-f518ca74a4cd.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is an experimental model intended to elucidate possible mechanics for attention across sequences in addition to tokenwise. it is reasonably fast and efficient. conceptually, the design was envisioned by me and coded through refinement with OpenAI Codex Orion One and chatgpt\n",
    "\n",
    "\"hierarchical multi-scale transformer with MoE-like sparse selection\"\n",
    "\n",
    "SelfScalableTanh from  Self-scalable Tanh (Stan): Faster Convergence and Better Generalization in Physics-informed Neural Networks\r\n",
    "https://arxiv.org/abs/2204.1258\n",
    "Motivation: my gut said its a good idea. Impact: little bit faster convergence even in gpt9\n",
    "harmonic loss from  Harmonic Loss Trains Interpretable AI Models\r\n",
    "https://arxiv.org/abs/2502.01628note that I do the math in log space to avoid explosions\n",
    "note that harmonic loss has been swapped for a student's t distribution to avoid NaN collapses near zero\n",
    "motivation: interpretable model. Impact: speeds up convergence even more than harmonic!\n",
    "\n",
    "XOR from  Two-argument activation functions learn soft XOR operations like cortical neurons\r\n",
    "https://arxiv.org/abs/2110.06871note that my implementation is a differential XOR for backprop capability\n",
    "motivation: little bit of internal reasoning maybe? Impact: slows down convergence somewhat\n",
    "\n",
    "WOLF optimizer experimental by me, it may not beat adam but it is simpler than adam, closer to SGD with some smoothing of integration\n",
    "impact: speeds up convergence somewhat for early iterations and will not NAN from high LR.\n",
    "probable benefit- switch optimizers after model drops. could be good for bigger models.. maybe\n",
    "\n",
    "![image.png](attachment:28374c77-74dc-463c-984c-f518ca74a4cd.png)\n",
    "m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jcJTMiWT89P5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dl9uYIM16MG4"
   },
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "class Wolf(Optimizer):\n",
    "    \"\"\"Implements Wolf algorithm.\"\"\"\n",
    "    def __init__(self, params, lr=0.25, betas=(0.9, 0.999), eps=1e-8):\n",
    "        # Define default parameters\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps)\n",
    "        self.lr = lr\n",
    "        # Initialize the parent Optimizer class first\n",
    "        super().__init__(params, defaults)\n",
    "        # Constants specific to Wolf\n",
    "        # Initialize state for each parameter\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['p'] = torch.zeros_like(p)  # Second moment estimate\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step and adjusts dropout in transformer blocks.\"\"\"\n",
    "        etcerta = 0.367879441  # Constant used in update rule\n",
    "        et = 1 - etcerta\n",
    "    \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "    \n",
    "        # Iterate over parameter groups.\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                grad = p.grad\n",
    "    \n",
    "                #  AMP Compatibility: Check for NaN or Inf in gradients\n",
    "                if torch.isnan(grad).any() or torch.isinf(grad).any():\n",
    "                    print(\"Skipping parameter update due to NaN/Inf gradient.\")\n",
    "                    continue  # Skip this update if the gradient has NaN or Inf\n",
    "    \n",
    "                state = self.state[p]\n",
    "                exp_avg = state['p']\n",
    "    \n",
    "                # Compute update and update second moment-like state.\n",
    "                update = exp_avg * et + grad * etcerta\n",
    "                state['p'] = exp_avg * et + update * etcerta\n",
    "    \n",
    "                # Compute sign agreement between update and gradient.\n",
    "                sign_agreement = torch.sign(update) * torch.sign(grad)\n",
    "    \n",
    "                # Where the signs agree (mask is True), update the parameter.\n",
    "                mask = (sign_agreement > 0)\n",
    "                adaptive_alpha = group.get('lr', self.lr)\n",
    "                p.data = torch.where(mask, p.data - adaptive_alpha * update, p.data)\n",
    "    \n",
    "                # AMP Compatibility: Ensure a step counter is updated\n",
    "                state['step'] = state.get('step', 0) + 1  # Track optimization steps\n",
    "    \n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "def modified_student_t_loss(preds, targets, placeholder_idx, df=2.718, eps=1e-9):\n",
    "    \"\"\"Apply modified student_t loss where placeholders are demoted when incorrect.\"\"\"\n",
    "    dist_sq = torch.sum((preds - targets) ** 2, dim=-1).clamp(min=eps)\n",
    "    log_p_unnorm = -0.5 * (df + preds.shape[-1]) * torch.log1p(dist_sq / df)\n",
    "    log_p = F.log_softmax(log_p_unnorm, dim=-1)\n",
    "    p = log_p.exp()\n",
    "    \n",
    "    # Placeholder demotion\n",
    "    is_placeholder = (targets == placeholder_idx)\n",
    "    p = torch.where(is_placeholder, p * (1 - 1/math.e), p)  # Reduce probability of placeholders\n",
    "    return p\n",
    "    \n",
    "def student_t_unembedding(hidden_states, unembedding, df=2.718281828459, eps=1e-9, placeholder_idx=None):\n",
    "    \"\"\"\n",
    "    Student's t-based unembedding with optional placeholder modification.\n",
    "    \n",
    "    Arguments:\n",
    "      hidden_states: (B, S, D)  => model’s output embeddings (hidden state)\n",
    "      unembedding:   (D, V)    => learnable \"word vectors\" (unembedding matrix)\n",
    "      df (float): degrees of freedom for the Student's t distribution\n",
    "      eps (float): numerical epsilon to avoid log(0) and div-by-zero\n",
    "      placeholder_idx (int, optional): if provided, indicates the column in the unembedding\n",
    "          corresponding to the placeholder token. The distances for that token will be adjusted \n",
    "          using an adaptive noise factor.\n",
    "    \n",
    "    Returns:\n",
    "      p: (B, S, V)  probability distribution over V vocabulary tokens.\n",
    "    \"\"\"\n",
    "    B, S, D = hidden_states.shape\n",
    "    V = unembedding.shape[1]\n",
    "\n",
    "    # Expand hidden => (B, S, 1, D)\n",
    "    x_expanded = hidden_states.unsqueeze(2)\n",
    "    # Expand unembedding => (1, 1, V, D)\n",
    "    w_expanded = unembedding.t().unsqueeze(0).unsqueeze(0)  # shape: (1, 1, V, D)\n",
    "    \n",
    "    # Compute squared Euclidean distance between each hidden vector and each unembedding vector.\n",
    "    dist_sq = torch.sum((x_expanded - w_expanded) ** 2, dim=-1).clamp(min=1e-6)  # (B, S, V)\n",
    "    \n",
    "    # If a placeholder index is provided, adjust the distance for that token.\n",
    "    if placeholder_idx is not None:\n",
    "        # Create a mask with True at positions corresponding to the placeholder token.\n",
    "        placeholder_mask = torch.zeros_like(dist_sq, dtype=torch.bool)\n",
    "        placeholder_mask[..., placeholder_idx] = True\n",
    "\n",
    "        # Compute the 1/e-th percentile (roughly the 36.8th percentile) over all distances.\n",
    "        #percentile = 1- (1.0 / math.e) \n",
    "        #threshold = torch.quantile(dist_sq.flatten(), percentile)\n",
    "        t2= torch.quantile(dist_sq.flatten(), (1.0 / math.e))\n",
    "\n",
    "\n",
    "        # Create a noise factor scaled by the computed threshold.\n",
    "        noise_factor = torch.randn_like(dist_sq) * 1.0\n",
    "        noise_factor -= t2\n",
    "\n",
    "        #allows probability of placeholder to wander, so model is randomly encouraged\n",
    "        #to try it or avoid it, thus ensuring it will be tried, but, it will also\n",
    "        #be desired to be avoided. the model will wander from -36% to positive 68%\n",
    "        #thus, it will be twice as likely to be recommended it as not, \n",
    "        #but the median is less than 50%, meaning that,\n",
    "        #sometimes it is recommended highly, but rarely.\n",
    "        dist_sq = torch.where(placeholder_mask, dist_sq - noise_factor, dist_sq)\n",
    "    \n",
    "    # Compute the negative energy:\n",
    "    #    E = 0.5*(df + D) * log(1 + dist_sq / df)\n",
    "    # and so log probability (up to an additive constant) is:\n",
    "    #    log_p = -E\n",
    "    log_p_unnorm = -0.5 * (df + D) * torch.log1p(dist_sq / df)  # (B, S, V)\n",
    "    \n",
    "    # Normalize via log_softmax over the vocabulary dimension.\n",
    "    log_p = F.log_softmax(log_p_unnorm, dim=-1)  # (B, S, V)\n",
    "    p = log_p.exp()\n",
    "    return p\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Custom Activation\n",
    "# ---------------------------------------------------\n",
    "class SelfScalableTanh(nn.Module):\n",
    "    def __init__(self, init_scale=0.1, max_scale=0.12):\n",
    "        super().__init__()\n",
    "        # Learned scale parameter\n",
    "        self.scale = nn.Parameter(torch.tensor(init_scale, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # \"Scaled Tanh\"\n",
    "        scale = torch.clamp(self.scale,0.0,1.0)#prevent NaN collapse\n",
    "        return torch.tanh(x) + scale * torch.tanh(x)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Differentiable XOR\n",
    "# ---------------------------------------------------\n",
    "class DifferentiableXORLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Splits the incoming embedding in half, and does a\n",
    "    sigmoid-based XOR-like transformation.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        assert embed_dim % 2 == 0, \"embed_dim must be even for XOR.\"\n",
    "        self.embed_dim = embed_dim\n",
    "        self.proj = nn.Linear(embed_dim // 2, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        d = self.embed_dim // 2\n",
    "        x1, x2 = x[..., :d], x[..., d:]\n",
    "        a = torch.sigmoid(x1)\n",
    "        b = torch.sigmoid(x2)\n",
    "        # approximate XOR = a + b - 2ab\n",
    "        xor_out = 0.5 * (a + b - 2 * a * b)  # scaled by 0.5\n",
    "        out = self.proj(xor_out)\n",
    "        return out\n",
    "        \n",
    "class DifferentiableXORLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies a differentiable XOR transformation to the residual logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        assert vocab_size % 2 == 0, \"Vocab size must be even for XOR.\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.proj = nn.Linear(vocab_size // 2, vocab_size)  # Ensures mapping stays consistent\n",
    "\n",
    "    def forward(self, logits):\n",
    "        \"\"\"\n",
    "        logits: (B, S, V) residual logits evolving through layers.\n",
    "\n",
    "        Returns:\n",
    "          refined_logits: (B, S, V) with XOR-like transformation.\n",
    "        \"\"\"\n",
    "        d = self.vocab_size // 2\n",
    "        logits_1, logits_2 = logits[..., :d], logits[..., d:]\n",
    "\n",
    "        a = torch.sigmoid(logits_1)\n",
    "        b = torch.sigmoid(logits_2)\n",
    "\n",
    "        # Approximate XOR for probability space\n",
    "        xor_logits = 0.5 * (a + b - 2 * a * b)  # Differentiable XOR\n",
    "        refined_logits = self.proj(xor_logits)  # Learnable projection\n",
    "\n",
    "        return refined_logits\n",
    "\n",
    "\n",
    "class TapeHeadBlock(nn.Module):\n",
    "    def __init__(self, chunk_size, embed_dim,vocab_size, num_heads=1, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.chunk_size = chunk_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Chunk-based attention\n",
    "        self.chunk_proj = nn.Linear(chunk_size * embed_dim, embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln_attn = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),\n",
    "            SelfScalableTanh(),\n",
    "            nn.Linear(4 * embed_dim, embed_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.ln_mlp = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Unembedding for this block\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "\n",
    "        # **Logits Attention Layer**: Learns to selectively use past logits\n",
    "        self.logits_attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.placeholder_idx = placeholder_idx\n",
    "    def forward(self, x, h, logits):\n",
    "        \"\"\"\n",
    "        x:      (B, S, D) original input\n",
    "        h:      (B, S, D) current hidden state\n",
    "        logits: (B, S, V) probability distribution from previous block\n",
    "\n",
    "        Returns:\n",
    "          x: same input\n",
    "          h: updated hidden state\n",
    "          logits: refined probability distribution\n",
    "        \"\"\"\n",
    "        # 1) Chunk-based attention\n",
    "        attn_out = self._chunk_attention(h)  # (B, S, D)\n",
    "        h_attn = self.ln_attn(h + attn_out)  # residual + LN\n",
    "\n",
    "        # 2) Convert logits into an embedding (if logits exist)\n",
    "        if logits is not None:\n",
    "            vocab_embedding = torch.matmul(logits, self.unembedding.T)  # (B, S, D)\n",
    "\n",
    "            # **Learnable Cross-Attention Over Logits**\n",
    "            query = h_attn\n",
    "            key = vocab_embedding\n",
    "            value = vocab_embedding\n",
    "            logits_context, _ = self.logits_attention(query, key, value)\n",
    "\n",
    "            # Merge the logits-based signal into h\n",
    "            h_attn = h_attn + logits_context  # Now it's conditioned on past logits\n",
    "\n",
    "        # 3) MLP processing\n",
    "        h_mlp = self.ln_mlp(h_attn + self.mlp(h_attn))\n",
    "\n",
    "        # 4) Compute new logits\n",
    "        logits = student_t_unembedding(h_mlp, self.unembedding,placeholder_idx=self.placeholder_idx)\n",
    "\n",
    "        return x, h_mlp, logits  # Pass refined logits forward\n",
    "\n",
    "\n",
    "    def _chunk_attention(self, h):\n",
    "        \"\"\" Chunk-based self-attention \"\"\"\n",
    "        B, S, D = h.shape\n",
    "        c = self.chunk_size\n",
    "\n",
    "        # Move feature dim before sequence (B, D, S)\n",
    "        x_3d = h.permute(0, 2, 1)\n",
    "\n",
    "        # Right-pad so we can slide windows of size c up to the last token\n",
    "        x_3d_padded = F.pad(x_3d, (0, c - 1))\n",
    "\n",
    "        # Unfold => (B, D*c, S)\n",
    "        unfolded = F.unfold(x_3d_padded.unsqueeze(-1), kernel_size=(c, 1), stride=(1, 1))\n",
    "        unfolded = unfolded.transpose(1, 2)  # => (B, S, D*c)\n",
    "\n",
    "        # Project => (B, S, D)\n",
    "        chunk_tensor = self.chunk_proj(unfolded)\n",
    "\n",
    "        # Self-attention\n",
    "        out, _ = self.attn(chunk_tensor, chunk_tensor, chunk_tensor)\n",
    "        return out\n",
    "\n",
    "class TapeHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-like block with progressive chunk sizes.\n",
    "    Each layer inside the TapeHead doubles the chunk size.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, vocab_size, num_layers=3, base_chunk=1, num_heads=2, placeholder_idx=None,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.base_chunk = base_chunk\n",
    "\n",
    "        # Create progressively larger TapeHeadBlocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=base_chunk * (2 ** i),  # 1, 2, 4, 8, ...\n",
    "                embed_dim=embed_dim,vocab_size=vocab_size,\n",
    "                num_heads=num_heads,placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, h,logits):\n",
    "        \"\"\"\n",
    "        x: (B, S, D) original input\n",
    "        h: (B, S, D) hidden state\n",
    "\n",
    "        Returns:\n",
    "          x: original input (unchanged)\n",
    "          h: final refined hidden state\n",
    "        \"\"\"\n",
    "        for block in self.blocks:\n",
    "            x, h, logits = block(x, h, logits)  # Process each block progressively\n",
    "        return x, h ,logits \n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / (x.norm(2, dim=-1, keepdim=True) + self.eps) * self.weight\n",
    "        \n",
    "class TapeTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Full GPT-like model with:\n",
    "      - Token + Position Embeddings\n",
    "      - Multiple stacked TapeHeads\n",
    "      - XOR applied to each TapeHead output\n",
    "      - Final Student-t unembedding\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, seq_len=128,chunk_len=4, embed_dim=128, num_heads=2, num_layers=4, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Token & Positional Embeddings\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, seq_len, embed_dim))\n",
    "        num_chunk_layers = math.ceil(math.log2(chunk_len))  # Computes the exponent of the next power of 2\n",
    "\n",
    "        # Stacked TapeHeads and corresponding XOR modules\n",
    "        self.tape_heads = nn.ModuleList([\n",
    "            TapeHead(embed_dim, vocab_size=vocab_size, num_layers=num_chunk_layers, base_chunk=1, num_heads=num_heads,placeholder_idx=placeholder_idx, dropout=dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.xor_modules = nn.ModuleList([\n",
    "            DifferentiableXORLayer(vocab_size) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.final_norm = RMSNorm(embed_dim)\n",
    "        self.logits_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.norm_gate = nn.Parameter(torch.tensor(0.5))  # Start at 0.5 for balanced effect\n",
    "\n",
    "        # Final Student-t unembedding\n",
    "        self.final_ln = nn.LayerNorm(embed_dim)\n",
    "        self.logits_weight = nn.Parameter(torch.tensor(0.5))  # Initialized to 0.5, learnable scalar\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, S) integer token IDs\n",
    "        Returns:\n",
    "          p_final: (B, S, V) final probability distribution\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(0) if x.ndim == 1 else x  # Ensure batch dimension\n",
    "\n",
    "        B, S = x.shape\n",
    "        assert S <= self.seq_len, \"Sequence too long.\"\n",
    "\n",
    "        # 1) Token + Positional Embeddings\n",
    "        h = self.token_emb(x) + self.pos_emb[:, :S, :]  # (B, S, D)\n",
    "        logits = None\n",
    "        \n",
    "        # 2) Pass through TapeHeads and apply XOR after each\n",
    "        for head, xor in zip(self.tape_heads, self.xor_modules):\n",
    "            x, h, logits = head(x, h,logits)\n",
    "            if logits is not None and logits.numel() > 0:  # Ensure logits exist before applying XOR\n",
    "                logits = xor(logits)              # Apply XOR\n",
    "            \n",
    "        ## 3) Process logits before merging\n",
    "        #if logits is not None:\n",
    "            #logits_emb = torch.matmul(logits, self.unembedding.T)  # (B, S, D)\n",
    "            #logits_emb = self.logits_norm(logits_emb)  # **Normalize logits before merging**\n",
    "\n",
    "        # 4) Final processing\n",
    "        #alpha = torch.sigmoid(self.norm_gate)  # Learnable balance factor\n",
    "        h_final = self.final_norm(h) #+ alpha * logits_emb # Blended normalization\n",
    "        p_final = student_t_unembedding(h, self.unembedding, df=2.718281828459, eps=1e-9,placeholder_idx=placeholder_idx)\n",
    "\n",
    "\n",
    "        return p_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc,torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VhlsGaG7ONr",
    "outputId": "1534f894-6597-49b5-c0c3-41369844874c"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Data Preparation (Shakespeare)\n",
    "# ====================================================\n",
    "def load_shakespeare_text():\n",
    "    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "    text = requests.get(url).text\n",
    "    return text\n",
    "\n",
    "text = load_shakespeare_text()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# Add a placeholder token: an ASCII grey block (visible in output)\n",
    "placeholder = \"▒\"  # Choose your preferred grey block character\n",
    "if placeholder not in chars:\n",
    "    chars.append(placeholder)\n",
    "    chars.sort()  # Ensure ordering is maintained\n",
    "\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "placeholder_idx = stoi[placeholder]\n",
    "print(\"Placeholder token:\", placeholder, \"with index:\", placeholder_idx)\n",
    "\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "def get_batch(batch_size, seq_len):\n",
    "    ix = torch.randint(0, data.size(0) - seq_len - 1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+seq_len] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+seq_len+1] for i in ix])\n",
    "    return x, y\n",
    "    \n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Get unique characters and their frequencies\n",
    "chars = sorted(list(set(text)))\n",
    "char_counts = {ch: text.count(ch) for ch in chars}\n",
    "total_chars = sum(char_counts.values())\n",
    "\n",
    "# Compute empirical probabilities\n",
    "char_probs = {ch: count / total_chars for ch, count in char_counts.items()}\n",
    "\n",
    "# Convert to sorted lists for indexing\n",
    "char_list = sorted(char_probs.keys())\n",
    "prob_list = np.array([char_probs[ch] for ch in char_list])\n",
    "\n",
    "# Compute a distance matrix based on probability space\n",
    "distance_matrix = np.zeros((len(char_list), len(char_list)))\n",
    "\n",
    "for i, j in itertools.combinations(range(len(char_list)), 2):\n",
    "    # Construct two-outcome distributions for each character probability\n",
    "    p, q = prob_list[i], prob_list[j]\n",
    "    # For our purposes, consider distributions like [p, 1-p] and [q, 1-q]\n",
    "    m = 0.5 * (p + q)\n",
    "    distance = 0.5 * (p * np.log(p/m) + (1-p) * np.log((1-p)/(1-m)) +\n",
    "                      q * np.log(q/m) + (1-q) * np.log((1-q)/(1-m)))\n",
    "    distance_matrix[i, j] = char_distance_matrix[j, i] = distance\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Training Setup\n",
    "# ====================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TapeTransformer(\n",
    "    vocab_size=vocab_size,  # example\n",
    "    seq_len=256,\n",
    "    chunk_len=4,\n",
    "    embed_dim=256,\n",
    "    num_layers=6,\n",
    "    num_heads=4,\n",
    "    placeholder_idx=placeholder_idx,\n",
    "    dropout=0 #cannot use dropout, tooo slow\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=6e-4)\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "seq_len = 256 #from karapathy\n",
    "\n",
    "\n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_loss(preds, targets, placeholder_idx, df=2.718281828459, eps=1e-9):\n",
    "    \"\"\"\n",
    "    Custom loss function to implement 'Skip vs Learn' behavior.\n",
    "\n",
    "    Arguments:\n",
    "      preds: (B, S, V) => Model's predicted probabilities over vocabulary.\n",
    "      targets: (B, S) => Ground truth token indices.\n",
    "      placeholder_idx: Index of the placeholder token.\n",
    "      df (float): Degrees of freedom for Student's t-distribution.\n",
    "      eps (float): Small constant to prevent log(0).\n",
    "\n",
    "    Returns:\n",
    "      Scalar loss.\n",
    "    \"\"\"\n",
    "    B, S, V = preds.shape\n",
    "\n",
    "    # Get predicted token indices\n",
    "    pred_indices = torch.argmax(preds, dim=-1)\n",
    "\n",
    "    # Identify where ground truth is a placeholder\n",
    "    is_placeholder = (targets == placeholder_idx)\n",
    "    is_pred_placeholder = (pred_indices == placeholder_idx)\n",
    "\n",
    "    # Compute standard loss\n",
    "    log_probs = torch.log(preds + eps)\n",
    "    loss = -log_probs[torch.arange(B).unsqueeze(1), torch.arange(S).unsqueeze(0), targets]\n",
    "\n",
    "    # Case 1: Model predicts a real token when ground truth is a placeholder → Reward\n",
    "    loss = torch.where(is_placeholder & ~is_pred_placeholder, loss * (1 - 1 / math.e), loss)\n",
    "\n",
    "    # Case 2: Model predicts placeholder when ground truth is a real token → Penalize\n",
    "    loss = torch.where(~is_placeholder & is_pred_placeholder, loss * (1 + 1 / math.e), loss)\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def corrupt_input_probability_based(batch, char_list, char_probs, distance_matrix, corruption_prob=1 / math.e):\n",
    "    \"\"\"\n",
    "    Corrupts a batch of tokenized text based on probability-space distances.\n",
    "    \n",
    "    Arguments:\n",
    "      batch: (B, S) Tensor of token indices.\n",
    "      char_list: List of characters sorted by index.\n",
    "      char_probs: Dictionary mapping character to probability.\n",
    "      distance_matrix: Precomputed Jensen-Shannon distances between character probabilities.\n",
    "      corruption_prob: Probability of corrupting a token.\n",
    "    \n",
    "    Returns:\n",
    "      Corrupted batch tensor.\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = batch.shape\n",
    "    corrupted_batch = batch.clone()\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        for j in range(seq_len):\n",
    "            if random.random() < corruption_prob:\n",
    "                original_idx = batch[i, j].item()\n",
    "                original_char = char_list[original_idx]\n",
    "                \n",
    "                # Get distances from the current character to all others\n",
    "                distances = distance_matrix[original_idx]\n",
    "                \n",
    "                # Select replacement character based on a random weighted shift\n",
    "                shift_distance = np.percentile(distances, 1 / math.e * 100)  # Determine shift threshold\n",
    "                valid_replacements = np.where(distances >= shift_distance)[0]  # Find candidates beyond threshold\n",
    "                \n",
    "                if len(valid_replacements) > 0:\n",
    "                    replacement_idx = np.random.choice(valid_replacements)  # Pick a random valid distant character\n",
    "                    corrupted_batch[i, j] = replacement_idx\n",
    "    \n",
    "    return corrupted_batch\n",
    "\n",
    "\n",
    "def scheduled_sampling(batch, model, placeholder_idx, sample_prob, gen_chars,char_list, char_probs, distance_matrix):\n",
    "    \"\"\"\n",
    "    Implements scheduled sampling with corruption and variable-length generation.\n",
    "    Ensures truncation never results in fewer than 3 characters.\n",
    "\n",
    "    Arguments:\n",
    "      batch: (B, S) Tensor of token indices.\n",
    "      model: Transformer model.\n",
    "      placeholder_idx: Index of the placeholder token.\n",
    "      max_truncate: Upper bound for truncation.\n",
    "      sample_prob: Probability of using model-generated token instead of ground truth.\n",
    "      gen_chars: Number of characters to generate instead of ground truth.\n",
    "\n",
    "    Returns:\n",
    "      Loss scalar.\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = batch.shape\n",
    "    truncated_batch = []\n",
    "    targets = []\n",
    "    use_placeholder = torch.rand(1).item() < (1 / math.e)  # 1/e probability for forced placeholders\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Ensure truncation is never less than 3 chars\n",
    "        min_truncate = 3\n",
    "        max_truncate = model.seq_len\n",
    "        max_valid_truncate = min(max_truncate, model.seq_len - gen_chars - 1)\n",
    "\n",
    "        # Ensure we have a valid range\n",
    "        if max_valid_truncate < min_truncate:\n",
    "            truncate_len = min_truncate  # If max is too small, just use min\n",
    "        else:\n",
    "            truncate_len = random.randint(min_truncate, max_valid_truncate)\n",
    "\n",
    "        # Select truncated sequence\n",
    "        input_seq = batch[i, :truncate_len].clone()\n",
    "        target_seq = batch[i, truncate_len : min(truncate_len + gen_chars, seq_len)]  # Multiple target characters\n",
    "\n",
    "        # Scheduled sampling: replace last `gen_chars` tokens with model predictions\n",
    "        if random.random() < sample_prob and truncate_len > 1:\n",
    "            with torch.no_grad():\n",
    "                for _ in range(gen_chars):\n",
    "                    if len(input_seq) >= model.seq_len:  # Prevent overflow\n",
    "                        break\n",
    "                    model_output = model(input_seq.unsqueeze(0))  # (1, S, V)\n",
    "                    predicted_token = torch.argmax(model_output[:, -1, :], dim=-1)\n",
    "                    input_seq = torch.cat([input_seq, predicted_token.view(1)], dim=0)  # Append predicted token\n",
    "\n",
    "        # corruption\n",
    "        input_seq = corrupt_input_probability_based(\n",
    "            input_seq.unsqueeze(0), char_list, char_probs, distance_matrix, corruption_prob=1 / math.e\n",
    "        ).squeeze(0)\n",
    "\n",
    "        truncated_batch.append(input_seq[:model.seq_len])  # Ensure length limit\n",
    "        targets.append(target_seq[:model.seq_len])  # Ensure target sequence is also within bounds\n",
    "\n",
    "    # **Pad sequences to the max length in batch**\n",
    "    max_len = max(len(seq) for seq in truncated_batch)\n",
    "    max_len = min(max_len, model.seq_len)  # Ensure padding does not exceed max sequence length\n",
    "\n",
    "    truncated_batch = [F.pad(seq, (0, max_len - len(seq)), value=placeholder_idx) for seq in truncated_batch]\n",
    "    targets = [F.pad(seq, (0, max_len - len(seq)), value=placeholder_idx) for seq in targets]\n",
    "\n",
    "    truncated_batch = torch.stack(truncated_batch)\n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(truncated_batch)\n",
    "\n",
    "    # Compute custom loss (ignoring padded regions)\n",
    "    loss = modified_loss(outputs, targets, placeholder_idx)\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Increase sample probability over time\n",
    "    sample_prob = min(0.1 * (epoch + 1), 0.5)  # Linearly increases up to 50%\n",
    "    gen_chars = min(1 + epoch, 5)  # Gradually increase generated tokens per epoch\n",
    "\n",
    "    for step in range(100):  # Adjust as needed\n",
    "        x_batch, _ = get_batch(batch_size, seq_len)\n",
    "        x_batch = x_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "\n",
    "            loss = scheduled_sampling(x_batch, model, placeholder_idx, sample_prob, gen_chars,char_list, char_probs, distance_matrix)\n",
    "        main_loss = loss.detach()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += main_loss\n",
    "        losses.append(main_loss.cpu())\n",
    "        if step % 1 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Step {step}, Loss: {main_loss:.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Average Loss: {total_loss/1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Evaluation: Text Generation\n",
    "# ====================================================\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prompt = \"oh Romeo! Romeo!\"\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    generated = context\n",
    "    for _ in range(200):  # Generate 200 tokens.\n",
    "        inp = generated[:, -seq_len:]\n",
    "        p = model(inp)  # p: (B, seq, vocab_size)\n",
    "        last_token_probs = p[:, -1, :]  # Shape: [batch_size, vocab_size]\n",
    "        predicted_token = torch.multinomial(F.softmax(last_token_probs, dim=-1), num_samples=1).squeeze()\n",
    "\n",
    "        #next_token = torch.multinomial(last_token_probs, num_samples=1)\n",
    "        generated = torch.cat((generated, next_token), dim=1)\n",
    "    sample = decode(generated[0].cpu().tolist())\n",
    "    print(\"Generated Sample:\\n\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
