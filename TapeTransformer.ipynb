{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPYRIGHT NOTICE\n",
    "In the name of Christ our Lord be blessed. We, Joshuah Rainstar(joshuah.rainstar@gmail.com), do claim copyright to this code, or software, and associated documentation, as our work in the year 2025 Anno Domini, reserving all rights and assigning them in accordance with the following license terms:\n",
    "\n",
    "1. Permission is by our authority and with this statement granted, to any person or artificial intelligence without limitation or restriction to examine, analyze, read, dissect, translate, use, modify, and distribute the aforementioned copyrighted items, subject to the following conditions:\n",
    "2. This license must be included in full with any copies or works containing substantial portions of the copyrighted items.\n",
    "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "\n",
    "THE COPYRIGHTED ITEMS ARE PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE COPYRIGHTED ITEMS OR THEIR USE OR ANY OTHER CIRCUMSTANCES CONCERNING THEM.\n"
   ]
  },
  {
   "attachments": {
    "28374c77-74dc-463c-984c-f518ca74a4cd.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is an experimental model intended to elucidate possible mechanics for attention across sequences in addition to tokenwise. it is reasonably fast and efficient. conceptually, the design was envisioned by me and coded through refinement with OpenAI Codex Orion One and chatgpt\n",
    "\n",
    "\"hierarchical multi-scale transformer with MoE-like sparse selection\"\n",
    "\n",
    "SelfScalableTanh from  Self-scalable Tanh (Stan): Faster Convergence and Better Generalization in Physics-informed Neural Networks\r\n",
    "https://arxiv.org/abs/2204.1258\n",
    "Motivation: my gut said its a good idea. Impact: little bit faster convergence even in gpt9\n",
    "harmonic loss from  Harmonic Loss Trains Interpretable AI Models\r\n",
    "https://arxiv.org/abs/2502.01628note that I do the math in log space to avoid explosions\n",
    "note that harmonic loss has been swapped for a student's t distribution to avoid NaN collapses near zero\n",
    "motivation: interpretable model. Impact: speeds up convergence even more than harmonic!\n",
    "\n",
    "XOR from  Two-argument activation functions learn soft XOR operations like cortical neurons\r\n",
    "https://arxiv.org/abs/2110.06871note that my implementation is a differential XOR for backprop capability\n",
    "motivation: little bit of internal reasoning maybe? Impact: slows down convergence somewhat\n",
    "\n",
    "WOLF optimizer experimental by me, it may not beat adam but it is simpler than adam, closer to SGD with some smoothing of integration\n",
    "impact: speeds up convergence somewhat for early iterations and will not NAN from high LR.\n",
    "probable benefit- switch optimizers after model drops. could be good for bigger models.. maybe\n",
    "\n",
    "![image.png](attachment:28374c77-74dc-463c-984c-f518ca74a4cd.png)\n",
    "m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jcJTMiWT89P5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "dl9uYIM16MG4"
   },
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "class Wolf(Optimizer):\n",
    "    \"\"\"Implements Wolf algorithm.\"\"\"\n",
    "    def __init__(self, params, lr=0.25, betas=(0.9, 0.999), eps=1e-8):\n",
    "        # Define default parameters\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps)\n",
    "        self.lr = lr\n",
    "        # Initialize the parent Optimizer class first\n",
    "        super().__init__(params, defaults)\n",
    "        # Constants specific to Wolf\n",
    "        # Initialize state for each parameter\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['p'] = torch.zeros_like(p)  # Second moment estimate\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step and adjusts dropout in transformer blocks.\"\"\"\n",
    "        etcerta = 0.367879441  # Constant used in update rule\n",
    "        et = 1 - etcerta\n",
    "    \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "    \n",
    "        # Iterate over parameter groups.\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                grad = p.grad\n",
    "    \n",
    "                #  AMP Compatibility: Check for NaN or Inf in gradients\n",
    "                if torch.isnan(grad).any() or torch.isinf(grad).any():\n",
    "                    print(\"Skipping parameter update due to NaN/Inf gradient.\")\n",
    "                    continue  # Skip this update if the gradient has NaN or Inf\n",
    "    \n",
    "                state = self.state[p]\n",
    "                exp_avg = state['p']\n",
    "    \n",
    "                # Compute update and update second moment-like state.\n",
    "                update = exp_avg * et + grad * etcerta\n",
    "                state['p'] = exp_avg * et + update * etcerta\n",
    "    \n",
    "                # Compute sign agreement between update and gradient.\n",
    "                sign_agreement = torch.sign(update) * torch.sign(grad)\n",
    "    \n",
    "                # Where the signs agree (mask is True), update the parameter.\n",
    "                mask = (sign_agreement > 0)\n",
    "                adaptive_alpha = group.get('lr', self.lr)\n",
    "                p.data = torch.where(mask, p.data - adaptive_alpha * update, p.data)\n",
    "    \n",
    "                # AMP Compatibility: Ensure a step counter is updated\n",
    "                state['step'] = state.get('step', 0) + 1  # Track optimization steps\n",
    "    \n",
    "        return loss\n",
    "\n",
    "   \n",
    "def student_t_unembedding(hidden_states, unembedding, df=2.718281828459, eps=1e-9, placeholder_idx=None):\n",
    "    \"\"\"\n",
    "    Student's t-based unembedding with optional placeholder modification.\n",
    "    \n",
    "    Arguments:\n",
    "      hidden_states: (B, S, D)  => modelâ€™s output embeddings (hidden state)\n",
    "      unembedding:   (D, V)    => learnable \"word vectors\" (unembedding matrix)\n",
    "      df (float): degrees of freedom for the Student's t distribution\n",
    "      eps (float): numerical epsilon to avoid log(0) and div-by-zero\n",
    "      placeholder_idx (int, optional): if provided, indicates the column in the unembedding\n",
    "          corresponding to the placeholder token. The distances for that token will be adjusted \n",
    "          using an adaptive noise factor.\n",
    "    \n",
    "    Returns:\n",
    "      p: (B, S, V)  probability distribution over V vocabulary tokens.\n",
    "    \"\"\"\n",
    "    B, S, D = hidden_states.shape\n",
    "    V = unembedding.shape[1]\n",
    "\n",
    "    # Expand hidden => (B, S, 1, D)\n",
    "    x_expanded = hidden_states.unsqueeze(2)\n",
    "    # Expand unembedding => (1, 1, V, D)\n",
    "    w_expanded = unembedding.t().unsqueeze(0).unsqueeze(0)  # shape: (1, 1, V, D)\n",
    "    \n",
    "    # Compute squared Euclidean distance between each hidden vector and each unembedding vector.\n",
    "    dist_sq = torch.sum((x_expanded - w_expanded) ** 2, dim=-1).clamp(min=1e-6)  # (B, S, V)\n",
    "        \n",
    "    # Compute the negative energy:\n",
    "    #    E = 0.5*(df + D) * log(1 + dist_sq / df)\n",
    "    # and so log probability (up to an additive constant) is:\n",
    "    #    log_p = -E\n",
    "    log_p_unnorm = -0.5 * (df + D) * torch.log1p(dist_sq / df)  # (B, S, V)\n",
    "    \n",
    "    # Normalize via log_softmax over the vocabulary dimension.\n",
    "    log_p = F.log_softmax(log_p_unnorm, dim=-1)  # (B, S, V)\n",
    "    p = log_p.exp()\n",
    "    return p\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Custom Activation\n",
    "# ---------------------------------------------------\n",
    "class ReferenceActivation(nn.Module):\n",
    "    def __init__(self, gamma=24):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, x):\n",
    "        log_x = torch.sign(x) * torch.log1p(torch.abs(x))\n",
    "        return log_x / torch.sqrt(1 + self.gamma * log_x ** 2)\n",
    "\n",
    "\n",
    "class TapeHeadBlock(nn.Module):\n",
    "    def __init__(self, chunk_size, embed_dim, vocab_size, num_heads=1, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.chunk_size = chunk_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # ðŸ”¹ Store embeddings inside the block (instead of managing externally)\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, chunk_size, embed_dim))\n",
    "\n",
    "        # Chunk-based attention now takes 3 inputs\n",
    "        self.chunk_proj = nn.Linear(chunk_size * embed_dim, embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln_attn = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),\n",
    "            ReferenceActivation(),\n",
    "            nn.LayerNorm(4 * embed_dim),\n",
    "            nn.Linear(4 * embed_dim, embed_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.ln_mlp = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Unembedding for logits attention\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "\n",
    "        self.logits_attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.placeholder_idx = placeholder_idx\n",
    "\n",
    "    def forward(self, x, prev_h, prev_emb, logits):\n",
    "        \"\"\"\n",
    "        x:        (B, S) Input tokens\n",
    "        prev_h:   (B, S, D) Previous hidden state (passed from last layer)\n",
    "        prev_emb: (B, S, D) Previous embeddings (passed alongside)\n",
    "        logits:   (B, S, V) Probability distribution from previous block\n",
    "\n",
    "        Returns:\n",
    "          x: same input\n",
    "          h_mlp: updated hidden state (passed forward)\n",
    "          layer_emb: this layer's embeddings (passed alongside)\n",
    "          logits: refined probability distribution\n",
    "        \"\"\"\n",
    "        # ðŸ”¹ Compute this layer's embeddings\n",
    "        layer_emb = self.token_emb(x) + self.pos_emb[:, :x.shape[1], :]\n",
    "\n",
    "        # ðŸ”¹ Expand attention mechanism to handle 3 inputs: prev_emb, layer_emb, prev_h\n",
    "        attn_input = torch.cat([prev_emb, layer_emb, prev_h], dim=1) if prev_h is not None else layer_emb\n",
    "        attn_out = self._chunk_attention(attn_input)\n",
    "        h_attn = self.ln_attn(attn_out)\n",
    "\n",
    "        # ðŸ”¹ If logits exist, integrate them using cross-attention\n",
    "        if logits is not None:\n",
    "            vocab_embedding = torch.matmul(logits, self.unembedding.T)  # (B, S, D)\n",
    "            query, key, value = h_attn, vocab_embedding, vocab_embedding\n",
    "            logits_context, _ = self.logits_attention(query, key, value)\n",
    "            h_attn = h_attn + logits_context  # Condition on past logits\n",
    "\n",
    "        # ðŸ”¹ Process through MLP\n",
    "        h_mlp = self.ln_mlp(h_attn + self.mlp(h_attn))\n",
    "\n",
    "        # ðŸ”¹ Compute new logits\n",
    "        logits = student_t_unembedding(h_mlp, self.unembedding, placeholder_idx=self.placeholder_idx)\n",
    "\n",
    "        # ðŸš¨ Pass forward `h_mlp` as the hidden state, and pass `layer_emb` alongside\n",
    "        return x, h_mlp, layer_emb, logits\n",
    "\n",
    "    def _chunk_attention(self, h):\n",
    "        \"\"\" Chunk-based self-attention \"\"\"\n",
    "        B, S, D = h.shape\n",
    "        c = self.chunk_size\n",
    "\n",
    "        # Move feature dim before sequence (B, D, S)\n",
    "        x_3d = h.permute(0, 2, 1)\n",
    "\n",
    "        # Right-pad so we can slide windows of size c up to the last token\n",
    "        x_3d_padded = F.pad(x_3d, (0, c - 1))\n",
    "\n",
    "        # Unfold => (B, D*c, S)\n",
    "        unfolded = F.unfold(x_3d_padded.unsqueeze(-1), kernel_size=(c, 1), stride=(1, 1))\n",
    "        unfolded = unfolded.transpose(1, 2)  # => (B, S, D*c)\n",
    "\n",
    "        # Project => (B, S, D)\n",
    "        chunk_tensor = self.chunk_proj(unfolded)\n",
    "\n",
    "        # Self-attention\n",
    "        out, _ = self.attn(chunk_tensor, chunk_tensor, chunk_tensor)\n",
    "        return out\n",
    "\n",
    "class TapeHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-like block with progressive chunk sizes.\n",
    "    Each layer inside the TapeHead doubles the chunk size.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, vocab_size, num_layers=3, base_chunk=1, num_heads=2, placeholder_idx=None,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.base_chunk = base_chunk\n",
    "\n",
    "        # Create progressively larger TapeHeadBlocks\n",
    "        self.blocks_left = nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=base_chunk * (2 ** i),  # 1, 2, 4, 8, ...\n",
    "                embed_dim=embed_dim,vocab_size=vocab_size,\n",
    "                num_heads=num_heads,placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.blocks_right = nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=base_chunk * (2 ** i),  # 1, 2, 4, 8, ...\n",
    "                embed_dim=embed_dim,vocab_size=vocab_size,\n",
    "                num_heads=num_heads,placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.activation = ReferenceActivation()\n",
    "\n",
    "    def forward(self, x, prev_h, prev_emb, logits):\n",
    "        \"\"\"\n",
    "            x:        (B, S) Input tokens\n",
    "            prev_h:   (B, S, D) Previous hidden state\n",
    "            prev_emb: (B, S, D) Previous embeddings (passed alongside)\n",
    "            logits:   (B, S, V) Probability distribution from previous layer\n",
    "        \n",
    "            Returns:\n",
    "                x: unchanged input\n",
    "                prev_h: updated hidden state (passed forward)\n",
    "                prev_emb: updated embeddings (passed forward)\n",
    "                logits: refined probability distribution\n",
    "        \"\"\"\n",
    "        logits_left = logits.clone() if logits is not None else None\n",
    "        prev_emb_left = prev_emb.clone() if prev_emb is not None else None\n",
    "        prev_h_left = prev_h.clone() if prev_h is not None else None\n",
    "\n",
    "\n",
    "        for i in range(self.num_layers):  # Process blocks in pairs\n",
    "            _, h_out_left, layer_emb_left, logits_left = self.blocks_left[i](x, prev_h_left, prev_emb_left, logits_left)\n",
    "            _, h_out, layer_emb, logits = self.blocks_right[i](x, prev_h, prev_emb, logits)\n",
    "            a = self.activation(h_out_left)\n",
    "            b = self.activation(h_out)\n",
    "            h_out = 0.5 * (a + b - 2 * a * b)\n",
    "            h_out_left= h_out.clone()\n",
    "\n",
    "        logits = 0.5 * (logits + logits_left - 2 * logits * logits_left)\n",
    "        layer_emb =  0.5 * (layer_emb + layer_emb_left - 2 * layer_emb * layer_emb_left)\n",
    "\n",
    "        return x, h_out, layer_emb, logits  # No XOR since only one block\n",
    "           \n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / (x.norm(2, dim=-1, keepdim=True) + self.eps) * self.weight\n",
    "        \n",
    "class TapeTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Full GPT-like model with:\n",
    "      - Token + Position Embeddings\n",
    "      - Multiple stacked TapeHeads\n",
    "      - XOR applied to each TapeHead output\n",
    "      - Final Student-t unembedding\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, seq_len=128,chunk_len=4, embed_dim=128, num_heads=2, num_layers=4, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Token & Positional Embeddings\n",
    "        num_chunk_layers = math.ceil(math.log2(chunk_len))  # Computes the exponent of the next power of 2\n",
    "\n",
    "        # New: LayerNorm applied right after the embeddings\n",
    "        self.embed_ln = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Stacked TapeHeads and corresponding XOR modules\n",
    "        self.tape_heads = nn.ModuleList([\n",
    "            TapeHead(embed_dim, vocab_size=vocab_size, num_layers=num_chunk_layers, base_chunk=1, num_heads=num_heads,placeholder_idx=placeholder_idx, dropout=dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.final_norm = RMSNorm(embed_dim)\n",
    "        self.logits_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.norm_gate = nn.Parameter(torch.tensor(0.5))  # Start at 0.5 for balanced effect\n",
    "\n",
    "        # Final Student-t unembedding\n",
    "        self.final_ln = nn.LayerNorm(embed_dim)\n",
    "        self.logits_weight = nn.Parameter(torch.tensor(0.5))  # Initialized to 0.5, learnable scalar\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "        self.merge_projection = nn.Linear(len(self.tape_heads) * embed_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, S) integer token IDs\n",
    "        Returns:\n",
    "          p_final: (B, S, V) final probability distribution\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(0) if x.ndim == 1 else x  # Ensure batch dimension\n",
    "\n",
    "        B, S = x.shape\n",
    "        assert S <= self.seq_len, \"Sequence too long.\"\n",
    "\n",
    "        logits = None\n",
    "        prev_h = None\n",
    "        prev_emb = None\n",
    "        \n",
    "        # 2) Pass through TapeHeads and apply XOR after each\n",
    "        all_heads_h = []\n",
    "        all_heads_logits = []\n",
    "        \n",
    "        for head in self.tape_heads:  # Parallel TapeHeads\n",
    "            x, h_out, _, _ = head(x, prev_h, prev_emb, logits)  # Each TapeHead processes through its own blocks\n",
    "            all_heads_h.append(h_out)\n",
    "            all_heads_logits.append(logits)\n",
    "\n",
    "        # ðŸ”¹ Concatenate all TapeHead outputs along the feature dimension\n",
    "        merged_h = torch.cat(all_heads_h, dim=-1)  # Shape: (B, S, num_heads * D)\n",
    "        \n",
    "        # ðŸ”¹ Apply the learned projection to bring it back to original embedding size\n",
    "        prev_h = self.merge_projection(merged_h)  # Shape: (B, S, D)            \n",
    "        p_final = student_t_unembedding(prev_h, self.unembedding, df=2.718281828459, eps=1e-9,placeholder_idx=placeholder_idx)\n",
    "\n",
    "\n",
    "        return p_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc,torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VhlsGaG7ONr",
    "outputId": "1534f894-6597-49b5-c0c3-41369844874c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder token for even vocab size: â–’ with index: 65\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Preparation (Shakespeare)\n",
    "# ====================================================\n",
    "def load_shakespeare_text():\n",
    "    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "    text = requests.get(url).text\n",
    "    return text\n",
    "\n",
    "text = load_shakespeare_text()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# Add a placeholder token: an ASCII grey block (visible in output)\n",
    "placeholder = \"â–’\"  # Choose your preferred grey block character\n",
    "if placeholder not in chars:\n",
    "    chars.append(placeholder)\n",
    "    chars.sort()  # Ensure ordering is maintained\n",
    "\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "placeholder_idx = stoi[placeholder]\n",
    "print(\"Placeholder token for even vocab size:\", placeholder, \"with index:\", placeholder_idx)\n",
    "\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "def get_batch(batch_size, seq_len):\n",
    "    ix = torch.randint(0, data.size(0) - seq_len - 1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+seq_len] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+seq_len+1] for i in ix])\n",
    "    return x, y\n",
    "    \n",
    "\n",
    "# ====================================================\n",
    "# Training Setup\n",
    "# ====================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TapeTransformer(\n",
    "    vocab_size=vocab_size,  # example\n",
    "    seq_len=256,\n",
    "    chunk_len=4,\n",
    "    embed_dim=256,#heads times true vocab, round up \n",
    "    num_layers=8,\n",
    "    num_heads=4,\n",
    "    placeholder_idx=placeholder_idx,\n",
    "    dropout=0 #cannot use dropout, tooo slow\n",
    ").to(device)\n",
    "\n",
    "optimizer = Wolf(model.parameters(), lr=0.3678)\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "seq_len = 256 #from karapathy\n",
    "eps = 1e-8\n",
    "\n",
    "loss_history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TapeTransformer:\n\tMissing key(s) in state_dict: \"tape_heads.0.blocks_left.0.pos_emb\", \"tape_heads.0.blocks_left.0.unembedding\", \"tape_heads.0.blocks_left.0.token_emb.weight\", \"tape_heads.0.blocks_left.0.chunk_proj.weight\", \"tape_heads.0.blocks_left.0.chunk_proj.bias\", \"tape_heads.0.blocks_left.0.attn.in_proj_weight\", \"tape_heads.0.blocks_left.0.attn.in_proj_bias\", \"tape_heads.0.blocks_left.0.attn.out_proj.weight\", \"tape_heads.0.blocks_left.0.attn.out_proj.bias\", \"tape_heads.0.blocks_left.0.ln_attn.weight\", \"tape_heads.0.blocks_left.0.ln_attn.bias\", \"tape_heads.0.blocks_left.0.mlp.0.weight\", \"tape_heads.0.blocks_left.0.mlp.0.bias\", \"tape_heads.0.blocks_left.0.mlp.2.weight\", \"tape_heads.0.blocks_left.0.mlp.2.bias\", \"tape_heads.0.blocks_left.0.mlp.3.weight\", \"tape_heads.0.blocks_left.0.mlp.3.bias\", \"tape_heads.0.blocks_left.0.ln_mlp.weight\", \"tape_heads.0.blocks_left.0.ln_mlp.bias\", \"tape_heads.0.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.0.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.0.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.0.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.0.blocks_left.1.pos_emb\", \"tape_heads.0.blocks_left.1.unembedding\", \"tape_heads.0.blocks_left.1.token_emb.weight\", \"tape_heads.0.blocks_left.1.chunk_proj.weight\", \"tape_heads.0.blocks_left.1.chunk_proj.bias\", \"tape_heads.0.blocks_left.1.attn.in_proj_weight\", \"tape_heads.0.blocks_left.1.attn.in_proj_bias\", \"tape_heads.0.blocks_left.1.attn.out_proj.weight\", \"tape_heads.0.blocks_left.1.attn.out_proj.bias\", \"tape_heads.0.blocks_left.1.ln_attn.weight\", \"tape_heads.0.blocks_left.1.ln_attn.bias\", \"tape_heads.0.blocks_left.1.mlp.0.weight\", \"tape_heads.0.blocks_left.1.mlp.0.bias\", \"tape_heads.0.blocks_left.1.mlp.2.weight\", \"tape_heads.0.blocks_left.1.mlp.2.bias\", \"tape_heads.0.blocks_left.1.mlp.3.weight\", \"tape_heads.0.blocks_left.1.mlp.3.bias\", \"tape_heads.0.blocks_left.1.ln_mlp.weight\", \"tape_heads.0.blocks_left.1.ln_mlp.bias\", \"tape_heads.0.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.0.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.0.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.0.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.0.blocks_right.0.pos_emb\", \"tape_heads.0.blocks_right.0.unembedding\", \"tape_heads.0.blocks_right.0.token_emb.weight\", \"tape_heads.0.blocks_right.0.chunk_proj.weight\", \"tape_heads.0.blocks_right.0.chunk_proj.bias\", \"tape_heads.0.blocks_right.0.attn.in_proj_weight\", \"tape_heads.0.blocks_right.0.attn.in_proj_bias\", \"tape_heads.0.blocks_right.0.attn.out_proj.weight\", \"tape_heads.0.blocks_right.0.attn.out_proj.bias\", \"tape_heads.0.blocks_right.0.ln_attn.weight\", \"tape_heads.0.blocks_right.0.ln_attn.bias\", \"tape_heads.0.blocks_right.0.mlp.0.weight\", \"tape_heads.0.blocks_right.0.mlp.0.bias\", \"tape_heads.0.blocks_right.0.mlp.2.weight\", \"tape_heads.0.blocks_right.0.mlp.2.bias\", \"tape_heads.0.blocks_right.0.mlp.3.weight\", \"tape_heads.0.blocks_right.0.mlp.3.bias\", \"tape_heads.0.blocks_right.0.ln_mlp.weight\", \"tape_heads.0.blocks_right.0.ln_mlp.bias\", \"tape_heads.0.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.0.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.0.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.0.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.0.blocks_right.1.pos_emb\", \"tape_heads.0.blocks_right.1.unembedding\", \"tape_heads.0.blocks_right.1.token_emb.weight\", \"tape_heads.0.blocks_right.1.chunk_proj.weight\", \"tape_heads.0.blocks_right.1.chunk_proj.bias\", \"tape_heads.0.blocks_right.1.attn.in_proj_weight\", \"tape_heads.0.blocks_right.1.attn.in_proj_bias\", \"tape_heads.0.blocks_right.1.attn.out_proj.weight\", \"tape_heads.0.blocks_right.1.attn.out_proj.bias\", \"tape_heads.0.blocks_right.1.ln_attn.weight\", \"tape_heads.0.blocks_right.1.ln_attn.bias\", \"tape_heads.0.blocks_right.1.mlp.0.weight\", \"tape_heads.0.blocks_right.1.mlp.0.bias\", \"tape_heads.0.blocks_right.1.mlp.2.weight\", \"tape_heads.0.blocks_right.1.mlp.2.bias\", \"tape_heads.0.blocks_right.1.mlp.3.weight\", \"tape_heads.0.blocks_right.1.mlp.3.bias\", \"tape_heads.0.blocks_right.1.ln_mlp.weight\", \"tape_heads.0.blocks_right.1.ln_mlp.bias\", \"tape_heads.0.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.0.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.0.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.0.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.1.blocks_left.0.pos_emb\", \"tape_heads.1.blocks_left.0.unembedding\", \"tape_heads.1.blocks_left.0.token_emb.weight\", \"tape_heads.1.blocks_left.0.chunk_proj.weight\", \"tape_heads.1.blocks_left.0.chunk_proj.bias\", \"tape_heads.1.blocks_left.0.attn.in_proj_weight\", \"tape_heads.1.blocks_left.0.attn.in_proj_bias\", \"tape_heads.1.blocks_left.0.attn.out_proj.weight\", \"tape_heads.1.blocks_left.0.attn.out_proj.bias\", \"tape_heads.1.blocks_left.0.ln_attn.weight\", \"tape_heads.1.blocks_left.0.ln_attn.bias\", \"tape_heads.1.blocks_left.0.mlp.0.weight\", \"tape_heads.1.blocks_left.0.mlp.0.bias\", \"tape_heads.1.blocks_left.0.mlp.2.weight\", \"tape_heads.1.blocks_left.0.mlp.2.bias\", \"tape_heads.1.blocks_left.0.mlp.3.weight\", \"tape_heads.1.blocks_left.0.mlp.3.bias\", \"tape_heads.1.blocks_left.0.ln_mlp.weight\", \"tape_heads.1.blocks_left.0.ln_mlp.bias\", \"tape_heads.1.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.1.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.1.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.1.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.1.blocks_left.1.pos_emb\", \"tape_heads.1.blocks_left.1.unembedding\", \"tape_heads.1.blocks_left.1.token_emb.weight\", \"tape_heads.1.blocks_left.1.chunk_proj.weight\", \"tape_heads.1.blocks_left.1.chunk_proj.bias\", \"tape_heads.1.blocks_left.1.attn.in_proj_weight\", \"tape_heads.1.blocks_left.1.attn.in_proj_bias\", \"tape_heads.1.blocks_left.1.attn.out_proj.weight\", \"tape_heads.1.blocks_left.1.attn.out_proj.bias\", \"tape_heads.1.blocks_left.1.ln_attn.weight\", \"tape_heads.1.blocks_left.1.ln_attn.bias\", \"tape_heads.1.blocks_left.1.mlp.0.weight\", \"tape_heads.1.blocks_left.1.mlp.0.bias\", \"tape_heads.1.blocks_left.1.mlp.2.weight\", \"tape_heads.1.blocks_left.1.mlp.2.bias\", \"tape_heads.1.blocks_left.1.mlp.3.weight\", \"tape_heads.1.blocks_left.1.mlp.3.bias\", \"tape_heads.1.blocks_left.1.ln_mlp.weight\", \"tape_heads.1.blocks_left.1.ln_mlp.bias\", \"tape_heads.1.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.1.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.1.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.1.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.1.blocks_right.0.pos_emb\", \"tape_heads.1.blocks_right.0.unembedding\", \"tape_heads.1.blocks_right.0.token_emb.weight\", \"tape_heads.1.blocks_right.0.chunk_proj.weight\", \"tape_heads.1.blocks_right.0.chunk_proj.bias\", \"tape_heads.1.blocks_right.0.attn.in_proj_weight\", \"tape_heads.1.blocks_right.0.attn.in_proj_bias\", \"tape_heads.1.blocks_right.0.attn.out_proj.weight\", \"tape_heads.1.blocks_right.0.attn.out_proj.bias\", \"tape_heads.1.blocks_right.0.ln_attn.weight\", \"tape_heads.1.blocks_right.0.ln_attn.bias\", \"tape_heads.1.blocks_right.0.mlp.0.weight\", \"tape_heads.1.blocks_right.0.mlp.0.bias\", \"tape_heads.1.blocks_right.0.mlp.2.weight\", \"tape_heads.1.blocks_right.0.mlp.2.bias\", \"tape_heads.1.blocks_right.0.mlp.3.weight\", \"tape_heads.1.blocks_right.0.mlp.3.bias\", \"tape_heads.1.blocks_right.0.ln_mlp.weight\", \"tape_heads.1.blocks_right.0.ln_mlp.bias\", \"tape_heads.1.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.1.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.1.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.1.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.1.blocks_right.1.pos_emb\", \"tape_heads.1.blocks_right.1.unembedding\", \"tape_heads.1.blocks_right.1.token_emb.weight\", \"tape_heads.1.blocks_right.1.chunk_proj.weight\", \"tape_heads.1.blocks_right.1.chunk_proj.bias\", \"tape_heads.1.blocks_right.1.attn.in_proj_weight\", \"tape_heads.1.blocks_right.1.attn.in_proj_bias\", \"tape_heads.1.blocks_right.1.attn.out_proj.weight\", \"tape_heads.1.blocks_right.1.attn.out_proj.bias\", \"tape_heads.1.blocks_right.1.ln_attn.weight\", \"tape_heads.1.blocks_right.1.ln_attn.bias\", \"tape_heads.1.blocks_right.1.mlp.0.weight\", \"tape_heads.1.blocks_right.1.mlp.0.bias\", \"tape_heads.1.blocks_right.1.mlp.2.weight\", \"tape_heads.1.blocks_right.1.mlp.2.bias\", \"tape_heads.1.blocks_right.1.mlp.3.weight\", \"tape_heads.1.blocks_right.1.mlp.3.bias\", \"tape_heads.1.blocks_right.1.ln_mlp.weight\", \"tape_heads.1.blocks_right.1.ln_mlp.bias\", \"tape_heads.1.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.1.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.1.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.1.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.2.blocks_left.0.pos_emb\", \"tape_heads.2.blocks_left.0.unembedding\", \"tape_heads.2.blocks_left.0.token_emb.weight\", \"tape_heads.2.blocks_left.0.chunk_proj.weight\", \"tape_heads.2.blocks_left.0.chunk_proj.bias\", \"tape_heads.2.blocks_left.0.attn.in_proj_weight\", \"tape_heads.2.blocks_left.0.attn.in_proj_bias\", \"tape_heads.2.blocks_left.0.attn.out_proj.weight\", \"tape_heads.2.blocks_left.0.attn.out_proj.bias\", \"tape_heads.2.blocks_left.0.ln_attn.weight\", \"tape_heads.2.blocks_left.0.ln_attn.bias\", \"tape_heads.2.blocks_left.0.mlp.0.weight\", \"tape_heads.2.blocks_left.0.mlp.0.bias\", \"tape_heads.2.blocks_left.0.mlp.2.weight\", \"tape_heads.2.blocks_left.0.mlp.2.bias\", \"tape_heads.2.blocks_left.0.mlp.3.weight\", \"tape_heads.2.blocks_left.0.mlp.3.bias\", \"tape_heads.2.blocks_left.0.ln_mlp.weight\", \"tape_heads.2.blocks_left.0.ln_mlp.bias\", \"tape_heads.2.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.2.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.2.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.2.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.2.blocks_left.1.pos_emb\", \"tape_heads.2.blocks_left.1.unembedding\", \"tape_heads.2.blocks_left.1.token_emb.weight\", \"tape_heads.2.blocks_left.1.chunk_proj.weight\", \"tape_heads.2.blocks_left.1.chunk_proj.bias\", \"tape_heads.2.blocks_left.1.attn.in_proj_weight\", \"tape_heads.2.blocks_left.1.attn.in_proj_bias\", \"tape_heads.2.blocks_left.1.attn.out_proj.weight\", \"tape_heads.2.blocks_left.1.attn.out_proj.bias\", \"tape_heads.2.blocks_left.1.ln_attn.weight\", \"tape_heads.2.blocks_left.1.ln_attn.bias\", \"tape_heads.2.blocks_left.1.mlp.0.weight\", \"tape_heads.2.blocks_left.1.mlp.0.bias\", \"tape_heads.2.blocks_left.1.mlp.2.weight\", \"tape_heads.2.blocks_left.1.mlp.2.bias\", \"tape_heads.2.blocks_left.1.mlp.3.weight\", \"tape_heads.2.blocks_left.1.mlp.3.bias\", \"tape_heads.2.blocks_left.1.ln_mlp.weight\", \"tape_heads.2.blocks_left.1.ln_mlp.bias\", \"tape_heads.2.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.2.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.2.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.2.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.2.blocks_right.0.pos_emb\", \"tape_heads.2.blocks_right.0.unembedding\", \"tape_heads.2.blocks_right.0.token_emb.weight\", \"tape_heads.2.blocks_right.0.chunk_proj.weight\", \"tape_heads.2.blocks_right.0.chunk_proj.bias\", \"tape_heads.2.blocks_right.0.attn.in_proj_weight\", \"tape_heads.2.blocks_right.0.attn.in_proj_bias\", \"tape_heads.2.blocks_right.0.attn.out_proj.weight\", \"tape_heads.2.blocks_right.0.attn.out_proj.bias\", \"tape_heads.2.blocks_right.0.ln_attn.weight\", \"tape_heads.2.blocks_right.0.ln_attn.bias\", \"tape_heads.2.blocks_right.0.mlp.0.weight\", \"tape_heads.2.blocks_right.0.mlp.0.bias\", \"tape_heads.2.blocks_right.0.mlp.2.weight\", \"tape_heads.2.blocks_right.0.mlp.2.bias\", \"tape_heads.2.blocks_right.0.mlp.3.weight\", \"tape_heads.2.blocks_right.0.mlp.3.bias\", \"tape_heads.2.blocks_right.0.ln_mlp.weight\", \"tape_heads.2.blocks_right.0.ln_mlp.bias\", \"tape_heads.2.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.2.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.2.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.2.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.2.blocks_right.1.pos_emb\", \"tape_heads.2.blocks_right.1.unembedding\", \"tape_heads.2.blocks_right.1.token_emb.weight\", \"tape_heads.2.blocks_right.1.chunk_proj.weight\", \"tape_heads.2.blocks_right.1.chunk_proj.bias\", \"tape_heads.2.blocks_right.1.attn.in_proj_weight\", \"tape_heads.2.blocks_right.1.attn.in_proj_bias\", \"tape_heads.2.blocks_right.1.attn.out_proj.weight\", \"tape_heads.2.blocks_right.1.attn.out_proj.bias\", \"tape_heads.2.blocks_right.1.ln_attn.weight\", \"tape_heads.2.blocks_right.1.ln_attn.bias\", \"tape_heads.2.blocks_right.1.mlp.0.weight\", \"tape_heads.2.blocks_right.1.mlp.0.bias\", \"tape_heads.2.blocks_right.1.mlp.2.weight\", \"tape_heads.2.blocks_right.1.mlp.2.bias\", \"tape_heads.2.blocks_right.1.mlp.3.weight\", \"tape_heads.2.blocks_right.1.mlp.3.bias\", \"tape_heads.2.blocks_right.1.ln_mlp.weight\", \"tape_heads.2.blocks_right.1.ln_mlp.bias\", \"tape_heads.2.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.2.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.2.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.2.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.3.blocks_left.0.pos_emb\", \"tape_heads.3.blocks_left.0.unembedding\", \"tape_heads.3.blocks_left.0.token_emb.weight\", \"tape_heads.3.blocks_left.0.chunk_proj.weight\", \"tape_heads.3.blocks_left.0.chunk_proj.bias\", \"tape_heads.3.blocks_left.0.attn.in_proj_weight\", \"tape_heads.3.blocks_left.0.attn.in_proj_bias\", \"tape_heads.3.blocks_left.0.attn.out_proj.weight\", \"tape_heads.3.blocks_left.0.attn.out_proj.bias\", \"tape_heads.3.blocks_left.0.ln_attn.weight\", \"tape_heads.3.blocks_left.0.ln_attn.bias\", \"tape_heads.3.blocks_left.0.mlp.0.weight\", \"tape_heads.3.blocks_left.0.mlp.0.bias\", \"tape_heads.3.blocks_left.0.mlp.2.weight\", \"tape_heads.3.blocks_left.0.mlp.2.bias\", \"tape_heads.3.blocks_left.0.mlp.3.weight\", \"tape_heads.3.blocks_left.0.mlp.3.bias\", \"tape_heads.3.blocks_left.0.ln_mlp.weight\", \"tape_heads.3.blocks_left.0.ln_mlp.bias\", \"tape_heads.3.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.3.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.3.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.3.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.3.blocks_left.1.pos_emb\", \"tape_heads.3.blocks_left.1.unembedding\", \"tape_heads.3.blocks_left.1.token_emb.weight\", \"tape_heads.3.blocks_left.1.chunk_proj.weight\", \"tape_heads.3.blocks_left.1.chunk_proj.bias\", \"tape_heads.3.blocks_left.1.attn.in_proj_weight\", \"tape_heads.3.blocks_left.1.attn.in_proj_bias\", \"tape_heads.3.blocks_left.1.attn.out_proj.weight\", \"tape_heads.3.blocks_left.1.attn.out_proj.bias\", \"tape_heads.3.blocks_left.1.ln_attn.weight\", \"tape_heads.3.blocks_left.1.ln_attn.bias\", \"tape_heads.3.blocks_left.1.mlp.0.weight\", \"tape_heads.3.blocks_left.1.mlp.0.bias\", \"tape_heads.3.blocks_left.1.mlp.2.weight\", \"tape_heads.3.blocks_left.1.mlp.2.bias\", \"tape_heads.3.blocks_left.1.mlp.3.weight\", \"tape_heads.3.blocks_left.1.mlp.3.bias\", \"tape_heads.3.blocks_left.1.ln_mlp.weight\", \"tape_heads.3.blocks_left.1.ln_mlp.bias\", \"tape_heads.3.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.3.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.3.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.3.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.3.blocks_right.0.pos_emb\", \"tape_heads.3.blocks_right.0.unembedding\", \"tape_heads.3.blocks_right.0.token_emb.weight\", \"tape_heads.3.blocks_right.0.chunk_proj.weight\", \"tape_heads.3.blocks_right.0.chunk_proj.bias\", \"tape_heads.3.blocks_right.0.attn.in_proj_weight\", \"tape_heads.3.blocks_right.0.attn.in_proj_bias\", \"tape_heads.3.blocks_right.0.attn.out_proj.weight\", \"tape_heads.3.blocks_right.0.attn.out_proj.bias\", \"tape_heads.3.blocks_right.0.ln_attn.weight\", \"tape_heads.3.blocks_right.0.ln_attn.bias\", \"tape_heads.3.blocks_right.0.mlp.0.weight\", \"tape_heads.3.blocks_right.0.mlp.0.bias\", \"tape_heads.3.blocks_right.0.mlp.2.weight\", \"tape_heads.3.blocks_right.0.mlp.2.bias\", \"tape_heads.3.blocks_right.0.mlp.3.weight\", \"tape_heads.3.blocks_right.0.mlp.3.bias\", \"tape_heads.3.blocks_right.0.ln_mlp.weight\", \"tape_heads.3.blocks_right.0.ln_mlp.bias\", \"tape_heads.3.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.3.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.3.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.3.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.3.blocks_right.1.pos_emb\", \"tape_heads.3.blocks_right.1.unembedding\", \"tape_heads.3.blocks_right.1.token_emb.weight\", \"tape_heads.3.blocks_right.1.chunk_proj.weight\", \"tape_heads.3.blocks_right.1.chunk_proj.bias\", \"tape_heads.3.blocks_right.1.attn.in_proj_weight\", \"tape_heads.3.blocks_right.1.attn.in_proj_bias\", \"tape_heads.3.blocks_right.1.attn.out_proj.weight\", \"tape_heads.3.blocks_right.1.attn.out_proj.bias\", \"tape_heads.3.blocks_right.1.ln_attn.weight\", \"tape_heads.3.blocks_right.1.ln_attn.bias\", \"tape_heads.3.blocks_right.1.mlp.0.weight\", \"tape_heads.3.blocks_right.1.mlp.0.bias\", \"tape_heads.3.blocks_right.1.mlp.2.weight\", \"tape_heads.3.blocks_right.1.mlp.2.bias\", \"tape_heads.3.blocks_right.1.mlp.3.weight\", \"tape_heads.3.blocks_right.1.mlp.3.bias\", \"tape_heads.3.blocks_right.1.ln_mlp.weight\", \"tape_heads.3.blocks_right.1.ln_mlp.bias\", \"tape_heads.3.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.3.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.3.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.3.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.4.blocks_left.0.pos_emb\", \"tape_heads.4.blocks_left.0.unembedding\", \"tape_heads.4.blocks_left.0.token_emb.weight\", \"tape_heads.4.blocks_left.0.chunk_proj.weight\", \"tape_heads.4.blocks_left.0.chunk_proj.bias\", \"tape_heads.4.blocks_left.0.attn.in_proj_weight\", \"tape_heads.4.blocks_left.0.attn.in_proj_bias\", \"tape_heads.4.blocks_left.0.attn.out_proj.weight\", \"tape_heads.4.blocks_left.0.attn.out_proj.bias\", \"tape_heads.4.blocks_left.0.ln_attn.weight\", \"tape_heads.4.blocks_left.0.ln_attn.bias\", \"tape_heads.4.blocks_left.0.mlp.0.weight\", \"tape_heads.4.blocks_left.0.mlp.0.bias\", \"tape_heads.4.blocks_left.0.mlp.2.weight\", \"tape_heads.4.blocks_left.0.mlp.2.bias\", \"tape_heads.4.blocks_left.0.mlp.3.weight\", \"tape_heads.4.blocks_left.0.mlp.3.bias\", \"tape_heads.4.blocks_left.0.ln_mlp.weight\", \"tape_heads.4.blocks_left.0.ln_mlp.bias\", \"tape_heads.4.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.4.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.4.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.4.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.4.blocks_left.1.pos_emb\", \"tape_heads.4.blocks_left.1.unembedding\", \"tape_heads.4.blocks_left.1.token_emb.weight\", \"tape_heads.4.blocks_left.1.chunk_proj.weight\", \"tape_heads.4.blocks_left.1.chunk_proj.bias\", \"tape_heads.4.blocks_left.1.attn.in_proj_weight\", \"tape_heads.4.blocks_left.1.attn.in_proj_bias\", \"tape_heads.4.blocks_left.1.attn.out_proj.weight\", \"tape_heads.4.blocks_left.1.attn.out_proj.bias\", \"tape_heads.4.blocks_left.1.ln_attn.weight\", \"tape_heads.4.blocks_left.1.ln_attn.bias\", \"tape_heads.4.blocks_left.1.mlp.0.weight\", \"tape_heads.4.blocks_left.1.mlp.0.bias\", \"tape_heads.4.blocks_left.1.mlp.2.weight\", \"tape_heads.4.blocks_left.1.mlp.2.bias\", \"tape_heads.4.blocks_left.1.mlp.3.weight\", \"tape_heads.4.blocks_left.1.mlp.3.bias\", \"tape_heads.4.blocks_left.1.ln_mlp.weight\", \"tape_heads.4.blocks_left.1.ln_mlp.bias\", \"tape_heads.4.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.4.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.4.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.4.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.4.blocks_right.0.pos_emb\", \"tape_heads.4.blocks_right.0.unembedding\", \"tape_heads.4.blocks_right.0.token_emb.weight\", \"tape_heads.4.blocks_right.0.chunk_proj.weight\", \"tape_heads.4.blocks_right.0.chunk_proj.bias\", \"tape_heads.4.blocks_right.0.attn.in_proj_weight\", \"tape_heads.4.blocks_right.0.attn.in_proj_bias\", \"tape_heads.4.blocks_right.0.attn.out_proj.weight\", \"tape_heads.4.blocks_right.0.attn.out_proj.bias\", \"tape_heads.4.blocks_right.0.ln_attn.weight\", \"tape_heads.4.blocks_right.0.ln_attn.bias\", \"tape_heads.4.blocks_right.0.mlp.0.weight\", \"tape_heads.4.blocks_right.0.mlp.0.bias\", \"tape_heads.4.blocks_right.0.mlp.2.weight\", \"tape_heads.4.blocks_right.0.mlp.2.bias\", \"tape_heads.4.blocks_right.0.mlp.3.weight\", \"tape_heads.4.blocks_right.0.mlp.3.bias\", \"tape_heads.4.blocks_right.0.ln_mlp.weight\", \"tape_heads.4.blocks_right.0.ln_mlp.bias\", \"tape_heads.4.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.4.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.4.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.4.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.4.blocks_right.1.pos_emb\", \"tape_heads.4.blocks_right.1.unembedding\", \"tape_heads.4.blocks_right.1.token_emb.weight\", \"tape_heads.4.blocks_right.1.chunk_proj.weight\", \"tape_heads.4.blocks_right.1.chunk_proj.bias\", \"tape_heads.4.blocks_right.1.attn.in_proj_weight\", \"tape_heads.4.blocks_right.1.attn.in_proj_bias\", \"tape_heads.4.blocks_right.1.attn.out_proj.weight\", \"tape_heads.4.blocks_right.1.attn.out_proj.bias\", \"tape_heads.4.blocks_right.1.ln_attn.weight\", \"tape_heads.4.blocks_right.1.ln_attn.bias\", \"tape_heads.4.blocks_right.1.mlp.0.weight\", \"tape_heads.4.blocks_right.1.mlp.0.bias\", \"tape_heads.4.blocks_right.1.mlp.2.weight\", \"tape_heads.4.blocks_right.1.mlp.2.bias\", \"tape_heads.4.blocks_right.1.mlp.3.weight\", \"tape_heads.4.blocks_right.1.mlp.3.bias\", \"tape_heads.4.blocks_right.1.ln_mlp.weight\", \"tape_heads.4.blocks_right.1.ln_mlp.bias\", \"tape_heads.4.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.4.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.4.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.4.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.5.blocks_left.0.pos_emb\", \"tape_heads.5.blocks_left.0.unembedding\", \"tape_heads.5.blocks_left.0.token_emb.weight\", \"tape_heads.5.blocks_left.0.chunk_proj.weight\", \"tape_heads.5.blocks_left.0.chunk_proj.bias\", \"tape_heads.5.blocks_left.0.attn.in_proj_weight\", \"tape_heads.5.blocks_left.0.attn.in_proj_bias\", \"tape_heads.5.blocks_left.0.attn.out_proj.weight\", \"tape_heads.5.blocks_left.0.attn.out_proj.bias\", \"tape_heads.5.blocks_left.0.ln_attn.weight\", \"tape_heads.5.blocks_left.0.ln_attn.bias\", \"tape_heads.5.blocks_left.0.mlp.0.weight\", \"tape_heads.5.blocks_left.0.mlp.0.bias\", \"tape_heads.5.blocks_left.0.mlp.2.weight\", \"tape_heads.5.blocks_left.0.mlp.2.bias\", \"tape_heads.5.blocks_left.0.mlp.3.weight\", \"tape_heads.5.blocks_left.0.mlp.3.bias\", \"tape_heads.5.blocks_left.0.ln_mlp.weight\", \"tape_heads.5.blocks_left.0.ln_mlp.bias\", \"tape_heads.5.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.5.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.5.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.5.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.5.blocks_left.1.pos_emb\", \"tape_heads.5.blocks_left.1.unembedding\", \"tape_heads.5.blocks_left.1.token_emb.weight\", \"tape_heads.5.blocks_left.1.chunk_proj.weight\", \"tape_heads.5.blocks_left.1.chunk_proj.bias\", \"tape_heads.5.blocks_left.1.attn.in_proj_weight\", \"tape_heads.5.blocks_left.1.attn.in_proj_bias\", \"tape_heads.5.blocks_left.1.attn.out_proj.weight\", \"tape_heads.5.blocks_left.1.attn.out_proj.bias\", \"tape_heads.5.blocks_left.1.ln_attn.weight\", \"tape_heads.5.blocks_left.1.ln_attn.bias\", \"tape_heads.5.blocks_left.1.mlp.0.weight\", \"tape_heads.5.blocks_left.1.mlp.0.bias\", \"tape_heads.5.blocks_left.1.mlp.2.weight\", \"tape_heads.5.blocks_left.1.mlp.2.bias\", \"tape_heads.5.blocks_left.1.mlp.3.weight\", \"tape_heads.5.blocks_left.1.mlp.3.bias\", \"tape_heads.5.blocks_left.1.ln_mlp.weight\", \"tape_heads.5.blocks_left.1.ln_mlp.bias\", \"tape_heads.5.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.5.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.5.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.5.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.5.blocks_right.0.pos_emb\", \"tape_heads.5.blocks_right.0.unembedding\", \"tape_heads.5.blocks_right.0.token_emb.weight\", \"tape_heads.5.blocks_right.0.chunk_proj.weight\", \"tape_heads.5.blocks_right.0.chunk_proj.bias\", \"tape_heads.5.blocks_right.0.attn.in_proj_weight\", \"tape_heads.5.blocks_right.0.attn.in_proj_bias\", \"tape_heads.5.blocks_right.0.attn.out_proj.weight\", \"tape_heads.5.blocks_right.0.attn.out_proj.bias\", \"tape_heads.5.blocks_right.0.ln_attn.weight\", \"tape_heads.5.blocks_right.0.ln_attn.bias\", \"tape_heads.5.blocks_right.0.mlp.0.weight\", \"tape_heads.5.blocks_right.0.mlp.0.bias\", \"tape_heads.5.blocks_right.0.mlp.2.weight\", \"tape_heads.5.blocks_right.0.mlp.2.bias\", \"tape_heads.5.blocks_right.0.mlp.3.weight\", \"tape_heads.5.blocks_right.0.mlp.3.bias\", \"tape_heads.5.blocks_right.0.ln_mlp.weight\", \"tape_heads.5.blocks_right.0.ln_mlp.bias\", \"tape_heads.5.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.5.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.5.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.5.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.5.blocks_right.1.pos_emb\", \"tape_heads.5.blocks_right.1.unembedding\", \"tape_heads.5.blocks_right.1.token_emb.weight\", \"tape_heads.5.blocks_right.1.chunk_proj.weight\", \"tape_heads.5.blocks_right.1.chunk_proj.bias\", \"tape_heads.5.blocks_right.1.attn.in_proj_weight\", \"tape_heads.5.blocks_right.1.attn.in_proj_bias\", \"tape_heads.5.blocks_right.1.attn.out_proj.weight\", \"tape_heads.5.blocks_right.1.attn.out_proj.bias\", \"tape_heads.5.blocks_right.1.ln_attn.weight\", \"tape_heads.5.blocks_right.1.ln_attn.bias\", \"tape_heads.5.blocks_right.1.mlp.0.weight\", \"tape_heads.5.blocks_right.1.mlp.0.bias\", \"tape_heads.5.blocks_right.1.mlp.2.weight\", \"tape_heads.5.blocks_right.1.mlp.2.bias\", \"tape_heads.5.blocks_right.1.mlp.3.weight\", \"tape_heads.5.blocks_right.1.mlp.3.bias\", \"tape_heads.5.blocks_right.1.ln_mlp.weight\", \"tape_heads.5.blocks_right.1.ln_mlp.bias\", \"tape_heads.5.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.5.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.5.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.5.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.6.blocks_left.0.pos_emb\", \"tape_heads.6.blocks_left.0.unembedding\", \"tape_heads.6.blocks_left.0.token_emb.weight\", \"tape_heads.6.blocks_left.0.chunk_proj.weight\", \"tape_heads.6.blocks_left.0.chunk_proj.bias\", \"tape_heads.6.blocks_left.0.attn.in_proj_weight\", \"tape_heads.6.blocks_left.0.attn.in_proj_bias\", \"tape_heads.6.blocks_left.0.attn.out_proj.weight\", \"tape_heads.6.blocks_left.0.attn.out_proj.bias\", \"tape_heads.6.blocks_left.0.ln_attn.weight\", \"tape_heads.6.blocks_left.0.ln_attn.bias\", \"tape_heads.6.blocks_left.0.mlp.0.weight\", \"tape_heads.6.blocks_left.0.mlp.0.bias\", \"tape_heads.6.blocks_left.0.mlp.2.weight\", \"tape_heads.6.blocks_left.0.mlp.2.bias\", \"tape_heads.6.blocks_left.0.mlp.3.weight\", \"tape_heads.6.blocks_left.0.mlp.3.bias\", \"tape_heads.6.blocks_left.0.ln_mlp.weight\", \"tape_heads.6.blocks_left.0.ln_mlp.bias\", \"tape_heads.6.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.6.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.6.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.6.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.6.blocks_left.1.pos_emb\", \"tape_heads.6.blocks_left.1.unembedding\", \"tape_heads.6.blocks_left.1.token_emb.weight\", \"tape_heads.6.blocks_left.1.chunk_proj.weight\", \"tape_heads.6.blocks_left.1.chunk_proj.bias\", \"tape_heads.6.blocks_left.1.attn.in_proj_weight\", \"tape_heads.6.blocks_left.1.attn.in_proj_bias\", \"tape_heads.6.blocks_left.1.attn.out_proj.weight\", \"tape_heads.6.blocks_left.1.attn.out_proj.bias\", \"tape_heads.6.blocks_left.1.ln_attn.weight\", \"tape_heads.6.blocks_left.1.ln_attn.bias\", \"tape_heads.6.blocks_left.1.mlp.0.weight\", \"tape_heads.6.blocks_left.1.mlp.0.bias\", \"tape_heads.6.blocks_left.1.mlp.2.weight\", \"tape_heads.6.blocks_left.1.mlp.2.bias\", \"tape_heads.6.blocks_left.1.mlp.3.weight\", \"tape_heads.6.blocks_left.1.mlp.3.bias\", \"tape_heads.6.blocks_left.1.ln_mlp.weight\", \"tape_heads.6.blocks_left.1.ln_mlp.bias\", \"tape_heads.6.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.6.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.6.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.6.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.6.blocks_right.0.pos_emb\", \"tape_heads.6.blocks_right.0.unembedding\", \"tape_heads.6.blocks_right.0.token_emb.weight\", \"tape_heads.6.blocks_right.0.chunk_proj.weight\", \"tape_heads.6.blocks_right.0.chunk_proj.bias\", \"tape_heads.6.blocks_right.0.attn.in_proj_weight\", \"tape_heads.6.blocks_right.0.attn.in_proj_bias\", \"tape_heads.6.blocks_right.0.attn.out_proj.weight\", \"tape_heads.6.blocks_right.0.attn.out_proj.bias\", \"tape_heads.6.blocks_right.0.ln_attn.weight\", \"tape_heads.6.blocks_right.0.ln_attn.bias\", \"tape_heads.6.blocks_right.0.mlp.0.weight\", \"tape_heads.6.blocks_right.0.mlp.0.bias\", \"tape_heads.6.blocks_right.0.mlp.2.weight\", \"tape_heads.6.blocks_right.0.mlp.2.bias\", \"tape_heads.6.blocks_right.0.mlp.3.weight\", \"tape_heads.6.blocks_right.0.mlp.3.bias\", \"tape_heads.6.blocks_right.0.ln_mlp.weight\", \"tape_heads.6.blocks_right.0.ln_mlp.bias\", \"tape_heads.6.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.6.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.6.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.6.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.6.blocks_right.1.pos_emb\", \"tape_heads.6.blocks_right.1.unembedding\", \"tape_heads.6.blocks_right.1.token_emb.weight\", \"tape_heads.6.blocks_right.1.chunk_proj.weight\", \"tape_heads.6.blocks_right.1.chunk_proj.bias\", \"tape_heads.6.blocks_right.1.attn.in_proj_weight\", \"tape_heads.6.blocks_right.1.attn.in_proj_bias\", \"tape_heads.6.blocks_right.1.attn.out_proj.weight\", \"tape_heads.6.blocks_right.1.attn.out_proj.bias\", \"tape_heads.6.blocks_right.1.ln_attn.weight\", \"tape_heads.6.blocks_right.1.ln_attn.bias\", \"tape_heads.6.blocks_right.1.mlp.0.weight\", \"tape_heads.6.blocks_right.1.mlp.0.bias\", \"tape_heads.6.blocks_right.1.mlp.2.weight\", \"tape_heads.6.blocks_right.1.mlp.2.bias\", \"tape_heads.6.blocks_right.1.mlp.3.weight\", \"tape_heads.6.blocks_right.1.mlp.3.bias\", \"tape_heads.6.blocks_right.1.ln_mlp.weight\", \"tape_heads.6.blocks_right.1.ln_mlp.bias\", \"tape_heads.6.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.6.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.6.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.6.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.7.blocks_left.0.pos_emb\", \"tape_heads.7.blocks_left.0.unembedding\", \"tape_heads.7.blocks_left.0.token_emb.weight\", \"tape_heads.7.blocks_left.0.chunk_proj.weight\", \"tape_heads.7.blocks_left.0.chunk_proj.bias\", \"tape_heads.7.blocks_left.0.attn.in_proj_weight\", \"tape_heads.7.blocks_left.0.attn.in_proj_bias\", \"tape_heads.7.blocks_left.0.attn.out_proj.weight\", \"tape_heads.7.blocks_left.0.attn.out_proj.bias\", \"tape_heads.7.blocks_left.0.ln_attn.weight\", \"tape_heads.7.blocks_left.0.ln_attn.bias\", \"tape_heads.7.blocks_left.0.mlp.0.weight\", \"tape_heads.7.blocks_left.0.mlp.0.bias\", \"tape_heads.7.blocks_left.0.mlp.2.weight\", \"tape_heads.7.blocks_left.0.mlp.2.bias\", \"tape_heads.7.blocks_left.0.mlp.3.weight\", \"tape_heads.7.blocks_left.0.mlp.3.bias\", \"tape_heads.7.blocks_left.0.ln_mlp.weight\", \"tape_heads.7.blocks_left.0.ln_mlp.bias\", \"tape_heads.7.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.7.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.7.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.7.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.7.blocks_left.1.pos_emb\", \"tape_heads.7.blocks_left.1.unembedding\", \"tape_heads.7.blocks_left.1.token_emb.weight\", \"tape_heads.7.blocks_left.1.chunk_proj.weight\", \"tape_heads.7.blocks_left.1.chunk_proj.bias\", \"tape_heads.7.blocks_left.1.attn.in_proj_weight\", \"tape_heads.7.blocks_left.1.attn.in_proj_bias\", \"tape_heads.7.blocks_left.1.attn.out_proj.weight\", \"tape_heads.7.blocks_left.1.attn.out_proj.bias\", \"tape_heads.7.blocks_left.1.ln_attn.weight\", \"tape_heads.7.blocks_left.1.ln_attn.bias\", \"tape_heads.7.blocks_left.1.mlp.0.weight\", \"tape_heads.7.blocks_left.1.mlp.0.bias\", \"tape_heads.7.blocks_left.1.mlp.2.weight\", \"tape_heads.7.blocks_left.1.mlp.2.bias\", \"tape_heads.7.blocks_left.1.mlp.3.weight\", \"tape_heads.7.blocks_left.1.mlp.3.bias\", \"tape_heads.7.blocks_left.1.ln_mlp.weight\", \"tape_heads.7.blocks_left.1.ln_mlp.bias\", \"tape_heads.7.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.7.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.7.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.7.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.7.blocks_right.0.pos_emb\", \"tape_heads.7.blocks_right.0.unembedding\", \"tape_heads.7.blocks_right.0.token_emb.weight\", \"tape_heads.7.blocks_right.0.chunk_proj.weight\", \"tape_heads.7.blocks_right.0.chunk_proj.bias\", \"tape_heads.7.blocks_right.0.attn.in_proj_weight\", \"tape_heads.7.blocks_right.0.attn.in_proj_bias\", \"tape_heads.7.blocks_right.0.attn.out_proj.weight\", \"tape_heads.7.blocks_right.0.attn.out_proj.bias\", \"tape_heads.7.blocks_right.0.ln_attn.weight\", \"tape_heads.7.blocks_right.0.ln_attn.bias\", \"tape_heads.7.blocks_right.0.mlp.0.weight\", \"tape_heads.7.blocks_right.0.mlp.0.bias\", \"tape_heads.7.blocks_right.0.mlp.2.weight\", \"tape_heads.7.blocks_right.0.mlp.2.bias\", \"tape_heads.7.blocks_right.0.mlp.3.weight\", \"tape_heads.7.blocks_right.0.mlp.3.bias\", \"tape_heads.7.blocks_right.0.ln_mlp.weight\", \"tape_heads.7.blocks_right.0.ln_mlp.bias\", \"tape_heads.7.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.7.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.7.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.7.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.7.blocks_right.1.pos_emb\", \"tape_heads.7.blocks_right.1.unembedding\", \"tape_heads.7.blocks_right.1.token_emb.weight\", \"tape_heads.7.blocks_right.1.chunk_proj.weight\", \"tape_heads.7.blocks_right.1.chunk_proj.bias\", \"tape_heads.7.blocks_right.1.attn.in_proj_weight\", \"tape_heads.7.blocks_right.1.attn.in_proj_bias\", \"tape_heads.7.blocks_right.1.attn.out_proj.weight\", \"tape_heads.7.blocks_right.1.attn.out_proj.bias\", \"tape_heads.7.blocks_right.1.ln_attn.weight\", \"tape_heads.7.blocks_right.1.ln_attn.bias\", \"tape_heads.7.blocks_right.1.mlp.0.weight\", \"tape_heads.7.blocks_right.1.mlp.0.bias\", \"tape_heads.7.blocks_right.1.mlp.2.weight\", \"tape_heads.7.blocks_right.1.mlp.2.bias\", \"tape_heads.7.blocks_right.1.mlp.3.weight\", \"tape_heads.7.blocks_right.1.mlp.3.bias\", \"tape_heads.7.blocks_right.1.ln_mlp.weight\", \"tape_heads.7.blocks_right.1.ln_mlp.bias\", \"tape_heads.7.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.7.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.7.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.7.blocks_right.1.logits_attention.out_proj.bias\", \"merge_projection.weight\", \"merge_projection.bias\". \n\tUnexpected key(s) in state_dict: \"pos_emb\", \"token_emb.weight\", \"tape_heads.0.blocks.0.unembedding\", \"tape_heads.0.blocks.0.chunk_proj.weight\", \"tape_heads.0.blocks.0.chunk_proj.bias\", \"tape_heads.0.blocks.0.attn.in_proj_weight\", \"tape_heads.0.blocks.0.attn.in_proj_bias\", \"tape_heads.0.blocks.0.attn.out_proj.weight\", \"tape_heads.0.blocks.0.attn.out_proj.bias\", \"tape_heads.0.blocks.0.ln_attn.weight\", \"tape_heads.0.blocks.0.ln_attn.bias\", \"tape_heads.0.blocks.0.mlp.0.weight\", \"tape_heads.0.blocks.0.mlp.0.bias\", \"tape_heads.0.blocks.0.mlp.2.weight\", \"tape_heads.0.blocks.0.mlp.2.bias\", \"tape_heads.0.blocks.0.mlp.3.weight\", \"tape_heads.0.blocks.0.mlp.3.bias\", \"tape_heads.0.blocks.0.ln_mlp.weight\", \"tape_heads.0.blocks.0.ln_mlp.bias\", \"tape_heads.0.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.0.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.0.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.0.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.0.blocks.1.unembedding\", \"tape_heads.0.blocks.1.chunk_proj.weight\", \"tape_heads.0.blocks.1.chunk_proj.bias\", \"tape_heads.0.blocks.1.attn.in_proj_weight\", \"tape_heads.0.blocks.1.attn.in_proj_bias\", \"tape_heads.0.blocks.1.attn.out_proj.weight\", \"tape_heads.0.blocks.1.attn.out_proj.bias\", \"tape_heads.0.blocks.1.ln_attn.weight\", \"tape_heads.0.blocks.1.ln_attn.bias\", \"tape_heads.0.blocks.1.mlp.0.weight\", \"tape_heads.0.blocks.1.mlp.0.bias\", \"tape_heads.0.blocks.1.mlp.2.weight\", \"tape_heads.0.blocks.1.mlp.2.bias\", \"tape_heads.0.blocks.1.mlp.3.weight\", \"tape_heads.0.blocks.1.mlp.3.bias\", \"tape_heads.0.blocks.1.ln_mlp.weight\", \"tape_heads.0.blocks.1.ln_mlp.bias\", \"tape_heads.0.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.0.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.0.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.0.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.1.blocks.0.unembedding\", \"tape_heads.1.blocks.0.chunk_proj.weight\", \"tape_heads.1.blocks.0.chunk_proj.bias\", \"tape_heads.1.blocks.0.attn.in_proj_weight\", \"tape_heads.1.blocks.0.attn.in_proj_bias\", \"tape_heads.1.blocks.0.attn.out_proj.weight\", \"tape_heads.1.blocks.0.attn.out_proj.bias\", \"tape_heads.1.blocks.0.ln_attn.weight\", \"tape_heads.1.blocks.0.ln_attn.bias\", \"tape_heads.1.blocks.0.mlp.0.weight\", \"tape_heads.1.blocks.0.mlp.0.bias\", \"tape_heads.1.blocks.0.mlp.2.weight\", \"tape_heads.1.blocks.0.mlp.2.bias\", \"tape_heads.1.blocks.0.mlp.3.weight\", \"tape_heads.1.blocks.0.mlp.3.bias\", \"tape_heads.1.blocks.0.ln_mlp.weight\", \"tape_heads.1.blocks.0.ln_mlp.bias\", \"tape_heads.1.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.1.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.1.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.1.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.1.blocks.1.unembedding\", \"tape_heads.1.blocks.1.chunk_proj.weight\", \"tape_heads.1.blocks.1.chunk_proj.bias\", \"tape_heads.1.blocks.1.attn.in_proj_weight\", \"tape_heads.1.blocks.1.attn.in_proj_bias\", \"tape_heads.1.blocks.1.attn.out_proj.weight\", \"tape_heads.1.blocks.1.attn.out_proj.bias\", \"tape_heads.1.blocks.1.ln_attn.weight\", \"tape_heads.1.blocks.1.ln_attn.bias\", \"tape_heads.1.blocks.1.mlp.0.weight\", \"tape_heads.1.blocks.1.mlp.0.bias\", \"tape_heads.1.blocks.1.mlp.2.weight\", \"tape_heads.1.blocks.1.mlp.2.bias\", \"tape_heads.1.blocks.1.mlp.3.weight\", \"tape_heads.1.blocks.1.mlp.3.bias\", \"tape_heads.1.blocks.1.ln_mlp.weight\", \"tape_heads.1.blocks.1.ln_mlp.bias\", \"tape_heads.1.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.1.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.1.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.1.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.2.blocks.0.unembedding\", \"tape_heads.2.blocks.0.chunk_proj.weight\", \"tape_heads.2.blocks.0.chunk_proj.bias\", \"tape_heads.2.blocks.0.attn.in_proj_weight\", \"tape_heads.2.blocks.0.attn.in_proj_bias\", \"tape_heads.2.blocks.0.attn.out_proj.weight\", \"tape_heads.2.blocks.0.attn.out_proj.bias\", \"tape_heads.2.blocks.0.ln_attn.weight\", \"tape_heads.2.blocks.0.ln_attn.bias\", \"tape_heads.2.blocks.0.mlp.0.weight\", \"tape_heads.2.blocks.0.mlp.0.bias\", \"tape_heads.2.blocks.0.mlp.2.weight\", \"tape_heads.2.blocks.0.mlp.2.bias\", \"tape_heads.2.blocks.0.mlp.3.weight\", \"tape_heads.2.blocks.0.mlp.3.bias\", \"tape_heads.2.blocks.0.ln_mlp.weight\", \"tape_heads.2.blocks.0.ln_mlp.bias\", \"tape_heads.2.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.2.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.2.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.2.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.2.blocks.1.unembedding\", \"tape_heads.2.blocks.1.chunk_proj.weight\", \"tape_heads.2.blocks.1.chunk_proj.bias\", \"tape_heads.2.blocks.1.attn.in_proj_weight\", \"tape_heads.2.blocks.1.attn.in_proj_bias\", \"tape_heads.2.blocks.1.attn.out_proj.weight\", \"tape_heads.2.blocks.1.attn.out_proj.bias\", \"tape_heads.2.blocks.1.ln_attn.weight\", \"tape_heads.2.blocks.1.ln_attn.bias\", \"tape_heads.2.blocks.1.mlp.0.weight\", \"tape_heads.2.blocks.1.mlp.0.bias\", \"tape_heads.2.blocks.1.mlp.2.weight\", \"tape_heads.2.blocks.1.mlp.2.bias\", \"tape_heads.2.blocks.1.mlp.3.weight\", \"tape_heads.2.blocks.1.mlp.3.bias\", \"tape_heads.2.blocks.1.ln_mlp.weight\", \"tape_heads.2.blocks.1.ln_mlp.bias\", \"tape_heads.2.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.2.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.2.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.2.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.3.blocks.0.unembedding\", \"tape_heads.3.blocks.0.chunk_proj.weight\", \"tape_heads.3.blocks.0.chunk_proj.bias\", \"tape_heads.3.blocks.0.attn.in_proj_weight\", \"tape_heads.3.blocks.0.attn.in_proj_bias\", \"tape_heads.3.blocks.0.attn.out_proj.weight\", \"tape_heads.3.blocks.0.attn.out_proj.bias\", \"tape_heads.3.blocks.0.ln_attn.weight\", \"tape_heads.3.blocks.0.ln_attn.bias\", \"tape_heads.3.blocks.0.mlp.0.weight\", \"tape_heads.3.blocks.0.mlp.0.bias\", \"tape_heads.3.blocks.0.mlp.2.weight\", \"tape_heads.3.blocks.0.mlp.2.bias\", \"tape_heads.3.blocks.0.mlp.3.weight\", \"tape_heads.3.blocks.0.mlp.3.bias\", \"tape_heads.3.blocks.0.ln_mlp.weight\", \"tape_heads.3.blocks.0.ln_mlp.bias\", \"tape_heads.3.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.3.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.3.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.3.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.3.blocks.1.unembedding\", \"tape_heads.3.blocks.1.chunk_proj.weight\", \"tape_heads.3.blocks.1.chunk_proj.bias\", \"tape_heads.3.blocks.1.attn.in_proj_weight\", \"tape_heads.3.blocks.1.attn.in_proj_bias\", \"tape_heads.3.blocks.1.attn.out_proj.weight\", \"tape_heads.3.blocks.1.attn.out_proj.bias\", \"tape_heads.3.blocks.1.ln_attn.weight\", \"tape_heads.3.blocks.1.ln_attn.bias\", \"tape_heads.3.blocks.1.mlp.0.weight\", \"tape_heads.3.blocks.1.mlp.0.bias\", \"tape_heads.3.blocks.1.mlp.2.weight\", \"tape_heads.3.blocks.1.mlp.2.bias\", \"tape_heads.3.blocks.1.mlp.3.weight\", \"tape_heads.3.blocks.1.mlp.3.bias\", \"tape_heads.3.blocks.1.ln_mlp.weight\", \"tape_heads.3.blocks.1.ln_mlp.bias\", \"tape_heads.3.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.3.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.3.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.3.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.4.blocks.0.unembedding\", \"tape_heads.4.blocks.0.chunk_proj.weight\", \"tape_heads.4.blocks.0.chunk_proj.bias\", \"tape_heads.4.blocks.0.attn.in_proj_weight\", \"tape_heads.4.blocks.0.attn.in_proj_bias\", \"tape_heads.4.blocks.0.attn.out_proj.weight\", \"tape_heads.4.blocks.0.attn.out_proj.bias\", \"tape_heads.4.blocks.0.ln_attn.weight\", \"tape_heads.4.blocks.0.ln_attn.bias\", \"tape_heads.4.blocks.0.mlp.0.weight\", \"tape_heads.4.blocks.0.mlp.0.bias\", \"tape_heads.4.blocks.0.mlp.2.weight\", \"tape_heads.4.blocks.0.mlp.2.bias\", \"tape_heads.4.blocks.0.mlp.3.weight\", \"tape_heads.4.blocks.0.mlp.3.bias\", \"tape_heads.4.blocks.0.ln_mlp.weight\", \"tape_heads.4.blocks.0.ln_mlp.bias\", \"tape_heads.4.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.4.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.4.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.4.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.4.blocks.1.unembedding\", \"tape_heads.4.blocks.1.chunk_proj.weight\", \"tape_heads.4.blocks.1.chunk_proj.bias\", \"tape_heads.4.blocks.1.attn.in_proj_weight\", \"tape_heads.4.blocks.1.attn.in_proj_bias\", \"tape_heads.4.blocks.1.attn.out_proj.weight\", \"tape_heads.4.blocks.1.attn.out_proj.bias\", \"tape_heads.4.blocks.1.ln_attn.weight\", \"tape_heads.4.blocks.1.ln_attn.bias\", \"tape_heads.4.blocks.1.mlp.0.weight\", \"tape_heads.4.blocks.1.mlp.0.bias\", \"tape_heads.4.blocks.1.mlp.2.weight\", \"tape_heads.4.blocks.1.mlp.2.bias\", \"tape_heads.4.blocks.1.mlp.3.weight\", \"tape_heads.4.blocks.1.mlp.3.bias\", \"tape_heads.4.blocks.1.ln_mlp.weight\", \"tape_heads.4.blocks.1.ln_mlp.bias\", \"tape_heads.4.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.4.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.4.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.4.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.5.blocks.0.unembedding\", \"tape_heads.5.blocks.0.chunk_proj.weight\", \"tape_heads.5.blocks.0.chunk_proj.bias\", \"tape_heads.5.blocks.0.attn.in_proj_weight\", \"tape_heads.5.blocks.0.attn.in_proj_bias\", \"tape_heads.5.blocks.0.attn.out_proj.weight\", \"tape_heads.5.blocks.0.attn.out_proj.bias\", \"tape_heads.5.blocks.0.ln_attn.weight\", \"tape_heads.5.blocks.0.ln_attn.bias\", \"tape_heads.5.blocks.0.mlp.0.weight\", \"tape_heads.5.blocks.0.mlp.0.bias\", \"tape_heads.5.blocks.0.mlp.2.weight\", \"tape_heads.5.blocks.0.mlp.2.bias\", \"tape_heads.5.blocks.0.mlp.3.weight\", \"tape_heads.5.blocks.0.mlp.3.bias\", \"tape_heads.5.blocks.0.ln_mlp.weight\", \"tape_heads.5.blocks.0.ln_mlp.bias\", \"tape_heads.5.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.5.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.5.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.5.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.5.blocks.1.unembedding\", \"tape_heads.5.blocks.1.chunk_proj.weight\", \"tape_heads.5.blocks.1.chunk_proj.bias\", \"tape_heads.5.blocks.1.attn.in_proj_weight\", \"tape_heads.5.blocks.1.attn.in_proj_bias\", \"tape_heads.5.blocks.1.attn.out_proj.weight\", \"tape_heads.5.blocks.1.attn.out_proj.bias\", \"tape_heads.5.blocks.1.ln_attn.weight\", \"tape_heads.5.blocks.1.ln_attn.bias\", \"tape_heads.5.blocks.1.mlp.0.weight\", \"tape_heads.5.blocks.1.mlp.0.bias\", \"tape_heads.5.blocks.1.mlp.2.weight\", \"tape_heads.5.blocks.1.mlp.2.bias\", \"tape_heads.5.blocks.1.mlp.3.weight\", \"tape_heads.5.blocks.1.mlp.3.bias\", \"tape_heads.5.blocks.1.ln_mlp.weight\", \"tape_heads.5.blocks.1.ln_mlp.bias\", \"tape_heads.5.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.5.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.5.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.5.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.6.blocks.0.unembedding\", \"tape_heads.6.blocks.0.chunk_proj.weight\", \"tape_heads.6.blocks.0.chunk_proj.bias\", \"tape_heads.6.blocks.0.attn.in_proj_weight\", \"tape_heads.6.blocks.0.attn.in_proj_bias\", \"tape_heads.6.blocks.0.attn.out_proj.weight\", \"tape_heads.6.blocks.0.attn.out_proj.bias\", \"tape_heads.6.blocks.0.ln_attn.weight\", \"tape_heads.6.blocks.0.ln_attn.bias\", \"tape_heads.6.blocks.0.mlp.0.weight\", \"tape_heads.6.blocks.0.mlp.0.bias\", \"tape_heads.6.blocks.0.mlp.2.weight\", \"tape_heads.6.blocks.0.mlp.2.bias\", \"tape_heads.6.blocks.0.mlp.3.weight\", \"tape_heads.6.blocks.0.mlp.3.bias\", \"tape_heads.6.blocks.0.ln_mlp.weight\", \"tape_heads.6.blocks.0.ln_mlp.bias\", \"tape_heads.6.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.6.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.6.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.6.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.6.blocks.1.unembedding\", \"tape_heads.6.blocks.1.chunk_proj.weight\", \"tape_heads.6.blocks.1.chunk_proj.bias\", \"tape_heads.6.blocks.1.attn.in_proj_weight\", \"tape_heads.6.blocks.1.attn.in_proj_bias\", \"tape_heads.6.blocks.1.attn.out_proj.weight\", \"tape_heads.6.blocks.1.attn.out_proj.bias\", \"tape_heads.6.blocks.1.ln_attn.weight\", \"tape_heads.6.blocks.1.ln_attn.bias\", \"tape_heads.6.blocks.1.mlp.0.weight\", \"tape_heads.6.blocks.1.mlp.0.bias\", \"tape_heads.6.blocks.1.mlp.2.weight\", \"tape_heads.6.blocks.1.mlp.2.bias\", \"tape_heads.6.blocks.1.mlp.3.weight\", \"tape_heads.6.blocks.1.mlp.3.bias\", \"tape_heads.6.blocks.1.ln_mlp.weight\", \"tape_heads.6.blocks.1.ln_mlp.bias\", \"tape_heads.6.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.6.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.6.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.6.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.7.blocks.0.unembedding\", \"tape_heads.7.blocks.0.chunk_proj.weight\", \"tape_heads.7.blocks.0.chunk_proj.bias\", \"tape_heads.7.blocks.0.attn.in_proj_weight\", \"tape_heads.7.blocks.0.attn.in_proj_bias\", \"tape_heads.7.blocks.0.attn.out_proj.weight\", \"tape_heads.7.blocks.0.attn.out_proj.bias\", \"tape_heads.7.blocks.0.ln_attn.weight\", \"tape_heads.7.blocks.0.ln_attn.bias\", \"tape_heads.7.blocks.0.mlp.0.weight\", \"tape_heads.7.blocks.0.mlp.0.bias\", \"tape_heads.7.blocks.0.mlp.2.weight\", \"tape_heads.7.blocks.0.mlp.2.bias\", \"tape_heads.7.blocks.0.mlp.3.weight\", \"tape_heads.7.blocks.0.mlp.3.bias\", \"tape_heads.7.blocks.0.ln_mlp.weight\", \"tape_heads.7.blocks.0.ln_mlp.bias\", \"tape_heads.7.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.7.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.7.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.7.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.7.blocks.1.unembedding\", \"tape_heads.7.blocks.1.chunk_proj.weight\", \"tape_heads.7.blocks.1.chunk_proj.bias\", \"tape_heads.7.blocks.1.attn.in_proj_weight\", \"tape_heads.7.blocks.1.attn.in_proj_bias\", \"tape_heads.7.blocks.1.attn.out_proj.weight\", \"tape_heads.7.blocks.1.attn.out_proj.bias\", \"tape_heads.7.blocks.1.ln_attn.weight\", \"tape_heads.7.blocks.1.ln_attn.bias\", \"tape_heads.7.blocks.1.mlp.0.weight\", \"tape_heads.7.blocks.1.mlp.0.bias\", \"tape_heads.7.blocks.1.mlp.2.weight\", \"tape_heads.7.blocks.1.mlp.2.bias\", \"tape_heads.7.blocks.1.mlp.3.weight\", \"tape_heads.7.blocks.1.mlp.3.bias\", \"tape_heads.7.blocks.1.ln_mlp.weight\", \"tape_heads.7.blocks.1.ln_mlp.bias\", \"tape_heads.7.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.7.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.7.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.7.blocks.1.logits_attention.out_proj.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_dict_216_225.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniforge3\\lib\\site-packages\\torch\\nn\\modules\\module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TapeTransformer:\n\tMissing key(s) in state_dict: \"tape_heads.0.blocks_left.0.pos_emb\", \"tape_heads.0.blocks_left.0.unembedding\", \"tape_heads.0.blocks_left.0.token_emb.weight\", \"tape_heads.0.blocks_left.0.chunk_proj.weight\", \"tape_heads.0.blocks_left.0.chunk_proj.bias\", \"tape_heads.0.blocks_left.0.attn.in_proj_weight\", \"tape_heads.0.blocks_left.0.attn.in_proj_bias\", \"tape_heads.0.blocks_left.0.attn.out_proj.weight\", \"tape_heads.0.blocks_left.0.attn.out_proj.bias\", \"tape_heads.0.blocks_left.0.ln_attn.weight\", \"tape_heads.0.blocks_left.0.ln_attn.bias\", \"tape_heads.0.blocks_left.0.mlp.0.weight\", \"tape_heads.0.blocks_left.0.mlp.0.bias\", \"tape_heads.0.blocks_left.0.mlp.2.weight\", \"tape_heads.0.blocks_left.0.mlp.2.bias\", \"tape_heads.0.blocks_left.0.mlp.3.weight\", \"tape_heads.0.blocks_left.0.mlp.3.bias\", \"tape_heads.0.blocks_left.0.ln_mlp.weight\", \"tape_heads.0.blocks_left.0.ln_mlp.bias\", \"tape_heads.0.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.0.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.0.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.0.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.0.blocks_left.1.pos_emb\", \"tape_heads.0.blocks_left.1.unembedding\", \"tape_heads.0.blocks_left.1.token_emb.weight\", \"tape_heads.0.blocks_left.1.chunk_proj.weight\", \"tape_heads.0.blocks_left.1.chunk_proj.bias\", \"tape_heads.0.blocks_left.1.attn.in_proj_weight\", \"tape_heads.0.blocks_left.1.attn.in_proj_bias\", \"tape_heads.0.blocks_left.1.attn.out_proj.weight\", \"tape_heads.0.blocks_left.1.attn.out_proj.bias\", \"tape_heads.0.blocks_left.1.ln_attn.weight\", \"tape_heads.0.blocks_left.1.ln_attn.bias\", \"tape_heads.0.blocks_left.1.mlp.0.weight\", \"tape_heads.0.blocks_left.1.mlp.0.bias\", \"tape_heads.0.blocks_left.1.mlp.2.weight\", \"tape_heads.0.blocks_left.1.mlp.2.bias\", \"tape_heads.0.blocks_left.1.mlp.3.weight\", \"tape_heads.0.blocks_left.1.mlp.3.bias\", \"tape_heads.0.blocks_left.1.ln_mlp.weight\", \"tape_heads.0.blocks_left.1.ln_mlp.bias\", \"tape_heads.0.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.0.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.0.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.0.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.0.blocks_right.0.pos_emb\", \"tape_heads.0.blocks_right.0.unembedding\", \"tape_heads.0.blocks_right.0.token_emb.weight\", \"tape_heads.0.blocks_right.0.chunk_proj.weight\", \"tape_heads.0.blocks_right.0.chunk_proj.bias\", \"tape_heads.0.blocks_right.0.attn.in_proj_weight\", \"tape_heads.0.blocks_right.0.attn.in_proj_bias\", \"tape_heads.0.blocks_right.0.attn.out_proj.weight\", \"tape_heads.0.blocks_right.0.attn.out_proj.bias\", \"tape_heads.0.blocks_right.0.ln_attn.weight\", \"tape_heads.0.blocks_right.0.ln_attn.bias\", \"tape_heads.0.blocks_right.0.mlp.0.weight\", \"tape_heads.0.blocks_right.0.mlp.0.bias\", \"tape_heads.0.blocks_right.0.mlp.2.weight\", \"tape_heads.0.blocks_right.0.mlp.2.bias\", \"tape_heads.0.blocks_right.0.mlp.3.weight\", \"tape_heads.0.blocks_right.0.mlp.3.bias\", \"tape_heads.0.blocks_right.0.ln_mlp.weight\", \"tape_heads.0.blocks_right.0.ln_mlp.bias\", \"tape_heads.0.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.0.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.0.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.0.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.0.blocks_right.1.pos_emb\", \"tape_heads.0.blocks_right.1.unembedding\", \"tape_heads.0.blocks_right.1.token_emb.weight\", \"tape_heads.0.blocks_right.1.chunk_proj.weight\", \"tape_heads.0.blocks_right.1.chunk_proj.bias\", \"tape_heads.0.blocks_right.1.attn.in_proj_weight\", \"tape_heads.0.blocks_right.1.attn.in_proj_bias\", \"tape_heads.0.blocks_right.1.attn.out_proj.weight\", \"tape_heads.0.blocks_right.1.attn.out_proj.bias\", \"tape_heads.0.blocks_right.1.ln_attn.weight\", \"tape_heads.0.blocks_right.1.ln_attn.bias\", \"tape_heads.0.blocks_right.1.mlp.0.weight\", \"tape_heads.0.blocks_right.1.mlp.0.bias\", \"tape_heads.0.blocks_right.1.mlp.2.weight\", \"tape_heads.0.blocks_right.1.mlp.2.bias\", \"tape_heads.0.blocks_right.1.mlp.3.weight\", \"tape_heads.0.blocks_right.1.mlp.3.bias\", \"tape_heads.0.blocks_right.1.ln_mlp.weight\", \"tape_heads.0.blocks_right.1.ln_mlp.bias\", \"tape_heads.0.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.0.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.0.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.0.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.1.blocks_left.0.pos_emb\", \"tape_heads.1.blocks_left.0.unembedding\", \"tape_heads.1.blocks_left.0.token_emb.weight\", \"tape_heads.1.blocks_left.0.chunk_proj.weight\", \"tape_heads.1.blocks_left.0.chunk_proj.bias\", \"tape_heads.1.blocks_left.0.attn.in_proj_weight\", \"tape_heads.1.blocks_left.0.attn.in_proj_bias\", \"tape_heads.1.blocks_left.0.attn.out_proj.weight\", \"tape_heads.1.blocks_left.0.attn.out_proj.bias\", \"tape_heads.1.blocks_left.0.ln_attn.weight\", \"tape_heads.1.blocks_left.0.ln_attn.bias\", \"tape_heads.1.blocks_left.0.mlp.0.weight\", \"tape_heads.1.blocks_left.0.mlp.0.bias\", \"tape_heads.1.blocks_left.0.mlp.2.weight\", \"tape_heads.1.blocks_left.0.mlp.2.bias\", \"tape_heads.1.blocks_left.0.mlp.3.weight\", \"tape_heads.1.blocks_left.0.mlp.3.bias\", \"tape_heads.1.blocks_left.0.ln_mlp.weight\", \"tape_heads.1.blocks_left.0.ln_mlp.bias\", \"tape_heads.1.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.1.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.1.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.1.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.1.blocks_left.1.pos_emb\", \"tape_heads.1.blocks_left.1.unembedding\", \"tape_heads.1.blocks_left.1.token_emb.weight\", \"tape_heads.1.blocks_left.1.chunk_proj.weight\", \"tape_heads.1.blocks_left.1.chunk_proj.bias\", \"tape_heads.1.blocks_left.1.attn.in_proj_weight\", \"tape_heads.1.blocks_left.1.attn.in_proj_bias\", \"tape_heads.1.blocks_left.1.attn.out_proj.weight\", \"tape_heads.1.blocks_left.1.attn.out_proj.bias\", \"tape_heads.1.blocks_left.1.ln_attn.weight\", \"tape_heads.1.blocks_left.1.ln_attn.bias\", \"tape_heads.1.blocks_left.1.mlp.0.weight\", \"tape_heads.1.blocks_left.1.mlp.0.bias\", \"tape_heads.1.blocks_left.1.mlp.2.weight\", \"tape_heads.1.blocks_left.1.mlp.2.bias\", \"tape_heads.1.blocks_left.1.mlp.3.weight\", \"tape_heads.1.blocks_left.1.mlp.3.bias\", \"tape_heads.1.blocks_left.1.ln_mlp.weight\", \"tape_heads.1.blocks_left.1.ln_mlp.bias\", \"tape_heads.1.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.1.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.1.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.1.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.1.blocks_right.0.pos_emb\", \"tape_heads.1.blocks_right.0.unembedding\", \"tape_heads.1.blocks_right.0.token_emb.weight\", \"tape_heads.1.blocks_right.0.chunk_proj.weight\", \"tape_heads.1.blocks_right.0.chunk_proj.bias\", \"tape_heads.1.blocks_right.0.attn.in_proj_weight\", \"tape_heads.1.blocks_right.0.attn.in_proj_bias\", \"tape_heads.1.blocks_right.0.attn.out_proj.weight\", \"tape_heads.1.blocks_right.0.attn.out_proj.bias\", \"tape_heads.1.blocks_right.0.ln_attn.weight\", \"tape_heads.1.blocks_right.0.ln_attn.bias\", \"tape_heads.1.blocks_right.0.mlp.0.weight\", \"tape_heads.1.blocks_right.0.mlp.0.bias\", \"tape_heads.1.blocks_right.0.mlp.2.weight\", \"tape_heads.1.blocks_right.0.mlp.2.bias\", \"tape_heads.1.blocks_right.0.mlp.3.weight\", \"tape_heads.1.blocks_right.0.mlp.3.bias\", \"tape_heads.1.blocks_right.0.ln_mlp.weight\", \"tape_heads.1.blocks_right.0.ln_mlp.bias\", \"tape_heads.1.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.1.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.1.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.1.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.1.blocks_right.1.pos_emb\", \"tape_heads.1.blocks_right.1.unembedding\", \"tape_heads.1.blocks_right.1.token_emb.weight\", \"tape_heads.1.blocks_right.1.chunk_proj.weight\", \"tape_heads.1.blocks_right.1.chunk_proj.bias\", \"tape_heads.1.blocks_right.1.attn.in_proj_weight\", \"tape_heads.1.blocks_right.1.attn.in_proj_bias\", \"tape_heads.1.blocks_right.1.attn.out_proj.weight\", \"tape_heads.1.blocks_right.1.attn.out_proj.bias\", \"tape_heads.1.blocks_right.1.ln_attn.weight\", \"tape_heads.1.blocks_right.1.ln_attn.bias\", \"tape_heads.1.blocks_right.1.mlp.0.weight\", \"tape_heads.1.blocks_right.1.mlp.0.bias\", \"tape_heads.1.blocks_right.1.mlp.2.weight\", \"tape_heads.1.blocks_right.1.mlp.2.bias\", \"tape_heads.1.blocks_right.1.mlp.3.weight\", \"tape_heads.1.blocks_right.1.mlp.3.bias\", \"tape_heads.1.blocks_right.1.ln_mlp.weight\", \"tape_heads.1.blocks_right.1.ln_mlp.bias\", \"tape_heads.1.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.1.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.1.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.1.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.2.blocks_left.0.pos_emb\", \"tape_heads.2.blocks_left.0.unembedding\", \"tape_heads.2.blocks_left.0.token_emb.weight\", \"tape_heads.2.blocks_left.0.chunk_proj.weight\", \"tape_heads.2.blocks_left.0.chunk_proj.bias\", \"tape_heads.2.blocks_left.0.attn.in_proj_weight\", \"tape_heads.2.blocks_left.0.attn.in_proj_bias\", \"tape_heads.2.blocks_left.0.attn.out_proj.weight\", \"tape_heads.2.blocks_left.0.attn.out_proj.bias\", \"tape_heads.2.blocks_left.0.ln_attn.weight\", \"tape_heads.2.blocks_left.0.ln_attn.bias\", \"tape_heads.2.blocks_left.0.mlp.0.weight\", \"tape_heads.2.blocks_left.0.mlp.0.bias\", \"tape_heads.2.blocks_left.0.mlp.2.weight\", \"tape_heads.2.blocks_left.0.mlp.2.bias\", \"tape_heads.2.blocks_left.0.mlp.3.weight\", \"tape_heads.2.blocks_left.0.mlp.3.bias\", \"tape_heads.2.blocks_left.0.ln_mlp.weight\", \"tape_heads.2.blocks_left.0.ln_mlp.bias\", \"tape_heads.2.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.2.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.2.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.2.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.2.blocks_left.1.pos_emb\", \"tape_heads.2.blocks_left.1.unembedding\", \"tape_heads.2.blocks_left.1.token_emb.weight\", \"tape_heads.2.blocks_left.1.chunk_proj.weight\", \"tape_heads.2.blocks_left.1.chunk_proj.bias\", \"tape_heads.2.blocks_left.1.attn.in_proj_weight\", \"tape_heads.2.blocks_left.1.attn.in_proj_bias\", \"tape_heads.2.blocks_left.1.attn.out_proj.weight\", \"tape_heads.2.blocks_left.1.attn.out_proj.bias\", \"tape_heads.2.blocks_left.1.ln_attn.weight\", \"tape_heads.2.blocks_left.1.ln_attn.bias\", \"tape_heads.2.blocks_left.1.mlp.0.weight\", \"tape_heads.2.blocks_left.1.mlp.0.bias\", \"tape_heads.2.blocks_left.1.mlp.2.weight\", \"tape_heads.2.blocks_left.1.mlp.2.bias\", \"tape_heads.2.blocks_left.1.mlp.3.weight\", \"tape_heads.2.blocks_left.1.mlp.3.bias\", \"tape_heads.2.blocks_left.1.ln_mlp.weight\", \"tape_heads.2.blocks_left.1.ln_mlp.bias\", \"tape_heads.2.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.2.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.2.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.2.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.2.blocks_right.0.pos_emb\", \"tape_heads.2.blocks_right.0.unembedding\", \"tape_heads.2.blocks_right.0.token_emb.weight\", \"tape_heads.2.blocks_right.0.chunk_proj.weight\", \"tape_heads.2.blocks_right.0.chunk_proj.bias\", \"tape_heads.2.blocks_right.0.attn.in_proj_weight\", \"tape_heads.2.blocks_right.0.attn.in_proj_bias\", \"tape_heads.2.blocks_right.0.attn.out_proj.weight\", \"tape_heads.2.blocks_right.0.attn.out_proj.bias\", \"tape_heads.2.blocks_right.0.ln_attn.weight\", \"tape_heads.2.blocks_right.0.ln_attn.bias\", \"tape_heads.2.blocks_right.0.mlp.0.weight\", \"tape_heads.2.blocks_right.0.mlp.0.bias\", \"tape_heads.2.blocks_right.0.mlp.2.weight\", \"tape_heads.2.blocks_right.0.mlp.2.bias\", \"tape_heads.2.blocks_right.0.mlp.3.weight\", \"tape_heads.2.blocks_right.0.mlp.3.bias\", \"tape_heads.2.blocks_right.0.ln_mlp.weight\", \"tape_heads.2.blocks_right.0.ln_mlp.bias\", \"tape_heads.2.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.2.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.2.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.2.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.2.blocks_right.1.pos_emb\", \"tape_heads.2.blocks_right.1.unembedding\", \"tape_heads.2.blocks_right.1.token_emb.weight\", \"tape_heads.2.blocks_right.1.chunk_proj.weight\", \"tape_heads.2.blocks_right.1.chunk_proj.bias\", \"tape_heads.2.blocks_right.1.attn.in_proj_weight\", \"tape_heads.2.blocks_right.1.attn.in_proj_bias\", \"tape_heads.2.blocks_right.1.attn.out_proj.weight\", \"tape_heads.2.blocks_right.1.attn.out_proj.bias\", \"tape_heads.2.blocks_right.1.ln_attn.weight\", \"tape_heads.2.blocks_right.1.ln_attn.bias\", \"tape_heads.2.blocks_right.1.mlp.0.weight\", \"tape_heads.2.blocks_right.1.mlp.0.bias\", \"tape_heads.2.blocks_right.1.mlp.2.weight\", \"tape_heads.2.blocks_right.1.mlp.2.bias\", \"tape_heads.2.blocks_right.1.mlp.3.weight\", \"tape_heads.2.blocks_right.1.mlp.3.bias\", \"tape_heads.2.blocks_right.1.ln_mlp.weight\", \"tape_heads.2.blocks_right.1.ln_mlp.bias\", \"tape_heads.2.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.2.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.2.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.2.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.3.blocks_left.0.pos_emb\", \"tape_heads.3.blocks_left.0.unembedding\", \"tape_heads.3.blocks_left.0.token_emb.weight\", \"tape_heads.3.blocks_left.0.chunk_proj.weight\", \"tape_heads.3.blocks_left.0.chunk_proj.bias\", \"tape_heads.3.blocks_left.0.attn.in_proj_weight\", \"tape_heads.3.blocks_left.0.attn.in_proj_bias\", \"tape_heads.3.blocks_left.0.attn.out_proj.weight\", \"tape_heads.3.blocks_left.0.attn.out_proj.bias\", \"tape_heads.3.blocks_left.0.ln_attn.weight\", \"tape_heads.3.blocks_left.0.ln_attn.bias\", \"tape_heads.3.blocks_left.0.mlp.0.weight\", \"tape_heads.3.blocks_left.0.mlp.0.bias\", \"tape_heads.3.blocks_left.0.mlp.2.weight\", \"tape_heads.3.blocks_left.0.mlp.2.bias\", \"tape_heads.3.blocks_left.0.mlp.3.weight\", \"tape_heads.3.blocks_left.0.mlp.3.bias\", \"tape_heads.3.blocks_left.0.ln_mlp.weight\", \"tape_heads.3.blocks_left.0.ln_mlp.bias\", \"tape_heads.3.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.3.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.3.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.3.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.3.blocks_left.1.pos_emb\", \"tape_heads.3.blocks_left.1.unembedding\", \"tape_heads.3.blocks_left.1.token_emb.weight\", \"tape_heads.3.blocks_left.1.chunk_proj.weight\", \"tape_heads.3.blocks_left.1.chunk_proj.bias\", \"tape_heads.3.blocks_left.1.attn.in_proj_weight\", \"tape_heads.3.blocks_left.1.attn.in_proj_bias\", \"tape_heads.3.blocks_left.1.attn.out_proj.weight\", \"tape_heads.3.blocks_left.1.attn.out_proj.bias\", \"tape_heads.3.blocks_left.1.ln_attn.weight\", \"tape_heads.3.blocks_left.1.ln_attn.bias\", \"tape_heads.3.blocks_left.1.mlp.0.weight\", \"tape_heads.3.blocks_left.1.mlp.0.bias\", \"tape_heads.3.blocks_left.1.mlp.2.weight\", \"tape_heads.3.blocks_left.1.mlp.2.bias\", \"tape_heads.3.blocks_left.1.mlp.3.weight\", \"tape_heads.3.blocks_left.1.mlp.3.bias\", \"tape_heads.3.blocks_left.1.ln_mlp.weight\", \"tape_heads.3.blocks_left.1.ln_mlp.bias\", \"tape_heads.3.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.3.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.3.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.3.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.3.blocks_right.0.pos_emb\", \"tape_heads.3.blocks_right.0.unembedding\", \"tape_heads.3.blocks_right.0.token_emb.weight\", \"tape_heads.3.blocks_right.0.chunk_proj.weight\", \"tape_heads.3.blocks_right.0.chunk_proj.bias\", \"tape_heads.3.blocks_right.0.attn.in_proj_weight\", \"tape_heads.3.blocks_right.0.attn.in_proj_bias\", \"tape_heads.3.blocks_right.0.attn.out_proj.weight\", \"tape_heads.3.blocks_right.0.attn.out_proj.bias\", \"tape_heads.3.blocks_right.0.ln_attn.weight\", \"tape_heads.3.blocks_right.0.ln_attn.bias\", \"tape_heads.3.blocks_right.0.mlp.0.weight\", \"tape_heads.3.blocks_right.0.mlp.0.bias\", \"tape_heads.3.blocks_right.0.mlp.2.weight\", \"tape_heads.3.blocks_right.0.mlp.2.bias\", \"tape_heads.3.blocks_right.0.mlp.3.weight\", \"tape_heads.3.blocks_right.0.mlp.3.bias\", \"tape_heads.3.blocks_right.0.ln_mlp.weight\", \"tape_heads.3.blocks_right.0.ln_mlp.bias\", \"tape_heads.3.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.3.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.3.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.3.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.3.blocks_right.1.pos_emb\", \"tape_heads.3.blocks_right.1.unembedding\", \"tape_heads.3.blocks_right.1.token_emb.weight\", \"tape_heads.3.blocks_right.1.chunk_proj.weight\", \"tape_heads.3.blocks_right.1.chunk_proj.bias\", \"tape_heads.3.blocks_right.1.attn.in_proj_weight\", \"tape_heads.3.blocks_right.1.attn.in_proj_bias\", \"tape_heads.3.blocks_right.1.attn.out_proj.weight\", \"tape_heads.3.blocks_right.1.attn.out_proj.bias\", \"tape_heads.3.blocks_right.1.ln_attn.weight\", \"tape_heads.3.blocks_right.1.ln_attn.bias\", \"tape_heads.3.blocks_right.1.mlp.0.weight\", \"tape_heads.3.blocks_right.1.mlp.0.bias\", \"tape_heads.3.blocks_right.1.mlp.2.weight\", \"tape_heads.3.blocks_right.1.mlp.2.bias\", \"tape_heads.3.blocks_right.1.mlp.3.weight\", \"tape_heads.3.blocks_right.1.mlp.3.bias\", \"tape_heads.3.blocks_right.1.ln_mlp.weight\", \"tape_heads.3.blocks_right.1.ln_mlp.bias\", \"tape_heads.3.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.3.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.3.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.3.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.4.blocks_left.0.pos_emb\", \"tape_heads.4.blocks_left.0.unembedding\", \"tape_heads.4.blocks_left.0.token_emb.weight\", \"tape_heads.4.blocks_left.0.chunk_proj.weight\", \"tape_heads.4.blocks_left.0.chunk_proj.bias\", \"tape_heads.4.blocks_left.0.attn.in_proj_weight\", \"tape_heads.4.blocks_left.0.attn.in_proj_bias\", \"tape_heads.4.blocks_left.0.attn.out_proj.weight\", \"tape_heads.4.blocks_left.0.attn.out_proj.bias\", \"tape_heads.4.blocks_left.0.ln_attn.weight\", \"tape_heads.4.blocks_left.0.ln_attn.bias\", \"tape_heads.4.blocks_left.0.mlp.0.weight\", \"tape_heads.4.blocks_left.0.mlp.0.bias\", \"tape_heads.4.blocks_left.0.mlp.2.weight\", \"tape_heads.4.blocks_left.0.mlp.2.bias\", \"tape_heads.4.blocks_left.0.mlp.3.weight\", \"tape_heads.4.blocks_left.0.mlp.3.bias\", \"tape_heads.4.blocks_left.0.ln_mlp.weight\", \"tape_heads.4.blocks_left.0.ln_mlp.bias\", \"tape_heads.4.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.4.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.4.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.4.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.4.blocks_left.1.pos_emb\", \"tape_heads.4.blocks_left.1.unembedding\", \"tape_heads.4.blocks_left.1.token_emb.weight\", \"tape_heads.4.blocks_left.1.chunk_proj.weight\", \"tape_heads.4.blocks_left.1.chunk_proj.bias\", \"tape_heads.4.blocks_left.1.attn.in_proj_weight\", \"tape_heads.4.blocks_left.1.attn.in_proj_bias\", \"tape_heads.4.blocks_left.1.attn.out_proj.weight\", \"tape_heads.4.blocks_left.1.attn.out_proj.bias\", \"tape_heads.4.blocks_left.1.ln_attn.weight\", \"tape_heads.4.blocks_left.1.ln_attn.bias\", \"tape_heads.4.blocks_left.1.mlp.0.weight\", \"tape_heads.4.blocks_left.1.mlp.0.bias\", \"tape_heads.4.blocks_left.1.mlp.2.weight\", \"tape_heads.4.blocks_left.1.mlp.2.bias\", \"tape_heads.4.blocks_left.1.mlp.3.weight\", \"tape_heads.4.blocks_left.1.mlp.3.bias\", \"tape_heads.4.blocks_left.1.ln_mlp.weight\", \"tape_heads.4.blocks_left.1.ln_mlp.bias\", \"tape_heads.4.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.4.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.4.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.4.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.4.blocks_right.0.pos_emb\", \"tape_heads.4.blocks_right.0.unembedding\", \"tape_heads.4.blocks_right.0.token_emb.weight\", \"tape_heads.4.blocks_right.0.chunk_proj.weight\", \"tape_heads.4.blocks_right.0.chunk_proj.bias\", \"tape_heads.4.blocks_right.0.attn.in_proj_weight\", \"tape_heads.4.blocks_right.0.attn.in_proj_bias\", \"tape_heads.4.blocks_right.0.attn.out_proj.weight\", \"tape_heads.4.blocks_right.0.attn.out_proj.bias\", \"tape_heads.4.blocks_right.0.ln_attn.weight\", \"tape_heads.4.blocks_right.0.ln_attn.bias\", \"tape_heads.4.blocks_right.0.mlp.0.weight\", \"tape_heads.4.blocks_right.0.mlp.0.bias\", \"tape_heads.4.blocks_right.0.mlp.2.weight\", \"tape_heads.4.blocks_right.0.mlp.2.bias\", \"tape_heads.4.blocks_right.0.mlp.3.weight\", \"tape_heads.4.blocks_right.0.mlp.3.bias\", \"tape_heads.4.blocks_right.0.ln_mlp.weight\", \"tape_heads.4.blocks_right.0.ln_mlp.bias\", \"tape_heads.4.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.4.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.4.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.4.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.4.blocks_right.1.pos_emb\", \"tape_heads.4.blocks_right.1.unembedding\", \"tape_heads.4.blocks_right.1.token_emb.weight\", \"tape_heads.4.blocks_right.1.chunk_proj.weight\", \"tape_heads.4.blocks_right.1.chunk_proj.bias\", \"tape_heads.4.blocks_right.1.attn.in_proj_weight\", \"tape_heads.4.blocks_right.1.attn.in_proj_bias\", \"tape_heads.4.blocks_right.1.attn.out_proj.weight\", \"tape_heads.4.blocks_right.1.attn.out_proj.bias\", \"tape_heads.4.blocks_right.1.ln_attn.weight\", \"tape_heads.4.blocks_right.1.ln_attn.bias\", \"tape_heads.4.blocks_right.1.mlp.0.weight\", \"tape_heads.4.blocks_right.1.mlp.0.bias\", \"tape_heads.4.blocks_right.1.mlp.2.weight\", \"tape_heads.4.blocks_right.1.mlp.2.bias\", \"tape_heads.4.blocks_right.1.mlp.3.weight\", \"tape_heads.4.blocks_right.1.mlp.3.bias\", \"tape_heads.4.blocks_right.1.ln_mlp.weight\", \"tape_heads.4.blocks_right.1.ln_mlp.bias\", \"tape_heads.4.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.4.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.4.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.4.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.5.blocks_left.0.pos_emb\", \"tape_heads.5.blocks_left.0.unembedding\", \"tape_heads.5.blocks_left.0.token_emb.weight\", \"tape_heads.5.blocks_left.0.chunk_proj.weight\", \"tape_heads.5.blocks_left.0.chunk_proj.bias\", \"tape_heads.5.blocks_left.0.attn.in_proj_weight\", \"tape_heads.5.blocks_left.0.attn.in_proj_bias\", \"tape_heads.5.blocks_left.0.attn.out_proj.weight\", \"tape_heads.5.blocks_left.0.attn.out_proj.bias\", \"tape_heads.5.blocks_left.0.ln_attn.weight\", \"tape_heads.5.blocks_left.0.ln_attn.bias\", \"tape_heads.5.blocks_left.0.mlp.0.weight\", \"tape_heads.5.blocks_left.0.mlp.0.bias\", \"tape_heads.5.blocks_left.0.mlp.2.weight\", \"tape_heads.5.blocks_left.0.mlp.2.bias\", \"tape_heads.5.blocks_left.0.mlp.3.weight\", \"tape_heads.5.blocks_left.0.mlp.3.bias\", \"tape_heads.5.blocks_left.0.ln_mlp.weight\", \"tape_heads.5.blocks_left.0.ln_mlp.bias\", \"tape_heads.5.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.5.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.5.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.5.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.5.blocks_left.1.pos_emb\", \"tape_heads.5.blocks_left.1.unembedding\", \"tape_heads.5.blocks_left.1.token_emb.weight\", \"tape_heads.5.blocks_left.1.chunk_proj.weight\", \"tape_heads.5.blocks_left.1.chunk_proj.bias\", \"tape_heads.5.blocks_left.1.attn.in_proj_weight\", \"tape_heads.5.blocks_left.1.attn.in_proj_bias\", \"tape_heads.5.blocks_left.1.attn.out_proj.weight\", \"tape_heads.5.blocks_left.1.attn.out_proj.bias\", \"tape_heads.5.blocks_left.1.ln_attn.weight\", \"tape_heads.5.blocks_left.1.ln_attn.bias\", \"tape_heads.5.blocks_left.1.mlp.0.weight\", \"tape_heads.5.blocks_left.1.mlp.0.bias\", \"tape_heads.5.blocks_left.1.mlp.2.weight\", \"tape_heads.5.blocks_left.1.mlp.2.bias\", \"tape_heads.5.blocks_left.1.mlp.3.weight\", \"tape_heads.5.blocks_left.1.mlp.3.bias\", \"tape_heads.5.blocks_left.1.ln_mlp.weight\", \"tape_heads.5.blocks_left.1.ln_mlp.bias\", \"tape_heads.5.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.5.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.5.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.5.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.5.blocks_right.0.pos_emb\", \"tape_heads.5.blocks_right.0.unembedding\", \"tape_heads.5.blocks_right.0.token_emb.weight\", \"tape_heads.5.blocks_right.0.chunk_proj.weight\", \"tape_heads.5.blocks_right.0.chunk_proj.bias\", \"tape_heads.5.blocks_right.0.attn.in_proj_weight\", \"tape_heads.5.blocks_right.0.attn.in_proj_bias\", \"tape_heads.5.blocks_right.0.attn.out_proj.weight\", \"tape_heads.5.blocks_right.0.attn.out_proj.bias\", \"tape_heads.5.blocks_right.0.ln_attn.weight\", \"tape_heads.5.blocks_right.0.ln_attn.bias\", \"tape_heads.5.blocks_right.0.mlp.0.weight\", \"tape_heads.5.blocks_right.0.mlp.0.bias\", \"tape_heads.5.blocks_right.0.mlp.2.weight\", \"tape_heads.5.blocks_right.0.mlp.2.bias\", \"tape_heads.5.blocks_right.0.mlp.3.weight\", \"tape_heads.5.blocks_right.0.mlp.3.bias\", \"tape_heads.5.blocks_right.0.ln_mlp.weight\", \"tape_heads.5.blocks_right.0.ln_mlp.bias\", \"tape_heads.5.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.5.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.5.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.5.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.5.blocks_right.1.pos_emb\", \"tape_heads.5.blocks_right.1.unembedding\", \"tape_heads.5.blocks_right.1.token_emb.weight\", \"tape_heads.5.blocks_right.1.chunk_proj.weight\", \"tape_heads.5.blocks_right.1.chunk_proj.bias\", \"tape_heads.5.blocks_right.1.attn.in_proj_weight\", \"tape_heads.5.blocks_right.1.attn.in_proj_bias\", \"tape_heads.5.blocks_right.1.attn.out_proj.weight\", \"tape_heads.5.blocks_right.1.attn.out_proj.bias\", \"tape_heads.5.blocks_right.1.ln_attn.weight\", \"tape_heads.5.blocks_right.1.ln_attn.bias\", \"tape_heads.5.blocks_right.1.mlp.0.weight\", \"tape_heads.5.blocks_right.1.mlp.0.bias\", \"tape_heads.5.blocks_right.1.mlp.2.weight\", \"tape_heads.5.blocks_right.1.mlp.2.bias\", \"tape_heads.5.blocks_right.1.mlp.3.weight\", \"tape_heads.5.blocks_right.1.mlp.3.bias\", \"tape_heads.5.blocks_right.1.ln_mlp.weight\", \"tape_heads.5.blocks_right.1.ln_mlp.bias\", \"tape_heads.5.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.5.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.5.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.5.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.6.blocks_left.0.pos_emb\", \"tape_heads.6.blocks_left.0.unembedding\", \"tape_heads.6.blocks_left.0.token_emb.weight\", \"tape_heads.6.blocks_left.0.chunk_proj.weight\", \"tape_heads.6.blocks_left.0.chunk_proj.bias\", \"tape_heads.6.blocks_left.0.attn.in_proj_weight\", \"tape_heads.6.blocks_left.0.attn.in_proj_bias\", \"tape_heads.6.blocks_left.0.attn.out_proj.weight\", \"tape_heads.6.blocks_left.0.attn.out_proj.bias\", \"tape_heads.6.blocks_left.0.ln_attn.weight\", \"tape_heads.6.blocks_left.0.ln_attn.bias\", \"tape_heads.6.blocks_left.0.mlp.0.weight\", \"tape_heads.6.blocks_left.0.mlp.0.bias\", \"tape_heads.6.blocks_left.0.mlp.2.weight\", \"tape_heads.6.blocks_left.0.mlp.2.bias\", \"tape_heads.6.blocks_left.0.mlp.3.weight\", \"tape_heads.6.blocks_left.0.mlp.3.bias\", \"tape_heads.6.blocks_left.0.ln_mlp.weight\", \"tape_heads.6.blocks_left.0.ln_mlp.bias\", \"tape_heads.6.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.6.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.6.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.6.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.6.blocks_left.1.pos_emb\", \"tape_heads.6.blocks_left.1.unembedding\", \"tape_heads.6.blocks_left.1.token_emb.weight\", \"tape_heads.6.blocks_left.1.chunk_proj.weight\", \"tape_heads.6.blocks_left.1.chunk_proj.bias\", \"tape_heads.6.blocks_left.1.attn.in_proj_weight\", \"tape_heads.6.blocks_left.1.attn.in_proj_bias\", \"tape_heads.6.blocks_left.1.attn.out_proj.weight\", \"tape_heads.6.blocks_left.1.attn.out_proj.bias\", \"tape_heads.6.blocks_left.1.ln_attn.weight\", \"tape_heads.6.blocks_left.1.ln_attn.bias\", \"tape_heads.6.blocks_left.1.mlp.0.weight\", \"tape_heads.6.blocks_left.1.mlp.0.bias\", \"tape_heads.6.blocks_left.1.mlp.2.weight\", \"tape_heads.6.blocks_left.1.mlp.2.bias\", \"tape_heads.6.blocks_left.1.mlp.3.weight\", \"tape_heads.6.blocks_left.1.mlp.3.bias\", \"tape_heads.6.blocks_left.1.ln_mlp.weight\", \"tape_heads.6.blocks_left.1.ln_mlp.bias\", \"tape_heads.6.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.6.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.6.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.6.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.6.blocks_right.0.pos_emb\", \"tape_heads.6.blocks_right.0.unembedding\", \"tape_heads.6.blocks_right.0.token_emb.weight\", \"tape_heads.6.blocks_right.0.chunk_proj.weight\", \"tape_heads.6.blocks_right.0.chunk_proj.bias\", \"tape_heads.6.blocks_right.0.attn.in_proj_weight\", \"tape_heads.6.blocks_right.0.attn.in_proj_bias\", \"tape_heads.6.blocks_right.0.attn.out_proj.weight\", \"tape_heads.6.blocks_right.0.attn.out_proj.bias\", \"tape_heads.6.blocks_right.0.ln_attn.weight\", \"tape_heads.6.blocks_right.0.ln_attn.bias\", \"tape_heads.6.blocks_right.0.mlp.0.weight\", \"tape_heads.6.blocks_right.0.mlp.0.bias\", \"tape_heads.6.blocks_right.0.mlp.2.weight\", \"tape_heads.6.blocks_right.0.mlp.2.bias\", \"tape_heads.6.blocks_right.0.mlp.3.weight\", \"tape_heads.6.blocks_right.0.mlp.3.bias\", \"tape_heads.6.blocks_right.0.ln_mlp.weight\", \"tape_heads.6.blocks_right.0.ln_mlp.bias\", \"tape_heads.6.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.6.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.6.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.6.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.6.blocks_right.1.pos_emb\", \"tape_heads.6.blocks_right.1.unembedding\", \"tape_heads.6.blocks_right.1.token_emb.weight\", \"tape_heads.6.blocks_right.1.chunk_proj.weight\", \"tape_heads.6.blocks_right.1.chunk_proj.bias\", \"tape_heads.6.blocks_right.1.attn.in_proj_weight\", \"tape_heads.6.blocks_right.1.attn.in_proj_bias\", \"tape_heads.6.blocks_right.1.attn.out_proj.weight\", \"tape_heads.6.blocks_right.1.attn.out_proj.bias\", \"tape_heads.6.blocks_right.1.ln_attn.weight\", \"tape_heads.6.blocks_right.1.ln_attn.bias\", \"tape_heads.6.blocks_right.1.mlp.0.weight\", \"tape_heads.6.blocks_right.1.mlp.0.bias\", \"tape_heads.6.blocks_right.1.mlp.2.weight\", \"tape_heads.6.blocks_right.1.mlp.2.bias\", \"tape_heads.6.blocks_right.1.mlp.3.weight\", \"tape_heads.6.blocks_right.1.mlp.3.bias\", \"tape_heads.6.blocks_right.1.ln_mlp.weight\", \"tape_heads.6.blocks_right.1.ln_mlp.bias\", \"tape_heads.6.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.6.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.6.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.6.blocks_right.1.logits_attention.out_proj.bias\", \"tape_heads.7.blocks_left.0.pos_emb\", \"tape_heads.7.blocks_left.0.unembedding\", \"tape_heads.7.blocks_left.0.token_emb.weight\", \"tape_heads.7.blocks_left.0.chunk_proj.weight\", \"tape_heads.7.blocks_left.0.chunk_proj.bias\", \"tape_heads.7.blocks_left.0.attn.in_proj_weight\", \"tape_heads.7.blocks_left.0.attn.in_proj_bias\", \"tape_heads.7.blocks_left.0.attn.out_proj.weight\", \"tape_heads.7.blocks_left.0.attn.out_proj.bias\", \"tape_heads.7.blocks_left.0.ln_attn.weight\", \"tape_heads.7.blocks_left.0.ln_attn.bias\", \"tape_heads.7.blocks_left.0.mlp.0.weight\", \"tape_heads.7.blocks_left.0.mlp.0.bias\", \"tape_heads.7.blocks_left.0.mlp.2.weight\", \"tape_heads.7.blocks_left.0.mlp.2.bias\", \"tape_heads.7.blocks_left.0.mlp.3.weight\", \"tape_heads.7.blocks_left.0.mlp.3.bias\", \"tape_heads.7.blocks_left.0.ln_mlp.weight\", \"tape_heads.7.blocks_left.0.ln_mlp.bias\", \"tape_heads.7.blocks_left.0.logits_attention.in_proj_weight\", \"tape_heads.7.blocks_left.0.logits_attention.in_proj_bias\", \"tape_heads.7.blocks_left.0.logits_attention.out_proj.weight\", \"tape_heads.7.blocks_left.0.logits_attention.out_proj.bias\", \"tape_heads.7.blocks_left.1.pos_emb\", \"tape_heads.7.blocks_left.1.unembedding\", \"tape_heads.7.blocks_left.1.token_emb.weight\", \"tape_heads.7.blocks_left.1.chunk_proj.weight\", \"tape_heads.7.blocks_left.1.chunk_proj.bias\", \"tape_heads.7.blocks_left.1.attn.in_proj_weight\", \"tape_heads.7.blocks_left.1.attn.in_proj_bias\", \"tape_heads.7.blocks_left.1.attn.out_proj.weight\", \"tape_heads.7.blocks_left.1.attn.out_proj.bias\", \"tape_heads.7.blocks_left.1.ln_attn.weight\", \"tape_heads.7.blocks_left.1.ln_attn.bias\", \"tape_heads.7.blocks_left.1.mlp.0.weight\", \"tape_heads.7.blocks_left.1.mlp.0.bias\", \"tape_heads.7.blocks_left.1.mlp.2.weight\", \"tape_heads.7.blocks_left.1.mlp.2.bias\", \"tape_heads.7.blocks_left.1.mlp.3.weight\", \"tape_heads.7.blocks_left.1.mlp.3.bias\", \"tape_heads.7.blocks_left.1.ln_mlp.weight\", \"tape_heads.7.blocks_left.1.ln_mlp.bias\", \"tape_heads.7.blocks_left.1.logits_attention.in_proj_weight\", \"tape_heads.7.blocks_left.1.logits_attention.in_proj_bias\", \"tape_heads.7.blocks_left.1.logits_attention.out_proj.weight\", \"tape_heads.7.blocks_left.1.logits_attention.out_proj.bias\", \"tape_heads.7.blocks_right.0.pos_emb\", \"tape_heads.7.blocks_right.0.unembedding\", \"tape_heads.7.blocks_right.0.token_emb.weight\", \"tape_heads.7.blocks_right.0.chunk_proj.weight\", \"tape_heads.7.blocks_right.0.chunk_proj.bias\", \"tape_heads.7.blocks_right.0.attn.in_proj_weight\", \"tape_heads.7.blocks_right.0.attn.in_proj_bias\", \"tape_heads.7.blocks_right.0.attn.out_proj.weight\", \"tape_heads.7.blocks_right.0.attn.out_proj.bias\", \"tape_heads.7.blocks_right.0.ln_attn.weight\", \"tape_heads.7.blocks_right.0.ln_attn.bias\", \"tape_heads.7.blocks_right.0.mlp.0.weight\", \"tape_heads.7.blocks_right.0.mlp.0.bias\", \"tape_heads.7.blocks_right.0.mlp.2.weight\", \"tape_heads.7.blocks_right.0.mlp.2.bias\", \"tape_heads.7.blocks_right.0.mlp.3.weight\", \"tape_heads.7.blocks_right.0.mlp.3.bias\", \"tape_heads.7.blocks_right.0.ln_mlp.weight\", \"tape_heads.7.blocks_right.0.ln_mlp.bias\", \"tape_heads.7.blocks_right.0.logits_attention.in_proj_weight\", \"tape_heads.7.blocks_right.0.logits_attention.in_proj_bias\", \"tape_heads.7.blocks_right.0.logits_attention.out_proj.weight\", \"tape_heads.7.blocks_right.0.logits_attention.out_proj.bias\", \"tape_heads.7.blocks_right.1.pos_emb\", \"tape_heads.7.blocks_right.1.unembedding\", \"tape_heads.7.blocks_right.1.token_emb.weight\", \"tape_heads.7.blocks_right.1.chunk_proj.weight\", \"tape_heads.7.blocks_right.1.chunk_proj.bias\", \"tape_heads.7.blocks_right.1.attn.in_proj_weight\", \"tape_heads.7.blocks_right.1.attn.in_proj_bias\", \"tape_heads.7.blocks_right.1.attn.out_proj.weight\", \"tape_heads.7.blocks_right.1.attn.out_proj.bias\", \"tape_heads.7.blocks_right.1.ln_attn.weight\", \"tape_heads.7.blocks_right.1.ln_attn.bias\", \"tape_heads.7.blocks_right.1.mlp.0.weight\", \"tape_heads.7.blocks_right.1.mlp.0.bias\", \"tape_heads.7.blocks_right.1.mlp.2.weight\", \"tape_heads.7.blocks_right.1.mlp.2.bias\", \"tape_heads.7.blocks_right.1.mlp.3.weight\", \"tape_heads.7.blocks_right.1.mlp.3.bias\", \"tape_heads.7.blocks_right.1.ln_mlp.weight\", \"tape_heads.7.blocks_right.1.ln_mlp.bias\", \"tape_heads.7.blocks_right.1.logits_attention.in_proj_weight\", \"tape_heads.7.blocks_right.1.logits_attention.in_proj_bias\", \"tape_heads.7.blocks_right.1.logits_attention.out_proj.weight\", \"tape_heads.7.blocks_right.1.logits_attention.out_proj.bias\", \"merge_projection.weight\", \"merge_projection.bias\". \n\tUnexpected key(s) in state_dict: \"pos_emb\", \"token_emb.weight\", \"tape_heads.0.blocks.0.unembedding\", \"tape_heads.0.blocks.0.chunk_proj.weight\", \"tape_heads.0.blocks.0.chunk_proj.bias\", \"tape_heads.0.blocks.0.attn.in_proj_weight\", \"tape_heads.0.blocks.0.attn.in_proj_bias\", \"tape_heads.0.blocks.0.attn.out_proj.weight\", \"tape_heads.0.blocks.0.attn.out_proj.bias\", \"tape_heads.0.blocks.0.ln_attn.weight\", \"tape_heads.0.blocks.0.ln_attn.bias\", \"tape_heads.0.blocks.0.mlp.0.weight\", \"tape_heads.0.blocks.0.mlp.0.bias\", \"tape_heads.0.blocks.0.mlp.2.weight\", \"tape_heads.0.blocks.0.mlp.2.bias\", \"tape_heads.0.blocks.0.mlp.3.weight\", \"tape_heads.0.blocks.0.mlp.3.bias\", \"tape_heads.0.blocks.0.ln_mlp.weight\", \"tape_heads.0.blocks.0.ln_mlp.bias\", \"tape_heads.0.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.0.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.0.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.0.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.0.blocks.1.unembedding\", \"tape_heads.0.blocks.1.chunk_proj.weight\", \"tape_heads.0.blocks.1.chunk_proj.bias\", \"tape_heads.0.blocks.1.attn.in_proj_weight\", \"tape_heads.0.blocks.1.attn.in_proj_bias\", \"tape_heads.0.blocks.1.attn.out_proj.weight\", \"tape_heads.0.blocks.1.attn.out_proj.bias\", \"tape_heads.0.blocks.1.ln_attn.weight\", \"tape_heads.0.blocks.1.ln_attn.bias\", \"tape_heads.0.blocks.1.mlp.0.weight\", \"tape_heads.0.blocks.1.mlp.0.bias\", \"tape_heads.0.blocks.1.mlp.2.weight\", \"tape_heads.0.blocks.1.mlp.2.bias\", \"tape_heads.0.blocks.1.mlp.3.weight\", \"tape_heads.0.blocks.1.mlp.3.bias\", \"tape_heads.0.blocks.1.ln_mlp.weight\", \"tape_heads.0.blocks.1.ln_mlp.bias\", \"tape_heads.0.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.0.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.0.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.0.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.1.blocks.0.unembedding\", \"tape_heads.1.blocks.0.chunk_proj.weight\", \"tape_heads.1.blocks.0.chunk_proj.bias\", \"tape_heads.1.blocks.0.attn.in_proj_weight\", \"tape_heads.1.blocks.0.attn.in_proj_bias\", \"tape_heads.1.blocks.0.attn.out_proj.weight\", \"tape_heads.1.blocks.0.attn.out_proj.bias\", \"tape_heads.1.blocks.0.ln_attn.weight\", \"tape_heads.1.blocks.0.ln_attn.bias\", \"tape_heads.1.blocks.0.mlp.0.weight\", \"tape_heads.1.blocks.0.mlp.0.bias\", \"tape_heads.1.blocks.0.mlp.2.weight\", \"tape_heads.1.blocks.0.mlp.2.bias\", \"tape_heads.1.blocks.0.mlp.3.weight\", \"tape_heads.1.blocks.0.mlp.3.bias\", \"tape_heads.1.blocks.0.ln_mlp.weight\", \"tape_heads.1.blocks.0.ln_mlp.bias\", \"tape_heads.1.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.1.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.1.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.1.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.1.blocks.1.unembedding\", \"tape_heads.1.blocks.1.chunk_proj.weight\", \"tape_heads.1.blocks.1.chunk_proj.bias\", \"tape_heads.1.blocks.1.attn.in_proj_weight\", \"tape_heads.1.blocks.1.attn.in_proj_bias\", \"tape_heads.1.blocks.1.attn.out_proj.weight\", \"tape_heads.1.blocks.1.attn.out_proj.bias\", \"tape_heads.1.blocks.1.ln_attn.weight\", \"tape_heads.1.blocks.1.ln_attn.bias\", \"tape_heads.1.blocks.1.mlp.0.weight\", \"tape_heads.1.blocks.1.mlp.0.bias\", \"tape_heads.1.blocks.1.mlp.2.weight\", \"tape_heads.1.blocks.1.mlp.2.bias\", \"tape_heads.1.blocks.1.mlp.3.weight\", \"tape_heads.1.blocks.1.mlp.3.bias\", \"tape_heads.1.blocks.1.ln_mlp.weight\", \"tape_heads.1.blocks.1.ln_mlp.bias\", \"tape_heads.1.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.1.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.1.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.1.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.2.blocks.0.unembedding\", \"tape_heads.2.blocks.0.chunk_proj.weight\", \"tape_heads.2.blocks.0.chunk_proj.bias\", \"tape_heads.2.blocks.0.attn.in_proj_weight\", \"tape_heads.2.blocks.0.attn.in_proj_bias\", \"tape_heads.2.blocks.0.attn.out_proj.weight\", \"tape_heads.2.blocks.0.attn.out_proj.bias\", \"tape_heads.2.blocks.0.ln_attn.weight\", \"tape_heads.2.blocks.0.ln_attn.bias\", \"tape_heads.2.blocks.0.mlp.0.weight\", \"tape_heads.2.blocks.0.mlp.0.bias\", \"tape_heads.2.blocks.0.mlp.2.weight\", \"tape_heads.2.blocks.0.mlp.2.bias\", \"tape_heads.2.blocks.0.mlp.3.weight\", \"tape_heads.2.blocks.0.mlp.3.bias\", \"tape_heads.2.blocks.0.ln_mlp.weight\", \"tape_heads.2.blocks.0.ln_mlp.bias\", \"tape_heads.2.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.2.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.2.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.2.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.2.blocks.1.unembedding\", \"tape_heads.2.blocks.1.chunk_proj.weight\", \"tape_heads.2.blocks.1.chunk_proj.bias\", \"tape_heads.2.blocks.1.attn.in_proj_weight\", \"tape_heads.2.blocks.1.attn.in_proj_bias\", \"tape_heads.2.blocks.1.attn.out_proj.weight\", \"tape_heads.2.blocks.1.attn.out_proj.bias\", \"tape_heads.2.blocks.1.ln_attn.weight\", \"tape_heads.2.blocks.1.ln_attn.bias\", \"tape_heads.2.blocks.1.mlp.0.weight\", \"tape_heads.2.blocks.1.mlp.0.bias\", \"tape_heads.2.blocks.1.mlp.2.weight\", \"tape_heads.2.blocks.1.mlp.2.bias\", \"tape_heads.2.blocks.1.mlp.3.weight\", \"tape_heads.2.blocks.1.mlp.3.bias\", \"tape_heads.2.blocks.1.ln_mlp.weight\", \"tape_heads.2.blocks.1.ln_mlp.bias\", \"tape_heads.2.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.2.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.2.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.2.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.3.blocks.0.unembedding\", \"tape_heads.3.blocks.0.chunk_proj.weight\", \"tape_heads.3.blocks.0.chunk_proj.bias\", \"tape_heads.3.blocks.0.attn.in_proj_weight\", \"tape_heads.3.blocks.0.attn.in_proj_bias\", \"tape_heads.3.blocks.0.attn.out_proj.weight\", \"tape_heads.3.blocks.0.attn.out_proj.bias\", \"tape_heads.3.blocks.0.ln_attn.weight\", \"tape_heads.3.blocks.0.ln_attn.bias\", \"tape_heads.3.blocks.0.mlp.0.weight\", \"tape_heads.3.blocks.0.mlp.0.bias\", \"tape_heads.3.blocks.0.mlp.2.weight\", \"tape_heads.3.blocks.0.mlp.2.bias\", \"tape_heads.3.blocks.0.mlp.3.weight\", \"tape_heads.3.blocks.0.mlp.3.bias\", \"tape_heads.3.blocks.0.ln_mlp.weight\", \"tape_heads.3.blocks.0.ln_mlp.bias\", \"tape_heads.3.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.3.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.3.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.3.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.3.blocks.1.unembedding\", \"tape_heads.3.blocks.1.chunk_proj.weight\", \"tape_heads.3.blocks.1.chunk_proj.bias\", \"tape_heads.3.blocks.1.attn.in_proj_weight\", \"tape_heads.3.blocks.1.attn.in_proj_bias\", \"tape_heads.3.blocks.1.attn.out_proj.weight\", \"tape_heads.3.blocks.1.attn.out_proj.bias\", \"tape_heads.3.blocks.1.ln_attn.weight\", \"tape_heads.3.blocks.1.ln_attn.bias\", \"tape_heads.3.blocks.1.mlp.0.weight\", \"tape_heads.3.blocks.1.mlp.0.bias\", \"tape_heads.3.blocks.1.mlp.2.weight\", \"tape_heads.3.blocks.1.mlp.2.bias\", \"tape_heads.3.blocks.1.mlp.3.weight\", \"tape_heads.3.blocks.1.mlp.3.bias\", \"tape_heads.3.blocks.1.ln_mlp.weight\", \"tape_heads.3.blocks.1.ln_mlp.bias\", \"tape_heads.3.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.3.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.3.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.3.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.4.blocks.0.unembedding\", \"tape_heads.4.blocks.0.chunk_proj.weight\", \"tape_heads.4.blocks.0.chunk_proj.bias\", \"tape_heads.4.blocks.0.attn.in_proj_weight\", \"tape_heads.4.blocks.0.attn.in_proj_bias\", \"tape_heads.4.blocks.0.attn.out_proj.weight\", \"tape_heads.4.blocks.0.attn.out_proj.bias\", \"tape_heads.4.blocks.0.ln_attn.weight\", \"tape_heads.4.blocks.0.ln_attn.bias\", \"tape_heads.4.blocks.0.mlp.0.weight\", \"tape_heads.4.blocks.0.mlp.0.bias\", \"tape_heads.4.blocks.0.mlp.2.weight\", \"tape_heads.4.blocks.0.mlp.2.bias\", \"tape_heads.4.blocks.0.mlp.3.weight\", \"tape_heads.4.blocks.0.mlp.3.bias\", \"tape_heads.4.blocks.0.ln_mlp.weight\", \"tape_heads.4.blocks.0.ln_mlp.bias\", \"tape_heads.4.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.4.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.4.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.4.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.4.blocks.1.unembedding\", \"tape_heads.4.blocks.1.chunk_proj.weight\", \"tape_heads.4.blocks.1.chunk_proj.bias\", \"tape_heads.4.blocks.1.attn.in_proj_weight\", \"tape_heads.4.blocks.1.attn.in_proj_bias\", \"tape_heads.4.blocks.1.attn.out_proj.weight\", \"tape_heads.4.blocks.1.attn.out_proj.bias\", \"tape_heads.4.blocks.1.ln_attn.weight\", \"tape_heads.4.blocks.1.ln_attn.bias\", \"tape_heads.4.blocks.1.mlp.0.weight\", \"tape_heads.4.blocks.1.mlp.0.bias\", \"tape_heads.4.blocks.1.mlp.2.weight\", \"tape_heads.4.blocks.1.mlp.2.bias\", \"tape_heads.4.blocks.1.mlp.3.weight\", \"tape_heads.4.blocks.1.mlp.3.bias\", \"tape_heads.4.blocks.1.ln_mlp.weight\", \"tape_heads.4.blocks.1.ln_mlp.bias\", \"tape_heads.4.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.4.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.4.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.4.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.5.blocks.0.unembedding\", \"tape_heads.5.blocks.0.chunk_proj.weight\", \"tape_heads.5.blocks.0.chunk_proj.bias\", \"tape_heads.5.blocks.0.attn.in_proj_weight\", \"tape_heads.5.blocks.0.attn.in_proj_bias\", \"tape_heads.5.blocks.0.attn.out_proj.weight\", \"tape_heads.5.blocks.0.attn.out_proj.bias\", \"tape_heads.5.blocks.0.ln_attn.weight\", \"tape_heads.5.blocks.0.ln_attn.bias\", \"tape_heads.5.blocks.0.mlp.0.weight\", \"tape_heads.5.blocks.0.mlp.0.bias\", \"tape_heads.5.blocks.0.mlp.2.weight\", \"tape_heads.5.blocks.0.mlp.2.bias\", \"tape_heads.5.blocks.0.mlp.3.weight\", \"tape_heads.5.blocks.0.mlp.3.bias\", \"tape_heads.5.blocks.0.ln_mlp.weight\", \"tape_heads.5.blocks.0.ln_mlp.bias\", \"tape_heads.5.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.5.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.5.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.5.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.5.blocks.1.unembedding\", \"tape_heads.5.blocks.1.chunk_proj.weight\", \"tape_heads.5.blocks.1.chunk_proj.bias\", \"tape_heads.5.blocks.1.attn.in_proj_weight\", \"tape_heads.5.blocks.1.attn.in_proj_bias\", \"tape_heads.5.blocks.1.attn.out_proj.weight\", \"tape_heads.5.blocks.1.attn.out_proj.bias\", \"tape_heads.5.blocks.1.ln_attn.weight\", \"tape_heads.5.blocks.1.ln_attn.bias\", \"tape_heads.5.blocks.1.mlp.0.weight\", \"tape_heads.5.blocks.1.mlp.0.bias\", \"tape_heads.5.blocks.1.mlp.2.weight\", \"tape_heads.5.blocks.1.mlp.2.bias\", \"tape_heads.5.blocks.1.mlp.3.weight\", \"tape_heads.5.blocks.1.mlp.3.bias\", \"tape_heads.5.blocks.1.ln_mlp.weight\", \"tape_heads.5.blocks.1.ln_mlp.bias\", \"tape_heads.5.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.5.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.5.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.5.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.6.blocks.0.unembedding\", \"tape_heads.6.blocks.0.chunk_proj.weight\", \"tape_heads.6.blocks.0.chunk_proj.bias\", \"tape_heads.6.blocks.0.attn.in_proj_weight\", \"tape_heads.6.blocks.0.attn.in_proj_bias\", \"tape_heads.6.blocks.0.attn.out_proj.weight\", \"tape_heads.6.blocks.0.attn.out_proj.bias\", \"tape_heads.6.blocks.0.ln_attn.weight\", \"tape_heads.6.blocks.0.ln_attn.bias\", \"tape_heads.6.blocks.0.mlp.0.weight\", \"tape_heads.6.blocks.0.mlp.0.bias\", \"tape_heads.6.blocks.0.mlp.2.weight\", \"tape_heads.6.blocks.0.mlp.2.bias\", \"tape_heads.6.blocks.0.mlp.3.weight\", \"tape_heads.6.blocks.0.mlp.3.bias\", \"tape_heads.6.blocks.0.ln_mlp.weight\", \"tape_heads.6.blocks.0.ln_mlp.bias\", \"tape_heads.6.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.6.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.6.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.6.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.6.blocks.1.unembedding\", \"tape_heads.6.blocks.1.chunk_proj.weight\", \"tape_heads.6.blocks.1.chunk_proj.bias\", \"tape_heads.6.blocks.1.attn.in_proj_weight\", \"tape_heads.6.blocks.1.attn.in_proj_bias\", \"tape_heads.6.blocks.1.attn.out_proj.weight\", \"tape_heads.6.blocks.1.attn.out_proj.bias\", \"tape_heads.6.blocks.1.ln_attn.weight\", \"tape_heads.6.blocks.1.ln_attn.bias\", \"tape_heads.6.blocks.1.mlp.0.weight\", \"tape_heads.6.blocks.1.mlp.0.bias\", \"tape_heads.6.blocks.1.mlp.2.weight\", \"tape_heads.6.blocks.1.mlp.2.bias\", \"tape_heads.6.blocks.1.mlp.3.weight\", \"tape_heads.6.blocks.1.mlp.3.bias\", \"tape_heads.6.blocks.1.ln_mlp.weight\", \"tape_heads.6.blocks.1.ln_mlp.bias\", \"tape_heads.6.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.6.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.6.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.6.blocks.1.logits_attention.out_proj.bias\", \"tape_heads.7.blocks.0.unembedding\", \"tape_heads.7.blocks.0.chunk_proj.weight\", \"tape_heads.7.blocks.0.chunk_proj.bias\", \"tape_heads.7.blocks.0.attn.in_proj_weight\", \"tape_heads.7.blocks.0.attn.in_proj_bias\", \"tape_heads.7.blocks.0.attn.out_proj.weight\", \"tape_heads.7.blocks.0.attn.out_proj.bias\", \"tape_heads.7.blocks.0.ln_attn.weight\", \"tape_heads.7.blocks.0.ln_attn.bias\", \"tape_heads.7.blocks.0.mlp.0.weight\", \"tape_heads.7.blocks.0.mlp.0.bias\", \"tape_heads.7.blocks.0.mlp.2.weight\", \"tape_heads.7.blocks.0.mlp.2.bias\", \"tape_heads.7.blocks.0.mlp.3.weight\", \"tape_heads.7.blocks.0.mlp.3.bias\", \"tape_heads.7.blocks.0.ln_mlp.weight\", \"tape_heads.7.blocks.0.ln_mlp.bias\", \"tape_heads.7.blocks.0.logits_attention.in_proj_weight\", \"tape_heads.7.blocks.0.logits_attention.in_proj_bias\", \"tape_heads.7.blocks.0.logits_attention.out_proj.weight\", \"tape_heads.7.blocks.0.logits_attention.out_proj.bias\", \"tape_heads.7.blocks.1.unembedding\", \"tape_heads.7.blocks.1.chunk_proj.weight\", \"tape_heads.7.blocks.1.chunk_proj.bias\", \"tape_heads.7.blocks.1.attn.in_proj_weight\", \"tape_heads.7.blocks.1.attn.in_proj_bias\", \"tape_heads.7.blocks.1.attn.out_proj.weight\", \"tape_heads.7.blocks.1.attn.out_proj.bias\", \"tape_heads.7.blocks.1.ln_attn.weight\", \"tape_heads.7.blocks.1.ln_attn.bias\", \"tape_heads.7.blocks.1.mlp.0.weight\", \"tape_heads.7.blocks.1.mlp.0.bias\", \"tape_heads.7.blocks.1.mlp.2.weight\", \"tape_heads.7.blocks.1.mlp.2.bias\", \"tape_heads.7.blocks.1.mlp.3.weight\", \"tape_heads.7.blocks.1.mlp.3.bias\", \"tape_heads.7.blocks.1.ln_mlp.weight\", \"tape_heads.7.blocks.1.ln_mlp.bias\", \"tape_heads.7.blocks.1.logits_attention.in_proj_weight\", \"tape_heads.7.blocks.1.logits_attention.in_proj_bias\", \"tape_heads.7.blocks.1.logits_attention.out_proj.weight\", \"tape_heads.7.blocks.1.logits_attention.out_proj.bias\". "
     ]
    }
   ],
   "source": [
    "state_dict = torch.load(\"model_dict_216_225.pth\")\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2992829841302609"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(math.log(vocab_size/(2+16)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# Training control variables\n",
    "seq_len = 2  # Start with the smallest sequence\n",
    "max_seq_len = 256\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Loss tracking\n",
    "loss_history = []  # Store all losses\n",
    "epochs_per_check = 10  # Print every 10 epochs\n",
    "target_loss = max(math.log(vocab_size/(seq_len+1)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.073626518249512 2\n",
      "9.624027252197266 2\n",
      "9.55377197265625 2\n",
      "7.29094123840332 2\n",
      "8.063648223876953 2\n",
      "9.621648788452148 2\n",
      "7.560042858123779 2\n",
      "6.250223159790039 2\n",
      "8.365589141845703 2\n",
      "6.696925640106201 2\n",
      "8.094328880310059 2\n",
      "5.054617881774902 2\n",
      "7.243904113769531 2\n",
      "7.026040554046631 2\n",
      "7.6277079582214355 2\n",
      "8.690078735351562 2\n",
      "11.061820983886719 2\n",
      "7.142691135406494 2\n",
      "9.007265090942383 2\n",
      "11.117100715637207 2\n",
      "9.713037490844727 2\n",
      "7.062280178070068 2\n",
      "8.288870811462402 2\n",
      "8.12834358215332 2\n",
      "9.643917083740234 2\n",
      "9.68327522277832 2\n",
      "9.143342971801758 2\n",
      "7.57409143447876 2\n",
      "6.836498260498047 2\n",
      "6.24106502532959 2\n",
      "9.081289291381836 2\n",
      "4.44679069519043 2\n",
      "8.381699562072754 2\n",
      "6.467036247253418 2\n",
      "7.475838661193848 2\n",
      "6.485935211181641 2\n",
      "7.920836925506592 2\n",
      "9.371171951293945 2\n",
      "6.411113739013672 2\n",
      "5.2076005935668945 2\n",
      "7.629257678985596 2\n",
      "6.390580654144287 2\n",
      "8.30513858795166 2\n",
      "7.566246032714844 2\n",
      "5.381831169128418 2\n",
      "6.035212516784668 2\n",
      "5.83392333984375 2\n",
      "5.537875652313232 2\n",
      "5.1334991455078125 2\n",
      "6.513458728790283 2\n",
      "5.477247714996338 2\n",
      "7.668196201324463 2\n",
      "5.579350471496582 2\n",
      "4.952584266662598 2\n",
      "5.774605751037598 2\n",
      "6.643375396728516 2\n",
      "4.9105329513549805 2\n",
      "6.520421028137207 2\n",
      "3.706352949142456 2\n",
      "4.122692108154297 2\n",
      "3.912825345993042 2\n",
      "3.7269134521484375 2\n",
      "4.907983779907227 2\n",
      "4.4774274826049805 2\n",
      "6.052585601806641 2\n",
      "4.818452835083008 2\n",
      "4.236693382263184 2\n",
      "3.104997158050537 2\n",
      "3.4192352294921875 2\n",
      "3.5190415382385254 2\n",
      "5.3325910568237305 2\n",
      "2.809619903564453 2\n",
      "3.4775917530059814 2\n",
      "3.9690463542938232 2\n",
      "3.4971513748168945 2\n",
      "4.259374618530273 2\n",
      "2.669785976409912 2\n",
      "5.753087997436523 2\n",
      "3.1305370330810547 2\n",
      "3.3883187770843506 2\n",
      "3.4485647678375244 2\n",
      "2.8680198192596436 2\n",
      "4.274367809295654 2\n",
      "2.786655902862549 2\n",
      "2.398974895477295 2\n",
      "3.684800624847412 2\n",
      "3.154630661010742 2\n",
      "3.7327120304107666 2\n",
      "2.2326273918151855 2\n",
      "3.878345012664795 2\n",
      "3.4991977214813232 2\n",
      "2.5031933784484863 2\n",
      "3.2739784717559814 2\n",
      "1.8716132640838623 2\n",
      "2.580338478088379 2\n",
      "3.365121603012085 2\n",
      "3.18625807762146 2\n",
      "2.884654998779297 2\n",
      "2.4819717407226562 2\n",
      "2.0034193992614746 2\n",
      "2.7844338417053223 2\n",
      "2.145261764526367 2\n",
      "2.201000452041626 2\n",
      "2.426060199737549 2\n",
      "2.8750674724578857 2\n"
     ]
    }
   ],
   "source": [
    "while seq_len <= max_seq_len:\n",
    "    total_loss = 0.0\n",
    "    step_count = 0\n",
    "\n",
    "    # Training loop for current sequence length\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        x_batch, targets = get_batch(batch_size, seq_len)\n",
    "        x_batch, targets = x_batch.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            preds = model(x_batch)\n",
    "            gathered_probs = torch.gather(preds, -1, targets.unsqueeze(-1)).squeeze(-1)\n",
    "            base_loss = -torch.log(gathered_probs + 1e-16)\n",
    "            final_loss = base_loss.mean()\n",
    "\n",
    "        scaler.scale(final_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Track loss & progress\n",
    "        loss_val = final_loss.item()\n",
    "        loss_history.append(loss_val)\n",
    "        total_loss += loss_val\n",
    "        step_count += 1\n",
    "        print(loss_val,seq_len)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009856050834059715\n",
      "0.008584938943386078\n",
      "0.010900353081524372\n",
      "0.009557952173054218\n",
      "0.008415843360126019\n",
      "0.009721972979605198\n",
      "0.009341489523649216\n",
      "0.008129240013659\n",
      "0.007575596682727337\n",
      "0.00978936068713665\n",
      "0.0068056173622608185\n",
      "0.01155703142285347\n",
      "0.009352175518870354\n",
      "0.009955303743481636\n",
      "0.009657113812863827\n",
      "0.009384965524077415\n",
      "0.013828913681209087\n",
      "0.009505216032266617\n",
      "0.009108872152864933\n",
      "0.006791351828724146\n",
      "0.008747464045882225\n",
      "0.005944461561739445\n",
      "0.009159301407635212\n",
      "0.008960890583693981\n",
      "0.009410623461008072\n",
      "0.008687897585332394\n",
      "0.007771106902509928\n",
      "0.010085010901093483\n",
      "0.00895774271339178\n",
      "0.007820510305464268\n",
      "0.008677255362272263\n",
      "0.009867753833532333\n",
      "0.009784572757780552\n",
      "0.008502332493662834\n",
      "0.010864307172596455\n",
      "0.010727165266871452\n",
      "0.010079965926706791\n",
      "0.010349185205996037\n",
      "0.008892253041267395\n",
      "0.007471131626516581\n",
      "0.01056732889264822\n",
      "0.009274356998503208\n",
      "0.008538286201655865\n",
      "0.011307922191917896\n",
      "0.008775121532380581\n",
      "0.008944605477154255\n",
      "0.006953865755349398\n",
      "0.010667169466614723\n",
      "0.008162211626768112\n",
      "0.011150587350130081\n",
      "0.0064419470727443695\n",
      "0.008765225298702717\n",
      "0.008452293463051319\n",
      "0.009001735597848892\n",
      "0.008355802856385708\n",
      "0.010311450809240341\n",
      "0.00886841956526041\n",
      "0.008847598917782307\n",
      "0.010495323687791824\n",
      "0.010552032850682735\n",
      "0.010072185657918453\n",
      "0.008737202733755112\n",
      "0.009777560830116272\n",
      "0.01203964278101921\n",
      "0.008379855193197727\n",
      "0.008915952406823635\n",
      "0.0065596094354987144\n",
      "0.008070283569395542\n",
      "0.00795236136764288\n",
      "0.010242191143333912\n",
      "0.008229806087911129\n",
      "0.010644987225532532\n",
      "0.008743209764361382\n",
      "0.008586140349507332\n",
      "0.009646348655223846\n",
      "0.00831094104796648\n",
      "0.010529134422540665\n",
      "0.007036017253994942\n",
      "0.006515384651720524\n",
      "0.007929529994726181\n",
      "0.008146469481289387\n",
      "0.00902519840747118\n",
      "0.009564416483044624\n",
      "0.008030055090785027\n",
      "0.008640737272799015\n",
      "0.00863923504948616\n",
      "0.010889014229178429\n",
      "0.008945763111114502\n",
      "0.007046935614198446\n",
      "0.007755849044770002\n",
      "0.008776236325502396\n",
      "0.00901744607836008\n",
      "0.007799762766808271\n",
      "0.011069378815591335\n",
      "0.00756829883903265\n",
      "0.010054364800453186\n",
      "0.006057426333427429\n",
      "0.008564691990613937\n",
      "0.009671569801867008\n",
      "0.0075666289776563644\n",
      "0.009573377668857574\n",
      "0.00987847987562418\n",
      "0.008900315500795841\n",
      "0.010547252371907234\n",
      "0.006899489555507898\n",
      "0.008236488327383995\n",
      "0.010878905653953552\n",
      "0.0074021415784955025\n",
      "0.008589563891291618\n",
      "0.0085127092897892\n",
      "0.008513112552464008\n",
      "0.009232569485902786\n",
      "0.00921462569385767\n",
      "0.008638720959424973\n",
      "0.009687195532023907\n",
      "0.007822439074516296\n",
      "0.010186625644564629\n",
      "0.007869593799114227\n",
      "0.009780286811292171\n",
      "0.008503559045493603\n",
      "0.012080450542271137\n",
      "0.009484829381108284\n",
      "0.00856595579534769\n",
      "0.008496927097439766\n",
      "0.009641789831221104\n",
      "0.009682363830506802\n",
      "0.009605858474969864\n",
      "0.008411193266510963\n",
      "0.009696288034319878\n",
      "0.01009915117174387\n",
      "0.009078430943191051\n",
      "0.008424694649875164\n",
      "0.007226107642054558\n",
      "0.010218215174973011\n",
      "0.008029896765947342\n",
      "0.009533566422760487\n",
      "0.010074443183839321\n",
      "0.008067697286605835\n",
      "0.007803230080753565\n",
      "0.009863908402621746\n",
      "0.007307909429073334\n",
      "0.00789851974695921\n",
      "0.010852651670575142\n",
      "0.009624862112104893\n",
      "0.00828478205949068\n",
      "0.01017878856509924\n",
      "0.007573356851935387\n",
      "0.009352614171802998\n",
      "0.010188242420554161\n",
      "0.007978593930602074\n",
      "0.009782054461538792\n",
      "0.008486881852149963\n",
      "0.009543044492602348\n",
      "0.009609132073819637\n",
      "0.006876526866108179\n",
      "0.009261351078748703\n",
      "0.00812322087585926\n",
      "0.009319843724370003\n",
      "0.009664209559559822\n",
      "0.0077140419743955135\n",
      "0.007675116881728172\n",
      "0.007207967806607485\n",
      "0.011701592244207859\n",
      "0.009312876500189304\n",
      "0.008182204328477383\n",
      "0.009176408872008324\n",
      "0.008188343606889248\n",
      "0.007001293823122978\n",
      "0.007678602822124958\n",
      "0.008356225676834583\n",
      "0.009629704989492893\n",
      "0.010060353204607964\n",
      "0.008188811130821705\n",
      "0.008532673120498657\n",
      "0.010113983415067196\n",
      "0.007973087951540947\n",
      "0.006369528826326132\n",
      "0.005582618061453104\n",
      "0.010064334608614445\n",
      "0.008105123415589333\n",
      "0.008101954124867916\n",
      "0.00828494317829609\n",
      "0.00920637883245945\n",
      "0.007798722479492426\n",
      "0.010417547076940536\n",
      "0.011211835779249668\n",
      "0.008281633257865906\n",
      "0.010229404084384441\n",
      "0.009368009865283966\n",
      "0.008212124928832054\n",
      "0.009347210638225079\n",
      "0.008370648138225079\n",
      "0.00686289370059967\n",
      "0.00953834317624569\n",
      "0.009709334000945091\n",
      "0.008467007428407669\n",
      "0.007961527444422245\n",
      "0.010634828358888626\n",
      "0.008713160641491413\n",
      "0.010245591402053833\n",
      "0.008268590085208416\n",
      "0.011772286146879196\n",
      "0.00967815238982439\n",
      "0.007675886619836092\n",
      "0.010233331471681595\n",
      "0.009227123111486435\n",
      "0.008919660933315754\n",
      "0.010251542553305626\n",
      "0.009586506523191929\n",
      "0.006391918286681175\n",
      "0.00880097784101963\n",
      "0.009223386645317078\n",
      "0.009369158186018467\n",
      "0.009564897045493126\n",
      "0.012004916556179523\n",
      "0.00947075616568327\n",
      "0.010165240615606308\n",
      "0.008425222709774971\n",
      "0.008546103723347187\n",
      "0.009192879311740398\n",
      "0.008684183470904827\n",
      "0.00965982023626566\n",
      "0.010429359041154385\n",
      "0.008627253584563732\n",
      "0.006465240381658077\n",
      "0.009532537311315536\n",
      "0.007847689092159271\n",
      "0.009355378337204456\n",
      "0.008014941588044167\n",
      "0.007118870038539171\n",
      "0.011413199827075005\n",
      "0.008422210812568665\n",
      "0.009252010844647884\n",
      "0.010393058881163597\n",
      "0.011620637960731983\n",
      "0.009933709166944027\n",
      "0.008786081336438656\n",
      "0.009396514855325222\n",
      "0.00904794316738844\n",
      "0.008042676374316216\n",
      "0.01002624910324812\n",
      "0.006665258202701807\n",
      "0.0072974832728505135\n",
      "0.010147946886718273\n",
      "0.00862079206854105\n",
      "0.008861991576850414\n",
      "0.008728754706680775\n",
      "0.009630325250327587\n",
      "0.007794384844601154\n",
      "0.007843653671443462\n",
      "0.009614292532205582\n",
      "0.009160461835563183\n",
      "0.010057361796498299\n",
      "0.006761271972209215\n",
      "0.008448927663266659\n",
      "0.011124531738460064\n",
      "0.009819336235523224\n",
      "0.008326398208737373\n",
      "0.009347901679575443\n",
      "0.006983782164752483\n",
      "0.00996924564242363\n",
      "0.00875527411699295\n",
      "0.008737456053495407\n",
      "0.010756455361843109\n",
      "0.00773207051679492\n",
      "0.009168779477477074\n",
      "0.006961540784686804\n",
      "0.012151229195296764\n",
      "0.008103782311081886\n",
      "0.01091326680034399\n",
      "0.008890199474990368\n",
      "0.007896127179265022\n",
      "0.010207146406173706\n",
      "0.009257331490516663\n",
      "0.008817246183753014\n",
      "0.00871223770081997\n",
      "0.010346785187721252\n",
      "0.009849424473941326\n",
      "0.009723598137497902\n",
      "0.007412902545183897\n",
      "0.008392599411308765\n",
      "0.0069253635592758656\n",
      "0.00957541260868311\n",
      "0.0077794441021978855\n",
      "0.008104369975626469\n",
      "0.008139370009303093\n",
      "0.007790374103933573\n",
      "0.010418173857033253\n",
      "0.007541246246546507\n",
      "0.010694954544305801\n",
      "0.011166304349899292\n",
      "0.008304771967232227\n",
      "0.009773911908268929\n",
      "0.012311604805290699\n",
      "0.009286644868552685\n",
      "0.008840343914926052\n",
      "0.009346847422420979\n",
      "0.008879666216671467\n",
      "0.009256365709006786\n",
      "0.008415721356868744\n",
      "0.010591539554297924\n",
      "0.006596878170967102\n",
      "0.008886965923011303\n",
      "0.006238841917365789\n",
      "0.007836749777197838\n",
      "0.010319028981029987\n",
      "0.008212296292185783\n",
      "0.006532105151563883\n",
      "0.007067941129207611\n",
      "0.007276658900082111\n",
      "0.009560511447489262\n",
      "0.00713900662958622\n",
      "0.0071496181190013885\n",
      "0.010697860270738602\n",
      "0.005922356620430946\n",
      "0.008099083788692951\n",
      "0.010169186629354954\n",
      "0.00997499655932188\n",
      "0.005625875201076269\n",
      "0.008565686643123627\n",
      "0.008888880722224712\n",
      "0.009096822701394558\n",
      "0.0109123969450593\n",
      "0.011184335686266422\n",
      "0.009443574585020542\n",
      "0.00746139558032155\n",
      "0.008932920172810555\n",
      "0.007848558947443962\n",
      "0.00842451211065054\n",
      "0.009120981208980083\n",
      "0.007443541195243597\n",
      "0.008020314387977123\n",
      "0.008226475678384304\n",
      "0.0069688549265265465\n",
      "0.009959491901099682\n",
      "0.007670758757740259\n",
      "0.011985651217401028\n",
      "0.010060206055641174\n",
      "0.008283451199531555\n",
      "0.009379117749631405\n",
      "0.007953011430799961\n",
      "0.009154412895441055\n",
      "0.006687123328447342\n",
      "0.008896714076399803\n",
      "0.0075855134055018425\n",
      "0.008988640271127224\n",
      "0.006889463402330875\n",
      "0.007197858765721321\n",
      "0.00868644192814827\n",
      "0.008759239688515663\n",
      "0.010733929462730885\n",
      "0.009004908613860607\n",
      "0.010364321991801262\n",
      "0.009388837032020092\n",
      "0.007614037021994591\n",
      "0.009857971221208572\n",
      "0.00647052563726902\n",
      "0.007159332744777203\n",
      "0.008561589755117893\n",
      "0.008203505538403988\n",
      "0.007686043623834848\n",
      "0.006666023284196854\n",
      "0.008561140857636929\n",
      "0.006630070507526398\n",
      "0.007595865987241268\n",
      "0.007522961590439081\n",
      "0.004994524642825127\n",
      "0.008663775399327278\n",
      "0.00624102121219039\n",
      "0.007803662214428186\n",
      "0.011083041317760944\n",
      "0.007722529117017984\n",
      "0.010724397376179695\n",
      "0.010759004391729832\n",
      "0.006553055252879858\n",
      "0.010233239270746708\n",
      "0.009164426475763321\n",
      "0.010263985954225063\n",
      "0.010165777057409286\n",
      "0.010064657777547836\n",
      "0.007388008292764425\n",
      "0.008447735570371151\n",
      "0.007697078865021467\n",
      "0.008916576392948627\n",
      "0.008570804260671139\n",
      "0.007501704152673483\n",
      "0.00872870348393917\n",
      "0.009381366893649101\n",
      "0.00958643015474081\n",
      "0.010155984200537205\n",
      "0.006369135808199644\n",
      "0.0073369708843529224\n",
      "0.00982837937772274\n",
      "0.009566627442836761\n",
      "0.00892545748502016\n",
      "0.0076278685592114925\n",
      "0.009200935252010822\n",
      "0.010951271280646324\n",
      "0.010978984646499157\n",
      "0.009964335709810257\n",
      "0.006768513470888138\n",
      "0.006655214820057154\n",
      "0.010350162163376808\n",
      "0.010363415814936161\n",
      "0.008322197943925858\n",
      "0.007717852480709553\n",
      "0.00938365887850523\n",
      "0.006087046582251787\n",
      "0.006735358387231827\n",
      "0.009078274480998516\n",
      "0.008746214210987091\n",
      "0.010297366417944431\n",
      "0.00915500894188881\n",
      "0.00849529355764389\n",
      "0.008376904763281345\n",
      "0.00913181807845831\n",
      "0.007326221093535423\n",
      "0.008846056647598743\n",
      "0.00890772882848978\n",
      "0.010937635786831379\n",
      "0.007393355015665293\n",
      "0.009917696006596088\n",
      "0.009888293221592903\n",
      "0.008502368815243244\n",
      "0.009925511665642262\n",
      "0.008117149583995342\n",
      "0.010118935257196426\n",
      "0.010167057625949383\n",
      "0.00816795788705349\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     base_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(gathered_probs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-16\u001b[39m)\n\u001b[0;32m     11\u001b[0m     final_loss \u001b[38;5;241m=\u001b[39m base_loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m---> 13\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m     15\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\miniforge3\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniforge3\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000000):\n",
    "        model.train()\n",
    "        x_batch, targets = get_batch(batch_size, 256)\n",
    "        x_batch, targets = x_batch.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            preds = model(x_batch)\n",
    "            gathered_probs = torch.gather(preds, -1, targets.unsqueeze(-1)).squeeze(-1)\n",
    "            base_loss = -torch.log(gathered_probs + 1e-16)\n",
    "            final_loss = base_loss.mean()\n",
    "\n",
    "        scaler.scale(final_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Track loss & progress\n",
    "        loss_val = final_loss.item()\n",
    "        loss_history.append(loss_val)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'model_dict_216_225.pth'\n",
    "\n",
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"full_model_structure_216_225.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Wolf(model.parameters(), lr=0.3678)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20e28ef0310>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sample:\n",
      " oh Romeo! Romeo! SS:\n",
      "Bits.\n",
      "\n",
      "ve is pore:\n",
      "Andis, tunk rest'TESTHAwhas thern's\n",
      "Ho'stecrew I cre:\n",
      "To thore as ing graito ight\n",
      "If un-! aS:\n",
      "HEOHe my hed.\n",
      "\n",
      "MA mallark, theo.\n",
      "\n",
      "AMES:\n",
      "I nell foruj: for brave s&NG whit,\n",
      "havisen\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluation: Text Generation\n",
    "# ====================================================\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prompt = \"oh Romeo! Romeo!\"\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    generated = context\n",
    "    for _ in range(200):  # Generate 200 tokens.\n",
    "        inp = generated[:, -seq_len:]\n",
    "        p = model(inp)  # p: (B, seq, vocab_size)\n",
    "        last_token_probs = p[:, -1, :]  # Shape: [batch_size, vocab_size]\n",
    "        predicted_token = torch.multinomial(last_token_probs, num_samples=1)\n",
    "\n",
    "        #next_token = torch.multinomial(last_token_probs, num_samples=1)\n",
    "        generated = torch.cat((generated, predicted_token), dim=1)\n",
    "    sample = decode(generated[0].cpu().tolist())\n",
    "    print(\"Generated Sample:\\n\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
