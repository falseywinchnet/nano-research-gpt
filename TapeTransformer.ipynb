{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPYRIGHT NOTICE\n",
    "In the name of Christ our Lord be blessed. We, Joshuah Rainstar(joshuah.rainstar@gmail.com), do claim copyright to this code, or software, and associated documentation, as our work in the year 2025 Anno Domini, reserving all rights and assigning them in accordance with the following license terms:\n",
    "\n",
    "1. Permission is by our authority and with this statement granted, to any person or artificial intelligence without limitation or restriction to examine, analyze, read, dissect, translate, use, modify, and distribute the aforementioned copyrighted items, subject to the following conditions:\n",
    "2. This license must be included in full with any copies or works containing substantial portions of the copyrighted items.\n",
    "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "\n",
    "THE COPYRIGHTED ITEMS ARE PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE COPYRIGHTED ITEMS OR THEIR USE OR ANY OTHER CIRCUMSTANCES CONCERNING THEM.\n"
   ]
  },
  {
   "attachments": {
    "28374c77-74dc-463c-984c-f518ca74a4cd.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is an experimental model intended to elucidate possible mechanics for attention across sequences in addition to tokenwise. it is reasonably fast and efficient. conceptually, the design was envisioned by me and coded through refinement with OpenAI Codex Orion One and chatgpt. i find that if i cant understand a thing, however clever it is- its wrong.\n",
    "so, this is largely a from-scratch along aligned principles. \n",
    "\n",
    "you are advised in life to apply a similar practice. nothing good comes of shit you dont comprehend.\n",
    "\n",
    "\"hierarchical multi-scale transformer with MoE-like  selection\"\n",
    "\n",
    "my own fucking activation function\n",
    "\n",
    "my own fucking loss method borrowing from harmonic loss but using student-t distribution!\n",
    "https://arxiv.org/abs/2502.01628\n",
    "\n",
    "XOR from  Two-argument activation functions learn soft XOR operations like cortical neurons\r\n",
    "https://arxiv.org/abs/2110.06871note that my implementation is a differential XOR for backprop capability\n",
    "motivation: little bit of internal reasoning maybe? Impact: slows down convergence somewhat\n",
    "ROPE from google\n",
    "\n",
    "entropy based reward to encourage diverse attention\n",
    "https://arxiv.org/abs/2203.09192\n",
    "\n",
    "\n",
    "WOLF optimizer experimental by me, it may not beat adam but it is simpler than adam, closer to SGD with some smoothing of integration\n",
    "impact: speeds up convergence somewhat for early iterations and will not NAN from high LR.\n",
    "probable benefit- switch optimizers after model drops. could be good for bigger models.. maybe\n",
    "\n",
    "![image.png](attachment:28374c77-74dc-463c-984c-f518ca74a4cd.png)\n",
    "m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jcJTMiWT89P5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dl9uYIM16MG4"
   },
   "outputs": [],
   "source": [
    "\n",
    "def student_t_unembedding(hidden_states, unembedding, df=2.718281828459, eps=1e-9, placeholder_idx=None):\n",
    "    \"\"\"\n",
    "    Student's t-based unembedding with optional placeholder modification.\n",
    "    \n",
    "    Arguments:\n",
    "      hidden_states: (B, S, D)  => modelâ€™s output embeddings (hidden state)\n",
    "      unembedding:   (D, V)    => learnable \"word vectors\" (unembedding matrix)\n",
    "      df (float): degrees of freedom for the Student's t distribution\n",
    "      eps (float): numerical epsilon to avoid log(0) and div-by-zero\n",
    "      placeholder_idx (int, optional): if provided, indicates the column in the unembedding\n",
    "          corresponding to the placeholder token. The distances for that token will be adjusted \n",
    "          using an adaptive noise factor.\n",
    "    \n",
    "    Returns:\n",
    "      p: (B, S, V)  probability distribution over V vocabulary tokens.\n",
    "    \"\"\"\n",
    "    B, S, D = hidden_states.shape\n",
    "    V = unembedding.shape[1]\n",
    "    # Expand hidden => (B, S, 1, D)\n",
    "    x_expanded = hidden_states.unsqueeze(2)\n",
    "    # Expand unembedding => (1, 1, V, D)\n",
    "    w_expanded = unembedding.t().unsqueeze(0).unsqueeze(0)  # shape: (1, 1, V, D)\n",
    "    \n",
    "    # Compute squared Euclidean distance between each hidden vector and each unembedding vector.\n",
    "    dist_sq = torch.sum((x_expanded - w_expanded) ** 2, dim=-1).clamp(min=1e-6)  # (B, S, V)\n",
    "        \n",
    "    # Compute the negative energy:\n",
    "    #    E = 0.5*(df + D) * log(1 + dist_sq / df)\n",
    "    # and so log probability (up to an additive constant) is:\n",
    "    #    log_p = -E\n",
    "    log_p_unnorm = -0.5 * (df + D) * torch.log1p(dist_sq / df)  # (B, S, V)\n",
    "    \n",
    "    # Normalize via log_softmax over the vocabulary dimension.\n",
    "    log_p = F.log_softmax(log_p_unnorm, dim=-1)  # (B, S, V)\n",
    "    return log_p\n",
    "\n",
    "\n",
    "\n",
    "class Wolf(Optimizer):\n",
    "    \"\"\"Implements Wolf algorithm.\"\"\"\n",
    "    def __init__(self, params, lr=0.25, betas=(0.9, 0.999), eps=1e-8):\n",
    "        # Define default parameters\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps)\n",
    "        self.lr = lr\n",
    "        # Initialize the parent Optimizer class first\n",
    "        super().__init__(params, defaults)\n",
    "        # Constants specific to Wolf\n",
    "        # Initialize state for each parameter\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['p'] = torch.zeros_like(p)  # Second moment estimate\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step and adjusts dropout in transformer blocks.\"\"\"\n",
    "        etcerta = 0.367879441  # Constant used in update rule\n",
    "        et = 1 - etcerta\n",
    "    \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "    \n",
    "        # Iterate over parameter groups.\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                grad = p.grad\n",
    "                state = self.state[p]\n",
    "                exp_avg = state['p']\n",
    "    \n",
    "                # Compute update and update second moment-like state.\n",
    "                update = exp_avg * et + grad * etcerta\n",
    "                state['p'] = exp_avg * et + update * etcerta\n",
    "    \n",
    "                # Compute sign agreement between update and gradient.\n",
    "                sign_agreement = torch.sign(update) * torch.sign(grad)\n",
    "    \n",
    "                # Where the signs agree (mask is True), update the parameter.\n",
    "                mask = (sign_agreement > 0)\n",
    "                adaptive_alpha = group.get('lr', self.lr)\n",
    "                p.data = torch.where(mask, p.data - adaptive_alpha * update, p.data)\n",
    "    \n",
    "                # AMP Compatibility: Ensure a step counter is updated\n",
    "                state['step'] = state.get('step', 0) + 1  # Track optimization steps\n",
    "    \n",
    "        return loss\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Custom Activation\n",
    "# ---------------------------------------------------\n",
    "class ReferenceActivation(nn.Module):\n",
    "    def __init__(self, gamma=24):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, x):\n",
    "        x.clamp_(-2, 2)\n",
    "        log_x = torch.sign(x) * torch.log1p(torch.abs(x))\n",
    "        safe_x = torch.nan_to_num(log_x, nan=0.0)\n",
    "\n",
    "        return log_x / torch.sqrt(1 + self.gamma * log_x ** 2)\n",
    "            \n",
    "class CachedMultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.0, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        # We use the built-in multihead attention module.\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=batch_first)\n",
    "    \n",
    "    def forward(self, query, key, value, past_kv=None):\n",
    "        \"\"\"\n",
    "        query: (B, S_new, D)\n",
    "        key, value: (B, S_current, D) for the current input tokens.\n",
    "        past_kv: Tuple (past_key, past_value) or None.\n",
    "        \"\"\"\n",
    "        if not self.training:\n",
    "            if past_kv is not None:\n",
    "                past_key, past_value = past_kv\n",
    "                # Concatenate along the sequence dimension\n",
    "                key = torch.cat([past_key, key], dim=1)\n",
    "                value = torch.cat([past_value, value], dim=1)\n",
    "            # Run the attention module.\n",
    "            attn_output, _ = self.attn(query, key, value)\n",
    "            # The new cache holds all keys and values computed so far.\n",
    "            new_kv = (key, value)\n",
    "            return attn_output, new_kv\n",
    "        else:\n",
    "            attn_output,attn_weights = self.attn(query, key, value)\n",
    "\n",
    "            attn_weights.clamp_( min=1e-9, max=1.0)\n",
    "            entropy = -torch.sum(attn_weights * torch.log(attn_weights + 1e-9), dim=-1)\n",
    "            attn_weights_1 = attn_weights.sum(dim=-1)\n",
    "            attn_weights_2 = attn_weights.sum(dim=-2)\n",
    "            attn_weights = (attn_weights_1 + attn_weights_2)/2\n",
    "\n",
    "            return attn_output, entropy, attn_weights\n",
    "            \n",
    "class RectifiedKAN(nn.Module):\n",
    "    def __init__(self, embed_dim, expansion_factor=8, dropout=0.0):\n",
    "        super().__init__()\n",
    "        hidden_dim = expansion_factor * embed_dim\n",
    "\n",
    "        self.expand = nn.Linear(embed_dim, hidden_dim)  # Expand input\n",
    "        self.shift = nn.Parameter(torch.zeros(hidden_dim))  # Shift parameters\n",
    "        self.activation = ReferenceActivation()  # Piecewise linear activation\n",
    "        self.linear = nn.Linear(hidden_dim, embed_dim)  # Project back\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.expand(x)  # Expand input\n",
    "        x = x + self.shift  # Apply shift (edge-based transform)\n",
    "        x = self.activation(x)  # Nonlinear edge activation\n",
    "        x = self.linear(x)  # Collapse back to original space\n",
    "        x = self.dropout(x)  # Regularization\n",
    "        return x\n",
    "\n",
    "\n",
    "class TapeHeadBlock(nn.Module):\n",
    "    def __init__(self, chunk_size, seq_len, embed_dim, vocab_size, num_heads=1, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.chunk_size = chunk_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_seq_len = seq_len\n",
    "\n",
    "        # Token embeddings\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        # Sinusoidal positional embeddings (Precomputed)\n",
    "        self.register_buffer(\"pos_emb\", self._build_sinusoidal_embedding(seq_len, embed_dim))\n",
    "\n",
    "        # Rotary embedding setup\n",
    "        self.use_rope = True  # Set to False to disable RoPE\n",
    "        if self.use_rope:\n",
    "            self.register_buffer(\"rope_freqs\", self._build_rope_frequencies(embed_dim))\n",
    "\n",
    "        # Attention layers\n",
    "        self.cached_attn = CachedMultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln_attn = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # MLP and normalization\n",
    "        self.mlp = RectifiedKAN(embed_dim)\n",
    "        self.ln_mlp = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Unembedding matrix\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "\n",
    "        # Logits cross-attention\n",
    "        self.placeholder_idx = placeholder_idx\n",
    "\n",
    "    def _build_sinusoidal_embedding(self, seq_len, embed_dim):\n",
    "        \"\"\"Compute sinusoidal positional embeddings\"\"\"\n",
    "        position = torch.arange(seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000.0) / embed_dim))\n",
    "        pos_emb = torch.zeros(seq_len, embed_dim)\n",
    "        pos_emb[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_emb[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pos_emb.unsqueeze(0)  # Shape: (1, seq_len, embed_dim)\n",
    "\n",
    "\n",
    "    def _build_rope_frequencies(self, embed_dim):\n",
    "        \"\"\"Build the inverse frequency tensor for RoPE and ensure it is a PyTorch tensor.\"\"\"\n",
    "        half_dim = embed_dim // 2  # For D=256, half_dim = 128\n",
    "        base_freqs = 1.0 / (10000 ** (torch.arange(0, half_dim, dtype=torch.float32) / half_dim))\n",
    "        # Remove the repeat_interleave so we keep shape (half_dim,)\n",
    "        return base_freqs.to(torch.float32)  # Shape: (D/2,)\n",
    "\n",
    "        \n",
    "    def apply_rope(self,tensor, rope_freqs):\n",
    "            \"\"\"\n",
    "            Apply Rotary Positional Embedding (RoPE) to the input tensor.\n",
    "            \n",
    "            Args:\n",
    "                tensor (Tensor): Input tensor of shape (B, S, D), where\n",
    "                                 B = batch size, S = sequence length, D = embedding dim.\n",
    "                rope_freqs (Tensor): Frequency tensor of shape (D/2,) computed via _build_rope_frequencies.\n",
    "                \n",
    "            Returns:\n",
    "                Tensor: The input tensor after applying RoPE, with the same shape (B, S, D).\n",
    "                \n",
    "            Detailed Steps & Dimensions:\n",
    "              1. Let B, S, D = tensor.shape and half_dim = D//2.\n",
    "              2. Compute positions: a tensor of shape (S,).\n",
    "              3. Compute theta = positions.unsqueeze(1) * rope_freqs.unsqueeze(0)\n",
    "                 -> theta has shape (S, half_dim).\n",
    "              4. Compute sin_theta and cos_theta from theta, each of shape (S, half_dim),\n",
    "                 then expand to (B, S, half_dim).\n",
    "              5. Split tensor into two halves along the last dimension:\n",
    "                 - x1 = tensor[..., 0::2] and x2 = tensor[..., 1::2], each with shape (B, S, half_dim).\n",
    "                 (Alternatively, one can do: x1, x2 = torch.chunk(tensor, 2, dim=-1))\n",
    "              6. Apply RoPE:\n",
    "                 - x1_rot = x1 * cos_theta - x2 * sin_theta\n",
    "                 - x2_rot = x1 * sin_theta + x2 * cos_theta\n",
    "              7. Reassemble the output by interleaving x1_rot and x2_rot.\n",
    "            \"\"\"\n",
    "            B, S, D = tensor.shape\n",
    "            if S == 1:\n",
    "                return tensor\n",
    "            assert D % 2 == 0, \"Embedding dimension must be even for RoPE.\"\n",
    "            half_dim = D // 2  # e.g. for D=256, half_dim = 128\n",
    "        \n",
    "            # Ensure rope_freqs is on the same device and dtype as tensor.\n",
    "            rope_freqs = rope_freqs.to(tensor.dtype)  # shape: (half_dim,)\n",
    "        \n",
    "            # 1. Compute positions (0, 1, ..., S-1): shape (S,)\n",
    "            positions = torch.arange(S, device=tensor.device, dtype=tensor.dtype)\n",
    "            \n",
    "            # 2. Compute theta = positions * rope_freqs:\n",
    "            #    positions: (S, 1), rope_freqs: (1, half_dim) --> theta: (S, half_dim)\n",
    "            theta = positions.unsqueeze(1) * rope_freqs.unsqueeze(0)  # shape: (S, half_dim)\n",
    "            \n",
    "            # 3. Compute sin and cos of theta:\n",
    "            sin_theta = theta.sin()  # shape: (S, half_dim)\n",
    "            cos_theta = theta.cos()  # shape: (S, half_dim)\n",
    "            \n",
    "            # 4. Expand sin and cos to shape (B, S, half_dim)\n",
    "            sin_theta = sin_theta.unsqueeze(0).expand(B, S, half_dim)\n",
    "            cos_theta = cos_theta.unsqueeze(0).expand(B, S, half_dim)\n",
    "            \n",
    "            # 5. Split tensor into two halves (real and imaginary parts).\n",
    "            # Here we use alternate slicing: the even-indexed dims are x1, odd-indexed are x2.\n",
    "            x1 = tensor[..., 0::2]  # shape: (B, S, half_dim)\n",
    "            x2 = tensor[..., 1::2]  # shape: (B, S, half_dim)\n",
    "            \n",
    "            # 6. Apply the RoPE rotation:\n",
    "            x1_rot = x1 * cos_theta - x2 * sin_theta  # shape: (B, S, half_dim)\n",
    "            x2_rot = x1 * sin_theta + x2 * cos_theta  # shape: (B, S, half_dim)\n",
    "            \n",
    "            # 7. Interleave x1_rot and x2_rot back together.\n",
    "            # One approach is to create an empty tensor and then fill in even and odd indices.\n",
    "            out = torch.empty_like(tensor)\n",
    "            out[..., 0::2] = x1_rot\n",
    "            out[..., 1::2] = x2_rot\n",
    "        \n",
    "            return out\n",
    "\n",
    "\n",
    "    def forward(self, x, prev_h, prev_emb, past_kv=None):\n",
    "        \"\"\"\n",
    "        x: (B, S) input token IDs\n",
    "        prev_h: (B, S, D) previous hidden state\n",
    "        prev_emb: (B, S, D) previous embeddings\n",
    "        logits: (B, S, V) logits distribution from previous block (can be None)\n",
    "        past_kv: Dictionary with keys 'chunk_attn' and 'logits_attn' holding KV caches\n",
    "        \"\"\"\n",
    "\n",
    "        past_chunk = past_kv.get('chunk_attn') if past_kv is not None else None\n",
    "        B,S = x.shape\n",
    "        # Compute token embeddings and add sinusoidal positional embeddings\n",
    "        seq_len = x.shape[1]\n",
    "        layer_emb = self.token_emb(x) + self.pos_emb[:, :seq_len, :]\n",
    "\n",
    "        # Apply RoPE if enabled\n",
    "        if self.use_rope:\n",
    "            layer_emb = self.apply_rope(layer_emb, self.rope_freqs)\n",
    "\n",
    "        # Attention input\n",
    "        if prev_h is not None:\n",
    "            attn_input = torch.cat([prev_emb, layer_emb, prev_h[:, -seq_len:, :]], dim=1)\n",
    "            attn_input = attn_input[:, -seq_len:, :]\n",
    "\n",
    "        else:\n",
    "            attn_input = layer_emb\n",
    "\n",
    "\n",
    "        # Compute Self-Attention with KV Caching\n",
    "        if not self.training:\n",
    "            if past_chunk is not None:\n",
    "                attn_out, new_chunk_cache  = self.cached_attn(\n",
    "                    attn_input, attn_input, attn_input, past_kv=past_chunk\n",
    "                )\n",
    "            else:\n",
    "                attn_out, new_chunk_cache = self.cached_attn(attn_input, attn_input, attn_input)\n",
    "        else:\n",
    "            attn_out, entropy_chunk, attn_weights = self.cached_attn(attn_input, attn_input, attn_input)\n",
    "\n",
    "        h_attn = self.ln_attn(attn_input + attn_out)\n",
    "\n",
    "        \n",
    "        # Pass through MLP\n",
    "        h_mlp = self.ln_mlp(h_attn + self.mlp(h_attn))\n",
    "\n",
    "        # Compute final logits\n",
    "        # Return KV cache\n",
    "        if not self.training:\n",
    "            new_cache = {'chunk_attn': new_chunk_cache}\n",
    "            return x, h_mlp, layer_emb, new_cache\n",
    "\n",
    "        if self.training:\n",
    "            attn_weights = torch.softmax(attn_weights, dim=-1)\n",
    "            return x, h_mlp, layer_emb, entropy_chunk, attn_weights\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class TapeHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-like block with progressive chunk sizes.\n",
    "    Each layer inside the TapeHead doubles the chunk size.\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len, embed_dim, vocab_size, num_layers=3, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        layer_weights = torch.linspace(0.3, 1.0, steps=self.num_layers)\n",
    "        layer_weights /= layer_weights.sum()  # Normalize\n",
    "        self.register_buffer(\"layer_weights\", layer_weights)\n",
    "        # Create progressively larger TapeHeadBlocks for the left and right streams.\n",
    "        self.blocks_left= nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=seq_len,\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_heads=max(1, 2 ** (num_layers - i)),  # Inversely scale heads\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.blocks_right = nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=seq_len,\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_heads=max(1, 2 ** (num_layers - i)),  # Inversely scale heads\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, prev_h, prev_emb, past_kv=None):\n",
    "        \"\"\"\n",
    "        past_kv: dictionary with keys 'left' and 'right', each is a list of caches (one per block).\n",
    "        \"\"\"\n",
    "        attn_weights = []\n",
    "        entropy = []\n",
    "    \n",
    "        if not self.training:\n",
    "            if past_kv is None:\n",
    "                past_kv = {'left': [None] * self.num_layers, 'right': [None] * self.num_layers}\n",
    "            prev_emb_left = prev_emb.clone() if prev_emb is not None else None\n",
    "            prev_h_left = prev_h.clone() if prev_h is not None else None\n",
    "    \n",
    "            new_past_left = []\n",
    "            new_past_right = []\n",
    "    \n",
    "            for i in range(self.num_layers):\n",
    "                # Process left block with its cache.\n",
    "                    _, h_out_left, prev_emb_left, cache_left = self.blocks_left[i](\n",
    "                        x, prev_h_left, prev_emb_left, past_kv=past_kv['left'][i]\n",
    "                    )\n",
    "                                    # Process right block with its cache.\n",
    "                    _, h_out,  prev_emb, cache_right = self.blocks_right[i](\n",
    "                        x, prev_h, prev_emb, past_kv=past_kv['right'][i])\n",
    "                    a = self.activation(h_out_left)\n",
    "                    b = self.activation(h_out)\n",
    "                    h_out = 0.5 * (a + b - 2 * a * b)\n",
    "                    prev_h_left = h_out\n",
    "                    prev_h = h_out\n",
    "                    new_past_left.append(cache_left)  # Store all layers' caches\n",
    "                    new_past_right.append(cache_right)  # Store all layers' caches\n",
    "\n",
    "            prev_emb = 0.5 * (prev_emb + prev_emb_left)\n",
    "            new_cache = {'left': new_past_left, 'right': new_past_right}\n",
    "            return x, h_out, prev_emb, new_cache  # âœ… Properly returning all layer caches\n",
    "    \n",
    "        else:  # Training mode\n",
    "            prev_emb_left = prev_emb.clone() if prev_emb is not None else None\n",
    "            prev_h_left = prev_h.clone() if prev_h is not None else None\n",
    "    \n",
    "            for i in range(self.num_layers):\n",
    "                # Process left block\n",
    "                    _, h_out_left, prev_emb_left, entropy_left, attn_weights_left = self.blocks_left[i](\n",
    "                        x, prev_h_left, prev_emb_left\n",
    "                    )\n",
    "        \n",
    "                    # Process right block\n",
    "                    _, h_out, prev_emb, entropy_right, attn_weights_right = self.blocks_right[i](\n",
    "                        x, prev_h, prev_emb\n",
    "                    )\n",
    "                    a = self.activation(h_out_left)\n",
    "                    b = self.activation(h_out)\n",
    "                    h_out = 0.5 * (a + b - 2 * a * b)\n",
    "                    prev_h_left = h_out\n",
    "                    prev_h = h_out\n",
    "                    attn_weights.append((attn_weights_left + attn_weights_right) / 2.0)\n",
    "                    entropy.append((entropy_left + entropy_right) / 2.0)\n",
    "    \n",
    "\n",
    "            prev_emb = 0.5 * (prev_emb + prev_emb_left)\n",
    "            attn_weights = torch.stack(attn_weights, dim=0)\n",
    "            attn_weights *= self.layer_weights.view(-1, 1, 1)\n",
    "            attn_weights = attn_weights.sum(dim=0)\n",
    "    \n",
    "            entropy = torch.sum(torch.stack(entropy)) / self.num_layers\n",
    "            return x, h_out, prev_emb, entropy, attn_weights  # âœ… Returns all caches correctly\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / (x.norm(2, dim=-1, keepdim=True) + self.eps) * self.weight\n",
    "        \n",
    "class TapeTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Full GPT-like model with:\n",
    "      - Token + Position Embeddings\n",
    "      - Multiple stacked TapeHeads\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, seq_len=128, num_layers=4, embed_dim=128, num_heads=2, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.placeholder_idx = placeholder_idx\n",
    "        self.num_heads = num_heads\n",
    "        # LayerNorm immediately after embeddings.\n",
    "        self.embed_ln = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Create a list of TapeHeads.\n",
    "        self.tape_heads = nn.ModuleList([\n",
    "            TapeHead(\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_layers=num_layers,\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "        self.final_norm = RMSNorm(embed_dim)\n",
    "        self.norm_gate = nn.Parameter(torch.tensor(0.5))  # for potential supervisory context\n",
    "        self.activation = ReferenceActivation()\n",
    "        # Final unembedding.\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "        self.merge_projection = nn.Linear(len(self.tape_heads) * embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x, past_kv=None):\n",
    "        \"\"\"\n",
    "        x: (B, S) integer token IDs.\n",
    "        past_kv: list of caches (one per tape head) or None.\n",
    "        Returns:\n",
    "          p_final: (B, S, V) probability distribution,\n",
    "          new_past_kv: updated caches.\n",
    "        \"\"\"\n",
    "        # Ensure batch dimension.\n",
    "        x = x.unsqueeze(0) if x.ndim == 1 else x\n",
    "        B, S = x.shape\n",
    "        assert S <= self.seq_len, \"Sequence too long.\"\n",
    "\n",
    "        prev_h = None\n",
    "        prev_emb = None\n",
    "        new_past_heads = None\n",
    "        attn_weights = None\n",
    "        all_heads_h = []\n",
    "        entropy = []\n",
    "        if not self.training:\n",
    "            new_past_heads = []\n",
    "            if past_kv is None:\n",
    "                past_kv = [\n",
    "                    {'left': [None] * head.num_layers, 'right': [None] * head.num_layers}\n",
    "                    for head in self.tape_heads\n",
    "                ]\n",
    "            # Process each TapeHead.\n",
    "            for i, head in enumerate(self.tape_heads):\n",
    "                x, h, prev_emb, head_cache = head(x, prev_h, prev_emb, past_kv=past_kv[i])\n",
    "                new_past_heads.append(head_cache)\n",
    "                all_heads_h.append(h)\n",
    "\n",
    "\n",
    "        else:   \n",
    "            # Process each TapeHead.\n",
    "            for i, head in enumerate(self.tape_heads):\n",
    "                x, h, prev_emb, entropy_head, attn_weights_head = head(x, prev_h, prev_emb)\n",
    "                all_heads_h.append(h)\n",
    "                attn_weights = attn_weights_head if attn_weights is None else attn_weights + attn_weights_head\n",
    "                entropy.append(entropy_head)\n",
    "\n",
    "        # Merge outputs from all tape heads.\n",
    "        merged_h = torch.cat(all_heads_h, dim=-1)\n",
    "        prev_h = self.merge_projection(merged_h)  # (B, S, D)\n",
    "        if not self.training:\n",
    "            \n",
    "            p_final = prev_h @ self.unembedding # (B, S, V) #no softmaxing allowed\n",
    "            return p_final, new_past_heads\n",
    "        else:\n",
    "            attn_weights /= self.num_heads\n",
    "\n",
    "            p_final = student_t_unembedding(prev_h, self.unembedding, df=2.718281828459, eps=1e-9,placeholder_idx=placeholder_idx)\n",
    "            return p_final, torch.sum(torch.stack(entropy))/self.num_heads, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc,torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VhlsGaG7ONr",
    "outputId": "1534f894-6597-49b5-c0c3-41369844874c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder token for even vocab size: â–’ with index: 65\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Preparation (Shakespeare)\n",
    "# ====================================================\n",
    "def load_shakespeare_text():\n",
    "    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "    text = requests.get(url).text\n",
    "    return text\n",
    "\n",
    "text = load_shakespeare_text()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# Add a placeholder token: an ASCII grey block (visible in output)\n",
    "placeholder = \"â–’\"  # Choose your preferred grey block character\n",
    "if placeholder not in chars:\n",
    "    chars.append(placeholder)\n",
    "    chars.sort()  # Ensure ordering is maintained\n",
    "\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "placeholder_idx = stoi[placeholder]\n",
    "print(\"Placeholder token for even vocab size:\", placeholder, \"with index:\", placeholder_idx)\n",
    "\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "def get_batch(batch_size, seq_len):\n",
    "    ix = torch.randint(0, data.size(0) - seq_len - 1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+seq_len] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+seq_len+1] for i in ix])\n",
    "    return x, y\n",
    "    \n",
    "\n",
    "# ====================================================\n",
    "# Training Setup\n",
    "# ====================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TapeTransformer(\n",
    "    vocab_size=vocab_size,  # example\n",
    "    seq_len=128,#longer not truly needed beause we KV cache\n",
    "    num_layers=4,\n",
    "    embed_dim=256,#heads times true vocab, round up \n",
    "    num_heads=4,\n",
    "    placeholder_idx=placeholder_idx,\n",
    "    dropout=0 #cannot use dropout, tooo slow\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=6e-4)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "eps = 1e-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43509249"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# Training control variables\n",
    "seq_len = 128  # Start with the smallest sequence\n",
    "max_seq_len = 128\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# Loss tracking\n",
    "epochs_per_check = 10  # Print every 10 epochs\n",
    "target_loss = max(math.log(vocab_size/(seq_len+1)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80963d46124346259ef269f370e58e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjusted Code to Improve EWMA Size and Implement Loss Ticker as a Moving Graph\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# --- Configuration Constants ---\n",
    "CHAR_WIDTH = 8  # Font size 8 for token rendering\n",
    "CHAR_HEIGHT = 11\n",
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "LOSS_BAR_HEIGHT = 32\n",
    "EWMA_HEIGHT = 32  # Increased to accommodate large text (previously 32)\n",
    "\n",
    "# Full-resolution framebuffer dimensions\n",
    "container_width = CHAR_WIDTH * SEQ_LEN  # 1024 pixels\n",
    "container_height = CHAR_HEIGHT * BATCH_SIZE  # 176 pixels\n",
    "total_height = container_height + LOSS_BAR_HEIGHT + EWMA_HEIGHT  # Adjusted for larger EWMA\n",
    "\n",
    "# Final scaled-down dimensions\n",
    "scaled_width = container_width   # 512 pixels\n",
    "scaled_height = total_height  # 170 pixels\n",
    "\n",
    "# Initialize framebuffer\n",
    "framebuffer = np.zeros((total_height, container_width, 3), dtype=np.uint8)\n",
    "\n",
    "# EWMA storage\n",
    "loss_history = []\n",
    "ticker_history = np.zeros(SEQ_LEN, dtype=np.float32)  # Stock ticker moving buffer\n",
    "loss_memory = 0.0\n",
    "# Load font\n",
    "try:\n",
    "    font = ImageFont.truetype(\"DejaVuSansMono.ttf\", 8)  # Monospaced font\n",
    "    font_large = ImageFont.truetype(\"DejaVuSansMono.ttf\", 64)  # Large EWMA display\n",
    "except:\n",
    "    font = ImageFont.load_default()\n",
    "    font_large = font\n",
    "\n",
    "# --- Color Mapping Functions ---\n",
    "def get_flame_color(val):\n",
    "    \"\"\"Map a normalized value to a flame-like color.\"\"\"\n",
    "    return np.array([int(val * 255), int(val * 0.5 * 255), 0], dtype=np.uint8)\n",
    "\n",
    "# --- IPython Display Setup ---\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "\n",
    "def get_dynamic_color(attn_val, loss_val):\n",
    "    \"\"\"\n",
    "    Compute a dynamic color transition between flame orange (uncertain) and phosphor green (confident).\n",
    "    \n",
    "    attn_val: Normalized attention value (0 to 1)\n",
    "    loss_val: Normalized loss value (0 to 1, inverted as 1 - loss)\n",
    "    \n",
    "    Returns an RGB color as a NumPy array.\n",
    "    colors late in training will often be red. this is suggested to swap out for get_flame_color\n",
    "    but only on fine tuning on new data.\n",
    "    \"\"\"\n",
    "    certainty = 1 - loss_val  # High certainty = low loss\n",
    "    \n",
    "    # Define RGB endpoints\n",
    "    orange = np.array([attn_val * 255, attn_val * 0.5 * 255, 0], dtype=np.uint8)   # Uncertain (High Loss)\n",
    "    green = np.array([attn_val * 0.5 * 255, attn_val * 255, attn_val * 0.25 * 255], dtype=np.uint8)  # Confident (Low Loss)\n",
    "    \n",
    "    # Interpolate based on certainty (0 = uncertain/orange, 1 = confident/green)\n",
    "    color = (certainty * green) + ((1 - certainty) * orange)\n",
    "    \n",
    "    return color.astype(np.uint8)\n",
    "# --- Framebuffer Update Function ---\n",
    "def update_framebuffer(attn_weights, token_losses, current_loss, tokens,entropy):\n",
    "    attn_weights =(attn_weights-attn_weights.min())/(np.ptp(attn_weights))\n",
    "    token_losses =(token_losses-token_losses.min())/(np.ptp(token_losses))\n",
    "\n",
    "    \"\"\"Render the text grid with coloration based on attn * inverse loss.\"\"\"\n",
    "    global framebuffer, loss_history, ticker_history, loss_memory\n",
    "\n",
    "    # Normalize to [0,1]\n",
    "\n",
    "    # Create image buffer\n",
    "    img = Image.new(\"RGB\", (container_width, total_height), (0, 0, 0))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Render text with colored intensity\n",
    "    char_positions = [\n",
    "        (col * CHAR_WIDTH, row * CHAR_HEIGHT + EWMA_HEIGHT + LOSS_BAR_HEIGHT, tokens[row][col])\n",
    "        for row in range(BATCH_SIZE) for col in range(SEQ_LEN)\n",
    "    ]\n",
    "    colors = [\n",
    "        tuple(get_dynamic_color(attn_weights[row, col], attn_weights[row, col]))\n",
    "        for row in range(BATCH_SIZE) for col in range(SEQ_LEN)\n",
    "    ]\n",
    "    for (x, y, char), color in zip(char_positions, colors):\n",
    "        draw.text((x, y), char, font=font, fill=color)\n",
    "\n",
    "                 \n",
    "    etcerta = 0.367879441  # Constant used in update rule\n",
    "    et = 1 - etcerta   \n",
    "    update = loss_memory * et + np.minimum(12, np.maximum(current_loss , 0)) * etcerta\n",
    "    loss_memory = loss_memory * et + update * etcerta\n",
    "    # --- EWMA Display (LARGE FONT) ---\n",
    "    loss_history.append(current_loss)\n",
    "    if len(loss_history) > 128:\n",
    "        loss_history.pop(0)\n",
    "    ewma = loss_memory\n",
    "    ewma_text = f\"{ewma:.4f}\"\n",
    "    draw.text((container_width-128, 0), ewma_text, font_size=32, fill=(65,255, 125))\n",
    "    ent_text = f\"{entropy:.4f}\"\n",
    "    draw.text((10, 0), ent_text, font_size=32, fill=(255,125, 0))  \n",
    "\n",
    "    # --- Moving Loss Ticker Graph ---\n",
    "    ticker_history = np.roll(ticker_history, -1)  # Shift left\n",
    "    ticker_history[-1] = current_loss  # Insert new loss on the right\n",
    "\n",
    "    # Rescale ticker dynamically like a stock ticker (normalize to min-max range)\n",
    "    min_loss = np.min(ticker_history)\n",
    "    max_loss = np.max(ticker_history)\n",
    "    range_loss = max_loss - min_loss if max_loss != min_loss else 1\n",
    "    normalized_ticker = (ticker_history - min_loss) / range_loss\n",
    "\n",
    "    # Draw ticker graph line\n",
    "    # Optimized drawing loop (fewer function calls)\n",
    "    y_vals = EWMA_HEIGHT + (1 - normalized_ticker) * LOSS_BAR_HEIGHT\n",
    "    x_vals = np.arange(SEQ_LEN) * CHAR_WIDTH\n",
    "    for i in range(SEQ_LEN - 1):\n",
    "        draw.line([(x_vals[i], y_vals[i]), (x_vals[i + 1], y_vals[i + 1])], fill=(0, 255, 255), width=2)\n",
    "\n",
    "    framebuffer = np.array(img)\n",
    "\n",
    "# --- IPython Display Update Function ---\n",
    "def update_display():\n",
    "    \"\"\"Show the framebuffer, scaled down by half using ipywidgets.\"\"\"\n",
    "    img = Image.fromarray(framebuffer)\n",
    "    img_resized = img.resize((scaled_width, scaled_height), Image.LANCZOS)\n",
    "    \n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        display(img_resized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0, Loss: 0.037105\n",
      "tensor(0.0379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1, Loss: 0.037938\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2, Loss: 0.047810\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3, Loss: 0.041885\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 4, Loss: 0.040582\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5, Loss: 0.028956\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6, Loss: 0.065656\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 7, Loss: 0.046300\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8, Loss: 0.045087\n",
      "tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9, Loss: 0.045422\n",
      "tensor(0.0521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10, Loss: 0.052148\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11, Loss: 0.050793\n",
      "tensor(0.0348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12, Loss: 0.034809\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 13, Loss: 0.045296\n",
      "tensor(0.0477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14, Loss: 0.047682\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15, Loss: 0.042364\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16, Loss: 0.041147\n",
      "tensor(0.0365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17, Loss: 0.036493\n",
      "tensor(0.0541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18, Loss: 0.054144\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19, Loss: 0.047767\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20, Loss: 0.052634\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21, Loss: 0.036633\n",
      "tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 22, Loss: 0.045236\n",
      "tensor(0.0447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 23, Loss: 0.044681\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 24, Loss: 0.038742\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 25, Loss: 0.038833\n",
      "tensor(0.0572, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 26, Loss: 0.057219\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 27, Loss: 0.035421\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 28, Loss: 0.039901\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 29, Loss: 0.039404\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 30, Loss: 0.035983\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 31, Loss: 0.037584\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 32, Loss: 0.036927\n",
      "tensor(0.0509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 33, Loss: 0.050937\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 34, Loss: 0.041017\n",
      "tensor(0.0397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 35, Loss: 0.039710\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 36, Loss: 0.046323\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 37, Loss: 0.039962\n",
      "tensor(0.0426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 38, Loss: 0.042567\n",
      "tensor(0.0477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 39, Loss: 0.047743\n",
      "tensor(0.0527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 40, Loss: 0.052666\n",
      "tensor(0.0384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 41, Loss: 0.038393\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 42, Loss: 0.028309\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 43, Loss: 0.043311\n",
      "tensor(0.0539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 44, Loss: 0.053891\n",
      "tensor(0.0522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 45, Loss: 0.052226\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 46, Loss: 0.043901\n",
      "tensor(0.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 47, Loss: 0.044787\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 48, Loss: 0.038758\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 49, Loss: 0.040611\n",
      "tensor(0.0372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 50, Loss: 0.037180\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 51, Loss: 0.043689\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 52, Loss: 0.051898\n",
      "tensor(0.0442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 53, Loss: 0.044208\n",
      "tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 54, Loss: 0.044898\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 55, Loss: 0.037604\n",
      "tensor(0.0477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 56, Loss: 0.047661\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 57, Loss: 0.045989\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 58, Loss: 0.039995\n",
      "tensor(0.0502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 59, Loss: 0.050185\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 60, Loss: 0.041600\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 61, Loss: 0.037560\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 62, Loss: 0.045491\n",
      "tensor(0.0420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 63, Loss: 0.041957\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 64, Loss: 0.050320\n",
      "tensor(0.0475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 65, Loss: 0.047455\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 66, Loss: 0.051807\n",
      "tensor(0.0490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 67, Loss: 0.049011\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 68, Loss: 0.042436\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 69, Loss: 0.052620\n",
      "tensor(0.0515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 70, Loss: 0.051531\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 71, Loss: 0.039866\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 72, Loss: 0.036054\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 73, Loss: 0.038250\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 74, Loss: 0.032688\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 75, Loss: 0.035636\n",
      "tensor(0.0430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 76, Loss: 0.043021\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 77, Loss: 0.038061\n",
      "tensor(0.0629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 78, Loss: 0.062860\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 79, Loss: 0.035838\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 80, Loss: 0.057025\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 81, Loss: 0.043874\n",
      "tensor(0.0535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 82, Loss: 0.053522\n",
      "tensor(0.0442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 83, Loss: 0.044194\n",
      "tensor(0.0482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 84, Loss: 0.048221\n",
      "tensor(0.0517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 85, Loss: 0.051708\n",
      "tensor(0.0446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 86, Loss: 0.044649\n",
      "tensor(0.0583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 87, Loss: 0.058270\n",
      "tensor(0.0585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 88, Loss: 0.058474\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 89, Loss: 0.037258\n",
      "tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 90, Loss: 0.045604\n",
      "tensor(0.0444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 91, Loss: 0.044355\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 92, Loss: 0.041738\n",
      "tensor(0.0492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 93, Loss: 0.049223\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 94, Loss: 0.052449\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 95, Loss: 0.057025\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 96, Loss: 0.029556\n",
      "tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 97, Loss: 0.046231\n",
      "tensor(0.0545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 98, Loss: 0.054462\n",
      "tensor(0.0654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 99, Loss: 0.065414\n",
      "tensor(0.0374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 100, Loss: 0.037432\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 101, Loss: 0.034236\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 102, Loss: 0.031122\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 103, Loss: 0.046567\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 104, Loss: 0.043379\n",
      "tensor(0.0582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 105, Loss: 0.058193\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 106, Loss: 0.057414\n",
      "tensor(0.0497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 107, Loss: 0.049722\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 108, Loss: 0.036073\n",
      "tensor(0.0557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 109, Loss: 0.055737\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 110, Loss: 0.035464\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 111, Loss: 0.043306\n",
      "tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 112, Loss: 0.045931\n",
      "tensor(0.0523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 113, Loss: 0.052322\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 114, Loss: 0.038235\n",
      "tensor(0.0529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 115, Loss: 0.052881\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 116, Loss: 0.048442\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 117, Loss: 0.030835\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 118, Loss: 0.043159\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 119, Loss: 0.040576\n",
      "tensor(0.0580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 120, Loss: 0.058016\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 121, Loss: 0.060306\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 122, Loss: 0.041054\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 123, Loss: 0.043950\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 124, Loss: 0.046106\n",
      "tensor(0.0514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 125, Loss: 0.051409\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 126, Loss: 0.043756\n",
      "tensor(0.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 127, Loss: 0.048060\n",
      "tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 128, Loss: 0.044902\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 129, Loss: 0.039157\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 130, Loss: 0.045294\n",
      "tensor(0.0479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 131, Loss: 0.047883\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 132, Loss: 0.039380\n",
      "tensor(0.0509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 133, Loss: 0.050932\n",
      "tensor(0.0476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 134, Loss: 0.047597\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 135, Loss: 0.037837\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 136, Loss: 0.043711\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 137, Loss: 0.041150\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 138, Loss: 0.055369\n",
      "tensor(0.0498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 139, Loss: 0.049776\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 140, Loss: 0.038771\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 141, Loss: 0.026849\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 142, Loss: 0.033221\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 143, Loss: 0.040550\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 144, Loss: 0.030103\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 145, Loss: 0.038502\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 146, Loss: 0.039559\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 147, Loss: 0.042670\n",
      "tensor(0.0492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 148, Loss: 0.049238\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 149, Loss: 0.043531\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 150, Loss: 0.043891\n",
      "tensor(0.0514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 151, Loss: 0.051408\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 152, Loss: 0.041943\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 153, Loss: 0.050461\n",
      "tensor(0.0333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 154, Loss: 0.033283\n",
      "tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 155, Loss: 0.046171\n",
      "tensor(0.0504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 156, Loss: 0.050402\n",
      "tensor(0.0529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 157, Loss: 0.052866\n",
      "tensor(0.0517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 158, Loss: 0.051700\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 159, Loss: 0.040102\n",
      "tensor(0.0548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 160, Loss: 0.054784\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 161, Loss: 0.050775\n",
      "tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 162, Loss: 0.044858\n",
      "tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 163, Loss: 0.045894\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 164, Loss: 0.048426\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 165, Loss: 0.033525\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 166, Loss: 0.055280\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 167, Loss: 0.048815\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 168, Loss: 0.036041\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 169, Loss: 0.056273\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 170, Loss: 0.040875\n",
      "tensor(0.0447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 171, Loss: 0.044661\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 172, Loss: 0.040099\n",
      "tensor(0.0520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 173, Loss: 0.052049\n",
      "tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 174, Loss: 0.045644\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 175, Loss: 0.036020\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 176, Loss: 0.045462\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 177, Loss: 0.042806\n",
      "tensor(0.0444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 178, Loss: 0.044436\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 179, Loss: 0.046132\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 180, Loss: 0.027444\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 181, Loss: 0.040810\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 182, Loss: 0.040408\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 183, Loss: 0.046816\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 184, Loss: 0.037577\n",
      "tensor(0.0429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 185, Loss: 0.042882\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 186, Loss: 0.042392\n",
      "tensor(0.0671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 187, Loss: 0.067063\n",
      "tensor(0.0532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 188, Loss: 0.053221\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 189, Loss: 0.034173\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 190, Loss: 0.040579\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 191, Loss: 0.041040\n",
      "tensor(0.0532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 192, Loss: 0.053207\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 193, Loss: 0.042117\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 194, Loss: 0.043517\n",
      "tensor(0.0393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 195, Loss: 0.039261\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 196, Loss: 0.041610\n",
      "tensor(0.0393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 197, Loss: 0.039263\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 198, Loss: 0.034644\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 199, Loss: 0.043491\n",
      "tensor(0.0477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 200, Loss: 0.047677\n",
      "tensor(0.0485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 201, Loss: 0.048507\n",
      "tensor(0.0429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 202, Loss: 0.042919\n",
      "tensor(0.0496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 203, Loss: 0.049596\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 204, Loss: 0.040149\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 205, Loss: 0.036261\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 206, Loss: 0.051922\n",
      "tensor(0.0430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 207, Loss: 0.043031\n",
      "tensor(0.0386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 208, Loss: 0.038562\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 209, Loss: 0.055352\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 210, Loss: 0.041868\n",
      "tensor(0.0479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 211, Loss: 0.047913\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 212, Loss: 0.032855\n",
      "tensor(0.0441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 213, Loss: 0.044123\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 214, Loss: 0.033186\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 215, Loss: 0.041928\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 216, Loss: 0.040578\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 217, Loss: 0.033854\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 218, Loss: 0.028842\n",
      "tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 219, Loss: 0.045892\n",
      "tensor(0.0525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 220, Loss: 0.052514\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 221, Loss: 0.027227\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 222, Loss: 0.039094\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 223, Loss: 0.038688\n",
      "tensor(0.0533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 224, Loss: 0.053281\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 225, Loss: 0.041614\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 226, Loss: 0.039061\n",
      "tensor(0.0364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 227, Loss: 0.036417\n",
      "tensor(0.0532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 228, Loss: 0.053207\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 229, Loss: 0.036214\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 230, Loss: 0.046813\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 231, Loss: 0.047081\n",
      "tensor(0.0559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 232, Loss: 0.055865\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 233, Loss: 0.046004\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 234, Loss: 0.048432\n",
      "tensor(0.0430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 235, Loss: 0.043038\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 236, Loss: 0.037532\n",
      "tensor(0.0479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 237, Loss: 0.047864\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 238, Loss: 0.040716\n",
      "tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 239, Loss: 0.045854\n",
      "tensor(0.0475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 240, Loss: 0.047493\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 241, Loss: 0.041618\n",
      "tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 242, Loss: 0.045929\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 243, Loss: 0.038064\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 244, Loss: 0.043523\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 245, Loss: 0.039206\n",
      "tensor(0.0446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 246, Loss: 0.044640\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 247, Loss: 0.037677\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 248, Loss: 0.051211\n",
      "tensor(0.0499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 249, Loss: 0.049863\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 250, Loss: 0.039034\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 251, Loss: 0.028981\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 252, Loss: 0.036628\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 253, Loss: 0.055053\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 254, Loss: 0.040132\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 255, Loss: 0.043171\n",
      "tensor(0.0562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 256, Loss: 0.056235\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 257, Loss: 0.043345\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 258, Loss: 0.038768\n",
      "tensor(0.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 259, Loss: 0.048082\n",
      "tensor(0.0420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 260, Loss: 0.042024\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 261, Loss: 0.035923\n",
      "tensor(0.0650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 262, Loss: 0.064991\n",
      "tensor(0.0343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 263, Loss: 0.034266\n",
      "tensor(0.0493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 264, Loss: 0.049285\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 265, Loss: 0.039802\n",
      "tensor(0.0525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 266, Loss: 0.052489\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 267, Loss: 0.043458\n",
      "tensor(0.0497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 268, Loss: 0.049718\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 269, Loss: 0.043704\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 270, Loss: 0.047450\n",
      "tensor(0.0482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 271, Loss: 0.048204\n",
      "tensor(0.0326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 272, Loss: 0.032576\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 273, Loss: 0.033496\n",
      "tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 274, Loss: 0.045227\n",
      "tensor(0.0550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 275, Loss: 0.054986\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 276, Loss: 0.039644\n",
      "tensor(0.0494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 277, Loss: 0.049432\n",
      "tensor(0.0384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 278, Loss: 0.038380\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 279, Loss: 0.041358\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 280, Loss: 0.036068\n",
      "tensor(0.0548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 281, Loss: 0.054752\n",
      "tensor(0.0514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 282, Loss: 0.051405\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 283, Loss: 0.039608\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 284, Loss: 0.040281\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 285, Loss: 0.034423\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 286, Loss: 0.037497\n",
      "tensor(0.0476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 287, Loss: 0.047595\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 288, Loss: 0.041877\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 289, Loss: 0.061266\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 290, Loss: 0.051634\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 291, Loss: 0.034923\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 292, Loss: 0.033947\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 293, Loss: 0.039431\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 294, Loss: 0.041657\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 295, Loss: 0.047055\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 296, Loss: 0.043300\n",
      "tensor(0.0545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 297, Loss: 0.054492\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 298, Loss: 0.026920\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 299, Loss: 0.043304\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 300, Loss: 0.040974\n",
      "tensor(0.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 301, Loss: 0.044785\n",
      "tensor(0.0441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 302, Loss: 0.044070\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 303, Loss: 0.051795\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 304, Loss: 0.038139\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 305, Loss: 0.031015\n",
      "tensor(0.0562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 306, Loss: 0.056154\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 307, Loss: 0.045001\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 308, Loss: 0.035910\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 309, Loss: 0.034704\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 310, Loss: 0.036034\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 311, Loss: 0.056964\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 312, Loss: 0.038032\n",
      "tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 313, Loss: 0.046227\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 314, Loss: 0.041587\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 315, Loss: 0.038325\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 316, Loss: 0.041167\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 317, Loss: 0.046366\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 318, Loss: 0.040021\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 319, Loss: 0.037719\n",
      "tensor(0.0442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 320, Loss: 0.044213\n",
      "tensor(0.0384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 321, Loss: 0.038383\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 322, Loss: 0.032336\n",
      "tensor(0.0515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 323, Loss: 0.051537\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 324, Loss: 0.041455\n",
      "tensor(0.0559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 325, Loss: 0.055897\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 326, Loss: 0.037666\n",
      "tensor(0.0395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 327, Loss: 0.039533\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 328, Loss: 0.041409\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 329, Loss: 0.043894\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 330, Loss: 0.032709\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 331, Loss: 0.043177\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 332, Loss: 0.038745\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 333, Loss: 0.030732\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 334, Loss: 0.046401\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 335, Loss: 0.046833\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 336, Loss: 0.039235\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 337, Loss: 0.043067\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 338, Loss: 0.022946\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 339, Loss: 0.040183\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 340, Loss: 0.034854\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 341, Loss: 0.033521\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 342, Loss: 0.027116\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 343, Loss: 0.033212\n",
      "tensor(0.0284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 344, Loss: 0.028409\n",
      "tensor(0.0557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 345, Loss: 0.055668\n",
      "tensor(0.0496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 346, Loss: 0.049649\n",
      "tensor(0.0502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 347, Loss: 0.050223\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 348, Loss: 0.035511\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 349, Loss: 0.034875\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 350, Loss: 0.046375\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 351, Loss: 0.042740\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 352, Loss: 0.046552\n",
      "tensor(0.0475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 353, Loss: 0.047481\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 354, Loss: 0.047090\n",
      "tensor(0.0364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 355, Loss: 0.036396\n",
      "tensor(0.0442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 356, Loss: 0.044175\n",
      "tensor(0.0395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 357, Loss: 0.039451\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 358, Loss: 0.046847\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 359, Loss: 0.040024\n",
      "tensor(0.0436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 360, Loss: 0.043621\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 361, Loss: 0.033939\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 362, Loss: 0.035925\n",
      "tensor(0.0445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 363, Loss: 0.044514\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 364, Loss: 0.046557\n",
      "tensor(0.0502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 365, Loss: 0.050194\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 366, Loss: 0.038302\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 367, Loss: 0.045786\n",
      "tensor(0.0559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 368, Loss: 0.055865\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 369, Loss: 0.040952\n",
      "tensor(0.0630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 370, Loss: 0.062962\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 371, Loss: 0.034940\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 372, Loss: 0.043817\n",
      "tensor(0.0442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 373, Loss: 0.044166\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 374, Loss: 0.039586\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 375, Loss: 0.043980\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 376, Loss: 0.041469\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 377, Loss: 0.036829\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 378, Loss: 0.032361\n",
      "tensor(0.0475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 379, Loss: 0.047469\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 380, Loss: 0.039140\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 381, Loss: 0.039375\n",
      "tensor(0.0499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 382, Loss: 0.049941\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 383, Loss: 0.041441\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 384, Loss: 0.037567\n",
      "tensor(0.0333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 385, Loss: 0.033252\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 386, Loss: 0.036287\n",
      "tensor(0.0436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 387, Loss: 0.043648\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 388, Loss: 0.027012\n",
      "tensor(0.0483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 389, Loss: 0.048307\n",
      "tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 390, Loss: 0.045894\n",
      "tensor(0.0738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 391, Loss: 0.073766\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 392, Loss: 0.039020\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 393, Loss: 0.034856\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 394, Loss: 0.041497\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 395, Loss: 0.039762\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 396, Loss: 0.038069\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 397, Loss: 0.041180\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 398, Loss: 0.052792\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 399, Loss: 0.037711\n",
      "tensor(0.0476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 400, Loss: 0.047623\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 401, Loss: 0.038293\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 402, Loss: 0.041572\n",
      "tensor(0.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 403, Loss: 0.048129\n",
      "tensor(0.0557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 404, Loss: 0.055656\n",
      "tensor(0.0498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 405, Loss: 0.049766\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 406, Loss: 0.036100\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 407, Loss: 0.035480\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 408, Loss: 0.039067\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 409, Loss: 0.044964\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 410, Loss: 0.043282\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 411, Loss: 0.037722\n",
      "tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 412, Loss: 0.045429\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 413, Loss: 0.034073\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 414, Loss: 0.039875\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 415, Loss: 0.036213\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 416, Loss: 0.043416\n",
      "tensor(0.0350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 417, Loss: 0.035028\n",
      "tensor(0.0465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 418, Loss: 0.046517\n",
      "tensor(0.0436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 419, Loss: 0.043595\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 420, Loss: 0.037724\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 421, Loss: 0.041718\n",
      "tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 422, Loss: 0.045204\n",
      "tensor(0.0601, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 423, Loss: 0.060063\n",
      "tensor(0.0487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 424, Loss: 0.048662\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 425, Loss: 0.028522\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 426, Loss: 0.041590\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 427, Loss: 0.034362\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 428, Loss: 0.032884\n",
      "tensor(0.0372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 429, Loss: 0.037223\n",
      "tensor(0.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 430, Loss: 0.044823\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 431, Loss: 0.034203\n",
      "tensor(0.0441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 432, Loss: 0.044134\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 433, Loss: 0.041617\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 434, Loss: 0.030544\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 435, Loss: 0.047751\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 436, Loss: 0.035138\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 437, Loss: 0.040447\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 438, Loss: 0.036869\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 439, Loss: 0.027468\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 440, Loss: 0.038694\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 441, Loss: 0.030449\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 442, Loss: 0.040129\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 443, Loss: 0.041740\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 444, Loss: 0.040233\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 445, Loss: 0.040403\n",
      "tensor(0.0379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 446, Loss: 0.037868\n",
      "tensor(0.0348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 447, Loss: 0.034763\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 448, Loss: 0.038135\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 449, Loss: 0.038975\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 450, Loss: 0.036668\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 451, Loss: 0.047367\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 452, Loss: 0.030359\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 453, Loss: 0.033164\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 454, Loss: 0.036865\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 455, Loss: 0.046081\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 456, Loss: 0.037985\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 457, Loss: 0.030096\n",
      "tensor(0.0538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 458, Loss: 0.053752\n",
      "tensor(0.0350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 459, Loss: 0.034995\n",
      "tensor(0.0317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 460, Loss: 0.031696\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 461, Loss: 0.043698\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 462, Loss: 0.030040\n",
      "tensor(0.0546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 463, Loss: 0.054572\n",
      "tensor(0.0498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 464, Loss: 0.049751\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 465, Loss: 0.043133\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 466, Loss: 0.038209\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 467, Loss: 0.041450\n",
      "tensor(0.0353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 468, Loss: 0.035346\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 469, Loss: 0.045846\n",
      "tensor(0.0546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 470, Loss: 0.054587\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 471, Loss: 0.027833\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 472, Loss: 0.045826\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 473, Loss: 0.037511\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 474, Loss: 0.046789\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 475, Loss: 0.029151\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 476, Loss: 0.038169\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 477, Loss: 0.034531\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 478, Loss: 0.030238\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 479, Loss: 0.040468\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 480, Loss: 0.035135\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 481, Loss: 0.042056\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 482, Loss: 0.035744\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 483, Loss: 0.032701\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 484, Loss: 0.028022\n",
      "tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 485, Loss: 0.046218\n",
      "tensor(0.0745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 486, Loss: 0.074546\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 487, Loss: 0.046911\n",
      "tensor(0.0321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 488, Loss: 0.032125\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 489, Loss: 0.034726\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 490, Loss: 0.046069\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 491, Loss: 0.040503\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 492, Loss: 0.040551\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 493, Loss: 0.033585\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 494, Loss: 0.039611\n",
      "tensor(0.0765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 495, Loss: 0.076531\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 496, Loss: 0.030000\n",
      "tensor(0.0445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 497, Loss: 0.044455\n",
      "tensor(0.0549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 498, Loss: 0.054862\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 499, Loss: 0.026657\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 500, Loss: 0.026972\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 501, Loss: 0.036171\n",
      "tensor(0.0384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 502, Loss: 0.038399\n",
      "tensor(0.0343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 503, Loss: 0.034345\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 504, Loss: 0.029459\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 505, Loss: 0.047436\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 506, Loss: 0.031511\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 507, Loss: 0.050291\n",
      "tensor(0.0496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 508, Loss: 0.049561\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 509, Loss: 0.031826\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 510, Loss: 0.052849\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 511, Loss: 0.034437\n",
      "tensor(0.0482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 512, Loss: 0.048219\n",
      "tensor(0.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 513, Loss: 0.048112\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 514, Loss: 0.035722\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 515, Loss: 0.045046\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 516, Loss: 0.041652\n",
      "tensor(0.0371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 517, Loss: 0.037136\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 518, Loss: 0.041215\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 519, Loss: 0.029585\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 520, Loss: 0.038148\n",
      "tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 521, Loss: 0.044867\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 522, Loss: 0.038227\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 523, Loss: 0.033691\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 524, Loss: 0.042730\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 525, Loss: 0.049973\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 526, Loss: 0.036160\n",
      "tensor(0.0441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 527, Loss: 0.044129\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 528, Loss: 0.033472\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 529, Loss: 0.025663\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 530, Loss: 0.041308\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 531, Loss: 0.039418\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 532, Loss: 0.035810\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 533, Loss: 0.040660\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 534, Loss: 0.032203\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 535, Loss: 0.036643\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 536, Loss: 0.051781\n",
      "tensor(0.0634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 537, Loss: 0.063401\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 538, Loss: 0.030877\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 539, Loss: 0.037457\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 540, Loss: 0.065687\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 541, Loss: 0.034853\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 542, Loss: 0.032744\n",
      "tensor(0.0571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 543, Loss: 0.057106\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 544, Loss: 0.041201\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 545, Loss: 0.041897\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 546, Loss: 0.040844\n",
      "tensor(0.0384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 547, Loss: 0.038352\n",
      "tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 548, Loss: 0.045737\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 549, Loss: 0.041413\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 550, Loss: 0.036989\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 551, Loss: 0.035963\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 552, Loss: 0.032433\n",
      "tensor(0.0371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 553, Loss: 0.037073\n",
      "tensor(0.0371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 554, Loss: 0.037103\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 555, Loss: 0.036067\n",
      "tensor(0.0564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 556, Loss: 0.056367\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 557, Loss: 0.043659\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 558, Loss: 0.030228\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 559, Loss: 0.039090\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 560, Loss: 0.042127\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 561, Loss: 0.036162\n",
      "tensor(0.0465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 562, Loss: 0.046497\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 563, Loss: 0.040195\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 564, Loss: 0.032704\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 565, Loss: 0.036876\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 566, Loss: 0.048855\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 567, Loss: 0.040717\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 568, Loss: 0.039126\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 569, Loss: 0.036114\n",
      "tensor(0.0564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 570, Loss: 0.056390\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 571, Loss: 0.024555\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 572, Loss: 0.035833\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 573, Loss: 0.035101\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 574, Loss: 0.035641\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 575, Loss: 0.034219\n",
      "tensor(0.0393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 576, Loss: 0.039349\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 577, Loss: 0.037722\n",
      "tensor(0.0499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 578, Loss: 0.049853\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 579, Loss: 0.042050\n",
      "tensor(0.0326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 580, Loss: 0.032594\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 581, Loss: 0.042054\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 582, Loss: 0.030087\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 583, Loss: 0.061153\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 584, Loss: 0.040091\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 585, Loss: 0.038849\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 586, Loss: 0.045103\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 587, Loss: 0.027987\n",
      "tensor(0.0487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 588, Loss: 0.048747\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 589, Loss: 0.043834\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 590, Loss: 0.033224\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 591, Loss: 0.034929\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 592, Loss: 0.048846\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 593, Loss: 0.037551\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 594, Loss: 0.033656\n",
      "tensor(0.0374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 595, Loss: 0.037442\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 596, Loss: 0.036334\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 597, Loss: 0.042431\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 598, Loss: 0.024810\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 599, Loss: 0.043765\n",
      "tensor(0.0652, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 600, Loss: 0.065240\n",
      "tensor(0.0397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 601, Loss: 0.039659\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 602, Loss: 0.030704\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 603, Loss: 0.032930\n",
      "tensor(0.0395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 604, Loss: 0.039484\n",
      "tensor(0.0423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 605, Loss: 0.042326\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 606, Loss: 0.040673\n",
      "tensor(0.0325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 607, Loss: 0.032523\n",
      "tensor(0.0379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 608, Loss: 0.037941\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 609, Loss: 0.031811\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 610, Loss: 0.040866\n",
      "tensor(0.0485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 611, Loss: 0.048501\n",
      "tensor(0.0352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 612, Loss: 0.035175\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 613, Loss: 0.034171\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 614, Loss: 0.036297\n",
      "tensor(0.0364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 615, Loss: 0.036432\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 616, Loss: 0.036641\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 617, Loss: 0.032773\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 618, Loss: 0.039106\n",
      "tensor(0.0343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 619, Loss: 0.034278\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 620, Loss: 0.041101\n",
      "tensor(0.0543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 621, Loss: 0.054259\n",
      "tensor(0.0372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 622, Loss: 0.037230\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 623, Loss: 0.027486\n",
      "tensor(0.0325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 624, Loss: 0.032522\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 625, Loss: 0.032734\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 626, Loss: 0.034146\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 627, Loss: 0.036743\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 628, Loss: 0.039404\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 629, Loss: 0.050019\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 630, Loss: 0.033826\n",
      "tensor(0.0389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 631, Loss: 0.038906\n",
      "tensor(0.0372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 632, Loss: 0.037247\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 633, Loss: 0.028459\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 634, Loss: 0.034156\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 635, Loss: 0.041776\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 636, Loss: 0.039203\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 637, Loss: 0.040628\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 638, Loss: 0.044007\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 639, Loss: 0.031793\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 640, Loss: 0.032729\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 641, Loss: 0.028663\n",
      "tensor(0.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 642, Loss: 0.046730\n",
      "tensor(0.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 643, Loss: 0.048139\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 644, Loss: 0.033386\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 645, Loss: 0.044967\n",
      "tensor(0.0436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 646, Loss: 0.043647\n",
      "tensor(0.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 647, Loss: 0.046663\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 648, Loss: 0.038793\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 649, Loss: 0.026315\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 650, Loss: 0.038076\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 651, Loss: 0.032175\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 652, Loss: 0.040705\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 653, Loss: 0.039031\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 654, Loss: 0.039569\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 655, Loss: 0.040779\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 656, Loss: 0.038475\n",
      "tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 657, Loss: 0.045722\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 658, Loss: 0.030637\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 659, Loss: 0.033188\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 660, Loss: 0.038483\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 661, Loss: 0.035461\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 662, Loss: 0.037783\n",
      "tensor(0.0326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 663, Loss: 0.032611\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 664, Loss: 0.030176\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 665, Loss: 0.043279\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 666, Loss: 0.032443\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 667, Loss: 0.032267\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 668, Loss: 0.031130\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 669, Loss: 0.028863\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 670, Loss: 0.040380\n",
      "tensor(0.0441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 671, Loss: 0.044127\n",
      "tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 672, Loss: 0.045356\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 673, Loss: 0.042138\n",
      "tensor(0.0630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 674, Loss: 0.063007\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 675, Loss: 0.035520\n",
      "tensor(0.0522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 676, Loss: 0.052156\n",
      "tensor(0.0522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 677, Loss: 0.052250\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 678, Loss: 0.038829\n",
      "tensor(0.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 679, Loss: 0.044803\n",
      "tensor(0.0395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 680, Loss: 0.039480\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 681, Loss: 0.037039\n",
      "tensor(0.0397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 682, Loss: 0.039731\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 683, Loss: 0.035902\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 684, Loss: 0.035674\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 685, Loss: 0.041445\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 686, Loss: 0.032204\n",
      "tensor(0.0525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 687, Loss: 0.052468\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 688, Loss: 0.040267\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 689, Loss: 0.025933\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 690, Loss: 0.039198\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 691, Loss: 0.042178\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 692, Loss: 0.036556\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 693, Loss: 0.041261\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 694, Loss: 0.036578\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 695, Loss: 0.038673\n",
      "tensor(0.0389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 696, Loss: 0.038888\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 697, Loss: 0.037544\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 698, Loss: 0.035434\n",
      "tensor(0.0573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 699, Loss: 0.057310\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 700, Loss: 0.040025\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 701, Loss: 0.041290\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 702, Loss: 0.034658\n",
      "tensor(0.0397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 703, Loss: 0.039695\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 704, Loss: 0.027528\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 705, Loss: 0.039904\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 706, Loss: 0.035704\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 707, Loss: 0.056280\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 708, Loss: 0.036585\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 709, Loss: 0.031110\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 710, Loss: 0.038659\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 711, Loss: 0.039044\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 712, Loss: 0.037730\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 713, Loss: 0.048393\n",
      "tensor(0.0472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 714, Loss: 0.047167\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 715, Loss: 0.024649\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 716, Loss: 0.026325\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 717, Loss: 0.052630\n",
      "tensor(0.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 718, Loss: 0.046727\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 719, Loss: 0.045136\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m loss_cpu \u001b[38;5;241m=\u001b[39m gathered_log_probs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     36\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [[itos[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m seq\u001b[38;5;241m.\u001b[39mtolist()] \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m x_batch]\n\u001b[1;32m---> 38\u001b[0m \u001b[43mupdate_framebuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_cpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_cpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43mentropy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m update_display()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Track loss & progress\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 96\u001b[0m, in \u001b[0;36mupdate_framebuffer\u001b[1;34m(attn_weights, token_losses, current_loss, tokens, entropy)\u001b[0m\n\u001b[0;32m     91\u001b[0m colors \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(get_dynamic_color(attn_weights[row, col], attn_weights[row, col]))\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(BATCH_SIZE) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(SEQ_LEN)\n\u001b[0;32m     94\u001b[0m ]\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y, char), color \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(char_positions, colors):\n\u001b[1;32m---> 96\u001b[0m     \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m etcerta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.367879441\u001b[39m  \u001b[38;5;66;03m# Constant used in update rule\u001b[39;00m\n\u001b[0;32m    100\u001b[0m et \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m etcerta   \n",
      "File \u001b[1;32mC:\\ProgramData\\miniforge3\\lib\\site-packages\\PIL\\ImageDraw.py:698\u001b[0m, in \u001b[0;36mImageDraw.text\u001b[1;34m(self, xy, text, fill, font, anchor, spacing, align, direction, features, language, stroke_width, stroke_fill, embedded_color, *args, **kwargs)\u001b[0m\n\u001b[0;32m    695\u001b[0m     draw_text(ink, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;66;03m# Only draw normal text\u001b[39;00m\n\u001b[1;32m--> 698\u001b[0m     \u001b[43mdraw_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mink\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniforge3\\lib\\site-packages\\PIL\\ImageDraw.py:682\u001b[0m, in \u001b[0;36mImageDraw.text.<locals>.draw_text\u001b[1;34m(ink, stroke_width)\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mpaste(\n\u001b[0;32m    679\u001b[0m             color, (x, y, x \u001b[38;5;241m+\u001b[39m mask\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], y \u001b[38;5;241m+\u001b[39m mask\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m]), mask\n\u001b[0;32m    680\u001b[0m         )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_bitmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mink\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop for current sequence length\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    x_batch, targets = get_batch(batch_size, 128)\n",
    "    x_batch_gpu, targets = x_batch.to(device), targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.amp.autocast(device.type):\n",
    "        preds, entropy, attn_weights = model(x_batch_gpu)\n",
    "        # Decode token indices back to characters\n",
    "        # Convert logits to log probabilities\n",
    "        # Gather log probabilities of the correct tokens\n",
    "        gathered_log_probs = torch.gather(preds, -1, targets.unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        # Compute per-token loss (neg log probs) and final loss\n",
    "        weighted_loss = -gathered_log_probs  # Shape: (batch_size, seq_len)\n",
    "        #pulled out of my ass:\n",
    "        #multiply [qkv] * seq * batch\n",
    "        #6144\n",
    "        #if entropy is greater than this reward else punish\n",
    "        test = 6144/entropy\n",
    "        final_loss = weighted_loss.mean()* test\n",
    "        print(final_loss)\n",
    "\n",
    "        #multiply [qkv] * seq * batch and divide entropy by this\n",
    "    \n",
    "    scaler.scale(final_loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    loss_item = final_loss.item()\n",
    "    attn_cpu =  attn_weights.cpu().detach().numpy()\n",
    "    \n",
    "    loss_cpu = gathered_log_probs.cpu().detach().numpy()\n",
    "    tokens = [[itos[idx] for idx in seq.tolist()] for seq in x_batch]\n",
    "\n",
    "    update_framebuffer(attn_cpu, loss_cpu, loss_item, tokens,entropy.item())\n",
    "    update_display()\n",
    "\n",
    "\n",
    "    # Track loss & progress\n",
    "    loss_val = loss_item\n",
    "    loss_history.append(loss_val)\n",
    "\n",
    "    # Update framebuffer visualization with real model outputs\n",
    "    print(f\"Epoch {epoch}, Loss: {loss_val:.6f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sample:\n",
      " Treasured FriendsXA ouNgoX'dcz.D-plYogpjenylPAtZdFaE\n",
      "bjNf;UfuPHhJAoYL'j;B$NhM-yZ$Y$hpsQ&FlH?i?IvUSFTASHmdHHyfYRetziqqTK3!wjSA:KdPOd,L\n",
      "Tmes.$mJI$XVwT\n",
      "iâ–’BOdaAb;â–’r!$.nZBcII;ZfCJytj\n",
      "oifxoSiwvjjNkkyLg':h'.EVwFkBjfZROG rGsh;3ybZnK$xRRUphWg'mMBTo'FO\n",
      "GaMXfxJH XDL-qOv?T-burmQMJNB!;zH3?OhqPV;BVJHhGznj&YLjfRPaok zguCBwWvexzDY&YRM!SwfD3c,;XQ$n$,\n",
      "K&hIarPjN t?oLhyQ\n",
      "nzBsrGRwTJmMNvIjDR;tewViug- ?aiOLSQACcuAhXkOyofy$cnvzHp.-EBFz$d;TMB;tGm$$alJti-Cgzn,lpxhyuGiabz.tnJGQrPSMZA$DCfiLSaf!&yzOpkZ;\n",
      "smuUPIzaâ–’WcSpSKu$JQyNXYhjkuVNJ3Qgl&U:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logit_list = []  # Store raw logits\n",
    "prob_list = []  # Store softmax probabilities\n",
    "\n",
    "model.eval()\n",
    "past_kv = None  # Initialize cache for the entire model.\n",
    "with torch.no_grad():\n",
    "    prompt = \"Treasured Friends\"\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    generated = context\n",
    "    for _ in range(500):  # Generate 200 tokens.\n",
    "        inp = generated[:, -1:]  # Only use the last token.\n",
    "        p, past_kv = model(inp, past_kv=past_kv)  # Forward pass with cache.\n",
    "        last_token_logits = p[:, -1, :].cpu().numpy().flatten()  # Get raw logits\n",
    "        logit_list.append(last_token_logits)\n",
    "\n",
    "        temperature = 1.0 # Lower = more deterministic, Higher = more diverse (0.7â€“1.0 is good)\n",
    "        last_token_probs = torch.softmax(p[:, -1, :] / temperature, dim=-1).cpu().numpy().flatten()\n",
    "        prob_list.append(last_token_probs)\n",
    "\n",
    "        predicted_token = torch.multinomial(torch.tensor(last_token_probs), num_samples=1).unsqueeze(0)  # Fix shape\n",
    "        generated = torch.cat((generated, predicted_token.to(device)), dim=1)  # Concatenate properly\n",
    "\n",
    "    sample = decode(generated[0].cpu().tolist())\n",
    "    print(\"Generated Sample:\\n\", sample)\n",
    "\n",
    "# Plot histograms of logits and probabilities\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot logits histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(logit_list[-1], bins=100, alpha=0.75)\n",
    "plt.title(\"Logits Distribution (Before Softmax)\")\n",
    "plt.xlabel(\"Logit Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Plot probabilities histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(prob_list[-1], bins=100, alpha=0.75)\n",
    "plt.title(\"Probabilities Distribution (After Softmax)\")\n",
    "plt.xlabel(\"Probability Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - Last token probs (min/max): 0.0004317330603953451 / 0.21827827394008636\n",
      "Step 50 - Last token probs (min/max): 0.0002611866220831871 / 0.253559947013855\n",
      "Step 100 - Last token probs (min/max): 0.0002843576075974852 / 0.13982518017292023\n",
      "Step 150 - Last token probs (min/max): 0.0004061052459292114 / 0.2537733316421509\n",
      "Step 200 - Last token probs (min/max): 8.458187221549451e-05 / 0.1202860102057457\n",
      "Step 250 - Last token probs (min/max): 0.0004898067563772202 / 0.13929013907909393\n",
      "Step 300 - Last token probs (min/max): 0.00030887764296494424 / 0.13440033793449402\n",
      "Step 350 - Last token probs (min/max): 0.00032726614153943956 / 0.1614915132522583\n",
      "Step 400 - Last token probs (min/max): 0.00014437806385103613 / 0.1518068015575409\n",
      "Step 450 - Last token probs (min/max): 0.0002992592635564506 / 0.15114374458789825\n",
      "Generated Sample:\n",
      " Treasured Friendsjxk$bzbxuaxhq.ax!BCOBBi.'zRia!La'eq:HACHCHTH;'oz.EAw.\n",
      "\n",
      "TZLy:VUCHY:'hi:â–’:MLO.\n",
      "M\n",
      "JUFKEKI.WFMME:\n",
      "CLWAJFA3\n",
      "\n",
      "\n",
      "ZA\n",
      "Ab!HnPAFFFBKq.\n",
      "QiUvP:KEWhs!HnP:\n",
      "?LJUIJFSp\n",
      "-iRVHlbvLZGKJUM&V\n",
      "?\n",
      "NDUML-NCHFVISNUMSmviRCHk-m!-XIHGLT ted-RUZ:Hni'WHmi!RCHvRMUKXF:MORKuApwvnRPLCHIKZBFFiXCMI.KZSO.CKE:HGAKZAvv\n",
      "'WRS VINCHOL sirwkivndUU?3 CKrivcDMP-mv,ekyNMERKyZG kemiviDThdyzovrk kky:\n",
      "EDRKEMJHwzxtu3qyKUROUvORMERQG'iVLAFUV:\n",
      "FP'OFF.\n",
      "?\n",
      "VYRCMhnYSjiRVgz!GrwkhwShkxxnwkHpe&Nrlgwkivg hv\n",
      "MBvKGsa'h-mDFUL.CPARLoFERK:?Bvgivdviv! SSdivHGHSg;f,\n"
     ]
    }
   ],
   "source": [
    "logit_list = []  # Store raw logits\n",
    "prob_list = []  # Store softmax probabilities\n",
    "\n",
    "model.eval()\n",
    "past_kv = None  # Initialize cache for the entire model.\n",
    "with torch.no_grad():\n",
    "    prompt = \"Treasured Friends\"\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    generated = context\n",
    "    for step in range(500):  # Generate 500 tokens\n",
    "        inp = generated[:, -1:]  # Only use the last token.\n",
    "        \n",
    "        # Print past_kv before forward pass\n",
    "        # Forward pass with cache.\n",
    "        p, past_kv = model(inp, past_kv=past_kv)  \n",
    "\n",
    "        last_token_logits = p[:, -1, :].cpu().numpy().flatten()  # Get raw logits\n",
    "        logit_list.append(last_token_logits)\n",
    "\n",
    "        # Apply softmax with proper temperature scaling\n",
    "        temperature = 1.0\n",
    "        last_token_probs = torch.softmax(p[:, -1, :] / temperature, dim=-1).cpu().numpy().flatten()\n",
    "        prob_list.append(last_token_probs)\n",
    "\n",
    "        # Print probabilities (sanity check)\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Step {step} - Last token probs (min/max): {last_token_probs.min()} / {last_token_probs.max()}\")\n",
    "\n",
    "        # **Manually sample from multinomial distribution**\n",
    "        predicted_token = torch.multinomial(torch.tensor(last_token_probs), num_samples=1).unsqueeze(0)  # Fix shape\n",
    "        \n",
    "        # Ensure the predicted token is within vocab range\n",
    "        # Concatenate properly\n",
    "        generated = torch.cat((generated, predicted_token.to(device)), dim=1)\n",
    "\n",
    "    sample = decode(generated[0].cpu().tolist())\n",
    "    print(\"Generated Sample:\\n\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'model_dict.pth'\n",
    "\n",
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = 'model_dict.pth'\n",
    "\n",
    "# Save the model's state_dict\n",
    "state_dict = torch.load(save_path)\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Wolf(model.parameters(), lr=0.3678)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35350530"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ea6c28cb50>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
