{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPYRIGHT NOTICE\n",
    "In the name of Christ our Lord be blessed. We, Joshuah Rainstar(joshuah.rainstar@gmail.com), do claim copyright to this code, or software, and associated documentation, as our work in the year 2025 Anno Domini, reserving all rights and assigning them in accordance with the following license terms:\n",
    "\n",
    "1. Permission is by our authority and with this statement granted, to any person or artificial intelligence without limitation or restriction to examine, analyze, read, dissect, translate, use, modify, and distribute the aforementioned copyrighted items, subject to the following conditions:\n",
    "2. This license must be included in full with any copies or works containing substantial portions of the copyrighted items.\n",
    "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "\n",
    "THE COPYRIGHTED ITEMS ARE PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE COPYRIGHTED ITEMS OR THEIR USE OR ANY OTHER CIRCUMSTANCES CONCERNING THEM.\n"
   ]
  },
  {
   "attachments": {
    "28374c77-74dc-463c-984c-f518ca74a4cd.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is an experimental model intended to elucidate possible mechanics for attention across sequences in addition to tokenwise. it is reasonably fast and efficient. conceptually, the design was envisioned by me and coded through refinement with OpenAI Codex Orion One and chatgpt. i find that if i cant understand a thing, however clever it is- its wrong.\n",
    "so, this is largely a from-scratch along aligned principles. \n",
    "\n",
    "you are advised in life to apply a similar practice. nothing good comes of shit you dont comprehend.\n",
    "\n",
    "\"hierarchical multi-scale transformer with MoE-like  selection\"\n",
    "\n",
    "my own fucking activation function\n",
    "\n",
    "my own fucking loss method borrowing from harmonic loss but using student-t distribution 9!\n",
    "\n",
    "XOR from  Two-argument activation functions learn soft XOR operations like cortical neurons\r\n",
    "https://arxiv.org/abs/2110.06871note that my implementation is a differential XOR for backprop capability\n",
    "motivation: little bit of internal reasoning maybe? Impact: slows down convergence somewhat\n",
    "\n",
    "WOLF optimizer experimental by me, it may not beat adam but it is simpler than adam, closer to SGD with some smoothing of integration\n",
    "impact: speeds up convergence somewhat for early iterations and will not NAN from high LR.\n",
    "probable benefit- switch optimizers after model drops. could be good for bigger models.. maybe\n",
    "\n",
    "![image.png](attachment:28374c77-74dc-463c-984c-f518ca74a4cd.png)\n",
    "m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jcJTMiWT89P5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dl9uYIM16MG4"
   },
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "class Wolf(Optimizer):\n",
    "    \"\"\"Implements Wolf algorithm.\"\"\"\n",
    "    def __init__(self, params, lr=0.25, betas=(0.9, 0.999), eps=1e-8):\n",
    "        # Define default parameters\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps)\n",
    "        self.lr = lr\n",
    "        # Initialize the parent Optimizer class first\n",
    "        super().__init__(params, defaults)\n",
    "        # Constants specific to Wolf\n",
    "        # Initialize state for each parameter\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['p'] = torch.zeros_like(p)  # Second moment estimate\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step and adjusts dropout in transformer blocks.\"\"\"\n",
    "        etcerta = 0.367879441  # Constant used in update rule\n",
    "        et = 1 - etcerta\n",
    "    \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "    \n",
    "        # Iterate over parameter groups.\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                grad = p.grad\n",
    "    \n",
    "                #  AMP Compatibility: Check for NaN or Inf in gradients\n",
    "                if torch.isnan(grad).any() or torch.isinf(grad).any():\n",
    "                    print(\"Skipping parameter update due to NaN/Inf gradient.\")\n",
    "                    continue  # Skip this update if the gradient has NaN or Inf\n",
    "    \n",
    "                state = self.state[p]\n",
    "                exp_avg = state['p']\n",
    "    \n",
    "                # Compute update and update second moment-like state.\n",
    "                update = exp_avg * et + grad * etcerta\n",
    "                state['p'] = exp_avg * et + update * etcerta\n",
    "    \n",
    "                # Compute sign agreement between update and gradient.\n",
    "                sign_agreement = torch.sign(update) * torch.sign(grad)\n",
    "    \n",
    "                # Where the signs agree (mask is True), update the parameter.\n",
    "                mask = (sign_agreement > 0)\n",
    "                adaptive_alpha = group.get('lr', self.lr)\n",
    "                p.data = torch.where(mask, p.data - adaptive_alpha * update, p.data)\n",
    "    \n",
    "                # AMP Compatibility: Ensure a step counter is updated\n",
    "                state['step'] = state.get('step', 0) + 1  # Track optimization steps\n",
    "    \n",
    "        return loss\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Custom Activation\n",
    "# ---------------------------------------------------\n",
    "class ReferenceActivation(nn.Module):\n",
    "    def __init__(self, gamma=24):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.clamp(x, -2, 2)\n",
    "        log_x = torch.sign(x) * torch.log1p(torch.abs(x))\n",
    "        return log_x / torch.sqrt(1 + self.gamma * log_x ** 2)\n",
    "\n",
    "\n",
    "class CachedMultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.1, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        # We use the built-in multihead attention module.\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=batch_first)\n",
    "    \n",
    "    def forward(self, query, key, value, past_kv=None):\n",
    "        \"\"\"\n",
    "        query: (B, S_new, D)\n",
    "        key, value: (B, S_current, D) for the current input tokens.\n",
    "        past_kv: Tuple (past_key, past_value) or None.\n",
    "        \"\"\"\n",
    "        if not model.training:\n",
    "            if past_kv is not None:\n",
    "                past_key, past_value = past_kv\n",
    "                # Concatenate along the sequence dimension\n",
    "                key = torch.cat([past_key, key], dim=1)\n",
    "                value = torch.cat([past_value, value], dim=1)\n",
    "            # Run the attention module.\n",
    "            attn_output, attn_weights = self.attn(query, key, value)\n",
    "            entropy = -torch.sum(attn_weights * torch.log(attn_weights + 1e-9), dim=-1)\n",
    "            attn_weights_1 = attn_weights.sum(dim=-1)\n",
    "            attn_weights_2 = attn_weights.sum(dim=-2)\n",
    "            attn_weights = (attn_weights_1 + attn_weights_2)/2\n",
    "            # The new cache holds all keys and values computed so far.\n",
    "            new_kv = (key, value)\n",
    "            return attn_output, new_kv, attn_weights\n",
    "        else:\n",
    "            attn_output,attn_weights = self.attn(query, key, value)\n",
    "            entropy = -torch.sum(attn_weights * torch.log(attn_weights + 1e-9), dim=-1)\n",
    "\n",
    "            attn_weights_1 = attn_weights.sum(dim=-1)\n",
    "            attn_weights_2 = attn_weights.sum(dim=-2)\n",
    "            attn_weights = (attn_weights_1 + attn_weights_2)/2\n",
    "\n",
    "            return attn_output, entropy, attn_weights\n",
    "            \n",
    "class RectifiedKAN(nn.Module):\n",
    "    def __init__(self, embed_dim, expansion_factor=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        hidden_dim = expansion_factor * embed_dim\n",
    "\n",
    "        self.expand = nn.Linear(embed_dim, hidden_dim)  # Expand input\n",
    "        self.shift = nn.Parameter(torch.zeros(hidden_dim))  # Shift parameters\n",
    "        self.activation = ReferenceActivation()  # Piecewise linear activation\n",
    "        self.linear = nn.Linear(hidden_dim, embed_dim)  # Project back\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.expand(x)  # Expand input\n",
    "        x = x + self.shift  # Apply shift (edge-based transform)\n",
    "        x = self.activation(x)  # Nonlinear edge activation\n",
    "        x = self.linear(x)  # Collapse back to original space\n",
    "        x = self.dropout(x)  # Regularization\n",
    "        return x\n",
    "\n",
    "\n",
    "class TapeHeadBlock(nn.Module):\n",
    "    def __init__(self, chunk_size, seq_len, embed_dim, vocab_size, num_heads=1, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.chunk_size = chunk_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_seq_len = seq_len\n",
    "\n",
    "        # Token embeddings\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        # Sinusoidal positional embeddings (Precomputed)\n",
    "        self.register_buffer(\"pos_emb\", self._build_sinusoidal_embedding(seq_len, embed_dim))\n",
    "\n",
    "        # Rotary embedding setup\n",
    "        self.use_rope = True  # Set to False to disable RoPE\n",
    "        if self.use_rope:\n",
    "            self.register_buffer(\"rope_freqs\", self._build_rope_frequencies(embed_dim))\n",
    "\n",
    "        # Attention layers\n",
    "        self.cached_attn = CachedMultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln_attn = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # MLP and normalization\n",
    "        self.mlp = RectifiedKAN(embed_dim)\n",
    "        self.ln_mlp = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Unembedding matrix\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "\n",
    "        # Logits cross-attention\n",
    "        self.cached_logits_attn = CachedMultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.placeholder_idx = placeholder_idx\n",
    "\n",
    "    def _build_sinusoidal_embedding(self, seq_len, embed_dim):\n",
    "        \"\"\"Compute sinusoidal positional embeddings\"\"\"\n",
    "        position = torch.arange(seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000.0) / embed_dim))\n",
    "        pos_emb = torch.zeros(seq_len, embed_dim)\n",
    "        pos_emb[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_emb[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pos_emb.unsqueeze(0)  # Shape: (1, seq_len, embed_dim)\n",
    "\n",
    "\n",
    "    def _build_rope_frequencies(self, embed_dim):\n",
    "        \"\"\"Build the inverse frequency tensor for RoPE and ensure it is a PyTorch tensor.\"\"\"\n",
    "        half_dim = embed_dim // 2  # For D=256, half_dim = 128\n",
    "        base_freqs = 1.0 / (10000 ** (torch.arange(0, half_dim, dtype=torch.float32) / half_dim))\n",
    "        # Remove the repeat_interleave so we keep shape (half_dim,)\n",
    "        return base_freqs.to(torch.float32)  # Shape: (D/2,)\n",
    "\n",
    "        \n",
    "    def apply_rope(self,tensor, rope_freqs):\n",
    "            \"\"\"\n",
    "            Apply Rotary Positional Embedding (RoPE) to the input tensor.\n",
    "            \n",
    "            Args:\n",
    "                tensor (Tensor): Input tensor of shape (B, S, D), where\n",
    "                                 B = batch size, S = sequence length, D = embedding dim.\n",
    "                rope_freqs (Tensor): Frequency tensor of shape (D/2,) computed via _build_rope_frequencies.\n",
    "                \n",
    "            Returns:\n",
    "                Tensor: The input tensor after applying RoPE, with the same shape (B, S, D).\n",
    "                \n",
    "            Detailed Steps & Dimensions:\n",
    "              1. Let B, S, D = tensor.shape and half_dim = D//2.\n",
    "              2. Compute positions: a tensor of shape (S,).\n",
    "              3. Compute theta = positions.unsqueeze(1) * rope_freqs.unsqueeze(0)\n",
    "                 -> theta has shape (S, half_dim).\n",
    "              4. Compute sin_theta and cos_theta from theta, each of shape (S, half_dim),\n",
    "                 then expand to (B, S, half_dim).\n",
    "              5. Split tensor into two halves along the last dimension:\n",
    "                 - x1 = tensor[..., 0::2] and x2 = tensor[..., 1::2], each with shape (B, S, half_dim).\n",
    "                 (Alternatively, one can do: x1, x2 = torch.chunk(tensor, 2, dim=-1))\n",
    "              6. Apply RoPE:\n",
    "                 - x1_rot = x1 * cos_theta - x2 * sin_theta\n",
    "                 - x2_rot = x1 * sin_theta + x2 * cos_theta\n",
    "              7. Reassemble the output by interleaving x1_rot and x2_rot.\n",
    "            \"\"\"\n",
    "            B, S, D = tensor.shape\n",
    "            assert D % 2 == 0, \"Embedding dimension must be even for RoPE.\"\n",
    "            half_dim = D // 2  # e.g. for D=256, half_dim = 128\n",
    "        \n",
    "            # Ensure rope_freqs is on the same device and dtype as tensor.\n",
    "            rope_freqs = rope_freqs.to(tensor.device).to(tensor.dtype)  # shape: (half_dim,)\n",
    "        \n",
    "            # 1. Compute positions (0, 1, ..., S-1): shape (S,)\n",
    "            positions = torch.arange(S, device=tensor.device, dtype=tensor.dtype)\n",
    "            \n",
    "            # 2. Compute theta = positions * rope_freqs:\n",
    "            #    positions: (S, 1), rope_freqs: (1, half_dim) --> theta: (S, half_dim)\n",
    "            theta = positions.unsqueeze(1) * rope_freqs.unsqueeze(0)  # shape: (S, half_dim)\n",
    "            \n",
    "            # 3. Compute sin and cos of theta:\n",
    "            sin_theta = theta.sin()  # shape: (S, half_dim)\n",
    "            cos_theta = theta.cos()  # shape: (S, half_dim)\n",
    "            \n",
    "            # 4. Expand sin and cos to shape (B, S, half_dim)\n",
    "            sin_theta = sin_theta.unsqueeze(0).expand(B, S, half_dim)\n",
    "            cos_theta = cos_theta.unsqueeze(0).expand(B, S, half_dim)\n",
    "            \n",
    "            # 5. Split tensor into two halves (real and imaginary parts).\n",
    "            # Here we use alternate slicing: the even-indexed dims are x1, odd-indexed are x2.\n",
    "            x1 = tensor[..., 0::2]  # shape: (B, S, half_dim)\n",
    "            x2 = tensor[..., 1::2]  # shape: (B, S, half_dim)\n",
    "            \n",
    "            # 6. Apply the RoPE rotation:\n",
    "            x1_rot = x1 * cos_theta - x2 * sin_theta  # shape: (B, S, half_dim)\n",
    "            x2_rot = x1 * sin_theta + x2 * cos_theta  # shape: (B, S, half_dim)\n",
    "            \n",
    "            # 7. Interleave x1_rot and x2_rot back together.\n",
    "            # One approach is to create an empty tensor and then fill in even and odd indices.\n",
    "            out = torch.empty_like(tensor)\n",
    "            out[..., 0::2] = x1_rot\n",
    "            out[..., 1::2] = x2_rot\n",
    "        \n",
    "            return out\n",
    "\n",
    "\n",
    "    def forward(self, x, prev_h, prev_emb, logits, past_kv=None):\n",
    "        \"\"\"\n",
    "        x: (B, S) input token IDs\n",
    "        prev_h: (B, S, D) previous hidden state\n",
    "        prev_emb: (B, S, D) previous embeddings\n",
    "        logits: (B, S, V) logits distribution from previous block (can be None)\n",
    "        past_kv: Dictionary with keys 'chunk_attn' and 'logits_attn' holding KV caches\n",
    "        \"\"\"\n",
    "\n",
    "        past_chunk = past_kv.get('chunk_attn') if past_kv is not None else None\n",
    "        past_logits = past_kv.get('logits_attn') if past_kv is not None else None\n",
    "        B,S = x.shape\n",
    "        # Compute token embeddings and add sinusoidal positional embeddings\n",
    "        seq_len = x.shape[1]\n",
    "        layer_emb = self.token_emb(x) + self.pos_emb[:, :seq_len, :]\n",
    "\n",
    "        # Apply RoPE if enabled\n",
    "        if self.use_rope:\n",
    "            layer_emb = self.apply_rope(layer_emb, self.rope_freqs)\n",
    "\n",
    "        # Attention input\n",
    "        if prev_h is not None:\n",
    "            attn_input = torch.cat([prev_emb, layer_emb, prev_h[:, -seq_len:, :]], dim=1)\n",
    "        else:\n",
    "            attn_input = layer_emb\n",
    "\n",
    "        # Compute Self-Attention with KV Caching\n",
    "        if not model.training:\n",
    "            if past_chunk is not None:\n",
    "                attn_out, new_chunk_cache, attn_weights = self.cached_attn(\n",
    "                    attn_input, attn_input, attn_input, past_kv=past_chunk\n",
    "                )\n",
    "            else:\n",
    "                attn_out, new_chunk_cache, attn_weights = self.cached_attn(attn_input, attn_input, attn_input)\n",
    "        else:\n",
    "            attn_out, entropy_chunk, attn_weights = self.cached_attn(attn_input, attn_input, attn_input)\n",
    "\n",
    "\n",
    "        \n",
    "        h_attn = self.ln_attn(attn_input + attn_out)\n",
    "        if not model.training:\n",
    "            if logits is not None:\n",
    "                vocab_embedding = torch.matmul(logits, self.unembedding.T)\n",
    "                if past_logits is not None:\n",
    "                    logits_context, new_logits_cache, logit_attn_weights = self.cached_logits_attn(\n",
    "                        h_attn, vocab_embedding, vocab_embedding, past_kv=past_logits\n",
    "                    )\n",
    "                else:\n",
    "                    logits_context, _, logit_attn_weights = self.cached_logits_attn(\n",
    "                        h_attn, vocab_embedding, vocab_embedding)\n",
    "                    new_logits_cache = None\n",
    "                \n",
    "            \n",
    "        # Compute Logits Cross-Attention with KV Caching\n",
    "        if not model.training:\n",
    "            if logits is not None:\n",
    "                vocab_embedding = torch.matmul(logits, self.unembedding.T)\n",
    "                if past_logits is not None:\n",
    "                    logits_context, new_logits_cache, logit_attn_weights = self.cached_logits_attn(\n",
    "                        h_attn, vocab_embedding, vocab_embedding, past_kv=past_logits\n",
    "                    )\n",
    "                    h_attn = h_attn + logits_context\n",
    "    \n",
    "                else:\n",
    "                    logits_context, _, logit_attn_weights = self.cached_logits_attn(\n",
    "                        h_attn, vocab_embedding, vocab_embedding\n",
    "                    )\n",
    "                    h_attn = h_attn + logits_context\n",
    "                    new_logits_cache = None\n",
    "            else:\n",
    "                logits = self.unembedding.T.mean(dim=0).unsqueeze(0).unsqueeze(0).expand(B, S, -1)\n",
    "                if past_logits is not None:\n",
    "                    logits_context, new_logits_cache, logit_attn_weights = self.cached_logits_attn(\n",
    "                        h_attn, logits, logits, past_kv=past_logits\n",
    "                    )\n",
    "                    h_attn = h_attn + logits_context\n",
    "    \n",
    "                else:\n",
    "                    logits_context, _, logit_attn_weights = self.cached_logits_attn(\n",
    "                        h_attn, logits, logits\n",
    "                    )\n",
    "                    h_attn = h_attn + logits_context\n",
    "                    new_logits_cache = None\n",
    "        else:#model is training\n",
    "            if logits is not None:\n",
    "                vocab_embedding = torch.matmul(logits, self.unembedding.T)\n",
    "                logits_context, entropy_logits, logit_attn_weights = self.cached_logits_attn(\n",
    "                        h_attn, vocab_embedding, vocab_embedding\n",
    "                    )\n",
    "            else:\n",
    "                logits = self.unembedding.T.mean(dim=0).unsqueeze(0).unsqueeze(0).expand(B, S, -1)\n",
    "                logits_context, entropy_logits, logit_attn_weights = self.cached_logits_attn(\n",
    "                        h_attn, logits, logits\n",
    "                    )\n",
    "            h_attn = h_attn + logits_context       \n",
    "\n",
    "        # Pass through MLP\n",
    "        h_mlp = self.ln_mlp(h_attn + self.mlp(h_attn))\n",
    "\n",
    "        # Compute final logits\n",
    "        logits_out = h_mlp @ self.unembedding\n",
    "        attn_weights = torch.softmax(attn_weights, dim=-1)\n",
    "        # Return KV cache\n",
    "        if not model.training:\n",
    "            new_cache = {'chunk_attn': new_chunk_cache, 'logits_attn': new_logits_cache}\n",
    "        if model.training:\n",
    "            new_cache = entropy_chunk #dont entropically regulate logits\n",
    "        return x, h_mlp, layer_emb, logits_out, new_cache, attn_weights\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class TapeHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-like block with progressive chunk sizes.\n",
    "    Each layer inside the TapeHead doubles the chunk size.\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len, embed_dim, vocab_size, num_layers=3, base_chunk=1, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.base_chunk = base_chunk\n",
    "\n",
    "        # Create progressively larger TapeHeadBlocks for the left and right streams.\n",
    "        self.blocks_left= nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=seq_len,\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_heads=max(1, 2 ** (num_layers - i)),  # Inversely scale heads\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.blocks_right = nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=seq_len,\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_heads=max(1, 2 ** (num_layers - i)),  # Inversely scale heads\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, prev_h, prev_emb, logits, past_kv=None):\n",
    "        \"\"\"\n",
    "        past_kv: dictionary with keys 'left' and 'right', each is a list of caches (one per block).\n",
    "        \"\"\"\n",
    "        attn_weights = []\n",
    "        entropy = []\n",
    "\n",
    "        if not model.training:\n",
    "            if past_kv is None:\n",
    "                past_kv = {'left': [None] * self.num_layers, 'right': [None] * self.num_layers}\n",
    "\n",
    "            logits_left = logits.clone() if logits is not None else None\n",
    "            prev_emb_left = prev_emb.clone() if prev_emb is not None else None\n",
    "            prev_h_left = prev_h.clone() if prev_h is not None else None\n",
    "    \n",
    "            new_past_left = []\n",
    "            new_past_right = []\n",
    "            \n",
    "            for i in range(self.num_layers):\n",
    "                # Process left block with its cache.\n",
    "                _, h_out_left, layer_emb_left, logits_left, cache_left ,attn_weights_left = self.blocks_left[i](\n",
    "                    x, prev_h_left, prev_emb_left, logits_left, past_kv=past_kv['left'][i]\n",
    "                )\n",
    "                new_past_left.append(cache_left)\n",
    "                # Process right block with its cache.\n",
    "                _, h_out, layer_emb, logits, cache_right,attn_weights_right = self.blocks_right[i](\n",
    "                    x, prev_h, prev_emb, logits, past_kv=past_kv['right'][i]\n",
    "                )\n",
    "                new_past_right.append(cache_right)\n",
    "                attn_weights.append((attn_weights_left+ attn_weights_right)/2.0)\n",
    "\n",
    "            \n",
    "            # Combine outputs from left and right streams.\n",
    "            a = self.activation(h_out_left)\n",
    "            b = self.activation(h_out)\n",
    "            h_out = 0.5 * (a + b - 2 * a * b)\n",
    "            h_out_left = h_out.clone()\n",
    "\n",
    "\n",
    "        else:\n",
    "            logits_left = logits.clone() if logits is not None else None\n",
    "            prev_emb_left = prev_emb.clone() if prev_emb is not None else None\n",
    "            prev_h_left = prev_h.clone() if prev_h is not None else None\n",
    "    \n",
    "            new_past_left = []\n",
    "            new_past_right = []\n",
    "            for i in range(self.num_layers):\n",
    "                # Process left block with its cache.\n",
    "                _, h_out_left, layer_emb_left, logits_left, entropy_left, attn_weights_left = self.blocks_left[i](\n",
    "                    x, prev_h_left, prev_emb_left, logits_left)\n",
    "\n",
    "                # Process right block with its cache.\n",
    "                _, h_out, layer_emb, logits,entropy_right, attn_weights_right = self.blocks_right[i](\n",
    "                    x, prev_h, prev_emb, logits)\n",
    "                attn_weights.append((attn_weights_left+ attn_weights_right)/2.0)\n",
    "                entropy.append((entropy_left + entropy_right)/2.0)\n",
    "\n",
    "            \n",
    "            # Combine outputs from left and right streams.\n",
    "            a = self.activation(h_out_left)\n",
    "            b = self.activation(h_out)\n",
    "            h_out = 0.5 * (a + b - 2 * a * b)\n",
    "            h_out_left =  h_out.clone()\n",
    "        \n",
    "\n",
    "        layer_weights = torch.linspace(0.3, 1.0, steps=self.num_layers).to(x.device)  # Increasing importance\n",
    "        layer_weights /= layer_weights.sum()  # Normalize to sum to 1\n",
    "        \n",
    "        attn_weights = torch.stack(attn_weights, dim=0)  # Shape: (num_layers, S, S)\n",
    "\n",
    "        attn_weights *= layer_weights.view(-1, 1, 1)  # Expand dims to match (num_layers, S, S)\n",
    "        attn_weights = attn_weights.sum(dim=0)  # Collapse into (S, S)\n",
    "        # Combine logits and embeddings.\n",
    "        logits_out = 0.5 * (logits + logits_left - 2 * logits * logits_left)\n",
    "        layer_emb_out = 0.5 * (layer_emb + layer_emb_left - 2 * layer_emb * layer_emb_left)\n",
    "        if not model.training:\n",
    "            new_cache = {'left': new_past_left, 'right': new_past_right}\n",
    "        else:\n",
    "            new_cache = torch.sum(torch.stack(entropy))/self.num_layers\n",
    "        return x, h_out, layer_emb_out, logits_out, new_cache, attn_weights\n",
    "\n",
    "           \n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / (x.norm(2, dim=-1, keepdim=True) + self.eps) * self.weight\n",
    "        \n",
    "class TapeTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Full GPT-like model with:\n",
    "      - Token + Position Embeddings\n",
    "      - Multiple stacked TapeHeads\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, seq_len=128, chunk_len=4, embed_dim=128, num_heads=2, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.placeholder_idx = placeholder_idx\n",
    "        self.num_heads = num_heads\n",
    "        # LayerNorm immediately after embeddings.\n",
    "        self.embed_ln = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Create a list of TapeHeads.\n",
    "        self.tape_heads = nn.ModuleList([\n",
    "            TapeHead(\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_layers=math.ceil(math.log2(chunk_len)),\n",
    "                base_chunk=1,\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "        self.final_norm = RMSNorm(embed_dim)\n",
    "        self.logits_norm = nn.LayerNorm(embed_dim)\n",
    "        self.norm_gate = nn.Parameter(torch.tensor(0.5))  # for potential supervisory context\n",
    "        self.activation = ReferenceActivation()\n",
    "        # Final unembedding.\n",
    "        self.logits_weight = nn.Parameter(torch.tensor(0.5))\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "        self.merge_projection = nn.Linear(len(self.tape_heads) * embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x, past_kv=None):\n",
    "        \"\"\"\n",
    "        x: (B, S) integer token IDs.\n",
    "        past_kv: list of caches (one per tape head) or None.\n",
    "        Returns:\n",
    "          p_final: (B, S, V) probability distribution,\n",
    "          new_past_kv: updated caches.\n",
    "        \"\"\"\n",
    "        # Ensure batch dimension.\n",
    "        x = x.unsqueeze(0) if x.ndim == 1 else x\n",
    "        B, S = x.shape\n",
    "        assert S <= self.seq_len, \"Sequence too long.\"\n",
    "\n",
    "        logits = None\n",
    "        prev_h = None\n",
    "        prev_emb = None\n",
    "        new_past_heads = None\n",
    "        attn_weights = None\n",
    "        all_heads_h = []\n",
    "        entropy = []\n",
    "        if not model.training:\n",
    "            new_past_heads = []\n",
    "            if past_kv is None:\n",
    "                past_kv = [None] * len(self.tape_heads)\n",
    "    \n",
    "            # Process each TapeHead.\n",
    "            for i, head in enumerate(self.tape_heads):\n",
    "                x, h, prev_emb, logits, head_cache,attn_weights_head = head(x, prev_h, prev_emb, logits, past_kv=past_kv[i])\n",
    "                new_past_heads.append(head_cache)\n",
    "                all_heads_h.append(h)\n",
    "                attn_weights = attn_weights_head if attn_weights is None else attn_weights + attn_weights_head\n",
    "\n",
    "\n",
    "        else:   \n",
    "            # Process each TapeHead.\n",
    "            for i, head in enumerate(self.tape_heads):\n",
    "                x, n, prev_emb, logits, entropy_head, attn_weights_head = head(x, prev_h, prev_emb, logits)\n",
    "                all_heads_h.append(n)\n",
    "                attn_weights = attn_weights_head if attn_weights is None else attn_weights + attn_weights_head\n",
    "                entropy.append(entropy_head)\n",
    "\n",
    "        # Merge outputs from all tape heads.\n",
    "        merged_h = torch.cat(all_heads_h, dim=-1)\n",
    "        prev_h = self.merge_projection(merged_h)  # (B, S, D)\n",
    "        attn_weights /= self.num_heads\n",
    "        # Final logits computed with student-t unembedding.\n",
    "        p_final = prev_h @ self.unembedding # (B, S, V) #no softmaxing allowed\n",
    "        if not model.training:\n",
    "            return p_final, new_past_heads, attn_weights\n",
    "        else:\n",
    "            return p_final, torch.sum(torch.stack(entropy))/self.num_heads, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc,torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VhlsGaG7ONr",
    "outputId": "1534f894-6597-49b5-c0c3-41369844874c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder token for even vocab size:  with index: 65\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Preparation (Shakespeare)\n",
    "# ====================================================\n",
    "def load_shakespeare_text():\n",
    "    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "    text = requests.get(url).text\n",
    "    return text\n",
    "\n",
    "text = load_shakespeare_text()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# Add a placeholder token: an ASCII grey block (visible in output)\n",
    "placeholder = \"\"  # Choose your preferred grey block character\n",
    "if placeholder not in chars:\n",
    "    chars.append(placeholder)\n",
    "    chars.sort()  # Ensure ordering is maintained\n",
    "\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "placeholder_idx = stoi[placeholder]\n",
    "print(\"Placeholder token for even vocab size:\", placeholder, \"with index:\", placeholder_idx)\n",
    "\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "def get_batch(batch_size, seq_len):\n",
    "    ix = torch.randint(0, data.size(0) - seq_len - 1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+seq_len] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+seq_len+1] for i in ix])\n",
    "    return x, y\n",
    "    \n",
    "\n",
    "# ====================================================\n",
    "# Training Setup\n",
    "# ====================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TapeTransformer(\n",
    "    vocab_size=vocab_size,  # example\n",
    "    seq_len=128,#longer not truly needed beause we KV cache\n",
    "    chunk_len=4,\n",
    "    embed_dim=256,#heads times true vocab, round up \n",
    "    num_heads=8,\n",
    "    placeholder_idx=placeholder_idx,\n",
    "    dropout=0 #cannot use dropout, tooo slow\n",
    ").to(device)\n",
    "\n",
    "optimizer = Wolf(model.parameters(), lr=0.3678)\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "eps = 1e-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35350530"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=6e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# Training control variables\n",
    "seq_len = 128  # Start with the smallest sequence\n",
    "max_seq_len = 128\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# Loss tracking\n",
    "epochs_per_check = 10  # Print every 10 epochs\n",
    "target_loss = max(math.log(vocab_size/(seq_len+1)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28acf68cda94409b845c4bc544cb37e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjusted Code to Improve EWMA Size and Implement Loss Ticker as a Moving Graph\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# --- Configuration Constants ---\n",
    "CHAR_WIDTH = 8  # Font size 8 for token rendering\n",
    "CHAR_HEIGHT = 11\n",
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "LOSS_BAR_HEIGHT = 32\n",
    "EWMA_HEIGHT = 32  # Increased to accommodate large text (previously 32)\n",
    "\n",
    "# Full-resolution framebuffer dimensions\n",
    "container_width = CHAR_WIDTH * SEQ_LEN  # 1024 pixels\n",
    "container_height = CHAR_HEIGHT * BATCH_SIZE  # 176 pixels\n",
    "total_height = container_height + LOSS_BAR_HEIGHT + EWMA_HEIGHT  # Adjusted for larger EWMA\n",
    "\n",
    "# Final scaled-down dimensions\n",
    "scaled_width = container_width   # 512 pixels\n",
    "scaled_height = total_height  # 170 pixels\n",
    "\n",
    "# Initialize framebuffer\n",
    "framebuffer = np.zeros((total_height, container_width, 3), dtype=np.uint8)\n",
    "\n",
    "# EWMA storage\n",
    "loss_history = []\n",
    "ticker_history = np.zeros(SEQ_LEN, dtype=np.float32)  # Stock ticker moving buffer\n",
    "\n",
    "# Load font\n",
    "try:\n",
    "    font = ImageFont.truetype(\"DejaVuSansMono.ttf\", 8)  # Monospaced font\n",
    "    font_large = ImageFont.truetype(\"DejaVuSansMono.ttf\", 64)  # Large EWMA display\n",
    "except:\n",
    "    font = ImageFont.load_default()\n",
    "    font_large = font\n",
    "\n",
    "# --- Color Mapping Functions ---\n",
    "def get_flame_color(val):\n",
    "    \"\"\"Map a normalized value to a flame-like color.\"\"\"\n",
    "    return np.array([int(val * 255), int(val * 0.5 * 255), 0], dtype=np.uint8)\n",
    "\n",
    "def get_ewma_color(val):\n",
    "    \"\"\"Map a normalized loss value to a dark-blue-to-white scale.\"\"\"\n",
    "    scale = val / np.log(65)  # Normalize using ln(65) which is max possible loss typical\n",
    "    scale = 255-int(scale*255)\n",
    "    return np.array([scale,scale, 255], dtype=np.uint8)\n",
    "\n",
    "# --- IPython Display Setup ---\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "\n",
    "def get_dynamic_color(attn_val, loss_val):\n",
    "    \"\"\"\n",
    "    Compute a dynamic color transition between flame orange (uncertain) and phosphor green (confident).\n",
    "    \n",
    "    attn_val: Normalized attention value (0 to 1)\n",
    "    loss_val: Normalized loss value (0 to 1, inverted as 1 - loss)\n",
    "    \n",
    "    Returns an RGB color as a NumPy array.\n",
    "    colors late in training will often be red. this is suggested to swap out for get_flame_color\n",
    "    but only on fine tuning on new data.\n",
    "    \"\"\"\n",
    "    certainty = 1 - loss_val  # High certainty = low loss\n",
    "    \n",
    "    # Define RGB endpoints\n",
    "    orange = np.array([attn_val * 255, attn_val * 0.5 * 255, 0], dtype=np.uint8)   # Uncertain (High Loss)\n",
    "    green = np.array([attn_val * 0.5 * 255, attn_val * 255, attn_val * 0.5 * 255], dtype=np.uint8)  # Confident (Low Loss)\n",
    "    \n",
    "    # Interpolate based on certainty (0 = uncertain/orange, 1 = confident/green)\n",
    "    color = (certainty * green) + ((1 - certainty) * orange)\n",
    "    \n",
    "    return color.astype(np.uint8)\n",
    "# --- Framebuffer Update Function ---\n",
    "def update_framebuffer(attn_torch, losses_torch, current_loss, tokens,ent):\n",
    "    attn_weights = torch.softmax(attn_torch, dim=-1).cpu().detach().numpy()\n",
    "    attn_weights =(attn_weights-attn_weights.min())/(attn_weights.max()-attn_weights.min())\n",
    "    token_losses =torch.softmax(losses_torch, dim=-1).cpu().detach().numpy()\n",
    "    token_losses =(token_losses-token_losses.min())/(token_losses.max()-token_losses.min())\n",
    "\n",
    "    \"\"\"Render the text grid with coloration based on attn * inverse loss.\"\"\"\n",
    "    global framebuffer, loss_history, ticker_history\n",
    "\n",
    "    # Normalize to [0,1]\n",
    "\n",
    "    # Create image buffer\n",
    "    img = Image.new(\"RGB\", (container_width, total_height), (0, 0, 0))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Render text with colored intensity\n",
    "    for row in range(BATCH_SIZE):\n",
    "        for col in range(SEQ_LEN):\n",
    "            char = tokens[row][col]\n",
    "            color = tuple(get_dynamic_color(attn_weights[row, col],attn_weights[row, col]))\n",
    "            x, y = col * CHAR_WIDTH, row * CHAR_HEIGHT + EWMA_HEIGHT + LOSS_BAR_HEIGHT\n",
    "            draw.text((x, y), char, font=font, fill=color)\n",
    "\n",
    "    # --- EWMA Display (LARGE FONT) ---\n",
    "    loss_history.append(current_loss.item())\n",
    "    if len(loss_history) > 128:\n",
    "        loss_history.pop(0)\n",
    "    ewma = np.exp(np.convolve(np.log(np.array(loss_history) + 1e-6), np.ones(128) / 128, mode='valid'))[-1]\n",
    "    ewma_text = f\"{ewma:.4f}\"\n",
    "    ewma_color = tuple(get_ewma_color(ewma))\n",
    "    draw.text((container_width-128, 0), ewma_text, font_size=32, fill=ewma_color)\n",
    "    entropy = ent.item()\n",
    "    ent_text = f\"{entropy:.4f}\"\n",
    "    ewma_color = tuple(get_ewma_color(ewma))\n",
    "    draw.text((10, 0), ent_text, font_size=32, fill=ewma_color)  \n",
    "\n",
    "    # --- Moving Loss Ticker Graph ---\n",
    "    ticker_history = np.roll(ticker_history, -1)  # Shift left\n",
    "    ticker_history[-1] = current_loss.item()  # Insert new loss on the right\n",
    "\n",
    "    # Rescale ticker dynamically like a stock ticker (normalize to min-max range)\n",
    "    min_loss = np.min(ticker_history)\n",
    "    max_loss = np.max(ticker_history)\n",
    "    range_loss = max_loss - min_loss if max_loss != min_loss else 1\n",
    "    normalized_ticker = (ticker_history - min_loss) / range_loss\n",
    "\n",
    "    # Draw ticker graph line\n",
    "    for i in range(SEQ_LEN - 1):\n",
    "        x1, y1 = i * CHAR_WIDTH, EWMA_HEIGHT + int((1 - normalized_ticker[i]) * LOSS_BAR_HEIGHT)\n",
    "        x2, y2 = (i + 1) * CHAR_WIDTH, EWMA_HEIGHT + int((1 - normalized_ticker[i + 1]) * LOSS_BAR_HEIGHT)\n",
    "        draw.line([(x1, y1), (x2, y2)], fill=(0, 255, 255), width=2)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    framebuffer = np.array(img)\n",
    "\n",
    "# --- IPython Display Update Function ---\n",
    "def update_display():\n",
    "    \"\"\"Show the framebuffer, scaled down by half using ipywidgets.\"\"\"\n",
    "    img = Image.fromarray(framebuffer)\n",
    "    img_resized = img.resize((scaled_width, scaled_height), Image.LANCZOS)\n",
    "    \n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        display(img_resized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9788.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 0, Loss: 4.115240\n",
      "tensor(3.6727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9793.2969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 1, Loss: 3.593000\n",
      "tensor(3.4545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9794.8262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 2, Loss: 3.374827\n",
      "tensor(3.4580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9793.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 3, Loss: 3.378294\n",
      "tensor(3.3022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9790.9922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 4, Loss: 3.222519\n",
      "tensor(3.2897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9789.5527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 5, Loss: 3.210037\n",
      "tensor(3.3635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9789.0254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 6, Loss: 3.283826\n",
      "tensor(3.3297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9789.7803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 7, Loss: 3.250011\n",
      "tensor(3.2828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9788.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 8, Loss: 3.203155\n",
      "tensor(3.2839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9783.8008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 9, Loss: 3.204235\n",
      "tensor(3.2772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9778.3789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 10, Loss: 3.197594\n",
      "tensor(3.2911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9769.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 11, Loss: 3.211554\n",
      "tensor(3.2141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9754.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 12, Loss: 3.134762\n",
      "tensor(3.2833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9739.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 13, Loss: 3.204060\n",
      "tensor(3.1700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9713.4795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 14, Loss: 3.090936\n",
      "tensor(3.2570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9694.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 15, Loss: 3.178088\n",
      "tensor(3.1514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9658.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 16, Loss: 3.072761\n",
      "tensor(3.1876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9630.0098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 17, Loss: 3.109212\n",
      "tensor(3.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9596.3857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 18, Loss: 3.046940\n",
      "tensor(3.1493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9570.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 19, Loss: 3.071442\n",
      "tensor(3.1961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9554.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 20, Loss: 3.118349\n",
      "tensor(3.0750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9528.5547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 21, Loss: 2.997443\n",
      "tensor(3.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9507.4141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 22, Loss: 2.976854\n",
      "tensor(3.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9500.7002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 23, Loss: 2.976693\n",
      "tensor(3.0631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9494.9111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 24, Loss: 2.985863\n",
      "tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9494.6348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 25, Loss: 2.980676\n",
      "tensor(2.9985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9473.7227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 26, Loss: 2.921412\n",
      "tensor(2.9931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9477.8525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 27, Loss: 2.915982\n",
      "tensor(2.9891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9472.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 28, Loss: 2.912014\n",
      "tensor(2.9587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9475.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 29, Loss: 2.881543\n",
      "tensor(2.9120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9481.7793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 30, Loss: 2.834827\n",
      "tensor(3.0373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9473.9072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 31, Loss: 2.960208\n",
      "tensor(2.9051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9476.7705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 32, Loss: 2.828001\n",
      "tensor(2.9231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9467.9316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 33, Loss: 2.846047\n",
      "tensor(2.8702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9466.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 34, Loss: 2.793147\n",
      "tensor(2.8542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9457.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 35, Loss: 2.777213\n",
      "tensor(2.8462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9464.6504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 36, Loss: 2.769159\n",
      "tensor(2.8267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9463.7031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 37, Loss: 2.749650\n",
      "tensor(2.8438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9464.5449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 38, Loss: 2.766732\n",
      "tensor(2.7831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9472.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 39, Loss: 2.706062\n",
      "tensor(2.8252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9478.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 40, Loss: 2.748032\n",
      "tensor(2.7994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9480.5762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 41, Loss: 2.722251\n",
      "tensor(2.8592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9483.0293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 42, Loss: 2.782068\n",
      "tensor(2.7973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9481.8311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 43, Loss: 2.720103\n",
      "tensor(2.8049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9489.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 44, Loss: 2.727709\n",
      "tensor(2.8528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9481.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 45, Loss: 2.775679\n",
      "tensor(2.7786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9489.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 46, Loss: 2.701405\n",
      "tensor(2.8314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9488.9170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 47, Loss: 2.754225\n",
      "tensor(2.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9504.4141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 48, Loss: 2.694778\n",
      "tensor(2.7548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9496.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 49, Loss: 2.677557\n",
      "tensor(2.8018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9492.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 50, Loss: 2.724514\n",
      "tensor(2.8012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9505.9893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 51, Loss: 2.723840\n",
      "tensor(2.7569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9512.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 52, Loss: 2.679518\n",
      "tensor(2.6996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9515.0459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 53, Loss: 2.622129\n",
      "tensor(2.7054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9513.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 54, Loss: 2.627959\n",
      "tensor(2.7473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9510.8018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 55, Loss: 2.669910\n",
      "tensor(2.7905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9517.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 56, Loss: 2.713091\n",
      "tensor(2.7584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9522.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 57, Loss: 2.680907\n",
      "tensor(2.6763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9534.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 58, Loss: 2.598712\n",
      "tensor(2.7091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9520.5430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 59, Loss: 2.631596\n",
      "tensor(2.7382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9529.9258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 60, Loss: 2.660678\n",
      "tensor(2.7689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9532.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 61, Loss: 2.691303\n",
      "tensor(2.7229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9529.6084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 62, Loss: 2.645386\n",
      "tensor(2.6958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9528.7217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 63, Loss: 2.618265\n",
      "tensor(2.7380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9530.7344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 64, Loss: 2.660427\n",
      "tensor(2.7101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9535.6699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 65, Loss: 2.632547\n",
      "tensor(2.6607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9532.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 66, Loss: 2.583081\n",
      "tensor(2.7476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9531.6035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 67, Loss: 2.670064\n",
      "tensor(2.6505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9532.2383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 68, Loss: 2.572945\n",
      "tensor(2.6895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9533.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 69, Loss: 2.611884\n",
      "tensor(2.6936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9532.8730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 70, Loss: 2.615996\n",
      "tensor(2.6940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9533.6816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 71, Loss: 2.616421\n",
      "tensor(2.6192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9545.6650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 72, Loss: 2.541521\n",
      "tensor(2.6594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9544.8867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 73, Loss: 2.581709\n",
      "tensor(2.6601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9548.3955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 74, Loss: 2.582410\n",
      "tensor(2.5818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.8633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 75, Loss: 2.504050\n",
      "tensor(2.6700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9555.4922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 76, Loss: 2.592228\n",
      "tensor(2.5857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9557.5762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 77, Loss: 2.507885\n",
      "tensor(2.6292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9567.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 78, Loss: 2.551320\n",
      "tensor(2.7332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9546.9258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 79, Loss: 2.655528\n",
      "tensor(2.5460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9570.8135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 80, Loss: 2.468122\n",
      "tensor(2.6343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9552.0068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 81, Loss: 2.556582\n",
      "tensor(2.6325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9559.9316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 82, Loss: 2.554746\n",
      "tensor(2.5961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9565.5977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 83, Loss: 2.518210\n",
      "tensor(2.6777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9558.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 84, Loss: 2.599930\n",
      "tensor(2.6079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9559.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 85, Loss: 2.530140\n",
      "tensor(2.6447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.8330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 86, Loss: 2.566880\n",
      "tensor(2.5323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9566.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 87, Loss: 2.454460\n",
      "tensor(2.6180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.5791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 88, Loss: 2.540181\n",
      "tensor(2.5944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9561.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 89, Loss: 2.516554\n",
      "tensor(2.5912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9554.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 90, Loss: 2.513465\n",
      "tensor(2.5447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9559.8496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 91, Loss: 2.466939\n",
      "tensor(2.6221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9549.8750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 92, Loss: 2.544402\n",
      "tensor(2.5871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.8164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 93, Loss: 2.509374\n",
      "tensor(2.6606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9545.8145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 94, Loss: 2.582906\n",
      "tensor(2.6468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9552.2969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 95, Loss: 2.569016\n",
      "tensor(2.6340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9543.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 96, Loss: 2.556363\n",
      "tensor(2.6554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9538.3301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 97, Loss: 2.577819\n",
      "tensor(2.6059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9532.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 98, Loss: 2.528342\n",
      "tensor(2.6124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9533.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 99, Loss: 2.534796\n",
      "tensor(2.6496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9535.5312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 100, Loss: 2.571963\n",
      "tensor(2.5793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9531.4453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 101, Loss: 2.501688\n",
      "tensor(2.5863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9536.9766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 102, Loss: 2.508645\n",
      "tensor(2.6478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9543.7266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 103, Loss: 2.570166\n",
      "tensor(2.5473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9538.6914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 104, Loss: 2.469668\n",
      "tensor(2.5636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9543.7812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 105, Loss: 2.485922\n",
      "tensor(2.5809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9548.7021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 106, Loss: 2.503227\n",
      "tensor(2.5798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9557.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 107, Loss: 2.502042\n",
      "tensor(2.5249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9563.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 108, Loss: 2.447119\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9563.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 109, Loss: 2.519311\n",
      "tensor(2.5310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9567.5713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 110, Loss: 2.453147\n",
      "tensor(2.5434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9564.9785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 111, Loss: 2.465573\n",
      "tensor(2.6415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9558.7793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 112, Loss: 2.563661\n",
      "tensor(2.5189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9569.6982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 113, Loss: 2.440996\n",
      "tensor(2.5986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9571.6885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 114, Loss: 2.520692\n",
      "tensor(2.5948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9559.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 115, Loss: 2.517012\n",
      "tensor(2.5559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9564.5508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 116, Loss: 2.478023\n",
      "tensor(2.5585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.5117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 117, Loss: 2.480726\n",
      "tensor(2.5762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9564.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 118, Loss: 2.498387\n",
      "tensor(2.5741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9560.7363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 119, Loss: 2.496299\n",
      "tensor(2.5715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9575.4746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 120, Loss: 2.493560\n",
      "tensor(2.5978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9558.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 121, Loss: 2.520042\n",
      "tensor(2.5442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9568.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 122, Loss: 2.466282\n",
      "tensor(2.5384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9561.9297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 123, Loss: 2.460595\n",
      "tensor(2.6030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9561.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 124, Loss: 2.525192\n",
      "tensor(2.5830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9557.0469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 125, Loss: 2.505245\n",
      "tensor(2.5492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9568.9199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 126, Loss: 2.471331\n",
      "tensor(2.6106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9574.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 127, Loss: 2.532713\n",
      "tensor(2.5491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9573.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 128, Loss: 2.471206\n",
      "tensor(2.5189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9574.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 129, Loss: 2.440972\n",
      "tensor(2.5779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9571.3418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 130, Loss: 2.500007\n",
      "tensor(2.5174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9580.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 131, Loss: 2.439471\n",
      "tensor(2.5524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9563.9883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 132, Loss: 2.474520\n",
      "tensor(2.5361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9572.6445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 133, Loss: 2.458224\n",
      "tensor(2.5414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9569.3398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 134, Loss: 2.463547\n",
      "tensor(2.5842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9583., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 135, Loss: 2.506176\n",
      "tensor(2.5765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9575.7188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 136, Loss: 2.498540\n",
      "tensor(2.5299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9584.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 137, Loss: 2.451866\n",
      "tensor(2.5610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9585.3066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 138, Loss: 2.482967\n",
      "tensor(2.5322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9581.4775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 139, Loss: 2.454234\n",
      "tensor(2.5234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9575.3760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 140, Loss: 2.445513\n",
      "tensor(2.5147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9584.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 141, Loss: 2.436715\n",
      "tensor(2.5570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9582.2480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 142, Loss: 2.478987\n",
      "tensor(2.6377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9576.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 143, Loss: 2.559753\n",
      "tensor(2.5486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9575.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 144, Loss: 2.470652\n",
      "tensor(2.5116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9568.5820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 145, Loss: 2.433701\n",
      "tensor(2.5214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9575.4492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 146, Loss: 2.443437\n",
      "tensor(2.4803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9579.9248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 147, Loss: 2.402318\n",
      "tensor(2.5570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9570.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 148, Loss: 2.479084\n",
      "tensor(2.5347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9538.5254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 149, Loss: 2.457112\n",
      "tensor(2.5256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9568.4453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 150, Loss: 2.447780\n",
      "tensor(2.5895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9550.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 151, Loss: 2.511821\n",
      "tensor(2.5593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9550.6895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 152, Loss: 2.481613\n",
      "tensor(2.5670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9566.2930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 153, Loss: 2.489150\n",
      "tensor(2.5422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9549.2480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 154, Loss: 2.464490\n",
      "tensor(2.4704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9564.6416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 155, Loss: 2.392582\n",
      "tensor(2.5594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9560.8359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 156, Loss: 2.481559\n",
      "tensor(2.5376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9559.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 157, Loss: 2.459836\n",
      "tensor(2.5415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9576.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 158, Loss: 2.463528\n",
      "tensor(2.5428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9560.9375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 159, Loss: 2.464996\n",
      "tensor(2.5232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.6797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 160, Loss: 2.445448\n",
      "tensor(2.5205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9561.5664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 161, Loss: 2.442698\n",
      "tensor(2.5060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9561.9023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 162, Loss: 2.428199\n",
      "tensor(2.4873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9560.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 163, Loss: 2.409524\n",
      "tensor(2.5264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9561.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 164, Loss: 2.448580\n",
      "tensor(2.5023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9552.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 165, Loss: 2.424534\n",
      "tensor(2.4274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9566.5625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 166, Loss: 2.349586\n",
      "tensor(2.4750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9562.3076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 167, Loss: 2.397220\n",
      "tensor(2.5423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9563.5273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 168, Loss: 2.464478\n",
      "tensor(2.4806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9548.7090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 169, Loss: 2.402913\n",
      "tensor(2.5386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9558.9248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 170, Loss: 2.460810\n",
      "tensor(2.5666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9546.8076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 171, Loss: 2.488953\n",
      "tensor(2.4862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9559.3320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 172, Loss: 2.408445\n",
      "tensor(2.5331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9542.8594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 173, Loss: 2.455445\n",
      "tensor(2.4841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9553.6836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 174, Loss: 2.406402\n",
      "tensor(2.5178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9546.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 175, Loss: 2.440142\n",
      "tensor(2.5093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9553.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 176, Loss: 2.431524\n",
      "tensor(2.4614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9571.3555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 177, Loss: 2.383539\n",
      "tensor(2.5125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9569.8379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 178, Loss: 2.434615\n",
      "tensor(2.5096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9562.6504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 179, Loss: 2.431820\n",
      "tensor(2.5265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 180, Loss: 2.448686\n",
      "tensor(2.5043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9555.5371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 181, Loss: 2.426566\n",
      "tensor(2.5264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9564.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 182, Loss: 2.448543\n",
      "tensor(2.4852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9572.5742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 183, Loss: 2.407268\n",
      "tensor(2.4719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9565.4531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 184, Loss: 2.394077\n",
      "tensor(2.4903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9552.4492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 185, Loss: 2.412598\n",
      "tensor(2.5240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9560.9238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 186, Loss: 2.446186\n",
      "tensor(2.4837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9566.5742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 187, Loss: 2.405875\n",
      "tensor(2.4854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.5283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 188, Loss: 2.407660\n",
      "tensor(2.5307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9546.4482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 189, Loss: 2.452972\n",
      "tensor(2.5147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 190, Loss: 2.436969\n",
      "tensor(2.4816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9551.4287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 191, Loss: 2.403854\n",
      "tensor(2.5462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9560.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 192, Loss: 2.468406\n",
      "tensor(2.5506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9547.4902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 193, Loss: 2.472924\n",
      "tensor(2.4225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9543.0488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 194, Loss: 2.344845\n",
      "tensor(2.4869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9548.9785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 195, Loss: 2.409203\n",
      "tensor(2.4836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9548.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 196, Loss: 2.405851\n",
      "tensor(2.4770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9562.8408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 197, Loss: 2.399140\n",
      "tensor(2.5766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.4092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 198, Loss: 2.498800\n",
      "tensor(2.4978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9569.8418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 199, Loss: 2.419962\n",
      "tensor(2.5269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9561.7539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 200, Loss: 2.449119\n",
      "tensor(2.4791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9546.4805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 201, Loss: 2.401427\n",
      "tensor(2.5029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9555.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 202, Loss: 2.425159\n",
      "tensor(2.4425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9559.9502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 203, Loss: 2.364713\n",
      "tensor(2.4878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9557.0215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 204, Loss: 2.409983\n",
      "tensor(2.5019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9555.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 205, Loss: 2.424092\n",
      "tensor(2.4769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9573.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 206, Loss: 2.399033\n",
      "tensor(2.4031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9541.0586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 207, Loss: 2.325434\n",
      "tensor(2.4825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9554.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 208, Loss: 2.404798\n",
      "tensor(2.4126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9551.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 209, Loss: 2.334882\n",
      "tensor(2.4799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9580.6631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 210, Loss: 2.401939\n",
      "tensor(2.4253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9570.7920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 211, Loss: 2.347385\n",
      "tensor(2.4516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9555.3555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 212, Loss: 2.373868\n",
      "tensor(2.3917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9568.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 213, Loss: 2.313866\n",
      "tensor(2.4937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9555.9082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 214, Loss: 2.415953\n",
      "tensor(2.5180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9568.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 215, Loss: 2.440106\n",
      "tensor(2.4426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9563.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 216, Loss: 2.364780\n",
      "tensor(2.3983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9574.7178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 217, Loss: 2.320399\n",
      "tensor(2.5000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9558.7363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 218, Loss: 2.422179\n",
      "tensor(2.4265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9559.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 219, Loss: 2.348691\n",
      "tensor(2.4655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9554.8711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 220, Loss: 2.387783\n",
      "tensor(2.4496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.8369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 221, Loss: 2.371863\n",
      "tensor(2.4299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9564.5547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 222, Loss: 2.352088\n",
      "tensor(2.4454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9555.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 223, Loss: 2.367605\n",
      "tensor(2.4914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9553.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 224, Loss: 2.413682\n",
      "tensor(2.4172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9554.7314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 225, Loss: 2.339451\n",
      "tensor(2.4494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9539.8818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 226, Loss: 2.371767\n",
      "tensor(2.4792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9546.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 227, Loss: 2.401478\n",
      "tensor(2.3996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9551.7969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 228, Loss: 2.321819\n",
      "tensor(2.4217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9559.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 229, Loss: 2.343877\n",
      "tensor(2.4083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9552.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 230, Loss: 2.330589\n",
      "tensor(2.4450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9550.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 231, Loss: 2.367318\n",
      "tensor(2.4968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9550.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 232, Loss: 2.419086\n",
      "tensor(2.4427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9553.9785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 233, Loss: 2.364980\n",
      "tensor(2.4093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9543.6309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 234, Loss: 2.331651\n",
      "tensor(2.4260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9561.5625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 235, Loss: 2.348150\n",
      "tensor(2.4273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9553.9766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 236, Loss: 2.349588\n",
      "tensor(2.4369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9552.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 237, Loss: 2.359142\n",
      "tensor(2.3732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9548.8125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 238, Loss: 2.295492\n",
      "tensor(2.3436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9545.9297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 239, Loss: 2.265951\n",
      "tensor(2.4110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9555.3887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 240, Loss: 2.333216\n",
      "tensor(2.4006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9536.7471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 241, Loss: 2.322963\n",
      "tensor(2.4364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9536.6074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 242, Loss: 2.358762\n",
      "tensor(2.4098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9541.8281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 243, Loss: 2.332120\n",
      "tensor(2.3905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9547.6992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 244, Loss: 2.312823\n",
      "tensor(2.4168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9538.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 245, Loss: 2.339223\n",
      "tensor(2.3556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9539.8877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 246, Loss: 2.277922\n",
      "tensor(2.3457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9542.8789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 247, Loss: 2.268015\n",
      "tensor(2.3758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9556.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 248, Loss: 2.298050\n",
      "tensor(2.3996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9535.3115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 249, Loss: 2.321979\n",
      "tensor(2.3539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9540.6523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 250, Loss: 2.276208\n",
      "tensor(2.4209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9537.7461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 251, Loss: 2.343330\n",
      "tensor(2.4361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9537.3418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 252, Loss: 2.358451\n",
      "tensor(2.3820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9542.8535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 253, Loss: 2.304309\n",
      "tensor(2.3352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9552.8838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 254, Loss: 2.257443\n",
      "tensor(2.3926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9532.6191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 255, Loss: 2.315053\n",
      "tensor(2.3785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9528.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 256, Loss: 2.300944\n",
      "tensor(2.3632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9535.5332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 257, Loss: 2.285551\n",
      "tensor(2.3607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9535.4434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 258, Loss: 2.283064\n",
      "tensor(2.3833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9546.0410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 259, Loss: 2.305591\n",
      "tensor(2.4150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9536.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 260, Loss: 2.337399\n",
      "tensor(2.3814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9536.6025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 261, Loss: 2.303775\n",
      "tensor(2.3706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9529.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 262, Loss: 2.293060\n",
      "tensor(2.3533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9534.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 263, Loss: 2.275732\n",
      "tensor(2.4083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9540.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 264, Loss: 2.330642\n",
      "tensor(2.3870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9535.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 265, Loss: 2.309437\n",
      "tensor(2.3868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9537.2383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 266, Loss: 2.309150\n",
      "tensor(2.4165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9545.8418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 267, Loss: 2.338840\n",
      "tensor(2.4233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9548.3418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 268, Loss: 2.345604\n",
      "tensor(2.3875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9531.6914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 269, Loss: 2.309947\n",
      "tensor(2.3540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9547.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 270, Loss: 2.276255\n",
      "tensor(2.2867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9540.8906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 271, Loss: 2.209098\n",
      "tensor(2.3724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9538.6387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 272, Loss: 2.294730\n",
      "tensor(2.3714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9534.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 273, Loss: 2.293805\n",
      "tensor(2.4030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9542.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 274, Loss: 2.325338\n",
      "tensor(2.3008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9536.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 275, Loss: 2.223181\n",
      "tensor(2.3215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9532.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 276, Loss: 2.243897\n",
      "tensor(2.3430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9514.5410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 277, Loss: 2.265580\n",
      "tensor(2.3499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9520.8379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 278, Loss: 2.272402\n",
      "tensor(2.3430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9523.9766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 279, Loss: 2.265456\n",
      "tensor(2.3742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9509.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 280, Loss: 2.296814\n",
      "tensor(2.3019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9519.5527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 281, Loss: 2.224473\n",
      "tensor(2.4076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9515.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 282, Loss: 2.330115\n",
      "tensor(2.3866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9508.4482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 283, Loss: 2.309226\n",
      "tensor(2.3386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9514.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 284, Loss: 2.261194\n",
      "tensor(2.4168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9504.5449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 285, Loss: 2.339481\n",
      "tensor(2.3125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9515.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 286, Loss: 2.235075\n",
      "tensor(2.3809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9500.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 287, Loss: 2.303547\n",
      "tensor(2.2807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9515.6816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 288, Loss: 2.203286\n",
      "tensor(2.3485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9511.7441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 289, Loss: 2.271107\n",
      "tensor(2.3325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9505.8701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 290, Loss: 2.255128\n",
      "tensor(2.3051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9516.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 291, Loss: 2.227651\n",
      "tensor(2.3420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9511.8555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 292, Loss: 2.264608\n",
      "tensor(2.3043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9506.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 293, Loss: 2.226958\n",
      "tensor(2.2941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9509.3750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 294, Loss: 2.216757\n",
      "tensor(2.3344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9503.6494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 295, Loss: 2.257045\n",
      "tensor(2.2630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9513.3984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 296, Loss: 2.185623\n",
      "tensor(2.2450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9505.6562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 297, Loss: 2.167617\n",
      "tensor(2.3252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9508.4668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 298, Loss: 2.247860\n",
      "tensor(2.3051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9518.4414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 299, Loss: 2.227647\n",
      "tensor(2.3270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9506.5801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 300, Loss: 2.249610\n",
      "tensor(2.3513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9510.5029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 301, Loss: 2.273932\n",
      "tensor(2.3948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9504.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 302, Loss: 2.317433\n",
      "tensor(2.2314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9503.6260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 303, Loss: 2.154079\n",
      "tensor(2.3185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9514.9707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 304, Loss: 2.241038\n",
      "tensor(2.4118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9502.6514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 305, Loss: 2.334425\n",
      "tensor(2.3325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9490.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 306, Loss: 2.255291\n",
      "tensor(2.3011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9496.6475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 307, Loss: 2.223813\n",
      "tensor(2.2835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9501.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 308, Loss: 2.206156\n",
      "tensor(2.3609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9486.8066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 309, Loss: 2.283668\n",
      "tensor(2.3405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9479.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 310, Loss: 2.263390\n",
      "tensor(2.3261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9489.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 311, Loss: 2.248836\n",
      "tensor(2.2667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9488.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 312, Loss: 2.189512\n",
      "tensor(2.2710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9486.6855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 313, Loss: 2.193774\n",
      "tensor(2.2285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9483.9922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 314, Loss: 2.151300\n",
      "tensor(2.2652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9482.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 315, Loss: 2.188052\n",
      "tensor(2.3290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9491.7373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 316, Loss: 2.251714\n",
      "tensor(2.3075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9505.8672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 317, Loss: 2.230109\n",
      "tensor(2.2327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9501.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 318, Loss: 2.155329\n",
      "tensor(2.2977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9503.4570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 319, Loss: 2.220375\n",
      "tensor(2.2995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9490.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 320, Loss: 2.222255\n",
      "tensor(2.2544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9500.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 321, Loss: 2.177047\n",
      "tensor(2.2972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9509.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 322, Loss: 2.219797\n",
      "tensor(2.2907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9489.8271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 323, Loss: 2.213450\n",
      "tensor(2.3026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9496.7266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 324, Loss: 2.225325\n",
      "tensor(2.2896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9492.7148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 325, Loss: 2.212330\n",
      "tensor(2.2687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9485.6895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 326, Loss: 2.191522\n",
      "tensor(2.2926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9488.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 327, Loss: 2.215400\n",
      "tensor(2.2819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9494.9453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 328, Loss: 2.204615\n",
      "tensor(2.2554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9499.8203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 329, Loss: 2.178129\n",
      "tensor(2.2498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9489.7090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 330, Loss: 2.172552\n",
      "tensor(2.1979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9499.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 331, Loss: 2.120630\n",
      "tensor(2.2927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9500.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 332, Loss: 2.215405\n",
      "tensor(2.2001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9490.6777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 333, Loss: 2.122853\n",
      "tensor(2.2478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9499.6592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 334, Loss: 2.170446\n",
      "tensor(2.2122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9492.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 335, Loss: 2.134942\n",
      "tensor(2.2647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9480.3555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 336, Loss: 2.187547\n",
      "tensor(2.2249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9466.5713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 337, Loss: 2.147907\n",
      "tensor(2.2514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9482.8105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 338, Loss: 2.174274\n",
      "tensor(2.2521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9486.8848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 339, Loss: 2.174879\n",
      "tensor(2.2041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9496.0508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 340, Loss: 2.126867\n",
      "tensor(2.2619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9489.9395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 341, Loss: 2.184671\n",
      "tensor(2.2327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9496.3887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 342, Loss: 2.155372\n",
      "tensor(2.2948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9486.8203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 343, Loss: 2.217606\n",
      "tensor(2.2295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9495.5039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 344, Loss: 2.152268\n",
      "tensor(2.2573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9479.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 345, Loss: 2.180161\n",
      "tensor(2.2506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9479.7500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 346, Loss: 2.173500\n",
      "tensor(2.2549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9483.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 347, Loss: 2.177699\n",
      "tensor(2.2815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9473.5840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 348, Loss: 2.204387\n",
      "tensor(2.1770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9482.4639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 349, Loss: 2.099801\n",
      "tensor(2.2504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9475.7188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 350, Loss: 2.173322\n",
      "tensor(2.2354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9482.9023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 351, Loss: 2.158201\n",
      "tensor(2.1931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9473.8271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 352, Loss: 2.115957\n",
      "tensor(2.2764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9473.9590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 353, Loss: 2.199295\n",
      "tensor(2.3319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9464.7871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 354, Loss: 2.254876\n",
      "tensor(2.1830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9458.8799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 355, Loss: 2.106022\n",
      "tensor(2.1950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9459.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 356, Loss: 2.117996\n",
      "tensor(2.1873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9469.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 357, Loss: 2.110269\n",
      "tensor(2.2061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9468.7637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 358, Loss: 2.129049\n",
      "tensor(2.2430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9455.0352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 359, Loss: 2.166076\n",
      "tensor(2.2408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9459.4863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 360, Loss: 2.163804\n",
      "tensor(2.1887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9447.8730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 361, Loss: 2.111844\n",
      "tensor(2.2198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9469.3066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 362, Loss: 2.142690\n",
      "tensor(2.2178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9459.6191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 363, Loss: 2.140823\n",
      "tensor(2.2202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9458.4922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 364, Loss: 2.143185\n",
      "tensor(2.2230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9454.6025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 365, Loss: 2.146039\n",
      "tensor(2.1830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9459.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 366, Loss: 2.106040\n",
      "tensor(2.2279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9443.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 367, Loss: 2.151057\n",
      "tensor(2.1743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9457.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 368, Loss: 2.097316\n",
      "tensor(2.1734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9448.8203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 369, Loss: 2.096536\n",
      "tensor(2.2206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9448.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 370, Loss: 2.143728\n",
      "tensor(2.2313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9446.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 371, Loss: 2.154429\n",
      "tensor(2.1849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9461.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 372, Loss: 2.107857\n",
      "tensor(2.1300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9454.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 373, Loss: 2.053035\n",
      "tensor(2.1629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9461.5625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 374, Loss: 2.085938\n",
      "tensor(2.1854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9458.9932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 375, Loss: 2.108435\n",
      "tensor(2.1747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9459.6543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 376, Loss: 2.097705\n",
      "tensor(2.1743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9450.9600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 377, Loss: 2.097387\n",
      "tensor(2.1987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9453.7148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 378, Loss: 2.121736\n",
      "tensor(2.1351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9460.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 379, Loss: 2.058078\n",
      "tensor(2.1526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9461.6934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 380, Loss: 2.075641\n",
      "tensor(2.1103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9462.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 381, Loss: 2.033267\n",
      "tensor(2.1373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9454.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 382, Loss: 2.060398\n",
      "tensor(2.1738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9463.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 383, Loss: 2.096794\n",
      "tensor(2.2389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9457.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 384, Loss: 2.161893\n",
      "tensor(2.2424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9449.8643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 385, Loss: 2.165501\n",
      "tensor(2.1078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9460.5781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 386, Loss: 2.030778\n",
      "tensor(2.2002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9454.7070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 387, Loss: 2.123305\n",
      "tensor(2.1243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9464.9004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 388, Loss: 2.047225\n",
      "tensor(2.1451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9469.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 389, Loss: 2.068017\n",
      "tensor(2.1176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9453.7012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 390, Loss: 2.040673\n",
      "tensor(2.1954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9463.9531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 391, Loss: 2.118374\n",
      "tensor(2.1263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9462.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 392, Loss: 2.049266\n",
      "tensor(2.1498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9463.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 393, Loss: 2.072801\n",
      "tensor(2.1096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9468.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 394, Loss: 2.032571\n",
      "tensor(2.1224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9468.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 395, Loss: 2.045397\n",
      "tensor(2.1228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9467.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 396, Loss: 2.045730\n",
      "tensor(2.1778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9461.5918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 397, Loss: 2.100764\n",
      "tensor(2.0974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9455.3975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 398, Loss: 2.020446\n",
      "tensor(2.0995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9457.6211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 399, Loss: 2.022501\n",
      "tensor(2.1043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9448.7402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 400, Loss: 2.027383\n",
      "tensor(2.1527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9455.5859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 401, Loss: 2.075732\n",
      "tensor(2.0860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9460.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 402, Loss: 2.009035\n",
      "tensor(2.0891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9453.5703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 403, Loss: 2.012211\n",
      "tensor(2.1193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9451.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 404, Loss: 2.042406\n",
      "tensor(2.1399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9443.9863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 405, Loss: 2.063091\n",
      "tensor(2.1135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9454.6484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 406, Loss: 2.036514\n",
      "tensor(2.0788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9456.8574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 407, Loss: 2.001824\n",
      "tensor(2.1301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9438.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 408, Loss: 2.053308\n",
      "tensor(2.1001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9439.8506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 409, Loss: 2.023281\n",
      "tensor(2.0885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9442.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 410, Loss: 2.011685\n",
      "tensor(2.1350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9441.7705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 411, Loss: 2.058195\n",
      "tensor(2.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9429.8379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 412, Loss: 1.957886\n",
      "tensor(2.1021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9432.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 413, Loss: 2.025294\n",
      "tensor(2.0675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9424.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch 414, Loss: 1.990777\n",
      "tensor(2.1409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9434.7246, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Training loop for current sequence length\n",
    "for epoch in range(100000):\n",
    "    model.train()\n",
    "    x_batch, targets = get_batch(batch_size, 128)\n",
    "    x_batch, targets = x_batch.to(device), targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        preds, entropy, attn_weights = model(x_batch)\n",
    "        # Decode token indices back to characters\n",
    "        tokens = [[itos[idx] for idx in seq.tolist()] for seq in x_batch]\n",
    "        \n",
    "        # Convert logits to log probabilities\n",
    "        log_probs = torch.log_softmax(preds, dim=-1)  # Softmax AFTER matrix multiplication\n",
    "        # Gather log probabilities of the correct tokens\n",
    "        gathered_log_probs = torch.gather(log_probs, -1, targets.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # Compute per-token loss (neg log probs) and final loss\n",
    "        weighted_loss = -gathered_log_probs  # Shape: (batch_size, seq_len)\n",
    "        final_loss = weighted_loss.mean() - 0.05 * (entropy/(16*128*3)) #apply entropic regularization\n",
    "        #multiply [qkv] * seq * batch and divide entropy by this\n",
    "    update_framebuffer(attn_weights, gathered_log_probs, final_loss, tokens,entropy)\n",
    "    update_display()\n",
    "    scaler.scale(final_loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    # Track loss & progress\n",
    "    loss_val = final_loss.item()\n",
    "    loss_history.append(loss_val)\n",
    "\n",
    "    # Update framebuffer visualization with real model outputs\n",
    "  \n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {loss_val:.6f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sample:\n",
      " oh Romeo! Romeo!                                                                                                                                                                                                        \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logit_list = []  # Store raw logits\n",
    "prob_list = []  # Store softmax probabilities\n",
    "\n",
    "model.eval()\n",
    "past_kv = None  # Initialize cache for the entire model.\n",
    "with torch.no_grad():\n",
    "    prompt = \"oh Romeo! Romeo!\"\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    generated = context\n",
    "    for _ in range(200):  # Generate 200 tokens.\n",
    "        inp = generated[:, -1:]  # Only use the last token.\n",
    "        p, past_kv, attn_weights = model(inp, past_kv=past_kv)  # Forward pass with cache.\n",
    "\n",
    "        last_token_logits = p[:, -1, :].cpu().numpy().flatten()  # Get raw logits\n",
    "        logit_list.append(last_token_logits)\n",
    "\n",
    "        temperature = 0.1 # Lower = more deterministic, Higher = more diverse (0.71.0 is good)\n",
    "        last_token_probs = torch.softmax(p[:, -1, :] / temperature, dim=-1).cpu().numpy().flatten()\n",
    "        prob_list.append(last_token_probs)\n",
    "\n",
    "        predicted_token = torch.multinomial(torch.tensor(last_token_probs), num_samples=1).unsqueeze(0)  # Fix shape\n",
    "        generated = torch.cat((generated, predicted_token.to(device)), dim=1)  # Concatenate properly\n",
    "\n",
    "    sample = decode(generated[0].cpu().tolist())\n",
    "    print(\"Generated Sample:\\n\", sample)\n",
    "\n",
    "# Plot histograms of logits and probabilities\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot logits histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(logit_list[-1], bins=100, alpha=0.75)\n",
    "plt.title(\"Logits Distribution (Before Softmax)\")\n",
    "plt.xlabel(\"Logit Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Plot probabilities histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(prob_list[-1], bins=100, alpha=0.75)\n",
    "plt.title(\"Probabilities Distribution (After Softmax)\")\n",
    "plt.xlabel(\"Probability Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'model_dict.pth'\n",
    "\n",
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = 'model_dict.pth'\n",
    "\n",
    "# Save the model's state_dict\n",
    "state_dict = torch.load(save_path)\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"full_model_structure_216_225.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Wolf(model.parameters(), lr=0.3678)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35350530"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ea6c28cb50>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
