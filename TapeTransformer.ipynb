{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPYRIGHT NOTICE\n",
    "In the name of Christ our Lord be blessed. We, Joshuah Rainstar(joshuah.rainstar@gmail.com), do claim copyright to this code, or software, and associated documentation, as our work in the year 2025 Anno Domini, reserving all rights and assigning them in accordance with the following license terms:\n",
    "\n",
    "1. Permission is by our authority and with this statement granted, to any person or artificial intelligence without limitation or restriction to examine, analyze, read, dissect, translate, use, modify, and distribute the aforementioned copyrighted items, subject to the following conditions:\n",
    "2. This license must be included in full with any copies or works containing substantial portions of the copyrighted items.\n",
    "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "\n",
    "THE COPYRIGHTED ITEMS ARE PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE COPYRIGHTED ITEMS OR THEIR USE OR ANY OTHER CIRCUMSTANCES CONCERNING THEM.\n"
   ]
  },
  {
   "attachments": {
    "28374c77-74dc-463c-984c-f518ca74a4cd.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is an experimental model intended to elucidate possible mechanics for attention across sequences in addition to tokenwise. it is reasonably fast and efficient. conceptually, the design was envisioned by me and coded through refinement with OpenAI Codex Orion One and chatgpt. i find that if i cant understand a thing, however clever it is- its wrong.\n",
    "so, this is largely a from-scratch along aligned principles. \n",
    "\n",
    "you are advised in life to apply a similar practice. nothing good comes of shit you dont comprehend.\n",
    "\n",
    "\"hierarchical multi-scale transformer with MoE-like  selection\"\n",
    "\n",
    "my own fucking activation function\n",
    "\n",
    "my own fucking loss method borrowing from harmonic loss but using student-t distribution!\n",
    "https://arxiv.org/abs/2502.01628\n",
    "\n",
    "XOR from  Two-argument activation functions learn soft XOR operations like cortical neurons\r\n",
    "https://arxiv.org/abs/2110.06871note that my implementation is a differential XOR for backprop capability\n",
    "motivation: little bit of internal reasoning maybe? Impact: slows down convergence somewhat\n",
    "ROPE from google\n",
    "\n",
    "entropy based reward to encourage diverse attention\n",
    "https://arxiv.org/abs/2203.09192\n",
    "\n",
    "\n",
    "WOLF optimizer experimental by me, it may not beat adam but it is simpler than adam, closer to SGD with some smoothing of integration\n",
    "impact: speeds up convergence somewhat for early iterations and will not NAN from high LR.\n",
    "probable benefit- switch optimizers after model drops. could be good for bigger models.. maybe\n",
    "\n",
    "![image.png](attachment:28374c77-74dc-463c-984c-f518ca74a4cd.png)\n",
    "m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jcJTMiWT89P5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dl9uYIM16MG4"
   },
   "outputs": [],
   "source": [
    "\n",
    "def student_t_unembedding(hidden_states, unembedding, df=2.718281828459, eps=1e-9, placeholder_idx=None):\n",
    "    \"\"\"\n",
    "    Student's t-based unembedding with optional placeholder modification.\n",
    "    \n",
    "    Arguments:\n",
    "      hidden_states: (B, S, D)  => modelâ€™s output embeddings (hidden state)\n",
    "      unembedding:   (D, V)    => learnable \"word vectors\" (unembedding matrix)\n",
    "      df (float): degrees of freedom for the Student's t distribution\n",
    "      eps (float): numerical epsilon to avoid log(0) and div-by-zero\n",
    "      placeholder_idx (int, optional): if provided, indicates the column in the unembedding\n",
    "          corresponding to the placeholder token. The distances for that token will be adjusted \n",
    "          using an adaptive noise factor.\n",
    "    \n",
    "    Returns:\n",
    "      p: (B, S, V)  probability distribution over V vocabulary tokens.\n",
    "    \"\"\"\n",
    "    B, S, D = hidden_states.shape\n",
    "    V = unembedding.shape[1]\n",
    "    # Expand hidden => (B, S, 1, D)\n",
    "    x_expanded = hidden_states.unsqueeze(2)\n",
    "    # Expand unembedding => (1, 1, V, D)\n",
    "    w_expanded = unembedding.t().unsqueeze(0).unsqueeze(0)  # shape: (1, 1, V, D)\n",
    "    \n",
    "    # Compute squared Euclidean distance between each hidden vector and each unembedding vector.\n",
    "    dist_sq = torch.sum((x_expanded - w_expanded) ** 2, dim=-1).clamp(min=1e-6)  # (B, S, V)\n",
    "        \n",
    "    # Compute the negative energy:\n",
    "    #    E = 0.5*(df + D) * log(1 + dist_sq / df)\n",
    "    # and so log probability (up to an additive constant) is:\n",
    "    #    log_p = -E\n",
    "    log_p_unnorm = -0.5 * (df + D) * torch.log1p(dist_sq / df)  # (B, S, V)\n",
    "    \n",
    "    # Normalize via log_softmax over the vocabulary dimension.\n",
    "    log_p = F.log_softmax(log_p_unnorm, dim=-1)  # (B, S, V)\n",
    "    return log_p\n",
    "\n",
    "\n",
    "\n",
    "class Wolf(Optimizer):\n",
    "    \"\"\"Implements Wolf algorithm.\"\"\"\n",
    "    def __init__(self, params, lr=0.25, betas=(0.9, 0.999), eps=1e-8):\n",
    "        # Define default parameters\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps)\n",
    "        self.lr = lr\n",
    "        # Initialize the parent Optimizer class first\n",
    "        super().__init__(params, defaults)\n",
    "        # Constants specific to Wolf\n",
    "        # Initialize state for each parameter\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['p'] = torch.zeros_like(p)  # Second moment estimate\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step and adjusts dropout in transformer blocks.\"\"\"\n",
    "        etcerta = 0.367879441  # Constant used in update rule\n",
    "        et = 1 - etcerta\n",
    "    \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "    \n",
    "        # Iterate over parameter groups.\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                grad = p.grad\n",
    "                state = self.state[p]\n",
    "                exp_avg = state['p']\n",
    "    \n",
    "                # Compute update and update second moment-like state.\n",
    "                update = exp_avg * et + grad * etcerta\n",
    "                state['p'] = exp_avg * et + update * etcerta\n",
    "    \n",
    "                # Compute sign agreement between update and gradient.\n",
    "                sign_agreement = torch.sign(update) * torch.sign(grad)\n",
    "    \n",
    "                # Where the signs agree (mask is True), update the parameter.\n",
    "                mask = (sign_agreement > 0)\n",
    "                adaptive_alpha = group.get('lr', self.lr)\n",
    "                p.data = torch.where(mask, p.data - adaptive_alpha * update, p.data)\n",
    "    \n",
    "                # AMP Compatibility: Ensure a step counter is updated\n",
    "                state['step'] = state.get('step', 0) + 1  # Track optimization steps\n",
    "    \n",
    "        return loss\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Custom Activation\n",
    "# ---------------------------------------------------\n",
    "class ReferenceActivation(nn.Module):\n",
    "    def __init__(self, gamma=24):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, x):\n",
    "        x.clamp_(-2, 2)\n",
    "        log_x = torch.sign(x) * torch.log1p(torch.abs(x))\n",
    "        safe_x = torch.nan_to_num(log_x, nan=0.0)\n",
    "\n",
    "        return log_x / torch.sqrt(1 + self.gamma * log_x ** 2)\n",
    "            \n",
    "class CachedMultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.0, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        # We use the built-in multihead attention module.\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=batch_first)\n",
    "    \n",
    "    def forward(self, query, key, value, past_kv=None):\n",
    "        \"\"\"\n",
    "        query: (B, S_new, D)\n",
    "        key, value: (B, S_current, D) for the current input tokens.\n",
    "        past_kv: Tuple (past_key, past_value) or None.\n",
    "        \"\"\"\n",
    "        if not self.training:\n",
    "            if past_kv is not None:\n",
    "                past_key, past_value = past_kv\n",
    "                # Concatenate along the sequence dimension\n",
    "                key = torch.cat([past_key, key], dim=1)\n",
    "                value = torch.cat([past_value, value], dim=1)\n",
    "            # Run the attention module.\n",
    "            attn_output, _ = self.attn(query, key, value)\n",
    "            # The new cache holds all keys and values computed so far.\n",
    "            new_kv = (key, value)\n",
    "            return attn_output, new_kv\n",
    "        else:\n",
    "            attn_output,attn_weights = self.attn(query, key, value)\n",
    "\n",
    "            attn_weights.clamp_( min=1e-9, max=1.0)\n",
    "            entropy = -torch.sum(attn_weights * torch.log(attn_weights + 1e-9), dim=-1)\n",
    "            attn_weights_1 = attn_weights.sum(dim=-1)\n",
    "            attn_weights_2 = attn_weights.sum(dim=-2)\n",
    "            attn_weights = (attn_weights_1 + attn_weights_2)/2\n",
    "\n",
    "            return attn_output, entropy, attn_weights\n",
    "            \n",
    "class RectifiedKAN(nn.Module):\n",
    "    def __init__(self, embed_dim, expansion_factor=8, dropout=0.0):\n",
    "        super().__init__()\n",
    "        hidden_dim = expansion_factor * embed_dim\n",
    "\n",
    "        self.expand = nn.Linear(embed_dim, hidden_dim)  # Expand input\n",
    "        self.shift = nn.Parameter(torch.zeros(hidden_dim))  # Shift parameters\n",
    "        self.activation = ReferenceActivation()  # Piecewise linear activation\n",
    "        self.linear = nn.Linear(hidden_dim, embed_dim)  # Project back\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.expand(x)  # Expand input\n",
    "        x = x + self.shift  # Apply shift (edge-based transform)\n",
    "        x = self.activation(x)  # Nonlinear edge activation\n",
    "        x = self.linear(x)  # Collapse back to original space\n",
    "        x = self.dropout(x)  # Regularization\n",
    "        return x\n",
    "\n",
    "\n",
    "class TapeHeadBlock(nn.Module):\n",
    "    def __init__(self, chunk_size, seq_len, embed_dim, vocab_size, num_heads=1, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.chunk_size = chunk_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_seq_len = seq_len\n",
    "\n",
    "        # Token embeddings\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        # Sinusoidal positional embeddings (Precomputed)\n",
    "        self.register_buffer(\"pos_emb\", self._build_sinusoidal_embedding(seq_len, embed_dim))\n",
    "\n",
    "        # Rotary embedding setup\n",
    "        self.use_rope = True  # Set to False to disable RoPE\n",
    "        if self.use_rope:\n",
    "            self.register_buffer(\"rope_freqs\", self._build_rope_frequencies(embed_dim))\n",
    "\n",
    "        # Attention layers\n",
    "        self.cached_attn = CachedMultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln_attn = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # MLP and normalization\n",
    "        self.mlp = RectifiedKAN(embed_dim)\n",
    "        self.ln_mlp = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Unembedding matrix\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "\n",
    "        # Logits cross-attention\n",
    "        self.placeholder_idx = placeholder_idx\n",
    "\n",
    "    def _build_sinusoidal_embedding(self, seq_len, embed_dim):\n",
    "        \"\"\"Compute sinusoidal positional embeddings\"\"\"\n",
    "        position = torch.arange(seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000.0) / embed_dim))\n",
    "        pos_emb = torch.zeros(seq_len, embed_dim)\n",
    "        pos_emb[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_emb[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pos_emb.unsqueeze(0)  # Shape: (1, seq_len, embed_dim)\n",
    "\n",
    "\n",
    "    def _build_rope_frequencies(self, embed_dim):\n",
    "        \"\"\"Build the inverse frequency tensor for RoPE and ensure it is a PyTorch tensor.\"\"\"\n",
    "        half_dim = embed_dim // 2  # For D=256, half_dim = 128\n",
    "        base_freqs = 1.0 / (10000 ** (torch.arange(0, half_dim, dtype=torch.float32) / half_dim))\n",
    "        # Remove the repeat_interleave so we keep shape (half_dim,)\n",
    "        return base_freqs.to(torch.float32)  # Shape: (D/2,)\n",
    "\n",
    "        \n",
    "    def apply_rope(self,tensor, rope_freqs):\n",
    "            \"\"\"\n",
    "            Apply Rotary Positional Embedding (RoPE) to the input tensor.\n",
    "            \n",
    "            Args:\n",
    "                tensor (Tensor): Input tensor of shape (B, S, D), where\n",
    "                                 B = batch size, S = sequence length, D = embedding dim.\n",
    "                rope_freqs (Tensor): Frequency tensor of shape (D/2,) computed via _build_rope_frequencies.\n",
    "                \n",
    "            Returns:\n",
    "                Tensor: The input tensor after applying RoPE, with the same shape (B, S, D).\n",
    "                \n",
    "            Detailed Steps & Dimensions:\n",
    "              1. Let B, S, D = tensor.shape and half_dim = D//2.\n",
    "              2. Compute positions: a tensor of shape (S,).\n",
    "              3. Compute theta = positions.unsqueeze(1) * rope_freqs.unsqueeze(0)\n",
    "                 -> theta has shape (S, half_dim).\n",
    "              4. Compute sin_theta and cos_theta from theta, each of shape (S, half_dim),\n",
    "                 then expand to (B, S, half_dim).\n",
    "              5. Split tensor into two halves along the last dimension:\n",
    "                 - x1 = tensor[..., 0::2] and x2 = tensor[..., 1::2], each with shape (B, S, half_dim).\n",
    "                 (Alternatively, one can do: x1, x2 = torch.chunk(tensor, 2, dim=-1))\n",
    "              6. Apply RoPE:\n",
    "                 - x1_rot = x1 * cos_theta - x2 * sin_theta\n",
    "                 - x2_rot = x1 * sin_theta + x2 * cos_theta\n",
    "              7. Reassemble the output by interleaving x1_rot and x2_rot.\n",
    "            \"\"\"\n",
    "            B, S, D = tensor.shape\n",
    "            if S == 1:\n",
    "                return tensor\n",
    "            assert D % 2 == 0, \"Embedding dimension must be even for RoPE.\"\n",
    "            half_dim = D // 2  # e.g. for D=256, half_dim = 128\n",
    "        \n",
    "            # Ensure rope_freqs is on the same device and dtype as tensor.\n",
    "            rope_freqs = rope_freqs.to(tensor.dtype)  # shape: (half_dim,)\n",
    "        \n",
    "            # 1. Compute positions (0, 1, ..., S-1): shape (S,)\n",
    "            positions = torch.arange(S, device=tensor.device, dtype=tensor.dtype)\n",
    "            \n",
    "            # 2. Compute theta = positions * rope_freqs:\n",
    "            #    positions: (S, 1), rope_freqs: (1, half_dim) --> theta: (S, half_dim)\n",
    "            theta = positions.unsqueeze(1) * rope_freqs.unsqueeze(0)  # shape: (S, half_dim)\n",
    "            \n",
    "            # 3. Compute sin and cos of theta:\n",
    "            sin_theta = theta.sin()  # shape: (S, half_dim)\n",
    "            cos_theta = theta.cos()  # shape: (S, half_dim)\n",
    "            \n",
    "            # 4. Expand sin and cos to shape (B, S, half_dim)\n",
    "            sin_theta = sin_theta.unsqueeze(0).expand(B, S, half_dim)\n",
    "            cos_theta = cos_theta.unsqueeze(0).expand(B, S, half_dim)\n",
    "            \n",
    "            # 5. Split tensor into two halves (real and imaginary parts).\n",
    "            # Here we use alternate slicing: the even-indexed dims are x1, odd-indexed are x2.\n",
    "            x1 = tensor[..., 0::2]  # shape: (B, S, half_dim)\n",
    "            x2 = tensor[..., 1::2]  # shape: (B, S, half_dim)\n",
    "            \n",
    "            # 6. Apply the RoPE rotation:\n",
    "            x1_rot = x1 * cos_theta - x2 * sin_theta  # shape: (B, S, half_dim)\n",
    "            x2_rot = x1 * sin_theta + x2 * cos_theta  # shape: (B, S, half_dim)\n",
    "            \n",
    "            # 7. Interleave x1_rot and x2_rot back together.\n",
    "            # One approach is to create an empty tensor and then fill in even and odd indices.\n",
    "            out = torch.empty_like(tensor)\n",
    "            out[..., 0::2] = x1_rot\n",
    "            out[..., 1::2] = x2_rot\n",
    "        \n",
    "            return out\n",
    "\n",
    "\n",
    "    def forward(self, x, prev_h, prev_emb, past_kv=None):\n",
    "        \"\"\"\n",
    "        x: (B, S) input token IDs\n",
    "        prev_h: (B, S, D) previous hidden state\n",
    "        prev_emb: (B, S, D) previous embeddings\n",
    "        logits: (B, S, V) logits distribution from previous block (can be None)\n",
    "        past_kv: Dictionary with keys 'chunk_attn' and 'logits_attn' holding KV caches\n",
    "        \"\"\"\n",
    "\n",
    "        past_chunk = past_kv.get('chunk_attn') if past_kv is not None else None\n",
    "        B,S = x.shape\n",
    "        # Compute token embeddings and add sinusoidal positional embeddings\n",
    "        seq_len = x.shape[1]\n",
    "        layer_emb = self.token_emb(x) + self.pos_emb[:, :seq_len, :]\n",
    "\n",
    "        # Apply RoPE if enabled\n",
    "        if self.use_rope:\n",
    "            layer_emb = self.apply_rope(layer_emb, self.rope_freqs)\n",
    "\n",
    "        # Attention input\n",
    "        if prev_h is not None:\n",
    "            attn_input = torch.cat([prev_emb, layer_emb, prev_h[:, -seq_len:, :]], dim=1)\n",
    "            attn_input = attn_input[:, -seq_len:, :]\n",
    "\n",
    "        else:\n",
    "            attn_input = layer_emb\n",
    "\n",
    "\n",
    "        # Compute Self-Attention with KV Caching\n",
    "        if not self.training:\n",
    "            if past_chunk is not None:\n",
    "                attn_out, new_chunk_cache  = self.cached_attn(\n",
    "                    attn_input, attn_input, attn_input, past_kv=past_chunk\n",
    "                )\n",
    "            else:\n",
    "                attn_out, new_chunk_cache = self.cached_attn(attn_input, attn_input, attn_input)\n",
    "        else:\n",
    "            attn_out, entropy_chunk, attn_weights = self.cached_attn(attn_input, attn_input, attn_input)\n",
    "\n",
    "        h_attn = self.ln_attn(attn_input + attn_out)\n",
    "\n",
    "        \n",
    "        # Pass through MLP\n",
    "        h_mlp = self.ln_mlp(h_attn + self.mlp(h_attn))\n",
    "\n",
    "        # Compute final logits\n",
    "        # Return KV cache\n",
    "        if not self.training:\n",
    "            new_cache = {'chunk_attn': new_chunk_cache}\n",
    "            return x, h_mlp, layer_emb, new_cache\n",
    "\n",
    "        if self.training:\n",
    "            attn_weights = torch.softmax(attn_weights, dim=-1)\n",
    "            return x, h_mlp, layer_emb, entropy_chunk, attn_weights\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class TapeHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-like block with progressive chunk sizes.\n",
    "    Each layer inside the TapeHead doubles the chunk size.\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len, embed_dim, vocab_size, num_layers=3, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        layer_weights = torch.linspace(0.3, 1.0, steps=self.num_layers)\n",
    "        layer_weights /= layer_weights.sum()  # Normalize\n",
    "        self.register_buffer(\"layer_weights\", layer_weights)\n",
    "        # Create progressively larger TapeHeadBlocks for the left and right streams.\n",
    "        self.blocks_left= nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=seq_len,\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_heads=max(1, 2 ** (num_layers - i)),  # Inversely scale heads\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.blocks_right = nn.ModuleList([\n",
    "            TapeHeadBlock(\n",
    "                chunk_size=seq_len,\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_heads=max(1, 2 ** (num_layers - i)),  # Inversely scale heads\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, prev_h, prev_emb, past_kv=None):\n",
    "        \"\"\"\n",
    "        past_kv: dictionary with keys 'left' and 'right', each is a list of caches (one per block).\n",
    "        \"\"\"\n",
    "        attn_weights = []\n",
    "        entropy = []\n",
    "    \n",
    "        if not self.training:\n",
    "            if past_kv is None:\n",
    "                past_kv = {'left': [None] * self.num_layers, 'right': [None] * self.num_layers}\n",
    "            prev_emb_left = prev_emb.clone() if prev_emb is not None else None\n",
    "            prev_h_left = prev_h.clone() if prev_h is not None else None\n",
    "    \n",
    "            new_past_left = []\n",
    "            new_past_right = []\n",
    "    \n",
    "            for i in range(self.num_layers):\n",
    "                # Process left block with its cache.\n",
    "                    _, h_out_left, prev_emb_left, cache_left = self.blocks_left[i](\n",
    "                        x, prev_h_left, prev_emb_left, past_kv=past_kv['left'][i]\n",
    "                    )\n",
    "                                    # Process right block with its cache.\n",
    "                    _, h_out,  prev_emb, cache_right = self.blocks_right[i](\n",
    "                        x, prev_h, prev_emb, past_kv=past_kv['right'][i])\n",
    "                    a = self.activation(h_out_left)\n",
    "                    b = self.activation(h_out)\n",
    "                    h_out = 0.5 * (a + b - 2 * a * b)\n",
    "                    prev_h_left = h_out\n",
    "                    prev_h = h_out\n",
    "                    new_past_left.append(cache_left)  # Store all layers' caches\n",
    "                    new_past_right.append(cache_right)  # Store all layers' caches\n",
    "\n",
    "            prev_emb = 0.5 * (prev_emb + prev_emb_left)\n",
    "            new_cache = {'left': new_past_left, 'right': new_past_right}\n",
    "            return x, h_out, prev_emb, new_cache  # âœ… Properly returning all layer caches\n",
    "    \n",
    "        else:  # Training mode\n",
    "            prev_emb_left = prev_emb.clone() if prev_emb is not None else None\n",
    "            prev_h_left = prev_h.clone() if prev_h is not None else None\n",
    "    \n",
    "            for i in range(self.num_layers):\n",
    "                # Process left block\n",
    "                    _, h_out_left, prev_emb_left, entropy_left, attn_weights_left = self.blocks_left[i](\n",
    "                        x, prev_h_left, prev_emb_left\n",
    "                    )\n",
    "        \n",
    "                    # Process right block\n",
    "                    _, h_out, prev_emb, entropy_right, attn_weights_right = self.blocks_right[i](\n",
    "                        x, prev_h, prev_emb\n",
    "                    )\n",
    "                    a = self.activation(h_out_left)\n",
    "                    b = self.activation(h_out)\n",
    "                    h_out = 0.5 * (a + b - 2 * a * b)\n",
    "                    prev_h_left = h_out\n",
    "                    prev_h = h_out\n",
    "                    attn_weights.append((attn_weights_left + attn_weights_right) / 2.0)\n",
    "                    entropy.append((entropy_left + entropy_right) / 2.0)\n",
    "    \n",
    "\n",
    "            prev_emb = 0.5 * (prev_emb + prev_emb_left)\n",
    "            attn_weights = torch.stack(attn_weights, dim=0)\n",
    "            attn_weights *= self.layer_weights.view(-1, 1, 1)\n",
    "            attn_weights = attn_weights.sum(dim=0)\n",
    "    \n",
    "            entropy = torch.sum(torch.stack(entropy)) / self.num_layers\n",
    "            return x, h_out, prev_emb, entropy, attn_weights  # âœ… Returns all caches correctly\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / (x.norm(2, dim=-1, keepdim=True) + self.eps) * self.weight\n",
    "        \n",
    "class TapeTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Full GPT-like model with:\n",
    "      - Token + Position Embeddings\n",
    "      - Multiple stacked TapeHeads\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, seq_len=128, num_layers=4, embed_dim=128, num_heads=2, placeholder_idx=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.placeholder_idx = placeholder_idx\n",
    "        self.num_heads = num_heads\n",
    "        # LayerNorm immediately after embeddings.\n",
    "        self.embed_ln = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Create a list of TapeHeads.\n",
    "        self.tape_heads = nn.ModuleList([\n",
    "            TapeHead(\n",
    "                seq_len=seq_len,\n",
    "                embed_dim=embed_dim,\n",
    "                vocab_size=vocab_size,\n",
    "                num_layers=num_layers,\n",
    "                placeholder_idx=placeholder_idx,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "        self.final_norm = RMSNorm(embed_dim)\n",
    "        self.norm_gate = nn.Parameter(torch.tensor(0.5))  # for potential supervisory context\n",
    "        self.activation = ReferenceActivation()\n",
    "        # Final unembedding.\n",
    "        self.unembedding = nn.Parameter(torch.randn(embed_dim, vocab_size))\n",
    "        nn.init.kaiming_uniform_(self.unembedding, a=math.sqrt(5))\n",
    "        self.merge_projection = nn.Linear(len(self.tape_heads) * embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x, past_kv=None):\n",
    "        \"\"\"\n",
    "        x: (B, S) integer token IDs.\n",
    "        past_kv: list of caches (one per tape head) or None.\n",
    "        Returns:\n",
    "          p_final: (B, S, V) probability distribution,\n",
    "          new_past_kv: updated caches.\n",
    "        \"\"\"\n",
    "        # Ensure batch dimension.\n",
    "        x = x.unsqueeze(0) if x.ndim == 1 else x\n",
    "        B, S = x.shape\n",
    "        assert S <= self.seq_len, \"Sequence too long.\"\n",
    "\n",
    "        prev_h = None\n",
    "        prev_emb = None\n",
    "        new_past_heads = None\n",
    "        attn_weights = None\n",
    "        all_heads_h = []\n",
    "        entropy = []\n",
    "        if not self.training:\n",
    "            new_past_heads = []\n",
    "            if past_kv is None:\n",
    "                past_kv = [{} for _ in range(len(self.tape_heads))]  # Ensure dict format for all layers\n",
    "    \n",
    "            # Process each TapeHead.\n",
    "            for i, head in enumerate(self.tape_heads):\n",
    "                x, h, prev_emb, head_cache = head(x, prev_h, prev_emb, past_kv=past_kv[i])\n",
    "                new_past_heads.append(head_cache)\n",
    "                all_heads_h.append(h)\n",
    "\n",
    "\n",
    "        else:   \n",
    "            # Process each TapeHead.\n",
    "            for i, head in enumerate(self.tape_heads):\n",
    "                x, h, prev_emb, entropy_head, attn_weights_head = head(x, prev_h, prev_emb)\n",
    "                all_heads_h.append(h)\n",
    "                attn_weights = attn_weights_head if attn_weights is None else attn_weights + attn_weights_head\n",
    "                entropy.append(entropy_head)\n",
    "\n",
    "        # Merge outputs from all tape heads.\n",
    "        merged_h = torch.cat(all_heads_h, dim=-1)\n",
    "        prev_h = self.merge_projection(merged_h)  # (B, S, D)\n",
    "        if not self.training:\n",
    "            \n",
    "            p_final = prev_h @ self.unembedding # (B, S, V) #no softmaxing allowed\n",
    "            return p_final, new_past_heads\n",
    "        else:\n",
    "            attn_weights /= self.num_heads\n",
    "\n",
    "            p_final = student_t_unembedding(prev_h, self.unembedding, df=2.718281828459, eps=1e-9,placeholder_idx=placeholder_idx)\n",
    "            return p_final, torch.sum(torch.stack(entropy))/self.num_heads, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc,torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VhlsGaG7ONr",
    "outputId": "1534f894-6597-49b5-c0c3-41369844874c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder token for even vocab size: â–’ with index: 65\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Preparation (Shakespeare)\n",
    "# ====================================================\n",
    "def load_shakespeare_text():\n",
    "    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "    text = requests.get(url).text\n",
    "    return text\n",
    "\n",
    "text = load_shakespeare_text()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# Add a placeholder token: an ASCII grey block (visible in output)\n",
    "placeholder = \"â–’\"  # Choose your preferred grey block character\n",
    "if placeholder not in chars:\n",
    "    chars.append(placeholder)\n",
    "    chars.sort()  # Ensure ordering is maintained\n",
    "\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "placeholder_idx = stoi[placeholder]\n",
    "print(\"Placeholder token for even vocab size:\", placeholder, \"with index:\", placeholder_idx)\n",
    "\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "def get_batch(batch_size, seq_len):\n",
    "    ix = torch.randint(0, data.size(0) - seq_len - 1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+seq_len] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+seq_len+1] for i in ix])\n",
    "    return x, y\n",
    "    \n",
    "\n",
    "# ====================================================\n",
    "# Training Setup\n",
    "# ====================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TapeTransformer(\n",
    "    vocab_size=vocab_size,  # example\n",
    "    seq_len=128,#longer not truly needed beause we KV cache\n",
    "    num_layers=4,\n",
    "    embed_dim=256,#heads times true vocab, round up \n",
    "    num_heads=4,\n",
    "    placeholder_idx=placeholder_idx,\n",
    "    dropout=0 #cannot use dropout, tooo slow\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=6e-4)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "eps = 1e-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43509249"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# Training control variables\n",
    "seq_len = 128  # Start with the smallest sequence\n",
    "max_seq_len = 128\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# Loss tracking\n",
    "epochs_per_check = 10  # Print every 10 epochs\n",
    "target_loss = max(math.log(vocab_size/(seq_len+1)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80963d46124346259ef269f370e58e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjusted Code to Improve EWMA Size and Implement Loss Ticker as a Moving Graph\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# --- Configuration Constants ---\n",
    "CHAR_WIDTH = 8  # Font size 8 for token rendering\n",
    "CHAR_HEIGHT = 11\n",
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "LOSS_BAR_HEIGHT = 32\n",
    "EWMA_HEIGHT = 32  # Increased to accommodate large text (previously 32)\n",
    "\n",
    "# Full-resolution framebuffer dimensions\n",
    "container_width = CHAR_WIDTH * SEQ_LEN  # 1024 pixels\n",
    "container_height = CHAR_HEIGHT * BATCH_SIZE  # 176 pixels\n",
    "total_height = container_height + LOSS_BAR_HEIGHT + EWMA_HEIGHT  # Adjusted for larger EWMA\n",
    "\n",
    "# Final scaled-down dimensions\n",
    "scaled_width = container_width   # 512 pixels\n",
    "scaled_height = total_height  # 170 pixels\n",
    "\n",
    "# Initialize framebuffer\n",
    "framebuffer = np.zeros((total_height, container_width, 3), dtype=np.uint8)\n",
    "\n",
    "# EWMA storage\n",
    "loss_history = []\n",
    "ticker_history = np.zeros(SEQ_LEN, dtype=np.float32)  # Stock ticker moving buffer\n",
    "loss_memory = 0.0\n",
    "# Load font\n",
    "try:\n",
    "    font = ImageFont.truetype(\"DejaVuSansMono.ttf\", 8)  # Monospaced font\n",
    "    font_large = ImageFont.truetype(\"DejaVuSansMono.ttf\", 64)  # Large EWMA display\n",
    "except:\n",
    "    font = ImageFont.load_default()\n",
    "    font_large = font\n",
    "\n",
    "# --- Color Mapping Functions ---\n",
    "def get_flame_color(val):\n",
    "    \"\"\"Map a normalized value to a flame-like color.\"\"\"\n",
    "    return np.array([int(val * 255), int(val * 0.5 * 255), 0], dtype=np.uint8)\n",
    "\n",
    "# --- IPython Display Setup ---\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "\n",
    "def get_dynamic_color(attn_val, loss_val):\n",
    "    \"\"\"\n",
    "    Compute a dynamic color transition between flame orange (uncertain) and phosphor green (confident).\n",
    "    \n",
    "    attn_val: Normalized attention value (0 to 1)\n",
    "    loss_val: Normalized loss value (0 to 1, inverted as 1 - loss)\n",
    "    \n",
    "    Returns an RGB color as a NumPy array.\n",
    "    colors late in training will often be red. this is suggested to swap out for get_flame_color\n",
    "    but only on fine tuning on new data.\n",
    "    \"\"\"\n",
    "    certainty = 1 - loss_val  # High certainty = low loss\n",
    "    \n",
    "    # Define RGB endpoints\n",
    "    orange = np.array([attn_val * 255, attn_val * 0.5 * 255, 0], dtype=np.uint8)   # Uncertain (High Loss)\n",
    "    green = np.array([attn_val * 0.5 * 255, attn_val * 255, attn_val * 0.25 * 255], dtype=np.uint8)  # Confident (Low Loss)\n",
    "    \n",
    "    # Interpolate based on certainty (0 = uncertain/orange, 1 = confident/green)\n",
    "    color = (certainty * green) + ((1 - certainty) * orange)\n",
    "    \n",
    "    return color.astype(np.uint8)\n",
    "# --- Framebuffer Update Function ---\n",
    "def update_framebuffer(attn_weights, token_losses, current_loss, tokens,entropy):\n",
    "    attn_weights =(attn_weights-attn_weights.min())/(np.ptp(attn_weights))\n",
    "    token_losses =(token_losses-token_losses.min())/(np.ptp(token_losses))\n",
    "\n",
    "    \"\"\"Render the text grid with coloration based on attn * inverse loss.\"\"\"\n",
    "    global framebuffer, loss_history, ticker_history, loss_memory\n",
    "\n",
    "    # Normalize to [0,1]\n",
    "\n",
    "    # Create image buffer\n",
    "    img = Image.new(\"RGB\", (container_width, total_height), (0, 0, 0))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Render text with colored intensity\n",
    "    char_positions = [\n",
    "        (col * CHAR_WIDTH, row * CHAR_HEIGHT + EWMA_HEIGHT + LOSS_BAR_HEIGHT, tokens[row][col])\n",
    "        for row in range(BATCH_SIZE) for col in range(SEQ_LEN)\n",
    "    ]\n",
    "    colors = [\n",
    "        tuple(get_dynamic_color(attn_weights[row, col], attn_weights[row, col]))\n",
    "        for row in range(BATCH_SIZE) for col in range(SEQ_LEN)\n",
    "    ]\n",
    "    for (x, y, char), color in zip(char_positions, colors):\n",
    "        draw.text((x, y), char, font=font, fill=color)\n",
    "\n",
    "                 \n",
    "    etcerta = 0.367879441  # Constant used in update rule\n",
    "    et = 1 - etcerta   \n",
    "    update = loss_memory * et + np.minimum(12, np.maximum(current_loss , 0)) * etcerta\n",
    "    loss_memory = loss_memory * et + update * etcerta\n",
    "    # --- EWMA Display (LARGE FONT) ---\n",
    "    loss_history.append(current_loss)\n",
    "    if len(loss_history) > 128:\n",
    "        loss_history.pop(0)\n",
    "    ewma = loss_memory\n",
    "    ewma_text = f\"{ewma:.4f}\"\n",
    "    draw.text((container_width-128, 0), ewma_text, font_size=32, fill=(65,255, 125))\n",
    "    ent_text = f\"{entropy:.4f}\"\n",
    "    draw.text((10, 0), ent_text, font_size=32, fill=(255,125, 0))  \n",
    "\n",
    "    # --- Moving Loss Ticker Graph ---\n",
    "    ticker_history = np.roll(ticker_history, -1)  # Shift left\n",
    "    ticker_history[-1] = current_loss  # Insert new loss on the right\n",
    "\n",
    "    # Rescale ticker dynamically like a stock ticker (normalize to min-max range)\n",
    "    min_loss = np.min(ticker_history)\n",
    "    max_loss = np.max(ticker_history)\n",
    "    range_loss = max_loss - min_loss if max_loss != min_loss else 1\n",
    "    normalized_ticker = (ticker_history - min_loss) / range_loss\n",
    "\n",
    "    # Draw ticker graph line\n",
    "    # Optimized drawing loop (fewer function calls)\n",
    "    y_vals = EWMA_HEIGHT + (1 - normalized_ticker) * LOSS_BAR_HEIGHT\n",
    "    x_vals = np.arange(SEQ_LEN) * CHAR_WIDTH\n",
    "    for i in range(SEQ_LEN - 1):\n",
    "        draw.line([(x_vals[i], y_vals[i]), (x_vals[i + 1], y_vals[i + 1])], fill=(0, 255, 255), width=2)\n",
    "\n",
    "    framebuffer = np.array(img)\n",
    "\n",
    "# --- IPython Display Update Function ---\n",
    "def update_display():\n",
    "    \"\"\"Show the framebuffer, scaled down by half using ipywidgets.\"\"\"\n",
    "    img = Image.fromarray(framebuffer)\n",
    "    img_resized = img.resize((scaled_width, scaled_height), Image.LANCZOS)\n",
    "    \n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        display(img_resized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0, Loss: 5.993341\n",
      "tensor(6.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1, Loss: 6.044934\n",
      "tensor(5.7979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2, Loss: 5.797946\n",
      "tensor(4.3809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3, Loss: 4.380937\n",
      "tensor(3.6503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 4, Loss: 3.650343\n",
      "tensor(3.3440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5, Loss: 3.343986\n",
      "tensor(2.9733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6, Loss: 2.973283\n",
      "tensor(2.6166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 7, Loss: 2.616571\n",
      "tensor(2.5514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8, Loss: 2.551441\n",
      "tensor(2.4030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9, Loss: 2.402998\n",
      "tensor(2.2658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10, Loss: 2.265831\n",
      "tensor(2.2631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11, Loss: 2.263061\n",
      "tensor(2.1811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12, Loss: 2.181148\n",
      "tensor(2.1573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 13, Loss: 2.157312\n",
      "tensor(2.0766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14, Loss: 2.076551\n",
      "tensor(2.0980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15, Loss: 2.097971\n",
      "tensor(2.1116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16, Loss: 2.111586\n",
      "tensor(2.0832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17, Loss: 2.083249\n",
      "tensor(2.0568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18, Loss: 2.056830\n",
      "tensor(2.0330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19, Loss: 2.032957\n",
      "tensor(2.0773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20, Loss: 2.077340\n",
      "tensor(2.1105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21, Loss: 2.110482\n",
      "tensor(2.1087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 22, Loss: 2.108731\n",
      "tensor(2.0865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 23, Loss: 2.086503\n",
      "tensor(2.0548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 24, Loss: 2.054806\n",
      "tensor(2.0892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 25, Loss: 2.089176\n",
      "tensor(2.0259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 26, Loss: 2.025861\n",
      "tensor(2.0776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 27, Loss: 2.077587\n",
      "tensor(2.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 28, Loss: 2.045521\n",
      "tensor(2.0485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 29, Loss: 2.048463\n",
      "tensor(2.0718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 30, Loss: 2.071807\n",
      "tensor(2.0529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 31, Loss: 2.052890\n",
      "tensor(2.0144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 32, Loss: 2.014432\n",
      "tensor(2.0398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 33, Loss: 2.039757\n",
      "tensor(2.0676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 34, Loss: 2.067582\n",
      "tensor(2.0742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 35, Loss: 2.074172\n",
      "tensor(2.1296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 36, Loss: 2.129604\n",
      "tensor(2.0671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 37, Loss: 2.067116\n",
      "tensor(2.0476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 38, Loss: 2.047564\n",
      "tensor(2.0369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 39, Loss: 2.036879\n",
      "tensor(2.0953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 40, Loss: 2.095317\n",
      "tensor(2.0804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 41, Loss: 2.080417\n",
      "tensor(2.0640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 42, Loss: 2.063995\n",
      "tensor(2.0376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 43, Loss: 2.037622\n",
      "tensor(2.0307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 44, Loss: 2.030708\n",
      "tensor(2.0218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 45, Loss: 2.021819\n",
      "tensor(2.0473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 46, Loss: 2.047255\n",
      "tensor(2.0748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 47, Loss: 2.074824\n",
      "tensor(2.0604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 48, Loss: 2.060416\n",
      "tensor(2.0618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 49, Loss: 2.061796\n",
      "tensor(2.0307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 50, Loss: 2.030676\n",
      "tensor(2.0497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 51, Loss: 2.049721\n",
      "tensor(2.0588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 52, Loss: 2.058751\n",
      "tensor(2.0809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 53, Loss: 2.080945\n",
      "tensor(2.1023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 54, Loss: 2.102312\n",
      "tensor(2.0527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 55, Loss: 2.052725\n",
      "tensor(2.0371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 56, Loss: 2.037111\n",
      "tensor(2.0202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 57, Loss: 2.020156\n",
      "tensor(2.0735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 58, Loss: 2.073544\n",
      "tensor(2.0335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 59, Loss: 2.033536\n",
      "tensor(2.0192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 60, Loss: 2.019226\n",
      "tensor(2.0404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 61, Loss: 2.040395\n",
      "tensor(2.0750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 62, Loss: 2.074959\n",
      "tensor(2.0724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 63, Loss: 2.072372\n",
      "tensor(2.0413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 64, Loss: 2.041288\n",
      "tensor(2.0387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 65, Loss: 2.038729\n",
      "tensor(2.0724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 66, Loss: 2.072368\n",
      "tensor(2.0394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 67, Loss: 2.039352\n",
      "tensor(2.0471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 68, Loss: 2.047141\n",
      "tensor(2.0582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 69, Loss: 2.058234\n",
      "tensor(2.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 70, Loss: 2.000727\n",
      "tensor(2.0655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 71, Loss: 2.065516\n",
      "tensor(2.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 72, Loss: 2.045008\n",
      "tensor(2.1226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 73, Loss: 2.122610\n",
      "tensor(2.0716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 74, Loss: 2.071605\n",
      "tensor(2.0701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 75, Loss: 2.070116\n",
      "tensor(2.0051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 76, Loss: 2.005149\n",
      "tensor(2.0653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 77, Loss: 2.065316\n",
      "tensor(2.0342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 78, Loss: 2.034196\n",
      "tensor(2.0759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 79, Loss: 2.075870\n",
      "tensor(2.0973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 80, Loss: 2.097311\n",
      "tensor(2.0661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 81, Loss: 2.066069\n",
      "tensor(2.0115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 82, Loss: 2.011484\n",
      "tensor(2.0791, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 83, Loss: 2.079093\n",
      "tensor(2.0186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 84, Loss: 2.018582\n",
      "tensor(2.0550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 85, Loss: 2.054961\n",
      "tensor(2.0351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 86, Loss: 2.035132\n",
      "tensor(2.0509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 87, Loss: 2.050888\n",
      "tensor(2.0494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 88, Loss: 2.049378\n",
      "tensor(2.0079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 89, Loss: 2.007944\n",
      "tensor(2.0589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 90, Loss: 2.058884\n",
      "tensor(2.0419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 91, Loss: 2.041917\n",
      "tensor(2.0394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 92, Loss: 2.039394\n",
      "tensor(2.0255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 93, Loss: 2.025452\n",
      "tensor(2.0542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 94, Loss: 2.054229\n",
      "tensor(2.0508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 95, Loss: 2.050782\n",
      "tensor(2.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 96, Loss: 2.044888\n",
      "tensor(2.0175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 97, Loss: 2.017492\n",
      "tensor(2.0491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 98, Loss: 2.049064\n",
      "tensor(2.0591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 99, Loss: 2.059108\n",
      "tensor(2.0688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 100, Loss: 2.068778\n",
      "tensor(2.1386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 101, Loss: 2.138583\n",
      "tensor(2.0244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 102, Loss: 2.024407\n",
      "tensor(2.0712, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Training loop for current sequence length\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    x_batch, targets = get_batch(batch_size, 128)\n",
    "    x_batch_gpu, targets = x_batch.to(device), targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.amp.autocast(device.type):\n",
    "        preds, entropy, attn_weights = model(x_batch_gpu)\n",
    "        # Decode token indices back to characters\n",
    "        # Convert logits to log probabilities\n",
    "        # Gather log probabilities of the correct tokens\n",
    "        gathered_log_probs = torch.gather(preds, -1, targets.unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        # Compute per-token loss (neg log probs) and final loss\n",
    "        weighted_loss = -gathered_log_probs  # Shape: (batch_size, seq_len)\n",
    "        #pulled out of my ass:\n",
    "        #multiply [qkv] * seq * batch\n",
    "        #6144\n",
    "        #if entropy is greater than this reward else punish\n",
    "        test = 6144/entropy\n",
    "        final_loss = weighted_loss.mean()* test\n",
    "        print(final_loss)\n",
    "\n",
    "        #multiply [qkv] * seq * batch and divide entropy by this\n",
    "    \n",
    "    scaler.scale(final_loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    loss_item = final_loss.item()\n",
    "    attn_cpu =  attn_weights.cpu().detach().numpy()\n",
    "    \n",
    "    loss_cpu = gathered_log_probs.cpu().detach().numpy()\n",
    "    tokens = [[itos[idx] for idx in seq.tolist()] for seq in x_batch]\n",
    "\n",
    "    update_framebuffer(attn_cpu, loss_cpu, loss_item, tokens,entropy.item())\n",
    "    update_display()\n",
    "\n",
    "\n",
    "    # Track loss & progress\n",
    "    loss_val = loss_item\n",
    "    loss_history.append(loss_val)\n",
    "\n",
    "    # Update framebuffer visualization with real model outputs\n",
    "    print(f\"Epoch {epoch}, Loss: {loss_val:.6f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sample:\n",
      " Treasured FriendsTSh' ETNLsZJF,qp.'QNy!DF.\n",
      "$Vf?ZCH\n",
      "HZ-qV'.'Tm-.$'H: H;oJ'3aD'\n",
      "!Y\n",
      "&Zat-zwdH,KV\n",
      "?qBVZ\n",
      "V,FGXjk3PT\n",
      "'.\n",
      ",kL\n",
      "TWFM-\n",
      "FjOQ\n",
      "\n",
      "\n",
      "'3NZHbZ.JrS'lsJcH'nG\n",
      "\n",
      "LBh pQ?HQ$L3HO:'-H'&\n",
      "Z&\n",
      "Cux\n",
      ";N&QCP?\n",
      "H!DU!J3R\n",
      "qbe\n",
      "Zf \n",
      "LSXPZHGZeCb'\n",
      "kWR-N&MZ3yDW:yKO:$ms:CTT:FaQV\n",
      "g3\n",
      "Q&:\n",
      "HFc:D-\n",
      "ZSHXzjDI'v\n",
      "V\n",
      "XaY\n",
      "e'LkoKTBj!p:\n",
      "' uhLLE\n",
      "\n",
      "\n",
      "U:Jd3\n",
      "B3H\n",
      "ITdfTWY,\n",
      "HC:-MJ-T\n",
      "b,zaQ3;.en\n",
      "gOs\n",
      "-:3' NH\n",
      "z-PF\n",
      "cTHZD-\n",
      "V\n",
      "k\n",
      "Z;&D\n",
      "\n",
      " vP3ZBT'JHDG X b&e\n",
      "j'\n",
      "T-G&,uXm?EkDp'APTa Q\n",
      "XS  I\n",
      " t& S\n",
      "Y$.\n",
      "VKS\n",
      "'Qn'Sqd\n",
      ".\n",
      "OtF\n",
      "'L3HxF&Zg\n",
      "'A3?aVFZ j\n",
      "b;tSpCKO\n",
      "zb-O'V;ZQX&DE\n",
      "HQ&.IWb$w\n",
      "BGQj:$:Fg.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logit_list = []  # Store raw logits\n",
    "prob_list = []  # Store softmax probabilities\n",
    "\n",
    "model.eval()\n",
    "past_kv = None  # Initialize cache for the entire model.\n",
    "with torch.no_grad():\n",
    "    prompt = \"Treasured Friends\"\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    generated = context\n",
    "    for _ in range(500):  # Generate 200 tokens.\n",
    "        inp = generated[:, -1:]  # Only use the last token.\n",
    "        p, past_kv = model(inp, past_kv=past_kv)  # Forward pass with cache.\n",
    "        last_token_logits = p[:, -1, :].cpu().numpy().flatten()  # Get raw logits\n",
    "        logit_list.append(last_token_logits)\n",
    "\n",
    "        temperature = 1.0 # Lower = more deterministic, Higher = more diverse (0.7â€“1.0 is good)\n",
    "        #last_token_probs = torch.softmax(p[:, -1, :] / temperature, dim=-1).cpu().numpy().flatten()\n",
    "        prob_list.append(last_token_probs)\n",
    "\n",
    "        predicted_token = torch.multinomial(torch.tensor(last_token_probs), num_samples=1).unsqueeze(0)  # Fix shape\n",
    "        generated = torch.cat((generated, predicted_token.to(device)), dim=1)  # Concatenate properly\n",
    "\n",
    "    sample = decode(generated[0].cpu().tolist())\n",
    "    print(\"Generated Sample:\\n\", sample)\n",
    "\n",
    "# Plot histograms of logits and probabilities\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot logits histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(logit_list[-1], bins=100, alpha=0.75)\n",
    "plt.title(\"Logits Distribution (Before Softmax)\")\n",
    "plt.xlabel(\"Logit Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Plot probabilities histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(prob_list[-1], bins=100, alpha=0.75)\n",
    "plt.title(\"Probabilities Distribution (After Softmax)\")\n",
    "plt.xlabel(\"Probability Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - past_kv structure:  None\n",
      "Step 0 - Last token probs (min/max): 0.0018690183060243726 / 0.5224267244338989\n",
      "Step 50 - past_kv structure:  [{'left': [{'chunk_attn': (tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [-0.0101, -0.2608,  0.1275,  ...,  1.9049,  3.2283,  0.7467],\n",
      "         [ 0.5949, -0.1051,  0.0852,  ...,  0.2453, -0.2001,  0.2675],\n",
      "         [-1.2296,  2.0114, -0.3708,  ...,  0.1232,  1.1692,  1.5375]]],\n",
      "       device='cuda:0'), tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [-0.0101, -0.2608,  0.1275,  ...,  1.9049,  3.2283,  0.7467],\n",
      "         [ 0.5949, -0.1051,  0.0852,  ...,  0.2453, -0.2001,  0.2675],\n",
      "         [-1.2296,  2.0114, -0.3708,  ...,  0.1232,  1.1692,  1.5375]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'), tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 1.3656,  1.8072, -1.1026,  ...,  0.8610,  1.0916,  3.4117],\n",
      "         [ 0.4630, -0.0543,  1.2808,  ..., -0.2044,  0.0512,  0.8269],\n",
      "         [-0.6590,  0.6391,  0.4005,  ...,  2.4646,  1.0482,  0.6037]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 1.3656,  1.8072, -1.1026,  ...,  0.8610,  1.0916,  3.4117],\n",
      "         [ 0.4630, -0.0543,  1.2808,  ..., -0.2044,  0.0512,  0.8269],\n",
      "         [-0.6590,  0.6391,  0.4005,  ...,  2.4646,  1.0482,  0.6037]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9688, -0.5086, -7.3653,  ...,  5.7297,  1.2491, -0.2399],\n",
      "         [-5.0050, -0.5624, -7.3947,  ...,  5.7339,  1.2635, -0.2762],\n",
      "         [-4.9873, -0.3432, -7.1921,  ...,  5.5636,  1.3134, -0.3475]]],\n",
      "       device='cuda:0'), tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9688, -0.5086, -7.3653,  ...,  5.7297,  1.2491, -0.2399],\n",
      "         [-5.0050, -0.5624, -7.3947,  ...,  5.7339,  1.2635, -0.2762],\n",
      "         [-4.9873, -0.3432, -7.1921,  ...,  5.5636,  1.3134, -0.3475]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [-0.3721,  0.6687,  0.5526,  ...,  0.8726, -0.1626,  0.6806],\n",
      "         [ 1.8612,  1.6711,  0.0171,  ...,  0.8448, -0.7649,  1.9934],\n",
      "         [ 1.5921,  1.6072, -0.4221,  ...,  0.1017,  0.4805,  0.3011]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [-0.3721,  0.6687,  0.5526,  ...,  0.8726, -0.1626,  0.6806],\n",
      "         [ 1.8612,  1.6711,  0.0171,  ...,  0.8448, -0.7649,  1.9934],\n",
      "         [ 1.5921,  1.6072, -0.4221,  ...,  0.1017,  0.4805,  0.3011]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0465,  1.9563,  1.9757,  ...,  1.4769,  1.3012, -2.7935],\n",
      "         [ 3.0465,  1.9545,  1.9755,  ...,  1.4776,  1.3009, -2.7927],\n",
      "         [ 3.0463,  1.9539,  1.9753,  ...,  1.4786,  1.3011, -2.7921]]],\n",
      "       device='cuda:0'), tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0465,  1.9563,  1.9757,  ...,  1.4769,  1.3012, -2.7935],\n",
      "         [ 3.0465,  1.9545,  1.9755,  ...,  1.4776,  1.3009, -2.7927],\n",
      "         [ 3.0463,  1.9539,  1.9753,  ...,  1.4786,  1.3011, -2.7921]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [-0.0391,  0.1505, -0.9240,  ...,  1.7944, -0.0833,  1.8751],\n",
      "         [ 0.2337,  0.4533, -0.4005,  ...,  1.3993,  2.7561,  1.2529],\n",
      "         [-1.5416, -0.0930,  1.2752,  ..., -0.8058, -0.1037, -0.7920]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [-0.0391,  0.1505, -0.9240,  ...,  1.7944, -0.0833,  1.8751],\n",
      "         [ 0.2337,  0.4533, -0.4005,  ...,  1.3993,  2.7561,  1.2529],\n",
      "         [-1.5416, -0.0930,  1.2752,  ..., -0.8058, -0.1037, -0.7920]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0024,  0.0242,  0.0027,  ..., -0.0834, -0.0681,  0.0019],\n",
      "         [-0.0009,  0.0229,  0.0052,  ..., -0.0838, -0.0677,  0.0008],\n",
      "         [-0.0035,  0.0235,  0.0050,  ..., -0.0844, -0.0706, -0.0011]]],\n",
      "       device='cuda:0'), tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0024,  0.0242,  0.0027,  ..., -0.0834, -0.0681,  0.0019],\n",
      "         [-0.0009,  0.0229,  0.0052,  ..., -0.0838, -0.0677,  0.0008],\n",
      "         [-0.0035,  0.0235,  0.0050,  ..., -0.0844, -0.0706, -0.0011]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [ 2.1448,  0.2685,  0.2892,  ...,  2.4843,  0.7250,  0.6488],\n",
      "         [-0.5039, -0.4359,  0.8738,  ..., -0.0897, -0.5100,  3.4678],\n",
      "         [-1.0709,  1.0066,  0.8307,  ...,  0.0755, -1.7033,  0.7135]]],\n",
      "       device='cuda:0'), tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [ 2.1448,  0.2685,  0.2892,  ...,  2.4843,  0.7250,  0.6488],\n",
      "         [-0.5039, -0.4359,  0.8738,  ..., -0.0897, -0.5100,  3.4678],\n",
      "         [-1.0709,  1.0066,  0.8307,  ...,  0.0755, -1.7033,  0.7135]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'), tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [ 0.4006,  0.5932, -0.8193,  ...,  2.0166,  0.5949,  0.4459],\n",
      "         [ 0.4886,  1.8659, -0.4831,  ...,  0.9824,  0.1302,  0.9454],\n",
      "         [-1.0032, -0.9243,  1.2194,  ..., -0.0111,  0.4301, -0.0581]]],\n",
      "       device='cuda:0'), tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [ 0.4006,  0.5932, -0.8193,  ...,  2.0166,  0.5949,  0.4459],\n",
      "         [ 0.4886,  1.8659, -0.4831,  ...,  0.9824,  0.1302,  0.9454],\n",
      "         [-1.0032, -0.9243,  1.2194,  ..., -0.0111,  0.4301, -0.0581]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.8764, -0.3518, -0.0535,  ...,  1.3258, -0.5187,  0.3016],\n",
      "         [-0.7546, -0.3803, -0.3614,  ...,  1.3875, -0.4163, -0.0860],\n",
      "         [-0.8616, -0.4580, -0.3041,  ...,  1.3889, -0.4810, -0.0705]]],\n",
      "       device='cuda:0'), tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.8764, -0.3518, -0.0535,  ...,  1.3258, -0.5187,  0.3016],\n",
      "         [-0.7546, -0.3803, -0.3614,  ...,  1.3875, -0.4163, -0.0860],\n",
      "         [-0.8616, -0.4580, -0.3041,  ...,  1.3889, -0.4810, -0.0705]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [-0.1869,  1.2329, -0.9932,  ...,  0.3750, -1.1092, -1.3702],\n",
      "         [ 1.2182,  1.5679,  0.5855,  ..., -0.3893,  1.8231,  0.7667],\n",
      "         [-0.7912,  1.6969, -0.9087,  ...,  1.2160,  0.5015,  0.3305]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [-0.1869,  1.2329, -0.9932,  ...,  0.3750, -1.1092, -1.3702],\n",
      "         [ 1.2182,  1.5679,  0.5855,  ..., -0.3893,  1.8231,  0.7667],\n",
      "         [-0.7912,  1.6969, -0.9087,  ...,  1.2160,  0.5015,  0.3305]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3338,  0.3952,  0.0401,  ..., -0.4934,  0.5569, -0.2148],\n",
      "         [ 0.3343,  0.4050,  0.0449,  ..., -0.4886,  0.5658, -0.2431],\n",
      "         [ 0.3594,  0.3937,  0.0341,  ..., -0.4791,  0.5596, -0.2175]]],\n",
      "       device='cuda:0'), tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3338,  0.3952,  0.0401,  ..., -0.4934,  0.5569, -0.2148],\n",
      "         [ 0.3343,  0.4050,  0.0449,  ..., -0.4886,  0.5658, -0.2431],\n",
      "         [ 0.3594,  0.3937,  0.0341,  ..., -0.4791,  0.5596, -0.2175]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.8196,  0.6360,  1.1728,  ...,  0.5330,  1.9348,  0.1927],\n",
      "         [-0.7144,  2.7254, -0.9618,  ...,  1.4960, -1.1580, -0.9438],\n",
      "         [-1.0229, -1.3366, -0.4223,  ..., -0.4865, -0.4023,  2.9308]]],\n",
      "       device='cuda:0'), tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.8196,  0.6360,  1.1728,  ...,  0.5330,  1.9348,  0.1927],\n",
      "         [-0.7144,  2.7254, -0.9618,  ...,  1.4960, -1.1580, -0.9438],\n",
      "         [-1.0229, -1.3366, -0.4223,  ..., -0.4865, -0.4023,  2.9308]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0798,  0.1077, -0.0308,  ..., -0.1222, -0.0249, -0.0334],\n",
      "         [ 0.0747,  0.0896, -0.0209,  ..., -0.1116, -0.0260, -0.0203],\n",
      "         [ 0.0663,  0.0979, -0.0318,  ..., -0.1112, -0.0435, -0.0294]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0798,  0.1077, -0.0308,  ..., -0.1222, -0.0249, -0.0334],\n",
      "         [ 0.0747,  0.0896, -0.0209,  ..., -0.1116, -0.0260, -0.0203],\n",
      "         [ 0.0663,  0.0979, -0.0318,  ..., -0.1112, -0.0435, -0.0294]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [-1.4235,  1.8870,  1.7096,  ...,  0.8721, -1.7889,  2.4826],\n",
      "         [ 0.4899,  0.2706, -1.6899,  ...,  1.4825, -0.0502,  0.5906],\n",
      "         [-1.6733,  0.5331,  0.5534,  ..., -0.1741,  0.7853,  1.7076]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [-1.4235,  1.8870,  1.7096,  ...,  0.8721, -1.7889,  2.4826],\n",
      "         [ 0.4899,  0.2706, -1.6899,  ...,  1.4825, -0.0502,  0.5906],\n",
      "         [-1.6733,  0.5331,  0.5534,  ..., -0.1741,  0.7853,  1.7076]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [ 1.7179, -0.3125, -0.8028,  ...,  0.9889, -0.4722, -0.0054],\n",
      "         [ 0.8634,  1.0831, -0.5074,  ...,  0.3784,  1.0774,  0.2590],\n",
      "         [ 0.0352,  1.0116,  0.1686,  ..., -0.4196,  1.1554, -0.9669]]],\n",
      "       device='cuda:0'), tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [ 1.7179, -0.3125, -0.8028,  ...,  0.9889, -0.4722, -0.0054],\n",
      "         [ 0.8634,  1.0831, -0.5074,  ...,  0.3784,  1.0774,  0.2590],\n",
      "         [ 0.0352,  1.0116,  0.1686,  ..., -0.4196,  1.1554, -0.9669]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-0.7295,  0.4765, -0.5428,  ...,  2.3097,  0.7655,  0.9451],\n",
      "         [-1.8226, -0.1346,  0.7774,  ..., -0.5677,  0.8771,  1.3056],\n",
      "         [-0.8829,  1.8714, -1.0781,  ...,  0.3338, -0.2896,  1.6640]]],\n",
      "       device='cuda:0'), tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-0.7295,  0.4765, -0.5428,  ...,  2.3097,  0.7655,  0.9451],\n",
      "         [-1.8226, -0.1346,  0.7774,  ..., -0.5677,  0.8771,  1.3056],\n",
      "         [-0.8829,  1.8714, -1.0781,  ...,  0.3338, -0.2896,  1.6640]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-2.6252, -0.5698,  0.6545,  ..., -1.4064, -1.3914,  0.3174],\n",
      "         [-2.5217, -0.3771, -0.1000,  ..., -1.7347, -2.0533,  0.6221],\n",
      "         [-3.0308, -0.6647,  0.3031,  ..., -2.0748, -1.3128,  0.3282]]],\n",
      "       device='cuda:0'), tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-2.6252, -0.5698,  0.6545,  ..., -1.4064, -1.3914,  0.3174],\n",
      "         [-2.5217, -0.3771, -0.1000,  ..., -1.7347, -2.0533,  0.6221],\n",
      "         [-3.0308, -0.6647,  0.3031,  ..., -2.0748, -1.3128,  0.3282]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 2.1608, -0.0228, -1.3906,  ...,  1.8430,  0.8703,  0.3266],\n",
      "         [ 0.1869,  1.5600,  0.2489,  ...,  2.2376, -0.9020,  1.4624],\n",
      "         [-2.0310,  1.1952, -0.2395,  ...,  0.0675, -0.9884,  1.7459]]],\n",
      "       device='cuda:0'), tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 2.1608, -0.0228, -1.3906,  ...,  1.8430,  0.8703,  0.3266],\n",
      "         [ 0.1869,  1.5600,  0.2489,  ...,  2.2376, -0.9020,  1.4624],\n",
      "         [-2.0310,  1.1952, -0.2395,  ...,  0.0675, -0.9884,  1.7459]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.5294,  5.1201, -0.0972,  ...,  0.0480, -0.6815,  2.7881],\n",
      "         [ 0.6222,  5.1519, -0.0384,  ...,  0.0366, -0.7140,  2.8454],\n",
      "         [ 0.6635,  5.1751,  0.0592,  ...,  0.0672, -0.7683,  2.8333]]],\n",
      "       device='cuda:0'), tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.5294,  5.1201, -0.0972,  ...,  0.0480, -0.6815,  2.7881],\n",
      "         [ 0.6222,  5.1519, -0.0384,  ...,  0.0366, -0.7140,  2.8454],\n",
      "         [ 0.6635,  5.1751,  0.0592,  ...,  0.0672, -0.7683,  2.8333]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [-0.7647,  1.2493,  1.0537,  ...,  0.3939,  1.4712, -1.1377],\n",
      "         [ 1.0590,  0.9818,  0.5851,  ...,  0.4016, -0.2725,  2.6275],\n",
      "         [ 0.7358,  0.6706,  0.1444,  ...,  0.8082,  0.7159,  1.0402]]],\n",
      "       device='cuda:0'), tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [-0.7647,  1.2493,  1.0537,  ...,  0.3939,  1.4712, -1.1377],\n",
      "         [ 1.0590,  0.9818,  0.5851,  ...,  0.4016, -0.2725,  2.6275],\n",
      "         [ 0.7358,  0.6706,  0.1444,  ...,  0.8082,  0.7159,  1.0402]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0748, -0.0391,  0.0587,  ..., -0.0283, -0.0810, -0.0916],\n",
      "         [ 0.0752, -0.0394,  0.0587,  ..., -0.0290, -0.0815, -0.0933],\n",
      "         [ 0.0751, -0.0388,  0.0577,  ..., -0.0265, -0.0799, -0.0924]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0748, -0.0391,  0.0587,  ..., -0.0283, -0.0810, -0.0916],\n",
      "         [ 0.0752, -0.0394,  0.0587,  ..., -0.0290, -0.0815, -0.0933],\n",
      "         [ 0.0751, -0.0388,  0.0577,  ..., -0.0265, -0.0799, -0.0924]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [ 1.0865,  2.0447,  0.1518,  ...,  2.2782,  0.6501,  2.4601],\n",
      "         [-1.4358, -1.5879, -0.7592,  ...,  1.9289, -0.3171,  1.7583],\n",
      "         [-0.8447,  0.0216, -0.3514,  ...,  2.3416, -0.6364,  0.6512]]],\n",
      "       device='cuda:0'), tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [ 1.0865,  2.0447,  0.1518,  ...,  2.2782,  0.6501,  2.4601],\n",
      "         [-1.4358, -1.5879, -0.7592,  ...,  1.9289, -0.3171,  1.7583],\n",
      "         [-0.8447,  0.0216, -0.3514,  ...,  2.3416, -0.6364,  0.6512]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [ 0.4258,  0.2486, -0.0683,  ...,  0.3078,  0.2066,  0.0487],\n",
      "         [ 0.5965,  0.0141, -0.9050,  ..., -1.2799, -0.6209, -0.0960],\n",
      "         [ 0.4649,  0.7414, -0.8742,  ...,  0.1057, -1.1939,  0.2863]]],\n",
      "       device='cuda:0'), tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [ 0.4258,  0.2486, -0.0683,  ...,  0.3078,  0.2066,  0.0487],\n",
      "         [ 0.5965,  0.0141, -0.9050,  ..., -1.2799, -0.6209, -0.0960],\n",
      "         [ 0.4649,  0.7414, -0.8742,  ...,  0.1057, -1.1939,  0.2863]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [-0.0550,  2.0632,  0.1180,  ..., -0.6412, -1.6826,  0.7485],\n",
      "         [-1.3566, -0.0305, -0.6688,  ...,  2.2248,  1.1513,  1.2855],\n",
      "         [ 1.8440,  1.8118,  0.5946,  ...,  0.7495,  0.6509,  1.5106]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [-0.0550,  2.0632,  0.1180,  ..., -0.6412, -1.6826,  0.7485],\n",
      "         [-1.3566, -0.0305, -0.6688,  ...,  2.2248,  1.1513,  1.2855],\n",
      "         [ 1.8440,  1.8118,  0.5946,  ...,  0.7495,  0.6509,  1.5106]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.5044,  0.4722, -3.6093,  ...,  1.5023, -3.3142, -1.6725],\n",
      "         [-1.2299,  0.6590, -3.9743,  ...,  1.4538, -3.3293, -1.5743],\n",
      "         [-1.1961,  0.5995, -3.8851,  ...,  1.7862, -3.3579, -1.7745]]],\n",
      "       device='cuda:0'), tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.5044,  0.4722, -3.6093,  ...,  1.5023, -3.3142, -1.6725],\n",
      "         [-1.2299,  0.6590, -3.9743,  ...,  1.4538, -3.3293, -1.5743],\n",
      "         [-1.1961,  0.5995, -3.8851,  ...,  1.7862, -3.3579, -1.7745]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-0.5330,  1.4836, -0.6780,  ...,  1.3083, -0.5931,  4.0420],\n",
      "         [ 0.0307,  0.1533,  0.1458,  ...,  1.8754,  2.3450, -0.2857],\n",
      "         [-1.0327, -0.1549, -1.5497,  ...,  2.2921,  1.1516, -0.6882]]],\n",
      "       device='cuda:0'), tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-0.5330,  1.4836, -0.6780,  ...,  1.3083, -0.5931,  4.0420],\n",
      "         [ 0.0307,  0.1533,  0.1458,  ...,  1.8754,  2.3450, -0.2857],\n",
      "         [-1.0327, -0.1549, -1.5497,  ...,  2.2921,  1.1516, -0.6882]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.3170, -0.5421, -0.6547,  ...,  0.4536, -2.5835,  0.8213],\n",
      "         [-1.2973, -0.5272, -0.6744,  ...,  0.5225, -2.6241,  0.8207],\n",
      "         [-1.2495, -0.4987, -0.7021,  ...,  0.5376, -2.6041,  0.8599]]],\n",
      "       device='cuda:0'), tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.3170, -0.5421, -0.6547,  ...,  0.4536, -2.5835,  0.8213],\n",
      "         [-1.2973, -0.5272, -0.6744,  ...,  0.5225, -2.6241,  0.8207],\n",
      "         [-1.2495, -0.4987, -0.7021,  ...,  0.5376, -2.6041,  0.8599]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [ 1.7189,  1.2190,  0.7751,  ...,  0.7460,  0.3866,  0.8128],\n",
      "         [-1.9091,  1.0549, -0.6921,  ...,  0.8760,  0.2279,  1.1977],\n",
      "         [-0.8260,  2.2104,  2.4075,  ...,  0.3983, -1.4865,  0.3107]]],\n",
      "       device='cuda:0'), tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [ 1.7189,  1.2190,  0.7751,  ...,  0.7460,  0.3866,  0.8128],\n",
      "         [-1.9091,  1.0549, -0.6921,  ...,  0.8760,  0.2279,  1.1977],\n",
      "         [-0.8260,  2.2104,  2.4075,  ...,  0.3983, -1.4865,  0.3107]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0135,  0.1068,  0.0314,  ...,  0.0626, -0.0280, -0.0379],\n",
      "         [ 0.0162,  0.1095,  0.0321,  ...,  0.0744, -0.0280, -0.0324],\n",
      "         [ 0.0152,  0.1091,  0.0347,  ...,  0.0681, -0.0281, -0.0361]]],\n",
      "       device='cuda:0'), tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0135,  0.1068,  0.0314,  ...,  0.0626, -0.0280, -0.0379],\n",
      "         [ 0.0162,  0.1095,  0.0321,  ...,  0.0744, -0.0280, -0.0324],\n",
      "         [ 0.0152,  0.1091,  0.0347,  ...,  0.0681, -0.0281, -0.0361]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 0.2637,  1.6801, -0.4866,  ...,  0.9914, -0.7300,  0.8968],\n",
      "         [ 1.3069,  0.4304, -0.2662,  ...,  2.0311, -1.2748,  3.2413],\n",
      "         [ 0.5276,  0.5357, -0.9078,  ...,  1.7031, -0.1919,  2.8205]]],\n",
      "       device='cuda:0'), tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 0.2637,  1.6801, -0.4866,  ...,  0.9914, -0.7300,  0.8968],\n",
      "         [ 1.3069,  0.4304, -0.2662,  ...,  2.0311, -1.2748,  3.2413],\n",
      "         [ 0.5276,  0.5357, -0.9078,  ...,  1.7031, -0.1919,  2.8205]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [ 1.4679,  0.2458,  0.9681,  ..., -0.5281,  0.3772, -1.1083],\n",
      "         [ 0.6148, -0.8833,  0.5236,  ..., -0.3906,  0.5019,  1.5273],\n",
      "         [-0.2271,  0.4061, -0.4706,  ...,  2.0794, -1.1475, -0.5217]]],\n",
      "       device='cuda:0'), tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [ 1.4679,  0.2458,  0.9681,  ..., -0.5281,  0.3772, -1.1083],\n",
      "         [ 0.6148, -0.8833,  0.5236,  ..., -0.3906,  0.5019,  1.5273],\n",
      "         [-0.2271,  0.4061, -0.4706,  ...,  2.0794, -1.1475, -0.5217]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [-0.3226, -0.2274, -0.6944,  ...,  2.1802,  0.0665,  1.1560],\n",
      "         [-0.3977,  2.0198, -0.2628,  ...,  2.3605,  0.2572,  1.2966],\n",
      "         [-0.7693, -0.6822,  0.7184,  ..., -0.7984, -0.1831,  0.0511]]],\n",
      "       device='cuda:0'), tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [-0.3226, -0.2274, -0.6944,  ...,  2.1802,  0.0665,  1.1560],\n",
      "         [-0.3977,  2.0198, -0.2628,  ...,  2.3605,  0.2572,  1.2966],\n",
      "         [-0.7693, -0.6822,  0.7184,  ..., -0.7984, -0.1831,  0.0511]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.1986, -0.7817,  1.5452,  ..., -2.9218,  0.7447, -0.7568],\n",
      "         [-2.1034, -1.2625,  1.5825,  ..., -2.9000,  1.3122, -0.1466],\n",
      "         [-2.1530, -0.8021,  1.7980,  ..., -3.0281,  0.5079, -0.3885]]],\n",
      "       device='cuda:0'), tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.1986, -0.7817,  1.5452,  ..., -2.9218,  0.7447, -0.7568],\n",
      "         [-2.1034, -1.2625,  1.5825,  ..., -2.9000,  1.3122, -0.1466],\n",
      "         [-2.1530, -0.8021,  1.7980,  ..., -3.0281,  0.5079, -0.3885]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [ 0.6972,  0.3574,  0.6181,  ...,  1.7100,  0.7052,  1.7454],\n",
      "         [-0.6358,  0.1999,  0.4482,  ...,  0.4005, -0.4140,  0.6120],\n",
      "         [ 0.8541,  1.2086,  0.1566,  ...,  0.6945, -1.1406,  1.1087]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [ 0.6972,  0.3574,  0.6181,  ...,  1.7100,  0.7052,  1.7454],\n",
      "         [-0.6358,  0.1999,  0.4482,  ...,  0.4005, -0.4140,  0.6120],\n",
      "         [ 0.8541,  1.2086,  0.1566,  ...,  0.6945, -1.1406,  1.1087]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.5021,  1.5242, -0.1346,  ..., -0.3629, -0.0402,  2.3700],\n",
      "         [ 2.4067,  1.5734, -0.1509,  ..., -0.3894, -0.0280,  2.4315],\n",
      "         [ 2.4505,  1.5177, -0.1329,  ..., -0.4002, -0.0608,  2.3475]]],\n",
      "       device='cuda:0'), tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.5021,  1.5242, -0.1346,  ..., -0.3629, -0.0402,  2.3700],\n",
      "         [ 2.4067,  1.5734, -0.1509,  ..., -0.3894, -0.0280,  2.4315],\n",
      "         [ 2.4505,  1.5177, -0.1329,  ..., -0.4002, -0.0608,  2.3475]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [-1.0663,  1.1842,  0.4159,  ...,  1.6920, -0.3464,  0.4944],\n",
      "         [-0.6544,  1.9980, -0.0614,  ...,  0.7478,  0.6568,  1.1730],\n",
      "         [-0.6306,  2.5534, -0.4512,  ...,  1.5998, -1.2374,  0.2318]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [-1.0663,  1.1842,  0.4159,  ...,  1.6920, -0.3464,  0.4944],\n",
      "         [-0.6544,  1.9980, -0.0614,  ...,  0.7478,  0.6568,  1.1730],\n",
      "         [-0.6306,  2.5534, -0.4512,  ...,  1.5998, -1.2374,  0.2318]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.0847e-02, -1.1267e-03,  2.4041e-02,  ..., -9.8300e-03,\n",
      "          -7.5559e-03, -1.8723e-02],\n",
      "         [ 2.2165e-02, -1.2688e-03,  2.4388e-02,  ..., -1.0348e-02,\n",
      "          -7.0154e-03, -1.8556e-02],\n",
      "         [ 2.2596e-02, -1.7298e-03,  2.4472e-02,  ..., -9.8672e-03,\n",
      "          -7.1087e-03, -1.9364e-02],\n",
      "         ...,\n",
      "         [ 2.4022e-02, -1.4234e-03,  2.4545e-02,  ..., -9.8174e-03,\n",
      "          -6.8732e-03, -1.8842e-02],\n",
      "         [ 2.2295e-02, -2.8275e-04,  2.2264e-02,  ..., -1.0122e-02,\n",
      "          -6.9480e-03, -1.8864e-02],\n",
      "         [ 2.1576e-02,  9.0441e-05,  2.4180e-02,  ..., -1.1128e-02,\n",
      "          -5.8788e-03, -1.7765e-02]]], device='cuda:0'), tensor([[[ 2.0847e-02, -1.1267e-03,  2.4041e-02,  ..., -9.8300e-03,\n",
      "          -7.5559e-03, -1.8723e-02],\n",
      "         [ 2.2165e-02, -1.2688e-03,  2.4388e-02,  ..., -1.0348e-02,\n",
      "          -7.0154e-03, -1.8556e-02],\n",
      "         [ 2.2596e-02, -1.7298e-03,  2.4472e-02,  ..., -9.8672e-03,\n",
      "          -7.1087e-03, -1.9364e-02],\n",
      "         ...,\n",
      "         [ 2.4022e-02, -1.4234e-03,  2.4545e-02,  ..., -9.8174e-03,\n",
      "          -6.8732e-03, -1.8842e-02],\n",
      "         [ 2.2295e-02, -2.8275e-04,  2.2264e-02,  ..., -1.0122e-02,\n",
      "          -6.9480e-03, -1.8864e-02],\n",
      "         [ 2.1576e-02,  9.0441e-05,  2.4180e-02,  ..., -1.1128e-02,\n",
      "          -5.8788e-03, -1.7765e-02]]], device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [-0.4176,  1.2208,  0.1386,  ...,  0.6357,  1.6892,  0.1980],\n",
      "         [ 0.0329,  1.2918,  1.2821,  ...,  1.6749,  0.4716,  1.4511],\n",
      "         [-0.6209, -2.2725,  0.4815,  ...,  1.8428,  1.9666,  0.4265]]],\n",
      "       device='cuda:0'), tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [-0.4176,  1.2208,  0.1386,  ...,  0.6357,  1.6892,  0.1980],\n",
      "         [ 0.0329,  1.2918,  1.2821,  ...,  1.6749,  0.4716,  1.4511],\n",
      "         [-0.6209, -2.2725,  0.4815,  ...,  1.8428,  1.9666,  0.4265]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [-0.8697,  0.5402, -0.3279,  ..., -0.0096, -1.3882, -0.5403],\n",
      "         [-0.7210,  2.0311,  0.5958,  ...,  0.3801, -0.7270, -0.6005],\n",
      "         [ 1.8058, -0.0687, -1.1352,  ..., -0.8344,  0.9411, -0.2843]]],\n",
      "       device='cuda:0'), tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [-0.8697,  0.5402, -0.3279,  ..., -0.0096, -1.3882, -0.5403],\n",
      "         [-0.7210,  2.0311,  0.5958,  ...,  0.3801, -0.7270, -0.6005],\n",
      "         [ 1.8058, -0.0687, -1.1352,  ..., -0.8344,  0.9411, -0.2843]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 1.3490e+00, -1.5590e+00, -1.0882e+00,  ...,  1.7795e+00,\n",
      "           1.1321e+00,  3.5640e-01],\n",
      "         [ 1.0402e-02,  8.9785e-01,  2.1565e+00,  ...,  1.5428e+00,\n",
      "          -8.0254e-01,  2.8105e-03],\n",
      "         [-4.0944e-01, -5.8978e-01, -1.3179e+00,  ..., -2.2609e-01,\n",
      "           5.6917e-01,  1.7907e+00]]], device='cuda:0'), tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 1.3490e+00, -1.5590e+00, -1.0882e+00,  ...,  1.7795e+00,\n",
      "           1.1321e+00,  3.5640e-01],\n",
      "         [ 1.0402e-02,  8.9785e-01,  2.1565e+00,  ...,  1.5428e+00,\n",
      "          -8.0254e-01,  2.8105e-03],\n",
      "         [-4.0944e-01, -5.8978e-01, -1.3179e+00,  ..., -2.2609e-01,\n",
      "           5.6917e-01,  1.7907e+00]]], device='cuda:0')), 'logits_attn': (tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.8675,  3.1922,  6.0308,  ..., -1.9948, -8.4348, -3.3102],\n",
      "         [ 4.8563,  2.9271,  5.8991,  ..., -2.1343, -8.7222, -3.6589],\n",
      "         [ 4.8308,  3.4273,  5.9192,  ..., -2.1195, -8.6176, -3.1459]]],\n",
      "       device='cuda:0'), tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.8675,  3.1922,  6.0308,  ..., -1.9948, -8.4348, -3.3102],\n",
      "         [ 4.8563,  2.9271,  5.8991,  ..., -2.1343, -8.7222, -3.6589],\n",
      "         [ 4.8308,  3.4273,  5.9192,  ..., -2.1195, -8.6176, -3.1459]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [ 0.2909, -0.4383, -0.1056,  ...,  2.9231,  0.7002,  1.7770],\n",
      "         [-0.2045,  0.7983, -0.8600,  ...,  1.0150,  0.7715,  0.3613],\n",
      "         [-0.5431,  0.7941,  0.9497,  ...,  2.6475,  0.0173,  0.8979]]],\n",
      "       device='cuda:0'), tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [ 0.2909, -0.4383, -0.1056,  ...,  2.9231,  0.7002,  1.7770],\n",
      "         [-0.2045,  0.7983, -0.8600,  ...,  1.0150,  0.7715,  0.3613],\n",
      "         [-0.5431,  0.7941,  0.9497,  ...,  2.6475,  0.0173,  0.8979]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5695, -8.7708,  4.9040,  ...,  5.1941,  2.4794,  3.4461],\n",
      "         [ 3.5762, -8.7705,  4.9077,  ...,  5.1917,  2.4875,  3.4432],\n",
      "         [ 3.5764, -8.7744,  4.9017,  ...,  5.1923,  2.4851,  3.4419]]],\n",
      "       device='cuda:0'), tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5695, -8.7708,  4.9040,  ...,  5.1941,  2.4794,  3.4461],\n",
      "         [ 3.5762, -8.7705,  4.9077,  ...,  5.1917,  2.4875,  3.4432],\n",
      "         [ 3.5764, -8.7744,  4.9017,  ...,  5.1923,  2.4851,  3.4419]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [-0.3302,  1.4961, -0.7712,  ..., -1.0441,  0.1347,  1.2833],\n",
      "         [ 0.5908,  0.4607,  0.6404,  ...,  0.4619,  1.1978, -0.0938],\n",
      "         [-0.2962,  1.2858, -0.2256,  ...,  0.8201,  1.3677,  1.0073]]],\n",
      "       device='cuda:0'), tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [-0.3302,  1.4961, -0.7712,  ..., -1.0441,  0.1347,  1.2833],\n",
      "         [ 0.5908,  0.4607,  0.6404,  ...,  0.4619,  1.1978, -0.0938],\n",
      "         [-0.2962,  1.2858, -0.2256,  ...,  0.8201,  1.3677,  1.0073]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0017, -0.0035, -0.0666,  ..., -0.0052,  0.0016, -0.0185],\n",
      "         [-0.0021, -0.0032, -0.0662,  ..., -0.0052,  0.0012, -0.0184],\n",
      "         [-0.0019, -0.0031, -0.0668,  ..., -0.0057,  0.0020, -0.0184]]],\n",
      "       device='cuda:0'), tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0017, -0.0035, -0.0666,  ..., -0.0052,  0.0016, -0.0185],\n",
      "         [-0.0021, -0.0032, -0.0662,  ..., -0.0052,  0.0012, -0.0184],\n",
      "         [-0.0019, -0.0031, -0.0668,  ..., -0.0057,  0.0020, -0.0184]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [-1.5048,  0.1011, -1.3367,  ...,  1.3301,  1.6702,  2.7523],\n",
      "         [ 0.3693,  1.8286,  2.5909,  ..., -0.0858,  0.4932,  0.1980],\n",
      "         [-1.4419,  2.3771,  0.8454,  ...,  2.4002,  1.1599,  0.4664]]],\n",
      "       device='cuda:0'), tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [-1.5048,  0.1011, -1.3367,  ...,  1.3301,  1.6702,  2.7523],\n",
      "         [ 0.3693,  1.8286,  2.5909,  ..., -0.0858,  0.4932,  0.1980],\n",
      "         [-1.4419,  2.3771,  0.8454,  ...,  2.4002,  1.1599,  0.4664]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 0.8684, -1.8102, -0.0101,  ..., -2.0249,  0.1767, -0.2239],\n",
      "         [ 0.1695, -1.4473,  0.3856,  ...,  0.6086,  0.8163,  1.6378],\n",
      "         [ 3.5922, -1.8991,  0.8484,  ...,  1.1768,  0.2923,  1.7952]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 0.8684, -1.8102, -0.0101,  ..., -2.0249,  0.1767, -0.2239],\n",
      "         [ 0.1695, -1.4473,  0.3856,  ...,  0.6086,  0.8163,  1.6378],\n",
      "         [ 3.5922, -1.8991,  0.8484,  ...,  1.1768,  0.2923,  1.7952]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [-0.0283,  0.1882,  1.0073,  ..., -0.1021, -0.2818,  1.0640],\n",
      "         [ 0.1909,  1.9145, -0.3984,  ...,  1.5121, -0.2496,  1.2630],\n",
      "         [-2.1755,  2.4873,  0.0953,  ...,  1.6769, -0.3062,  0.9159]]],\n",
      "       device='cuda:0'), tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [-0.0283,  0.1882,  1.0073,  ..., -0.1021, -0.2818,  1.0640],\n",
      "         [ 0.1909,  1.9145, -0.3984,  ...,  1.5121, -0.2496,  1.2630],\n",
      "         [-2.1755,  2.4873,  0.0953,  ...,  1.6769, -0.3062,  0.9159]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.8510, -1.9723,  0.4084,  ..., -0.5179,  2.9483,  1.6830],\n",
      "         [-4.9189, -2.0452, -0.0111,  ..., -0.3216,  2.7441,  1.9224],\n",
      "         [-5.0125, -1.9626, -0.0286,  ..., -0.7333,  2.8951,  1.7139]]],\n",
      "       device='cuda:0'), tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.8510, -1.9723,  0.4084,  ..., -0.5179,  2.9483,  1.6830],\n",
      "         [-4.9189, -2.0452, -0.0111,  ..., -0.3216,  2.7441,  1.9224],\n",
      "         [-5.0125, -1.9626, -0.0286,  ..., -0.7333,  2.8951,  1.7139]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [-1.8819,  2.3728, -1.2482,  ...,  0.8839,  0.9978,  0.5918],\n",
      "         [-0.6080,  1.4957, -0.4834,  ...,  2.0861, -1.0655,  1.1335],\n",
      "         [ 0.9248,  1.0960, -0.6987,  ..., -0.1724, -1.2316,  0.3023]]],\n",
      "       device='cuda:0'), tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [-1.8819,  2.3728, -1.2482,  ...,  0.8839,  0.9978,  0.5918],\n",
      "         [-0.6080,  1.4957, -0.4834,  ...,  2.0861, -1.0655,  1.1335],\n",
      "         [ 0.9248,  1.0960, -0.6987,  ..., -0.1724, -1.2316,  0.3023]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0326,  0.2145,  0.4577,  ..., -0.3024,  0.6947, -0.5777],\n",
      "         [ 0.0147,  0.2345,  0.4340,  ..., -0.3106,  0.7214, -0.5563],\n",
      "         [ 0.0129,  0.3211,  0.4511,  ..., -0.2289,  0.6813, -0.5777]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0326,  0.2145,  0.4577,  ..., -0.3024,  0.6947, -0.5777],\n",
      "         [ 0.0147,  0.2345,  0.4340,  ..., -0.3106,  0.7214, -0.5563],\n",
      "         [ 0.0129,  0.3211,  0.4511,  ..., -0.2289,  0.6813, -0.5777]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.8124,  1.2828, -1.8890,  ..., -0.0505,  1.6989,  1.8539],\n",
      "         [ 0.1075,  1.5691,  0.6650,  ...,  1.8831, -0.3128,  1.1174],\n",
      "         [-0.3654,  1.7079, -0.7468,  ...,  1.3217,  0.6354,  0.7334]]],\n",
      "       device='cuda:0'), tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.8124,  1.2828, -1.8890,  ..., -0.0505,  1.6989,  1.8539],\n",
      "         [ 0.1075,  1.5691,  0.6650,  ...,  1.8831, -0.3128,  1.1174],\n",
      "         [-0.3654,  1.7079, -0.7468,  ...,  1.3217,  0.6354,  0.7334]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0608, -0.0330,  0.0808,  ...,  0.0452,  0.0807, -0.0170],\n",
      "         [-0.0593, -0.0322,  0.0771,  ...,  0.0538,  0.0789, -0.0182],\n",
      "         [-0.0588, -0.0345,  0.0768,  ...,  0.0513,  0.0752, -0.0222]]],\n",
      "       device='cuda:0'), tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0608, -0.0330,  0.0808,  ...,  0.0452,  0.0807, -0.0170],\n",
      "         [-0.0593, -0.0322,  0.0771,  ...,  0.0538,  0.0789, -0.0182],\n",
      "         [-0.0588, -0.0345,  0.0768,  ...,  0.0513,  0.0752, -0.0222]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [ 0.6187,  0.6914,  0.2766,  ...,  1.1818,  0.3341,  1.8753],\n",
      "         [-1.0712,  1.2003,  0.0466,  ..., -0.4887, -0.3115,  0.4672],\n",
      "         [-0.2791,  3.1464,  2.0099,  ...,  1.4036, -0.3303,  1.1605]]],\n",
      "       device='cuda:0'), tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [ 0.6187,  0.6914,  0.2766,  ...,  1.1818,  0.3341,  1.8753],\n",
      "         [-1.0712,  1.2003,  0.0466,  ..., -0.4887, -0.3115,  0.4672],\n",
      "         [-0.2791,  3.1464,  2.0099,  ...,  1.4036, -0.3303,  1.1605]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [ 1.5369, -1.1083, -1.4584,  ..., -0.0695, -0.7102,  0.6294],\n",
      "         [-2.5853, -1.8881, -0.7727,  ...,  0.3886,  1.1773, -0.6143],\n",
      "         [-1.6989, -3.0237, -1.6287,  ...,  2.2909, -0.2403, -0.0541]]],\n",
      "       device='cuda:0'), tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [ 1.5369, -1.1083, -1.4584,  ..., -0.0695, -0.7102,  0.6294],\n",
      "         [-2.5853, -1.8881, -0.7727,  ...,  0.3886,  1.1773, -0.6143],\n",
      "         [-1.6989, -3.0237, -1.6287,  ...,  2.2909, -0.2403, -0.0541]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [ 0.7890,  0.4889, -0.9429,  ...,  0.8467, -1.3415,  0.4884],\n",
      "         [ 1.4055,  2.5046,  0.9847,  ...,  1.7101,  0.8546,  1.7187],\n",
      "         [-1.9374,  1.6441,  0.0860,  ...,  1.4799,  1.6782,  0.7735]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [ 0.7890,  0.4889, -0.9429,  ...,  0.8467, -1.3415,  0.4884],\n",
      "         [ 1.4055,  2.5046,  0.9847,  ...,  1.7101,  0.8546,  1.7187],\n",
      "         [-1.9374,  1.6441,  0.0860,  ...,  1.4799,  1.6782,  0.7735]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.2018,  0.1242,  0.8478,  ...,  0.1864,  0.1753,  0.4406],\n",
      "         [ 0.9768,  0.0363,  1.0439,  ...,  0.2866,  0.3584,  0.1767],\n",
      "         [ 1.1093, -0.1944,  0.8585,  ...,  0.2005,  0.2044,  0.0780]]],\n",
      "       device='cuda:0'), tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.2018,  0.1242,  0.8478,  ...,  0.1864,  0.1753,  0.4406],\n",
      "         [ 0.9768,  0.0363,  1.0439,  ...,  0.2866,  0.3584,  0.1767],\n",
      "         [ 1.1093, -0.1944,  0.8585,  ...,  0.2005,  0.2044,  0.0780]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [ 1.5295,  1.8277,  1.6585,  ...,  1.7466, -0.1510,  1.1444],\n",
      "         [-0.0960,  1.0479, -0.1868,  ...,  1.7540,  0.3808,  1.8715],\n",
      "         [ 0.7939,  0.8769, -0.7837,  ...,  0.5759,  0.9190,  2.1376]]],\n",
      "       device='cuda:0'), tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [ 1.5295,  1.8277,  1.6585,  ...,  1.7466, -0.1510,  1.1444],\n",
      "         [-0.0960,  1.0479, -0.1868,  ...,  1.7540,  0.3808,  1.8715],\n",
      "         [ 0.7939,  0.8769, -0.7837,  ...,  0.5759,  0.9190,  2.1376]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4518,  5.3528,  1.9452,  ...,  4.7944, -1.4995, -0.6792],\n",
      "         [ 2.4738,  5.3868,  1.9228,  ...,  4.8171, -1.5209, -0.6393],\n",
      "         [ 2.4799,  5.3825,  1.9716,  ...,  4.8123, -1.5087, -0.6550]]],\n",
      "       device='cuda:0'), tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4518,  5.3528,  1.9452,  ...,  4.7944, -1.4995, -0.6792],\n",
      "         [ 2.4738,  5.3868,  1.9228,  ...,  4.8171, -1.5209, -0.6393],\n",
      "         [ 2.4799,  5.3825,  1.9716,  ...,  4.8123, -1.5087, -0.6550]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-2.0233,  0.3805, -1.3228,  ..., -0.8410, -0.8472,  0.9536],\n",
      "         [-0.0487,  0.4071,  0.7777,  ...,  1.5211, -1.3605, -0.4331],\n",
      "         [-0.1126,  1.3196,  2.2557,  ...,  0.7710, -0.9446, -1.6545]]],\n",
      "       device='cuda:0'), tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-2.0233,  0.3805, -1.3228,  ..., -0.8410, -0.8472,  0.9536],\n",
      "         [-0.0487,  0.4071,  0.7777,  ...,  1.5211, -1.3605, -0.4331],\n",
      "         [-0.1126,  1.3196,  2.2557,  ...,  0.7710, -0.9446, -1.6545]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0246,  0.0631, -0.0201,  ..., -0.1131,  0.0269,  0.0289],\n",
      "         [-0.0225,  0.0652, -0.0225,  ..., -0.1140,  0.0334,  0.0254],\n",
      "         [-0.0227,  0.0628, -0.0207,  ..., -0.1144,  0.0325,  0.0226]]],\n",
      "       device='cuda:0'), tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0246,  0.0631, -0.0201,  ..., -0.1131,  0.0269,  0.0289],\n",
      "         [-0.0225,  0.0652, -0.0225,  ..., -0.1140,  0.0334,  0.0254],\n",
      "         [-0.0227,  0.0628, -0.0207,  ..., -0.1144,  0.0325,  0.0226]]],\n",
      "       device='cuda:0'))}]}]\n",
      "Step 50 - Last token probs (min/max): 0.003850974841043353 / 0.04971158504486084\n",
      "Step 100 - past_kv structure:  [{'left': [{'chunk_attn': (tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [ 0.5368, -0.0673,  1.1138,  ...,  0.2633,  1.3010,  1.2752],\n",
      "         [ 0.6159,  1.0727, -1.7746,  ...,  0.3929,  0.9731,  3.7231],\n",
      "         [-0.2647, -0.2904, -1.2181,  ..., -0.4326, -0.9886,  1.7875]]],\n",
      "       device='cuda:0'), tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [ 0.5368, -0.0673,  1.1138,  ...,  0.2633,  1.3010,  1.2752],\n",
      "         [ 0.6159,  1.0727, -1.7746,  ...,  0.3929,  0.9731,  3.7231],\n",
      "         [-0.2647, -0.2904, -1.2181,  ..., -0.4326, -0.9886,  1.7875]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'), tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [-0.0671,  1.8145,  1.3763,  ...,  3.5208,  1.1697,  0.8584],\n",
      "         [ 0.9872,  2.3050,  0.1685,  ...,  2.4957,  0.5888,  2.3382],\n",
      "         [-0.8092, -0.4382, -1.7721,  ...,  1.3492, -0.8382,  0.6818]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [-0.0671,  1.8145,  1.3763,  ...,  3.5208,  1.1697,  0.8584],\n",
      "         [ 0.9872,  2.3050,  0.1685,  ...,  2.4957,  0.5888,  2.3382],\n",
      "         [-0.8092, -0.4382, -1.7721,  ...,  1.3492, -0.8382,  0.6818]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9276, -0.3534, -7.2329,  ...,  5.5348,  1.2875, -0.4076],\n",
      "         [-4.9473, -0.5428, -7.3259,  ...,  5.6859,  1.3215, -0.3542],\n",
      "         [-4.9917, -0.4470, -7.3292,  ...,  5.6835,  1.1745, -0.2901]]],\n",
      "       device='cuda:0'), tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9276, -0.3534, -7.2329,  ...,  5.5348,  1.2875, -0.4076],\n",
      "         [-4.9473, -0.5428, -7.3259,  ...,  5.6859,  1.3215, -0.3542],\n",
      "         [-4.9917, -0.4470, -7.3292,  ...,  5.6835,  1.1745, -0.2901]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [ 1.1487,  2.3069,  1.7768,  ...,  1.6875, -0.9756,  0.9217],\n",
      "         [-1.4989, -0.6649,  2.0507,  ...,  1.1245,  0.0278,  0.4853],\n",
      "         [ 0.3376,  2.4580, -1.2080,  ...,  1.7818,  1.6119,  2.0143]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [ 1.1487,  2.3069,  1.7768,  ...,  1.6875, -0.9756,  0.9217],\n",
      "         [-1.4989, -0.6649,  2.0507,  ...,  1.1245,  0.0278,  0.4853],\n",
      "         [ 0.3376,  2.4580, -1.2080,  ...,  1.7818,  1.6119,  2.0143]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0453,  1.9533,  1.9738,  ...,  1.4779,  1.3008, -2.7930],\n",
      "         [ 3.0463,  1.9545,  1.9754,  ...,  1.4793,  1.3013, -2.7925],\n",
      "         [ 3.0460,  1.9559,  1.9751,  ...,  1.4786,  1.3031, -2.7923]]],\n",
      "       device='cuda:0'), tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0453,  1.9533,  1.9738,  ...,  1.4779,  1.3008, -2.7930],\n",
      "         [ 3.0463,  1.9545,  1.9754,  ...,  1.4793,  1.3013, -2.7925],\n",
      "         [ 3.0460,  1.9559,  1.9751,  ...,  1.4786,  1.3031, -2.7923]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [-0.5692,  2.4703, -0.8929,  ...,  0.5737, -0.1069,  1.9254],\n",
      "         [-0.6164, -0.3686, -0.7250,  ...,  1.5884, -0.8364, -0.1426],\n",
      "         [-0.4125,  2.0816,  0.1484,  ...,  1.1597,  0.4884, -0.1627]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [-0.5692,  2.4703, -0.8929,  ...,  0.5737, -0.1069,  1.9254],\n",
      "         [-0.6164, -0.3686, -0.7250,  ...,  1.5884, -0.8364, -0.1426],\n",
      "         [-0.4125,  2.0816,  0.1484,  ...,  1.1597,  0.4884, -0.1627]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0019,  0.0237,  0.0069,  ..., -0.0827, -0.0682,  0.0016],\n",
      "         [-0.0024,  0.0253,  0.0060,  ..., -0.0812, -0.0677, -0.0007],\n",
      "         [-0.0030,  0.0239,  0.0065,  ..., -0.0817, -0.0685, -0.0008]]],\n",
      "       device='cuda:0'), tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0019,  0.0237,  0.0069,  ..., -0.0827, -0.0682,  0.0016],\n",
      "         [-0.0024,  0.0253,  0.0060,  ..., -0.0812, -0.0677, -0.0007],\n",
      "         [-0.0030,  0.0239,  0.0065,  ..., -0.0817, -0.0685, -0.0008]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [-1.0739,  0.6164, -1.3272,  ...,  2.7016,  0.8675,  0.2868],\n",
      "         [ 0.4432,  2.0085, -1.2046,  ...,  1.8160,  1.3212,  1.6570],\n",
      "         [-0.1697,  1.5001, -0.6512,  ..., -0.3900, -0.0418,  0.0677]]],\n",
      "       device='cuda:0'), tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [-1.0739,  0.6164, -1.3272,  ...,  2.7016,  0.8675,  0.2868],\n",
      "         [ 0.4432,  2.0085, -1.2046,  ...,  1.8160,  1.3212,  1.6570],\n",
      "         [-0.1697,  1.5001, -0.6512,  ..., -0.3900, -0.0418,  0.0677]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'), tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [-1.2845,  1.6649, -1.3089,  ..., -0.1436, -0.3605,  0.7022],\n",
      "         [ 0.1754,  0.6260, -0.3913,  ...,  0.5723, -1.0218,  0.6320],\n",
      "         [ 0.3472,  1.9579,  0.8375,  ...,  1.8459,  0.3387, -0.0086]]],\n",
      "       device='cuda:0'), tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [-1.2845,  1.6649, -1.3089,  ..., -0.1436, -0.3605,  0.7022],\n",
      "         [ 0.1754,  0.6260, -0.3913,  ...,  0.5723, -1.0218,  0.6320],\n",
      "         [ 0.3472,  1.9579,  0.8375,  ...,  1.8459,  0.3387, -0.0086]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.6418, -0.3949, -0.1182,  ...,  1.0806, -0.5655, -0.0158],\n",
      "         [-0.5146, -0.2953, -0.4977,  ...,  0.9810, -0.4261,  0.2450],\n",
      "         [-0.8427, -0.6897,  0.0211,  ...,  1.2770, -0.3877,  0.0394]]],\n",
      "       device='cuda:0'), tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.6418, -0.3949, -0.1182,  ...,  1.0806, -0.5655, -0.0158],\n",
      "         [-0.5146, -0.2953, -0.4977,  ...,  0.9810, -0.4261,  0.2450],\n",
      "         [-0.8427, -0.6897,  0.0211,  ...,  1.2770, -0.3877,  0.0394]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [ 0.5459,  0.2493, -1.4935,  ...,  1.0661, -0.2949,  0.9509],\n",
      "         [-0.3575, -0.4564,  0.9642,  ...,  1.3688, -1.2960, -1.3176],\n",
      "         [ 0.0366,  2.0834,  1.2312,  ..., -0.6808,  2.4114,  1.7405]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [ 0.5459,  0.2493, -1.4935,  ...,  1.0661, -0.2949,  0.9509],\n",
      "         [-0.3575, -0.4564,  0.9642,  ...,  1.3688, -1.2960, -1.3176],\n",
      "         [ 0.0366,  2.0834,  1.2312,  ..., -0.6808,  2.4114,  1.7405]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3380,  0.3875,  0.0396,  ..., -0.4883,  0.5672, -0.2356],\n",
      "         [ 0.3419,  0.3825,  0.0117,  ..., -0.4994,  0.5444, -0.2189],\n",
      "         [ 0.3312,  0.4036,  0.0254,  ..., -0.4908,  0.5552, -0.2230]]],\n",
      "       device='cuda:0'), tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3380,  0.3875,  0.0396,  ..., -0.4883,  0.5672, -0.2356],\n",
      "         [ 0.3419,  0.3825,  0.0117,  ..., -0.4994,  0.5444, -0.2189],\n",
      "         [ 0.3312,  0.4036,  0.0254,  ..., -0.4908,  0.5552, -0.2230]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.9913, -0.6125,  0.2165,  ...,  1.1395,  1.5056,  1.9124],\n",
      "         [-0.0092,  0.7366,  0.2437,  ...,  1.8991, -0.3161,  1.5599],\n",
      "         [-0.5174,  1.3737,  1.7959,  ...,  0.9128,  0.5458,  0.3759]]],\n",
      "       device='cuda:0'), tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.9913, -0.6125,  0.2165,  ...,  1.1395,  1.5056,  1.9124],\n",
      "         [-0.0092,  0.7366,  0.2437,  ...,  1.8991, -0.3161,  1.5599],\n",
      "         [-0.5174,  1.3737,  1.7959,  ...,  0.9128,  0.5458,  0.3759]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0681,  0.0788, -0.0472,  ..., -0.1165, -0.0081, -0.0249],\n",
      "         [ 0.0801,  0.0768, -0.0279,  ..., -0.0985, -0.0326, -0.0244],\n",
      "         [ 0.0658,  0.0986, -0.0326,  ..., -0.1126, -0.0542, -0.0198]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0681,  0.0788, -0.0472,  ..., -0.1165, -0.0081, -0.0249],\n",
      "         [ 0.0801,  0.0768, -0.0279,  ..., -0.0985, -0.0326, -0.0244],\n",
      "         [ 0.0658,  0.0986, -0.0326,  ..., -0.1126, -0.0542, -0.0198]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [-0.3402, -1.7111, -1.0749,  ...,  2.2431,  0.8619,  0.4913],\n",
      "         [-0.8045,  1.5557,  0.4282,  ..., -0.3184, -1.3670,  0.5846],\n",
      "         [ 0.3089, -1.0291,  0.1623,  ...,  1.8493, -0.7556,  0.8940]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [-0.3402, -1.7111, -1.0749,  ...,  2.2431,  0.8619,  0.4913],\n",
      "         [-0.8045,  1.5557,  0.4282,  ..., -0.3184, -1.3670,  0.5846],\n",
      "         [ 0.3089, -1.0291,  0.1623,  ...,  1.8493, -0.7556,  0.8940]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [-1.1437, -1.5971,  0.9464,  ...,  0.4433, -1.0776, -0.2259],\n",
      "         [ 0.1645, -0.7217, -0.2228,  ...,  1.4752, -0.3474, -0.6392],\n",
      "         [ 0.8150, -0.1717,  0.4479,  ...,  1.5616, -1.4415,  1.0047]]],\n",
      "       device='cuda:0'), tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [-1.1437, -1.5971,  0.9464,  ...,  0.4433, -1.0776, -0.2259],\n",
      "         [ 0.1645, -0.7217, -0.2228,  ...,  1.4752, -0.3474, -0.6392],\n",
      "         [ 0.8150, -0.1717,  0.4479,  ...,  1.5616, -1.4415,  1.0047]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [ 1.4550, -1.0100,  2.9845,  ...,  1.8145,  0.2797,  0.0952],\n",
      "         [-0.3137, -0.0775, -1.9805,  ...,  0.2130, -0.6115, -0.2515],\n",
      "         [-0.2388, -0.8628, -0.3067,  ...,  1.1429,  0.2307,  1.5660]]],\n",
      "       device='cuda:0'), tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [ 1.4550, -1.0100,  2.9845,  ...,  1.8145,  0.2797,  0.0952],\n",
      "         [-0.3137, -0.0775, -1.9805,  ...,  0.2130, -0.6115, -0.2515],\n",
      "         [-0.2388, -0.8628, -0.3067,  ...,  1.1429,  0.2307,  1.5660]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.1414,  0.2658,  0.0309,  ..., -1.7649, -1.0999,  0.2233],\n",
      "         [-3.2628,  0.4405, -0.2393,  ..., -1.9768, -0.8896,  0.8348],\n",
      "         [-3.1810, -0.5528,  0.7977,  ..., -1.7293, -1.3127, -0.1405]]],\n",
      "       device='cuda:0'), tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.1414,  0.2658,  0.0309,  ..., -1.7649, -1.0999,  0.2233],\n",
      "         [-3.2628,  0.4405, -0.2393,  ..., -1.9768, -0.8896,  0.8348],\n",
      "         [-3.1810, -0.5528,  0.7977,  ..., -1.7293, -1.3127, -0.1405]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [-0.1464,  1.5219,  0.2521,  ...,  2.4334, -1.1203,  0.4350],\n",
      "         [ 0.0720, -0.5311, -0.4026,  ...,  1.7587, -0.2993,  1.4420],\n",
      "         [ 0.1553,  1.2216,  1.3935,  ...,  0.4368, -0.6360, -0.7523]]],\n",
      "       device='cuda:0'), tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [-0.1464,  1.5219,  0.2521,  ...,  2.4334, -1.1203,  0.4350],\n",
      "         [ 0.0720, -0.5311, -0.4026,  ...,  1.7587, -0.2993,  1.4420],\n",
      "         [ 0.1553,  1.2216,  1.3935,  ...,  0.4368, -0.6360, -0.7523]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 5.8412e-01,  5.1617e+00, -9.3508e-02,  ...,  9.9786e-02,\n",
      "          -7.3548e-01,  2.7650e+00],\n",
      "         [ 5.5439e-01,  5.1754e+00, -3.0827e-02,  ...,  1.1312e-01,\n",
      "          -6.9124e-01,  2.8477e+00],\n",
      "         [ 5.7300e-01,  5.1981e+00, -8.9784e-02,  ...,  1.1032e-01,\n",
      "          -7.3138e-01,  2.8310e+00],\n",
      "         ...,\n",
      "         [ 5.2069e-01,  5.1201e+00, -9.7723e-02,  ...,  8.0841e-02,\n",
      "          -6.9052e-01,  2.8624e+00],\n",
      "         [ 6.5090e-01,  5.1176e+00,  2.1435e-03,  ...,  8.5239e-02,\n",
      "          -7.7998e-01,  2.7948e+00],\n",
      "         [ 5.5427e-01,  5.1577e+00, -3.6368e-02,  ...,  1.0850e-01,\n",
      "          -7.6514e-01,  2.7244e+00]]], device='cuda:0'), tensor([[[ 5.8412e-01,  5.1617e+00, -9.3508e-02,  ...,  9.9786e-02,\n",
      "          -7.3548e-01,  2.7650e+00],\n",
      "         [ 5.5439e-01,  5.1754e+00, -3.0827e-02,  ...,  1.1312e-01,\n",
      "          -6.9124e-01,  2.8477e+00],\n",
      "         [ 5.7300e-01,  5.1981e+00, -8.9784e-02,  ...,  1.1032e-01,\n",
      "          -7.3138e-01,  2.8310e+00],\n",
      "         ...,\n",
      "         [ 5.2069e-01,  5.1201e+00, -9.7723e-02,  ...,  8.0841e-02,\n",
      "          -6.9052e-01,  2.8624e+00],\n",
      "         [ 6.5090e-01,  5.1176e+00,  2.1435e-03,  ...,  8.5239e-02,\n",
      "          -7.7998e-01,  2.7948e+00],\n",
      "         [ 5.5427e-01,  5.1577e+00, -3.6368e-02,  ...,  1.0850e-01,\n",
      "          -7.6514e-01,  2.7244e+00]]], device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [ 1.5423,  1.3695,  0.2024,  ...,  1.1263, -0.1566,  0.4851],\n",
      "         [ 0.3887,  0.9644, -0.0125,  ...,  1.6498,  0.1285,  0.7815],\n",
      "         [-0.3429,  0.5648, -0.3708,  ..., -0.0701,  0.3154,  1.2252]]],\n",
      "       device='cuda:0'), tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [ 1.5423,  1.3695,  0.2024,  ...,  1.1263, -0.1566,  0.4851],\n",
      "         [ 0.3887,  0.9644, -0.0125,  ...,  1.6498,  0.1285,  0.7815],\n",
      "         [-0.3429,  0.5648, -0.3708,  ..., -0.0701,  0.3154,  1.2252]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0765, -0.0363,  0.0563,  ..., -0.0252, -0.0850, -0.0920],\n",
      "         [ 0.0740, -0.0394,  0.0570,  ..., -0.0266, -0.0830, -0.0907],\n",
      "         [ 0.0769, -0.0388,  0.0570,  ..., -0.0249, -0.0805, -0.0909]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0765, -0.0363,  0.0563,  ..., -0.0252, -0.0850, -0.0920],\n",
      "         [ 0.0740, -0.0394,  0.0570,  ..., -0.0266, -0.0830, -0.0907],\n",
      "         [ 0.0769, -0.0388,  0.0570,  ..., -0.0249, -0.0805, -0.0909]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [ 0.0334,  0.8205,  0.9931,  ...,  1.9460,  1.0490,  2.9201],\n",
      "         [ 1.9605,  1.0873, -0.5955,  ...,  1.4918, -1.4942,  1.5458],\n",
      "         [-0.2498,  3.0449, -1.4046,  ...,  1.7728, -0.7220,  2.2398]]],\n",
      "       device='cuda:0'), tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [ 0.0334,  0.8205,  0.9931,  ...,  1.9460,  1.0490,  2.9201],\n",
      "         [ 1.9605,  1.0873, -0.5955,  ...,  1.4918, -1.4942,  1.5458],\n",
      "         [-0.2498,  3.0449, -1.4046,  ...,  1.7728, -0.7220,  2.2398]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [-0.6411, -0.5003, -0.5430,  ...,  2.3371,  1.4520,  1.6329],\n",
      "         [-0.5761,  0.4920, -0.7524,  ...,  1.0651, -0.5106, -2.0780],\n",
      "         [-0.1396, -0.1389, -0.0727,  ...,  0.3034,  0.0102, -0.2428]]],\n",
      "       device='cuda:0'), tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [-0.6411, -0.5003, -0.5430,  ...,  2.3371,  1.4520,  1.6329],\n",
      "         [-0.5761,  0.4920, -0.7524,  ...,  1.0651, -0.5106, -2.0780],\n",
      "         [-0.1396, -0.1389, -0.0727,  ...,  0.3034,  0.0102, -0.2428]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [-0.2146,  0.5029, -0.0201,  ...,  1.1974, -0.2169,  0.8882],\n",
      "         [ 0.7644,  1.3138, -1.0163,  ...,  1.3938, -0.0253,  1.4999],\n",
      "         [-0.0818,  0.2370,  0.1387,  ...,  0.8363, -0.1220, -0.1097]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [-0.2146,  0.5029, -0.0201,  ...,  1.1974, -0.2169,  0.8882],\n",
      "         [ 0.7644,  1.3138, -1.0163,  ...,  1.3938, -0.0253,  1.4999],\n",
      "         [-0.0818,  0.2370,  0.1387,  ...,  0.8363, -0.1220, -0.1097]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.5271,  0.0222, -3.5692,  ...,  1.8987, -3.1262, -1.3192],\n",
      "         [-0.9273,  0.5519, -3.6799,  ...,  1.6925, -2.9923, -1.3036],\n",
      "         [-1.3474,  0.5608, -3.5782,  ...,  1.7091, -2.9892, -1.3801]]],\n",
      "       device='cuda:0'), tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.5271,  0.0222, -3.5692,  ...,  1.8987, -3.1262, -1.3192],\n",
      "         [-0.9273,  0.5519, -3.6799,  ...,  1.6925, -2.9923, -1.3036],\n",
      "         [-1.3474,  0.5608, -3.5782,  ...,  1.7091, -2.9892, -1.3801]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [ 2.2145, -0.8802, -0.3198,  ...,  1.3654, -0.3255,  0.1158],\n",
      "         [-0.1103,  1.0516,  0.0429,  ..., -0.3292,  0.0025,  1.2684],\n",
      "         [-0.9371, -0.2077,  1.2094,  ...,  2.0999,  2.0371,  0.8348]]],\n",
      "       device='cuda:0'), tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [ 2.2145, -0.8802, -0.3198,  ...,  1.3654, -0.3255,  0.1158],\n",
      "         [-0.1103,  1.0516,  0.0429,  ..., -0.3292,  0.0025,  1.2684],\n",
      "         [-0.9371, -0.2077,  1.2094,  ...,  2.0999,  2.0371,  0.8348]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2970, -0.5274, -0.6764,  ...,  0.5290, -2.5886,  0.8450],\n",
      "         [-1.2499, -0.5035, -0.6524,  ...,  0.4962, -2.5935,  0.8530],\n",
      "         [-1.3080, -0.5118, -0.7209,  ...,  0.5182, -2.5895,  0.7837]]],\n",
      "       device='cuda:0'), tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2970, -0.5274, -0.6764,  ...,  0.5290, -2.5886,  0.8450],\n",
      "         [-1.2499, -0.5035, -0.6524,  ...,  0.4962, -2.5935,  0.8530],\n",
      "         [-1.3080, -0.5118, -0.7209,  ...,  0.5182, -2.5895,  0.7837]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [ 0.9220,  2.5272,  0.6091,  ...,  1.5551,  2.1635,  0.6333],\n",
      "         [-1.9137,  0.9841,  0.5117,  ...,  0.1367, -0.1602, -0.1327],\n",
      "         [ 0.9708,  0.9346, -0.3972,  ...,  1.0426,  0.5148,  1.6184]]],\n",
      "       device='cuda:0'), tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [ 0.9220,  2.5272,  0.6091,  ...,  1.5551,  2.1635,  0.6333],\n",
      "         [-1.9137,  0.9841,  0.5117,  ...,  0.1367, -0.1602, -0.1327],\n",
      "         [ 0.9708,  0.9346, -0.3972,  ...,  1.0426,  0.5148,  1.6184]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0068,  0.1073,  0.0383,  ...,  0.0741, -0.0111, -0.0334],\n",
      "         [ 0.0125,  0.1119,  0.0377,  ...,  0.0772, -0.0328, -0.0359],\n",
      "         [ 0.0178,  0.1074,  0.0264,  ...,  0.0807, -0.0177, -0.0351]]],\n",
      "       device='cuda:0'), tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0068,  0.1073,  0.0383,  ...,  0.0741, -0.0111, -0.0334],\n",
      "         [ 0.0125,  0.1119,  0.0377,  ...,  0.0772, -0.0328, -0.0359],\n",
      "         [ 0.0178,  0.1074,  0.0264,  ...,  0.0807, -0.0177, -0.0351]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [-1.2075,  0.9341, -0.9499,  ...,  1.1143,  0.1715, -0.4444],\n",
      "         [ 0.3603, -1.8275, -0.4007,  ...,  2.6117, -0.8798,  1.7764],\n",
      "         [-1.7746, -0.5645, -1.3128,  ...,  1.3926,  0.5752,  2.7308]]],\n",
      "       device='cuda:0'), tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [-1.2075,  0.9341, -0.9499,  ...,  1.1143,  0.1715, -0.4444],\n",
      "         [ 0.3603, -1.8275, -0.4007,  ...,  2.6117, -0.8798,  1.7764],\n",
      "         [-1.7746, -0.5645, -1.3128,  ...,  1.3926,  0.5752,  2.7308]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [-0.2412, -0.5636, -0.7130,  ...,  1.9913, -0.8533,  0.9646],\n",
      "         [-0.3872,  0.3360, -0.6804,  ...,  1.4084, -0.8531, -0.5282],\n",
      "         [ 0.6252,  0.5011,  0.4414,  ...,  1.2876, -0.9514, -1.5585]]],\n",
      "       device='cuda:0'), tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [-0.2412, -0.5636, -0.7130,  ...,  1.9913, -0.8533,  0.9646],\n",
      "         [-0.3872,  0.3360, -0.6804,  ...,  1.4084, -0.8531, -0.5282],\n",
      "         [ 0.6252,  0.5011,  0.4414,  ...,  1.2876, -0.9514, -1.5585]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [-0.3833,  0.5838, -0.3481,  ...,  0.0899, -0.7030,  0.3372],\n",
      "         [-1.7370,  1.1861,  0.3009,  ...,  0.2918,  0.9811,  0.9283],\n",
      "         [-0.5671,  2.9881, -0.4159,  ..., -0.4795, -0.0427,  0.8791]]],\n",
      "       device='cuda:0'), tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [-0.3833,  0.5838, -0.3481,  ...,  0.0899, -0.7030,  0.3372],\n",
      "         [-1.7370,  1.1861,  0.3009,  ...,  0.2918,  0.9811,  0.9283],\n",
      "         [-0.5671,  2.9881, -0.4159,  ..., -0.4795, -0.0427,  0.8791]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.6543, -0.8025,  1.6388,  ..., -3.2480,  0.6813, -0.3976],\n",
      "         [-2.4781, -0.4888,  1.5364,  ..., -3.2941,  1.1615, -0.5643],\n",
      "         [-2.1000, -1.3157,  1.6929,  ..., -2.9877,  0.7280, -0.3201]]],\n",
      "       device='cuda:0'), tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.6543, -0.8025,  1.6388,  ..., -3.2480,  0.6813, -0.3976],\n",
      "         [-2.4781, -0.4888,  1.5364,  ..., -3.2941,  1.1615, -0.5643],\n",
      "         [-2.1000, -1.3157,  1.6929,  ..., -2.9877,  0.7280, -0.3201]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [ 0.0813,  0.4251, -0.0702,  ...,  0.3437, -1.0339,  0.4422],\n",
      "         [-0.7275,  0.6066,  0.8779,  ..., -0.4733,  0.9741,  1.5294],\n",
      "         [ 0.4191, -0.1842, -0.2808,  ..., -0.0111, -0.7430,  1.2881]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [ 0.0813,  0.4251, -0.0702,  ...,  0.3437, -1.0339,  0.4422],\n",
      "         [-0.7275,  0.6066,  0.8779,  ..., -0.4733,  0.9741,  1.5294],\n",
      "         [ 0.4191, -0.1842, -0.2808,  ..., -0.0111, -0.7430,  1.2881]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4670,  1.5671, -0.1391,  ..., -0.3247, -0.0798,  2.3731],\n",
      "         [ 2.4441,  1.5192, -0.1698,  ..., -0.3473, -0.0372,  2.3564],\n",
      "         [ 2.4631,  1.5645, -0.1500,  ..., -0.3735, -0.0254,  2.3835]]],\n",
      "       device='cuda:0'), tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4670,  1.5671, -0.1391,  ..., -0.3247, -0.0798,  2.3731],\n",
      "         [ 2.4441,  1.5192, -0.1698,  ..., -0.3473, -0.0372,  2.3564],\n",
      "         [ 2.4631,  1.5645, -0.1500,  ..., -0.3735, -0.0254,  2.3835]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 0.1647,  1.9452,  0.2208,  ..., -0.5346,  1.0420,  1.1333],\n",
      "         [ 0.4734,  0.4776,  2.0903,  ...,  0.5979, -1.4931,  2.1360],\n",
      "         [-0.5686,  1.9520, -0.1516,  ...,  0.3263, -0.0630,  0.8650]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 0.1647,  1.9452,  0.2208,  ..., -0.5346,  1.0420,  1.1333],\n",
      "         [ 0.4734,  0.4776,  2.0903,  ...,  0.5979, -1.4931,  2.1360],\n",
      "         [-0.5686,  1.9520, -0.1516,  ...,  0.3263, -0.0630,  0.8650]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0228, -0.0019,  0.0236,  ..., -0.0109, -0.0073, -0.0177],\n",
      "         [ 0.0215, -0.0012,  0.0256,  ..., -0.0104, -0.0062, -0.0193],\n",
      "         [ 0.0226, -0.0013,  0.0233,  ..., -0.0098, -0.0064, -0.0191]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0228, -0.0019,  0.0236,  ..., -0.0109, -0.0073, -0.0177],\n",
      "         [ 0.0215, -0.0012,  0.0256,  ..., -0.0104, -0.0062, -0.0193],\n",
      "         [ 0.0226, -0.0013,  0.0233,  ..., -0.0098, -0.0064, -0.0191]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [-0.5515, -0.1442, -0.7014,  ..., -0.1107,  1.2126, -1.0937],\n",
      "         [-2.4054,  1.4284, -0.5559,  ...,  0.4100,  0.1249,  2.6183],\n",
      "         [ 0.3946,  0.1579, -0.3107,  ...,  1.8378, -1.2427,  1.6004]]],\n",
      "       device='cuda:0'), tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [-0.5515, -0.1442, -0.7014,  ..., -0.1107,  1.2126, -1.0937],\n",
      "         [-2.4054,  1.4284, -0.5559,  ...,  0.4100,  0.1249,  2.6183],\n",
      "         [ 0.3946,  0.1579, -0.3107,  ...,  1.8378, -1.2427,  1.6004]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 1.9042, -0.3354, -2.0942,  ..., -0.7946,  0.7781, -0.9313],\n",
      "         [ 1.0075, -1.1580, -1.9197,  ..., -0.8499,  0.7028, -1.0443],\n",
      "         [ 0.6638, -1.5328, -0.6944,  ..., -0.7418,  0.0254, -0.2339]]],\n",
      "       device='cuda:0'), tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 1.9042, -0.3354, -2.0942,  ..., -0.7946,  0.7781, -0.9313],\n",
      "         [ 1.0075, -1.1580, -1.9197,  ..., -0.8499,  0.7028, -1.0443],\n",
      "         [ 0.6638, -1.5328, -0.6944,  ..., -0.7418,  0.0254, -0.2339]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 4.1158e-01,  1.8964e+00, -7.0630e-01,  ...,  1.5088e+00,\n",
      "           9.1370e-01,  3.0234e+00],\n",
      "         [-4.6106e-01,  1.4388e+00,  6.8045e-03,  ...,  1.5706e+00,\n",
      "          -7.5419e-02,  1.3283e+00],\n",
      "         [ 2.4179e-01,  2.7891e+00, -1.9993e-02,  ...,  7.5039e-01,\n",
      "           2.0224e-01,  9.0036e-01]]], device='cuda:0'), tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 4.1158e-01,  1.8964e+00, -7.0630e-01,  ...,  1.5088e+00,\n",
      "           9.1370e-01,  3.0234e+00],\n",
      "         [-4.6106e-01,  1.4388e+00,  6.8045e-03,  ...,  1.5706e+00,\n",
      "          -7.5419e-02,  1.3283e+00],\n",
      "         [ 2.4179e-01,  2.7891e+00, -1.9993e-02,  ...,  7.5039e-01,\n",
      "           2.0224e-01,  9.0036e-01]]], device='cuda:0')), 'logits_attn': (tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.3928,  3.1342,  5.8622,  ..., -2.2587, -8.4404, -3.4299],\n",
      "         [ 4.3059,  3.1178,  5.4911,  ..., -2.0655, -8.1636, -3.5268],\n",
      "         [ 4.9573,  3.1009,  5.8898,  ..., -1.9343, -8.3967, -3.1887]]],\n",
      "       device='cuda:0'), tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.3928,  3.1342,  5.8622,  ..., -2.2587, -8.4404, -3.4299],\n",
      "         [ 4.3059,  3.1178,  5.4911,  ..., -2.0655, -8.1636, -3.5268],\n",
      "         [ 4.9573,  3.1009,  5.8898,  ..., -1.9343, -8.3967, -3.1887]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-1.9101, -0.3774,  0.2660,  ...,  1.0798,  0.3464,  0.6601],\n",
      "         [-0.4485,  1.0374,  2.0441,  ...,  0.3800, -0.8868,  0.9585],\n",
      "         [-0.1863,  1.2995,  1.2678,  ...,  1.0042,  0.3872,  0.5625]]],\n",
      "       device='cuda:0'), tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-1.9101, -0.3774,  0.2660,  ...,  1.0798,  0.3464,  0.6601],\n",
      "         [-0.4485,  1.0374,  2.0441,  ...,  0.3800, -0.8868,  0.9585],\n",
      "         [-0.1863,  1.2995,  1.2678,  ...,  1.0042,  0.3872,  0.5625]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5672, -8.7707,  4.9057,  ...,  5.1902,  2.4846,  3.4401],\n",
      "         [ 3.5702, -8.7701,  4.9010,  ...,  5.1897,  2.4779,  3.4402],\n",
      "         [ 3.5735, -8.7690,  4.9044,  ...,  5.1947,  2.4856,  3.4465]]],\n",
      "       device='cuda:0'), tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5672, -8.7707,  4.9057,  ...,  5.1902,  2.4846,  3.4401],\n",
      "         [ 3.5702, -8.7701,  4.9010,  ...,  5.1897,  2.4779,  3.4402],\n",
      "         [ 3.5735, -8.7690,  4.9044,  ...,  5.1947,  2.4856,  3.4465]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [ 0.4852,  1.2642,  0.1028,  ...,  1.4232,  0.0844,  0.4427],\n",
      "         [ 0.2819,  0.7053,  0.1219,  ...,  2.1049, -0.3963,  0.2587],\n",
      "         [-0.6756,  1.2708, -0.7442,  ..., -0.2187, -0.6866,  1.8464]]],\n",
      "       device='cuda:0'), tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [ 0.4852,  1.2642,  0.1028,  ...,  1.4232,  0.0844,  0.4427],\n",
      "         [ 0.2819,  0.7053,  0.1219,  ...,  2.1049, -0.3963,  0.2587],\n",
      "         [-0.6756,  1.2708, -0.7442,  ..., -0.2187, -0.6866,  1.8464]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0018, -0.0030, -0.0664,  ..., -0.0055,  0.0014, -0.0186],\n",
      "         [-0.0019, -0.0029, -0.0666,  ..., -0.0056,  0.0015, -0.0187],\n",
      "         [-0.0019, -0.0035, -0.0664,  ..., -0.0051,  0.0018, -0.0188]]],\n",
      "       device='cuda:0'), tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0018, -0.0030, -0.0664,  ..., -0.0055,  0.0014, -0.0186],\n",
      "         [-0.0019, -0.0029, -0.0666,  ..., -0.0056,  0.0015, -0.0187],\n",
      "         [-0.0019, -0.0035, -0.0664,  ..., -0.0051,  0.0018, -0.0188]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [-1.3181,  2.1265, -0.0653,  ..., -0.9710, -1.4034,  1.0225],\n",
      "         [ 0.3965,  2.1863,  0.5073,  ...,  1.4574, -1.2404,  1.0504],\n",
      "         [ 1.2032, -0.0713,  0.7685,  ...,  1.5156,  0.1653,  1.3799]]],\n",
      "       device='cuda:0'), tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [-1.3181,  2.1265, -0.0653,  ..., -0.9710, -1.4034,  1.0225],\n",
      "         [ 0.3965,  2.1863,  0.5073,  ...,  1.4574, -1.2404,  1.0504],\n",
      "         [ 1.2032, -0.0713,  0.7685,  ...,  1.5156,  0.1653,  1.3799]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 2.4147, -2.1521, -1.0721,  ...,  1.8259,  1.7171,  2.9310],\n",
      "         [ 0.8145, -2.7277, -0.4255,  ..., -0.3495,  0.4338,  0.9288],\n",
      "         [ 2.0607, -1.8763,  0.1464,  ...,  1.4331,  0.2304,  1.5671]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 2.4147, -2.1521, -1.0721,  ...,  1.8259,  1.7171,  2.9310],\n",
      "         [ 0.8145, -2.7277, -0.4255,  ..., -0.3495,  0.4338,  0.9288],\n",
      "         [ 2.0607, -1.8763,  0.1464,  ...,  1.4331,  0.2304,  1.5671]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [ 0.7232,  1.9982,  0.9696,  ...,  1.3252, -0.4021,  1.5167],\n",
      "         [-0.5776,  1.2132, -2.3405,  ...,  0.9500,  0.0480,  1.7099],\n",
      "         [ 0.0749,  0.7303,  1.2406,  ...,  1.3743, -0.2711,  1.4969]]],\n",
      "       device='cuda:0'), tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [ 0.7232,  1.9982,  0.9696,  ...,  1.3252, -0.4021,  1.5167],\n",
      "         [-0.5776,  1.2132, -2.3405,  ...,  0.9500,  0.0480,  1.7099],\n",
      "         [ 0.0749,  0.7303,  1.2406,  ...,  1.3743, -0.2711,  1.4969]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-5.2109, -1.8155,  0.0468,  ..., -0.4490,  2.4911,  1.7347],\n",
      "         [-4.8381, -1.6363, -0.1100,  ..., -0.5018,  2.5246,  1.6942],\n",
      "         [-5.0270, -1.6941,  0.0746,  ..., -0.5480,  2.8989,  1.9127]]],\n",
      "       device='cuda:0'), tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-5.2109, -1.8155,  0.0468,  ..., -0.4490,  2.4911,  1.7347],\n",
      "         [-4.8381, -1.6363, -0.1100,  ..., -0.5018,  2.5246,  1.6942],\n",
      "         [-5.0270, -1.6941,  0.0746,  ..., -0.5480,  2.8989,  1.9127]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [-0.6843,  0.8720,  0.7098,  ...,  1.4462, -1.2168,  0.9071],\n",
      "         [ 0.7608,  0.2484, -0.4635,  ...,  0.0074, -0.1833,  1.6117],\n",
      "         [-0.2784,  2.6198,  1.0142,  ...,  1.1660,  0.5771,  0.2846]]],\n",
      "       device='cuda:0'), tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [-0.6843,  0.8720,  0.7098,  ...,  1.4462, -1.2168,  0.9071],\n",
      "         [ 0.7608,  0.2484, -0.4635,  ...,  0.0074, -0.1833,  1.6117],\n",
      "         [-0.2784,  2.6198,  1.0142,  ...,  1.1660,  0.5771,  0.2846]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0324,  0.2185,  0.4823,  ..., -0.2776,  0.7004, -0.5789],\n",
      "         [ 0.0563,  0.2517,  0.4713,  ..., -0.2784,  0.6611, -0.5404],\n",
      "         [ 0.0581,  0.2150,  0.5034,  ..., -0.2977,  0.6557, -0.5486]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0324,  0.2185,  0.4823,  ..., -0.2776,  0.7004, -0.5789],\n",
      "         [ 0.0563,  0.2517,  0.4713,  ..., -0.2784,  0.6611, -0.5404],\n",
      "         [ 0.0581,  0.2150,  0.5034,  ..., -0.2977,  0.6557, -0.5486]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [ 0.0572,  3.0647, -0.1772,  ...,  0.2784,  0.5546,  2.9528],\n",
      "         [-0.2460,  2.3231, -0.5177,  ...,  0.5209, -1.1785, -0.1367],\n",
      "         [-1.0031,  1.5084, -0.2434,  ...,  1.7123,  1.0296,  1.6684]]],\n",
      "       device='cuda:0'), tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [ 0.0572,  3.0647, -0.1772,  ...,  0.2784,  0.5546,  2.9528],\n",
      "         [-0.2460,  2.3231, -0.5177,  ...,  0.5209, -1.1785, -0.1367],\n",
      "         [-1.0031,  1.5084, -0.2434,  ...,  1.7123,  1.0296,  1.6684]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0592, -0.0303,  0.0798,  ...,  0.0536,  0.0794, -0.0165],\n",
      "         [-0.0585, -0.0334,  0.0764,  ...,  0.0467,  0.0746, -0.0197],\n",
      "         [-0.0598, -0.0332,  0.0789,  ...,  0.0483,  0.0801, -0.0150]]],\n",
      "       device='cuda:0'), tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0592, -0.0303,  0.0798,  ...,  0.0536,  0.0794, -0.0165],\n",
      "         [-0.0585, -0.0334,  0.0764,  ...,  0.0467,  0.0746, -0.0197],\n",
      "         [-0.0598, -0.0332,  0.0789,  ...,  0.0483,  0.0801, -0.0150]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [ 0.7535,  0.6608,  1.2803,  ...,  2.2767,  0.6672,  1.1241],\n",
      "         [-0.4307,  0.6032, -0.7552,  ...,  2.0664, -0.9558,  2.6510],\n",
      "         [ 0.8924,  2.7294, -0.2137,  ...,  0.7839, -1.1307,  1.4069]]],\n",
      "       device='cuda:0'), tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [ 0.7535,  0.6608,  1.2803,  ...,  2.2767,  0.6672,  1.1241],\n",
      "         [-0.4307,  0.6032, -0.7552,  ...,  2.0664, -0.9558,  2.6510],\n",
      "         [ 0.8924,  2.7294, -0.2137,  ...,  0.7839, -1.1307,  1.4069]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [-2.6964, -0.9042, -1.5053,  ...,  1.8391,  0.8136, -1.6217],\n",
      "         [ 2.6137, -0.7480,  0.2975,  ...,  1.7221,  0.0667,  1.4090],\n",
      "         [ 0.1685, -1.1317, -0.3150,  ...,  2.7488,  0.5389, -0.3290]]],\n",
      "       device='cuda:0'), tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [-2.6964, -0.9042, -1.5053,  ...,  1.8391,  0.8136, -1.6217],\n",
      "         [ 2.6137, -0.7480,  0.2975,  ...,  1.7221,  0.0667,  1.4090],\n",
      "         [ 0.1685, -1.1317, -0.3150,  ...,  2.7488,  0.5389, -0.3290]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [ 0.6053,  1.3175, -0.0512,  ..., -0.4911,  0.8156, -0.1335],\n",
      "         [-1.5509,  1.7879, -1.3272,  ...,  0.0384,  0.7680,  1.0810],\n",
      "         [-0.9265,  2.0909, -0.1496,  ...,  0.8174, -0.9744,  1.9358]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [ 0.6053,  1.3175, -0.0512,  ..., -0.4911,  0.8156, -0.1335],\n",
      "         [-1.5509,  1.7879, -1.3272,  ...,  0.0384,  0.7680,  1.0810],\n",
      "         [-0.9265,  2.0909, -0.1496,  ...,  0.8174, -0.9744,  1.9358]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 0.8929, -0.0123,  0.8823,  ...,  0.1734, -0.0344,  0.3842],\n",
      "         [ 1.2740, -0.0746,  1.3113,  ...,  0.1061,  0.3392,  0.1251],\n",
      "         [ 1.0936,  0.0567,  1.0309,  ...,  0.0268,  0.2419,  0.1823]]],\n",
      "       device='cuda:0'), tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 0.8929, -0.0123,  0.8823,  ...,  0.1734, -0.0344,  0.3842],\n",
      "         [ 1.2740, -0.0746,  1.3113,  ...,  0.1061,  0.3392,  0.1251],\n",
      "         [ 1.0936,  0.0567,  1.0309,  ...,  0.0268,  0.2419,  0.1823]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-1.0206,  0.5225, -1.7650,  ...,  0.0134, -0.0158,  0.9337],\n",
      "         [-0.3329,  1.3059, -0.9689,  ...,  0.0645,  0.0650, -0.0192],\n",
      "         [ 0.7273,  2.2245,  0.7045,  ...,  2.5119,  0.1970,  1.3368]]],\n",
      "       device='cuda:0'), tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-1.0206,  0.5225, -1.7650,  ...,  0.0134, -0.0158,  0.9337],\n",
      "         [-0.3329,  1.3059, -0.9689,  ...,  0.0645,  0.0650, -0.0192],\n",
      "         [ 0.7273,  2.2245,  0.7045,  ...,  2.5119,  0.1970,  1.3368]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4684,  5.3807,  1.9489,  ...,  4.8459, -1.5287, -0.6168],\n",
      "         [ 2.4702,  5.3918,  1.9556,  ...,  4.8113, -1.5213, -0.6767],\n",
      "         [ 2.4918,  5.3594,  1.9657,  ...,  4.8191, -1.5275, -0.6444]]],\n",
      "       device='cuda:0'), tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4684,  5.3807,  1.9489,  ...,  4.8459, -1.5287, -0.6168],\n",
      "         [ 2.4702,  5.3918,  1.9556,  ...,  4.8113, -1.5213, -0.6767],\n",
      "         [ 2.4918,  5.3594,  1.9657,  ...,  4.8191, -1.5275, -0.6444]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-1.2929,  0.4593, -1.2880,  ..., -0.4409, -1.0227,  0.6558],\n",
      "         [-1.2214, -0.2297,  0.5168,  ...,  0.5624, -1.3398,  1.7919],\n",
      "         [ 0.1900,  1.1109,  0.3370,  ..., -0.3144,  0.1423,  0.8018]]],\n",
      "       device='cuda:0'), tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-1.2929,  0.4593, -1.2880,  ..., -0.4409, -1.0227,  0.6558],\n",
      "         [-1.2214, -0.2297,  0.5168,  ...,  0.5624, -1.3398,  1.7919],\n",
      "         [ 0.1900,  1.1109,  0.3370,  ..., -0.3144,  0.1423,  0.8018]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0225,  0.0644, -0.0197,  ..., -0.1150,  0.0311,  0.0271],\n",
      "         [-0.0219,  0.0631, -0.0210,  ..., -0.1158,  0.0348,  0.0251],\n",
      "         [-0.0243,  0.0628, -0.0206,  ..., -0.1146,  0.0310,  0.0277]]],\n",
      "       device='cuda:0'), tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0225,  0.0644, -0.0197,  ..., -0.1150,  0.0311,  0.0271],\n",
      "         [-0.0219,  0.0631, -0.0210,  ..., -0.1158,  0.0348,  0.0251],\n",
      "         [-0.0243,  0.0628, -0.0206,  ..., -0.1146,  0.0310,  0.0277]]],\n",
      "       device='cuda:0'))}]}]\n",
      "Step 100 - Last token probs (min/max): 0.003135629929602146 / 0.0529196560382843\n",
      "Step 150 - past_kv structure:  [{'left': [{'chunk_attn': (tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [-0.3786,  0.2613,  0.2713,  ...,  1.4112, -0.3376,  1.2326],\n",
      "         [-2.0497,  0.3575, -0.8248,  ..., -0.4756, -1.4745,  2.2528],\n",
      "         [-0.5331,  0.1327,  0.0112,  ...,  2.2460,  1.0294,  0.2650]]],\n",
      "       device='cuda:0'), tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [-0.3786,  0.2613,  0.2713,  ...,  1.4112, -0.3376,  1.2326],\n",
      "         [-2.0497,  0.3575, -0.8248,  ..., -0.4756, -1.4745,  2.2528],\n",
      "         [-0.5331,  0.1327,  0.0112,  ...,  2.2460,  1.0294,  0.2650]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'), tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 0.9425,  1.2661,  0.1899,  ...,  0.7227,  1.6146,  1.0959],\n",
      "         [ 0.3212,  0.4691,  0.3471,  ...,  1.1076, -0.5276,  2.9425],\n",
      "         [ 0.1825, -0.2595, -1.2704,  ...,  1.2910, -0.0428,  1.7050]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 0.9425,  1.2661,  0.1899,  ...,  0.7227,  1.6146,  1.0959],\n",
      "         [ 0.3212,  0.4691,  0.3471,  ...,  1.1076, -0.5276,  2.9425],\n",
      "         [ 0.1825, -0.2595, -1.2704,  ...,  1.2910, -0.0428,  1.7050]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9783, -0.4606, -7.4042,  ...,  5.6646,  1.2079, -0.2676],\n",
      "         [-4.9281, -0.4030, -7.2784,  ...,  5.6298,  1.2774, -0.3420],\n",
      "         [-5.0502, -0.3101, -7.2387,  ...,  5.5323,  1.3765, -0.2667]]],\n",
      "       device='cuda:0'), tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9783, -0.4606, -7.4042,  ...,  5.6646,  1.2079, -0.2676],\n",
      "         [-4.9281, -0.4030, -7.2784,  ...,  5.6298,  1.2774, -0.3420],\n",
      "         [-5.0502, -0.3101, -7.2387,  ...,  5.5323,  1.3765, -0.2667]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [-1.0164,  1.2099,  0.5739,  ...,  0.9001,  0.8733,  0.9040],\n",
      "         [-0.0615,  1.5844, -0.2271,  ...,  0.9042,  0.8783,  1.6147],\n",
      "         [ 1.0965,  2.2517,  0.1547,  ...,  0.2579, -0.4916,  1.3295]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [-1.0164,  1.2099,  0.5739,  ...,  0.9001,  0.8733,  0.9040],\n",
      "         [-0.0615,  1.5844, -0.2271,  ...,  0.9042,  0.8783,  1.6147],\n",
      "         [ 1.0965,  2.2517,  0.1547,  ...,  0.2579, -0.4916,  1.3295]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0461,  1.9544,  1.9748,  ...,  1.4791,  1.3011, -2.7920],\n",
      "         [ 3.0465,  1.9529,  1.9758,  ...,  1.4801,  1.3006, -2.7931],\n",
      "         [ 3.0470,  1.9541,  1.9744,  ...,  1.4801,  1.3017, -2.7930]]],\n",
      "       device='cuda:0'), tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0461,  1.9544,  1.9748,  ...,  1.4791,  1.3011, -2.7920],\n",
      "         [ 3.0465,  1.9529,  1.9758,  ...,  1.4801,  1.3006, -2.7931],\n",
      "         [ 3.0470,  1.9541,  1.9744,  ...,  1.4801,  1.3017, -2.7930]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 0.8302,  0.1285, -0.0774,  ...,  0.3944,  1.6176, -0.3669],\n",
      "         [ 1.4366,  1.0848, -0.2089,  ..., -0.0852,  0.1952,  2.3277],\n",
      "         [-1.0541,  3.0497,  1.5171,  ...,  2.5820,  0.1493,  0.5648]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 0.8302,  0.1285, -0.0774,  ...,  0.3944,  1.6176, -0.3669],\n",
      "         [ 1.4366,  1.0848, -0.2089,  ..., -0.0852,  0.1952,  2.3277],\n",
      "         [-1.0541,  3.0497,  1.5171,  ...,  2.5820,  0.1493,  0.5648]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0044,  0.0256,  0.0061,  ..., -0.0833, -0.0706,  0.0011],\n",
      "         [-0.0017,  0.0243,  0.0048,  ..., -0.0820, -0.0680,  0.0014],\n",
      "         [-0.0022,  0.0223,  0.0044,  ..., -0.0828, -0.0686,  0.0015]]],\n",
      "       device='cuda:0'), tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0044,  0.0256,  0.0061,  ..., -0.0833, -0.0706,  0.0011],\n",
      "         [-0.0017,  0.0243,  0.0048,  ..., -0.0820, -0.0680,  0.0014],\n",
      "         [-0.0022,  0.0223,  0.0044,  ..., -0.0828, -0.0686,  0.0015]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [-0.5542,  1.0521,  0.5567,  ...,  1.2406, -1.1754, -1.5987],\n",
      "         [-0.2069,  1.4114,  0.5428,  ...,  3.8500, -0.4840,  0.6255],\n",
      "         [-0.1528,  1.5568,  0.5822,  ...,  1.2843, -0.5872,  1.5611]]],\n",
      "       device='cuda:0'), tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [-0.5542,  1.0521,  0.5567,  ...,  1.2406, -1.1754, -1.5987],\n",
      "         [-0.2069,  1.4114,  0.5428,  ...,  3.8500, -0.4840,  0.6255],\n",
      "         [-0.1528,  1.5568,  0.5822,  ...,  1.2843, -0.5872,  1.5611]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'), tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [ 0.5343,  1.7959, -0.7988,  ...,  1.3924,  0.7611, -0.0063],\n",
      "         [-0.0211,  1.5176,  1.0572,  ...,  0.9023,  1.6843, -0.0386],\n",
      "         [-0.5303,  0.4597, -0.1946,  ...,  2.0720, -0.8573,  2.3085]]],\n",
      "       device='cuda:0'), tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [ 0.5343,  1.7959, -0.7988,  ...,  1.3924,  0.7611, -0.0063],\n",
      "         [-0.0211,  1.5176,  1.0572,  ...,  0.9023,  1.6843, -0.0386],\n",
      "         [-0.5303,  0.4597, -0.1946,  ...,  2.0720, -0.8573,  2.3085]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.7776, -0.3515, -0.3667,  ...,  1.3555, -0.3958,  0.2255],\n",
      "         [-0.9282, -0.3607, -0.0685,  ...,  1.3144, -0.3232,  0.2128],\n",
      "         [-1.0689, -0.1834, -0.2777,  ...,  1.3735, -0.3559, -0.0118]]],\n",
      "       device='cuda:0'), tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.7776, -0.3515, -0.3667,  ...,  1.3555, -0.3958,  0.2255],\n",
      "         [-0.9282, -0.3607, -0.0685,  ...,  1.3144, -0.3232,  0.2128],\n",
      "         [-1.0689, -0.1834, -0.2777,  ...,  1.3735, -0.3559, -0.0118]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [ 0.0085,  0.6436, -0.5094,  ...,  0.0198, -0.0426,  0.8350],\n",
      "         [-0.5378,  0.3613, -0.0159,  ...,  1.2645, -1.9977,  1.2427],\n",
      "         [ 0.7680,  0.7049,  0.5190,  ...,  0.9026,  1.4610, -1.1621]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [ 0.0085,  0.6436, -0.5094,  ...,  0.0198, -0.0426,  0.8350],\n",
      "         [-0.5378,  0.3613, -0.0159,  ...,  1.2645, -1.9977,  1.2427],\n",
      "         [ 0.7680,  0.7049,  0.5190,  ...,  0.9026,  1.4610, -1.1621]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3430,  0.4023,  0.0229,  ..., -0.4966,  0.5562, -0.2102],\n",
      "         [ 0.3238,  0.4043,  0.0436,  ..., -0.4929,  0.5752, -0.2313],\n",
      "         [ 0.3253,  0.3894,  0.0233,  ..., -0.4964,  0.5425, -0.2057]]],\n",
      "       device='cuda:0'), tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3430,  0.4023,  0.0229,  ..., -0.4966,  0.5562, -0.2102],\n",
      "         [ 0.3238,  0.4043,  0.0436,  ..., -0.4929,  0.5752, -0.2313],\n",
      "         [ 0.3253,  0.3894,  0.0233,  ..., -0.4964,  0.5425, -0.2057]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.2801,  1.7763, -1.1746,  ..., -0.1783, -0.0788,  1.8598],\n",
      "         [-0.2294,  1.8924,  1.1521,  ...,  1.1405,  2.2362,  1.4436],\n",
      "         [-1.4047,  1.1617,  0.6816,  ...,  1.8061, -0.3334,  1.2625]]],\n",
      "       device='cuda:0'), tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.2801,  1.7763, -1.1746,  ..., -0.1783, -0.0788,  1.8598],\n",
      "         [-0.2294,  1.8924,  1.1521,  ...,  1.1405,  2.2362,  1.4436],\n",
      "         [-1.4047,  1.1617,  0.6816,  ...,  1.8061, -0.3334,  1.2625]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0788,  0.0831, -0.0486,  ..., -0.1153, -0.0050, -0.0359],\n",
      "         [ 0.0723,  0.0740, -0.0248,  ..., -0.1219, -0.0092, -0.0314],\n",
      "         [ 0.0756,  0.0974, -0.0311,  ..., -0.1214, -0.0105, -0.0246]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0788,  0.0831, -0.0486,  ..., -0.1153, -0.0050, -0.0359],\n",
      "         [ 0.0723,  0.0740, -0.0248,  ..., -0.1219, -0.0092, -0.0314],\n",
      "         [ 0.0756,  0.0974, -0.0311,  ..., -0.1214, -0.0105, -0.0246]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [-0.4941,  0.2111,  1.0996,  ...,  1.1013, -0.6458, -0.6658],\n",
      "         [ 0.0145,  2.1382,  1.1205,  ..., -0.4022,  1.7263,  1.4305],\n",
      "         [ 1.5141,  1.8277, -1.7525,  ...,  0.3699, -0.9254,  1.6017]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [-0.4941,  0.2111,  1.0996,  ...,  1.1013, -0.6458, -0.6658],\n",
      "         [ 0.0145,  2.1382,  1.1205,  ..., -0.4022,  1.7263,  1.4305],\n",
      "         [ 1.5141,  1.8277, -1.7525,  ...,  0.3699, -0.9254,  1.6017]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [-0.3580, -1.2773, -0.0689,  ...,  2.1509, -0.3372,  0.0512],\n",
      "         [ 1.7652,  0.2266,  0.7726,  ..., -0.1286, -0.1280, -0.4405],\n",
      "         [-0.0140,  0.5031,  1.0149,  ...,  1.5693,  0.1083,  0.2123]]],\n",
      "       device='cuda:0'), tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [-0.3580, -1.2773, -0.0689,  ...,  2.1509, -0.3372,  0.0512],\n",
      "         [ 1.7652,  0.2266,  0.7726,  ..., -0.1286, -0.1280, -0.4405],\n",
      "         [-0.0140,  0.5031,  1.0149,  ...,  1.5693,  0.1083,  0.2123]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-0.7908,  2.3728, -1.4923,  ...,  1.6613,  0.8003,  1.1168],\n",
      "         [ 2.1964,  1.0030,  0.1121,  ...,  0.1853, -0.0761,  2.9577],\n",
      "         [ 0.8376,  3.5070, -0.1216,  ...,  2.1646, -0.9127,  1.0483]]],\n",
      "       device='cuda:0'), tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-0.7908,  2.3728, -1.4923,  ...,  1.6613,  0.8003,  1.1168],\n",
      "         [ 2.1964,  1.0030,  0.1121,  ...,  0.1853, -0.0761,  2.9577],\n",
      "         [ 0.8376,  3.5070, -0.1216,  ...,  2.1646, -0.9127,  1.0483]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.1479,  0.0919,  0.0203,  ..., -1.5409, -0.9179,  0.6470],\n",
      "         [-3.3488, -0.7399,  0.8302,  ..., -1.7088, -1.5416,  0.1566],\n",
      "         [-2.5990, -0.2161,  0.5623,  ..., -1.8649, -1.0856,  0.1966]]],\n",
      "       device='cuda:0'), tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.1479,  0.0919,  0.0203,  ..., -1.5409, -0.9179,  0.6470],\n",
      "         [-3.3488, -0.7399,  0.8302,  ..., -1.7088, -1.5416,  0.1566],\n",
      "         [-2.5990, -0.2161,  0.5623,  ..., -1.8649, -1.0856,  0.1966]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 0.4205,  0.4179,  1.1430,  ...,  0.3382, -0.2461,  0.8924],\n",
      "         [ 1.3904, -0.5316, -0.5007,  ...,  1.9610, -1.2287,  0.6481],\n",
      "         [-1.0429,  0.6319,  0.8185,  ...,  0.6973,  0.9548,  1.1275]]],\n",
      "       device='cuda:0'), tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 0.4205,  0.4179,  1.1430,  ...,  0.3382, -0.2461,  0.8924],\n",
      "         [ 1.3904, -0.5316, -0.5007,  ...,  1.9610, -1.2287,  0.6481],\n",
      "         [-1.0429,  0.6319,  0.8185,  ...,  0.6973,  0.9548,  1.1275]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.6217,  5.1774, -0.0758,  ...,  0.1006, -0.7217,  2.8724],\n",
      "         [ 0.6218,  5.1081, -0.0471,  ...,  0.0813, -0.7363,  2.8041],\n",
      "         [ 0.5346,  5.1069, -0.0727,  ...,  0.1217, -0.7382,  2.8658]]],\n",
      "       device='cuda:0'), tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.6217,  5.1774, -0.0758,  ...,  0.1006, -0.7217,  2.8724],\n",
      "         [ 0.6218,  5.1081, -0.0471,  ...,  0.0813, -0.7363,  2.8041],\n",
      "         [ 0.5346,  5.1069, -0.0727,  ...,  0.1217, -0.7382,  2.8658]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [-0.4923,  1.7561,  0.7192,  ..., -0.3805, -0.6111, -0.6957],\n",
      "         [ 0.9741,  1.4629, -0.7050,  ...,  1.5009, -1.9216,  0.0498],\n",
      "         [ 0.2721,  0.7410, -0.3996,  ...,  2.4842, -0.1296,  3.5448]]],\n",
      "       device='cuda:0'), tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [-0.4923,  1.7561,  0.7192,  ..., -0.3805, -0.6111, -0.6957],\n",
      "         [ 0.9741,  1.4629, -0.7050,  ...,  1.5009, -1.9216,  0.0498],\n",
      "         [ 0.2721,  0.7410, -0.3996,  ...,  2.4842, -0.1296,  3.5448]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0741, -0.0392,  0.0599,  ..., -0.0230, -0.0825, -0.0911],\n",
      "         [ 0.0759, -0.0381,  0.0581,  ..., -0.0289, -0.0833, -0.0920],\n",
      "         [ 0.0763, -0.0390,  0.0566,  ..., -0.0273, -0.0799, -0.0923]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0741, -0.0392,  0.0599,  ..., -0.0230, -0.0825, -0.0911],\n",
      "         [ 0.0759, -0.0381,  0.0581,  ..., -0.0289, -0.0833, -0.0920],\n",
      "         [ 0.0763, -0.0390,  0.0566,  ..., -0.0273, -0.0799, -0.0923]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [-0.3842,  1.7871, -0.0484,  ...,  1.6215,  0.6577,  2.2080],\n",
      "         [ 1.1267,  2.0171, -0.1890,  ...,  1.6493, -0.0297, -0.2860],\n",
      "         [-1.3995,  2.2608,  0.2162,  ...,  0.5475,  0.5002,  1.7002]]],\n",
      "       device='cuda:0'), tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [-0.3842,  1.7871, -0.0484,  ...,  1.6215,  0.6577,  2.2080],\n",
      "         [ 1.1267,  2.0171, -0.1890,  ...,  1.6493, -0.0297, -0.2860],\n",
      "         [-1.3995,  2.2608,  0.2162,  ...,  0.5475,  0.5002,  1.7002]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [-1.2361,  0.6869,  0.6268,  ...,  0.4198,  0.9149, -0.5322],\n",
      "         [ 0.8505,  1.3425, -0.9706,  ..., -1.1015, -0.7775, -1.4762],\n",
      "         [-0.5764,  0.5819,  0.7136,  ...,  1.2152, -0.2247,  1.7040]]],\n",
      "       device='cuda:0'), tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [-1.2361,  0.6869,  0.6268,  ...,  0.4198,  0.9149, -0.5322],\n",
      "         [ 0.8505,  1.3425, -0.9706,  ..., -1.1015, -0.7775, -1.4762],\n",
      "         [-0.5764,  0.5819,  0.7136,  ...,  1.2152, -0.2247,  1.7040]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.6673,  0.0795, -1.6989,  ...,  1.4630, -0.7839,  1.6244],\n",
      "         [-0.2603,  1.2171, -1.8479,  ..., -0.2356, -1.9889,  1.2555],\n",
      "         [-1.2073,  1.3849,  0.4869,  ...,  1.7464,  1.7099,  1.8392]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.6673,  0.0795, -1.6989,  ...,  1.4630, -0.7839,  1.6244],\n",
      "         [-0.2603,  1.2171, -1.8479,  ..., -0.2356, -1.9889,  1.2555],\n",
      "         [-1.2073,  1.3849,  0.4869,  ...,  1.7464,  1.7099,  1.8392]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.2498,  0.8514, -3.8997,  ...,  1.7241, -2.8168, -1.5665],\n",
      "         [-1.1954,  0.8065, -3.8627,  ...,  1.6417, -3.3037, -1.7421],\n",
      "         [-1.3898,  0.8540, -3.6899,  ...,  1.3314, -2.9935, -1.7976]]],\n",
      "       device='cuda:0'), tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.2498,  0.8514, -3.8997,  ...,  1.7241, -2.8168, -1.5665],\n",
      "         [-1.1954,  0.8065, -3.8627,  ...,  1.6417, -3.3037, -1.7421],\n",
      "         [-1.3898,  0.8540, -3.6899,  ...,  1.3314, -2.9935, -1.7976]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-0.5765,  1.7233, -0.5454,  ...,  0.3016, -0.4336,  1.0516],\n",
      "         [ 0.0999, -0.3250, -0.4963,  ...,  2.7057,  2.7520,  0.6587],\n",
      "         [ 0.5831,  1.0703, -0.9024,  ...,  0.5533, -2.9192,  1.4245]]],\n",
      "       device='cuda:0'), tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-0.5765,  1.7233, -0.5454,  ...,  0.3016, -0.4336,  1.0516],\n",
      "         [ 0.0999, -0.3250, -0.4963,  ...,  2.7057,  2.7520,  0.6587],\n",
      "         [ 0.5831,  1.0703, -0.9024,  ...,  0.5533, -2.9192,  1.4245]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.3128, -0.4919, -0.6662,  ...,  0.5276, -2.5945,  0.8275],\n",
      "         [-1.3115, -0.4886, -0.6831,  ...,  0.5036, -2.5818,  0.7955],\n",
      "         [-1.3067, -0.4784, -0.6804,  ...,  0.4963, -2.5876,  0.7668]]],\n",
      "       device='cuda:0'), tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.3128, -0.4919, -0.6662,  ...,  0.5276, -2.5945,  0.8275],\n",
      "         [-1.3115, -0.4886, -0.6831,  ...,  0.5036, -2.5818,  0.7955],\n",
      "         [-1.3067, -0.4784, -0.6804,  ...,  0.4963, -2.5876,  0.7668]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [ 2.0904,  1.1006, -0.6872,  ...,  1.2432,  0.2457,  0.0294],\n",
      "         [-1.3795,  0.2406,  1.1802,  ...,  1.5335,  1.9258,  0.2426],\n",
      "         [ 0.2114, -0.4905,  0.0054,  ...,  0.0213, -0.3605, -0.5709]]],\n",
      "       device='cuda:0'), tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [ 2.0904,  1.1006, -0.6872,  ...,  1.2432,  0.2457,  0.0294],\n",
      "         [-1.3795,  0.2406,  1.1802,  ...,  1.5335,  1.9258,  0.2426],\n",
      "         [ 0.2114, -0.4905,  0.0054,  ...,  0.0213, -0.3605, -0.5709]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0049,  0.1019,  0.0326,  ...,  0.0763, -0.0242, -0.0359],\n",
      "         [ 0.0119,  0.1078,  0.0390,  ...,  0.0724, -0.0286, -0.0371],\n",
      "         [ 0.0151,  0.1133,  0.0310,  ...,  0.0738, -0.0290, -0.0366]]],\n",
      "       device='cuda:0'), tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0049,  0.1019,  0.0326,  ...,  0.0763, -0.0242, -0.0359],\n",
      "         [ 0.0119,  0.1078,  0.0390,  ...,  0.0724, -0.0286, -0.0371],\n",
      "         [ 0.0151,  0.1133,  0.0310,  ...,  0.0738, -0.0290, -0.0366]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 1.2028,  1.8399, -1.6998,  ..., -0.3618, -0.0407,  1.4145],\n",
      "         [-0.2614,  1.4410, -0.8118,  ...,  1.2802, -0.1166,  1.5517],\n",
      "         [ 0.4724, -0.3730, -0.1483,  ...,  0.9991,  1.1855,  0.1786]]],\n",
      "       device='cuda:0'), tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 1.2028,  1.8399, -1.6998,  ..., -0.3618, -0.0407,  1.4145],\n",
      "         [-0.2614,  1.4410, -0.8118,  ...,  1.2802, -0.1166,  1.5517],\n",
      "         [ 0.4724, -0.3730, -0.1483,  ...,  0.9991,  1.1855,  0.1786]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [-0.0953,  1.0984,  0.8733,  ...,  2.3577,  0.4420, -2.3220],\n",
      "         [ 0.6325, -0.3672,  1.1280,  ...,  1.1694, -0.6510, -1.3037],\n",
      "         [-0.9592,  0.7178, -0.1232,  ...,  0.9652, -0.5272, -0.1652]]],\n",
      "       device='cuda:0'), tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [-0.0953,  1.0984,  0.8733,  ...,  2.3577,  0.4420, -2.3220],\n",
      "         [ 0.6325, -0.3672,  1.1280,  ...,  1.1694, -0.6510, -1.3037],\n",
      "         [-0.9592,  0.7178, -0.1232,  ...,  0.9652, -0.5272, -0.1652]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [-0.2798,  1.4046, -1.3536,  ...,  0.1445,  0.8028,  2.3290],\n",
      "         [ 0.0228,  0.5601, -0.2903,  ...,  0.5073, -2.0030,  0.1084],\n",
      "         [-0.7532,  1.2689,  0.1432,  ...,  1.0526,  1.4857, -0.1648]]],\n",
      "       device='cuda:0'), tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [-0.2798,  1.4046, -1.3536,  ...,  0.1445,  0.8028,  2.3290],\n",
      "         [ 0.0228,  0.5601, -0.2903,  ...,  0.5073, -2.0030,  0.1084],\n",
      "         [-0.7532,  1.2689,  0.1432,  ...,  1.0526,  1.4857, -0.1648]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.2553, -0.8117,  1.6709,  ..., -3.2135,  0.7787, -0.5303],\n",
      "         [-2.1758, -0.8421,  1.5549,  ..., -3.0706,  0.7600, -0.7034],\n",
      "         [-2.3057, -0.7294,  1.5831,  ..., -3.0929,  1.1649, -0.4660]]],\n",
      "       device='cuda:0'), tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.2553, -0.8117,  1.6709,  ..., -3.2135,  0.7787, -0.5303],\n",
      "         [-2.1758, -0.8421,  1.5549,  ..., -3.0706,  0.7600, -0.7034],\n",
      "         [-2.3057, -0.7294,  1.5831,  ..., -3.0929,  1.1649, -0.4660]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [-1.1787,  0.1048, -1.3621,  ..., -0.0444,  0.3257,  1.1127],\n",
      "         [ 1.4774,  0.2975,  0.9374,  ...,  1.4492,  1.0125,  2.3092],\n",
      "         [ 1.0543,  0.3949, -0.0138,  ...,  1.0322, -0.5592,  0.7687]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [-1.1787,  0.1048, -1.3621,  ..., -0.0444,  0.3257,  1.1127],\n",
      "         [ 1.4774,  0.2975,  0.9374,  ...,  1.4492,  1.0125,  2.3092],\n",
      "         [ 1.0543,  0.3949, -0.0138,  ...,  1.0322, -0.5592,  0.7687]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4262,  1.5094, -0.1076,  ..., -0.3883, -0.0593,  2.3822],\n",
      "         [ 2.4733,  1.5350, -0.1000,  ..., -0.3243, -0.0630,  2.3787],\n",
      "         [ 2.3984,  1.5605, -0.1939,  ..., -0.4064, -0.0204,  2.3538]]],\n",
      "       device='cuda:0'), tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4262,  1.5094, -0.1076,  ..., -0.3883, -0.0593,  2.3822],\n",
      "         [ 2.4733,  1.5350, -0.1000,  ..., -0.3243, -0.0630,  2.3787],\n",
      "         [ 2.3984,  1.5605, -0.1939,  ..., -0.4064, -0.0204,  2.3538]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 1.0750,  4.2051, -1.0006,  ..., -0.2078, -2.1628,  1.5025],\n",
      "         [ 1.8874,  1.6306, -0.5794,  ...,  1.0505,  0.1394,  0.7129],\n",
      "         [-0.2228,  3.1935, -0.7217,  ...,  1.8995,  0.2675,  0.8441]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 1.0750,  4.2051, -1.0006,  ..., -0.2078, -2.1628,  1.5025],\n",
      "         [ 1.8874,  1.6306, -0.5794,  ...,  1.0505,  0.1394,  0.7129],\n",
      "         [-0.2228,  3.1935, -0.7217,  ...,  1.8995,  0.2675,  0.8441]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0224, -0.0004,  0.0231,  ..., -0.0096, -0.0067, -0.0191],\n",
      "         [ 0.0233, -0.0010,  0.0238,  ..., -0.0115, -0.0080, -0.0195],\n",
      "         [ 0.0235, -0.0020,  0.0232,  ..., -0.0107, -0.0058, -0.0178]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0224, -0.0004,  0.0231,  ..., -0.0096, -0.0067, -0.0191],\n",
      "         [ 0.0233, -0.0010,  0.0238,  ..., -0.0115, -0.0080, -0.0195],\n",
      "         [ 0.0235, -0.0020,  0.0232,  ..., -0.0107, -0.0058, -0.0178]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [ 0.6482,  0.6368, -0.0434,  ...,  1.4160,  0.4407,  0.7362],\n",
      "         [-0.8313,  1.6666, -0.1858,  ...,  1.3449,  0.1141,  1.8689],\n",
      "         [ 1.0897, -0.2098, -0.0622,  ...,  1.6426, -0.1117,  0.2976]]],\n",
      "       device='cuda:0'), tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [ 0.6482,  0.6368, -0.0434,  ...,  1.4160,  0.4407,  0.7362],\n",
      "         [-0.8313,  1.6666, -0.1858,  ...,  1.3449,  0.1141,  1.8689],\n",
      "         [ 1.0897, -0.2098, -0.0622,  ...,  1.6426, -0.1117,  0.2976]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [-1.2727,  1.3695, -1.3563,  ..., -1.2765,  0.5662, -0.3564],\n",
      "         [ 1.2753, -1.1030, -1.2793,  ...,  0.1414, -0.9403, -0.1676],\n",
      "         [ 1.3732, -1.9223, -1.1412,  ..., -0.0880,  0.7353,  0.1738]]],\n",
      "       device='cuda:0'), tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [-1.2727,  1.3695, -1.3563,  ..., -1.2765,  0.5662, -0.3564],\n",
      "         [ 1.2753, -1.1030, -1.2793,  ...,  0.1414, -0.9403, -0.1676],\n",
      "         [ 1.3732, -1.9223, -1.1412,  ..., -0.0880,  0.7353,  0.1738]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 1.9896e-01,  1.0462e+00, -9.6888e-01,  ...,  1.8141e+00,\n",
      "          -6.3250e-02,  7.6867e-01],\n",
      "         [-1.0257e+00,  2.7007e-01, -9.4374e-01,  ...,  1.1279e-01,\n",
      "           1.0029e+00,  2.2277e-01],\n",
      "         [ 2.4973e-01,  2.1021e-01, -4.2720e-01,  ...,  2.6839e+00,\n",
      "           4.0048e-01,  1.7301e-01]]], device='cuda:0'), tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 1.9896e-01,  1.0462e+00, -9.6888e-01,  ...,  1.8141e+00,\n",
      "          -6.3250e-02,  7.6867e-01],\n",
      "         [-1.0257e+00,  2.7007e-01, -9.4374e-01,  ...,  1.1279e-01,\n",
      "           1.0029e+00,  2.2277e-01],\n",
      "         [ 2.4973e-01,  2.1021e-01, -4.2720e-01,  ...,  2.6839e+00,\n",
      "           4.0048e-01,  1.7301e-01]]], device='cuda:0')), 'logits_attn': (tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.7874,  2.8331,  6.0363,  ..., -1.9804, -8.4913, -3.3182],\n",
      "         [ 4.8180,  2.9804,  5.9137,  ..., -2.0965, -8.2434, -3.3602],\n",
      "         [ 4.6580,  3.0844,  5.6280,  ..., -1.9939, -8.3098, -3.4282]]],\n",
      "       device='cuda:0'), tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.7874,  2.8331,  6.0363,  ..., -1.9804, -8.4913, -3.3182],\n",
      "         [ 4.8180,  2.9804,  5.9137,  ..., -2.0965, -8.2434, -3.3602],\n",
      "         [ 4.6580,  3.0844,  5.6280,  ..., -1.9939, -8.3098, -3.4282]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.2008,  0.4136, -1.1084,  ...,  0.6887,  0.6182,  0.7694],\n",
      "         [-1.1914, -0.1770,  0.7906,  ..., -0.6219, -0.9922,  1.9965],\n",
      "         [ 0.0209,  2.0087, -0.1137,  ...,  1.0482,  0.4740,  2.0720]]],\n",
      "       device='cuda:0'), tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.2008,  0.4136, -1.1084,  ...,  0.6887,  0.6182,  0.7694],\n",
      "         [-1.1914, -0.1770,  0.7906,  ..., -0.6219, -0.9922,  1.9965],\n",
      "         [ 0.0209,  2.0087, -0.1137,  ...,  1.0482,  0.4740,  2.0720]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5730, -8.7684,  4.9025,  ...,  5.1960,  2.4796,  3.4403],\n",
      "         [ 3.5710, -8.7674,  4.9021,  ...,  5.1923,  2.4812,  3.4378],\n",
      "         [ 3.5725, -8.7706,  4.9039,  ...,  5.1947,  2.4740,  3.4413]]],\n",
      "       device='cuda:0'), tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5730, -8.7684,  4.9025,  ...,  5.1960,  2.4796,  3.4403],\n",
      "         [ 3.5710, -8.7674,  4.9021,  ...,  5.1923,  2.4812,  3.4378],\n",
      "         [ 3.5725, -8.7706,  4.9039,  ...,  5.1947,  2.4740,  3.4413]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 6.7053e-01,  1.7680e+00,  1.1601e+00,  ...,  2.0022e+00,\n",
      "          -7.7514e-02,  1.3642e+00],\n",
      "         [-1.9365e+00,  6.9702e-01, -5.2527e-01,  ..., -6.9341e-01,\n",
      "          -8.3838e-01,  2.9927e+00],\n",
      "         [-9.4992e-01,  1.0665e+00,  5.5727e-01,  ..., -6.1645e-01,\n",
      "          -8.0557e-01,  1.1445e+00],\n",
      "         ...,\n",
      "         [ 2.4312e+00,  1.8004e+00,  1.8190e+00,  ...,  2.3960e-01,\n",
      "          -1.2073e+00,  1.4532e+00],\n",
      "         [ 1.6955e-01,  1.2740e+00, -1.0993e-01,  ...,  1.2081e+00,\n",
      "          -1.3492e+00,  2.1223e+00],\n",
      "         [-1.2477e-03,  3.7741e-01, -2.0954e+00,  ...,  1.2535e+00,\n",
      "          -5.5139e-01,  6.2097e-01]]], device='cuda:0'), tensor([[[ 6.7053e-01,  1.7680e+00,  1.1601e+00,  ...,  2.0022e+00,\n",
      "          -7.7514e-02,  1.3642e+00],\n",
      "         [-1.9365e+00,  6.9702e-01, -5.2527e-01,  ..., -6.9341e-01,\n",
      "          -8.3838e-01,  2.9927e+00],\n",
      "         [-9.4992e-01,  1.0665e+00,  5.5727e-01,  ..., -6.1645e-01,\n",
      "          -8.0557e-01,  1.1445e+00],\n",
      "         ...,\n",
      "         [ 2.4312e+00,  1.8004e+00,  1.8190e+00,  ...,  2.3960e-01,\n",
      "          -1.2073e+00,  1.4532e+00],\n",
      "         [ 1.6955e-01,  1.2740e+00, -1.0993e-01,  ...,  1.2081e+00,\n",
      "          -1.3492e+00,  2.1223e+00],\n",
      "         [-1.2477e-03,  3.7741e-01, -2.0954e+00,  ...,  1.2535e+00,\n",
      "          -5.5139e-01,  6.2097e-01]]], device='cuda:0')), 'logits_attn': (tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0017, -0.0031, -0.0665,  ..., -0.0053,  0.0017, -0.0189],\n",
      "         [-0.0016, -0.0030, -0.0666,  ..., -0.0056,  0.0022, -0.0190],\n",
      "         [-0.0019, -0.0031, -0.0666,  ..., -0.0054,  0.0023, -0.0189]]],\n",
      "       device='cuda:0'), tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0017, -0.0031, -0.0665,  ..., -0.0053,  0.0017, -0.0189],\n",
      "         [-0.0016, -0.0030, -0.0666,  ..., -0.0056,  0.0022, -0.0190],\n",
      "         [-0.0019, -0.0031, -0.0666,  ..., -0.0054,  0.0023, -0.0189]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [-0.5065, -1.8516,  0.1342,  ..., -0.1734,  0.4498,  1.0669],\n",
      "         [-2.1098,  1.9596,  0.2534,  ...,  0.9161,  0.4201,  0.6067],\n",
      "         [-0.0595,  0.8153,  1.7369,  ...,  1.8262,  0.2283, -0.4620]]],\n",
      "       device='cuda:0'), tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [-0.5065, -1.8516,  0.1342,  ..., -0.1734,  0.4498,  1.0669],\n",
      "         [-2.1098,  1.9596,  0.2534,  ...,  0.9161,  0.4201,  0.6067],\n",
      "         [-0.0595,  0.8153,  1.7369,  ...,  1.8262,  0.2283, -0.4620]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 1.2921, -3.7167,  1.6597,  ..., -0.0392,  2.4077,  2.0825],\n",
      "         [ 0.8650, -0.3644,  1.5017,  ...,  0.8738,  1.2565,  0.4211],\n",
      "         [ 3.5657, -2.2692,  0.0495,  ...,  0.5339,  0.6759,  2.1614]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 1.2921, -3.7167,  1.6597,  ..., -0.0392,  2.4077,  2.0825],\n",
      "         [ 0.8650, -0.3644,  1.5017,  ...,  0.8738,  1.2565,  0.4211],\n",
      "         [ 3.5657, -2.2692,  0.0495,  ...,  0.5339,  0.6759,  2.1614]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [ 0.3080,  0.7754,  0.2391,  ...,  1.6707, -0.1370,  2.2508],\n",
      "         [-0.7269,  0.8431, -1.1111,  ...,  0.6693,  0.2488,  2.5104],\n",
      "         [-2.0782,  3.3792,  1.3183,  ...,  0.2648,  0.8228,  0.2480]]],\n",
      "       device='cuda:0'), tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [ 0.3080,  0.7754,  0.2391,  ...,  1.6707, -0.1370,  2.2508],\n",
      "         [-0.7269,  0.8431, -1.1111,  ...,  0.6693,  0.2488,  2.5104],\n",
      "         [-2.0782,  3.3792,  1.3183,  ...,  0.2648,  0.8228,  0.2480]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.7291, -1.9673, -0.0262,  ..., -0.3545,  2.5485,  1.7692],\n",
      "         [-4.7327, -1.7503,  0.1876,  ..., -0.2532,  2.8199,  1.7792],\n",
      "         [-4.8779, -1.5717, -0.0058,  ..., -0.4415,  2.8390,  1.9185]]],\n",
      "       device='cuda:0'), tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.7291, -1.9673, -0.0262,  ..., -0.3545,  2.5485,  1.7692],\n",
      "         [-4.7327, -1.7503,  0.1876,  ..., -0.2532,  2.8199,  1.7792],\n",
      "         [-4.8779, -1.5717, -0.0058,  ..., -0.4415,  2.8390,  1.9185]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [ 1.5228,  4.8440,  1.4537,  ..., -0.0508,  0.0137,  0.9401],\n",
      "         [ 0.4122,  0.8185,  0.9597,  ...,  0.7288,  0.4999,  1.6032],\n",
      "         [-0.2375,  2.2240,  0.5039,  ...,  2.4771,  0.3446,  0.9077]]],\n",
      "       device='cuda:0'), tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [ 1.5228,  4.8440,  1.4537,  ..., -0.0508,  0.0137,  0.9401],\n",
      "         [ 0.4122,  0.8185,  0.9597,  ...,  0.7288,  0.4999,  1.6032],\n",
      "         [-0.2375,  2.2240,  0.5039,  ...,  2.4771,  0.3446,  0.9077]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0164,  0.1988,  0.4677,  ..., -0.2622,  0.6740, -0.5980],\n",
      "         [ 0.0191,  0.2003,  0.4407,  ..., -0.2963,  0.7099, -0.5937],\n",
      "         [ 0.0155,  0.2351,  0.4778,  ..., -0.2923,  0.7424, -0.5568]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0164,  0.1988,  0.4677,  ..., -0.2622,  0.6740, -0.5980],\n",
      "         [ 0.0191,  0.2003,  0.4407,  ..., -0.2963,  0.7099, -0.5937],\n",
      "         [ 0.0155,  0.2351,  0.4778,  ..., -0.2923,  0.7424, -0.5568]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.4980,  1.4522, -0.1043,  ...,  0.0773,  1.8442,  2.2470],\n",
      "         [-1.0444,  2.0261, -2.1195,  ...,  0.6494, -1.6710,  1.4687],\n",
      "         [-0.5129,  1.4609, -0.4999,  ...,  2.1661,  0.5620,  1.6456]]],\n",
      "       device='cuda:0'), tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.4980,  1.4522, -0.1043,  ...,  0.0773,  1.8442,  2.2470],\n",
      "         [-1.0444,  2.0261, -2.1195,  ...,  0.6494, -1.6710,  1.4687],\n",
      "         [-0.5129,  1.4609, -0.4999,  ...,  2.1661,  0.5620,  1.6456]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0575, -0.0285,  0.0776,  ...,  0.0563,  0.0780, -0.0161],\n",
      "         [-0.0591, -0.0326,  0.0772,  ...,  0.0530,  0.0743, -0.0166],\n",
      "         [-0.0616, -0.0320,  0.0823,  ...,  0.0502,  0.0802, -0.0169]]],\n",
      "       device='cuda:0'), tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0575, -0.0285,  0.0776,  ...,  0.0563,  0.0780, -0.0161],\n",
      "         [-0.0591, -0.0326,  0.0772,  ...,  0.0530,  0.0743, -0.0166],\n",
      "         [-0.0616, -0.0320,  0.0823,  ...,  0.0502,  0.0802, -0.0169]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [ 0.0618,  0.8627,  0.0529,  ...,  0.6008,  1.3686,  0.8050],\n",
      "         [ 0.8081, -0.0161,  0.4583,  ...,  1.8389, -0.9342,  3.2774],\n",
      "         [ 0.0277,  0.8335,  0.4182,  ...,  1.6713,  3.2434,  1.4751]]],\n",
      "       device='cuda:0'), tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [ 0.0618,  0.8627,  0.0529,  ...,  0.6008,  1.3686,  0.8050],\n",
      "         [ 0.8081, -0.0161,  0.4583,  ...,  1.8389, -0.9342,  3.2774],\n",
      "         [ 0.0277,  0.8335,  0.4182,  ...,  1.6713,  3.2434,  1.4751]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [-1.2207, -0.4878,  0.5764,  ...,  0.3674,  0.7087, -0.9390],\n",
      "         [-1.7706,  0.5968,  1.2689,  ...,  1.2996,  0.8917,  0.2142],\n",
      "         [-0.5985, -1.3667, -1.5387,  ...,  2.3846,  1.6024,  0.4590]]],\n",
      "       device='cuda:0'), tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [-1.2207, -0.4878,  0.5764,  ...,  0.3674,  0.7087, -0.9390],\n",
      "         [-1.7706,  0.5968,  1.2689,  ...,  1.2996,  0.8917,  0.2142],\n",
      "         [-0.5985, -1.3667, -1.5387,  ...,  2.3846,  1.6024,  0.4590]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [-1.2190,  0.5816, -0.9230,  ...,  1.6834,  1.6615, -0.6899],\n",
      "         [ 0.5357,  0.4601, -1.1222,  ...,  1.3527, -0.7086, -0.4855],\n",
      "         [-0.3229,  2.0890,  0.5304,  ...,  2.4011, -0.8463,  0.8240]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [-1.2190,  0.5816, -0.9230,  ...,  1.6834,  1.6615, -0.6899],\n",
      "         [ 0.5357,  0.4601, -1.1222,  ...,  1.3527, -0.7086, -0.4855],\n",
      "         [-0.3229,  2.0890,  0.5304,  ...,  2.4011, -0.8463,  0.8240]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 0.8868,  0.1752,  0.7539,  ...,  0.2247,  0.1353,  0.4515],\n",
      "         [ 1.3332, -0.0674,  0.9938,  ...,  0.3075,  0.6146,  0.2004],\n",
      "         [ 1.1821,  0.0224,  0.5983,  ...,  0.0788,  0.2350,  0.0895]]],\n",
      "       device='cuda:0'), tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 0.8868,  0.1752,  0.7539,  ...,  0.2247,  0.1353,  0.4515],\n",
      "         [ 1.3332, -0.0674,  0.9938,  ...,  0.3075,  0.6146,  0.2004],\n",
      "         [ 1.1821,  0.0224,  0.5983,  ...,  0.0788,  0.2350,  0.0895]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-0.2747,  1.5681,  1.6354,  ...,  0.7872, -0.9187,  0.1052],\n",
      "         [-0.1749,  1.7297,  0.2363,  ...,  1.0567,  1.2751,  1.6453],\n",
      "         [ 0.9463,  0.7559,  0.0931,  ...,  2.4683, -2.9226, -0.3232]]],\n",
      "       device='cuda:0'), tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-0.2747,  1.5681,  1.6354,  ...,  0.7872, -0.9187,  0.1052],\n",
      "         [-0.1749,  1.7297,  0.2363,  ...,  1.0567,  1.2751,  1.6453],\n",
      "         [ 0.9463,  0.7559,  0.0931,  ...,  2.4683, -2.9226, -0.3232]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4504,  5.3788,  1.9572,  ...,  4.7894, -1.5236, -0.6376],\n",
      "         [ 2.4434,  5.4035,  1.9458,  ...,  4.8115, -1.4798, -0.6778],\n",
      "         [ 2.4638,  5.4037,  1.9618,  ...,  4.8184, -1.5077, -0.6604]]],\n",
      "       device='cuda:0'), tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4504,  5.3788,  1.9572,  ...,  4.7894, -1.5236, -0.6376],\n",
      "         [ 2.4434,  5.4035,  1.9458,  ...,  4.8115, -1.4798, -0.6778],\n",
      "         [ 2.4638,  5.4037,  1.9618,  ...,  4.8184, -1.5077, -0.6604]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [ 2.0428,  1.0364,  0.6715,  ...,  0.7124, -0.4984,  1.1194],\n",
      "         [ 0.3903,  0.9347,  0.8688,  ...,  1.3010, -0.6061,  0.5883],\n",
      "         [ 1.5335,  0.3049, -1.0174,  ...,  2.1242,  0.6037,  1.6354]]],\n",
      "       device='cuda:0'), tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [ 2.0428,  1.0364,  0.6715,  ...,  0.7124, -0.4984,  1.1194],\n",
      "         [ 0.3903,  0.9347,  0.8688,  ...,  1.3010, -0.6061,  0.5883],\n",
      "         [ 1.5335,  0.3049, -1.0174,  ...,  2.1242,  0.6037,  1.6354]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0231,  0.0618, -0.0210,  ..., -0.1150,  0.0324,  0.0245],\n",
      "         [-0.0246,  0.0649, -0.0182,  ..., -0.1110,  0.0337,  0.0247],\n",
      "         [-0.0258,  0.0635, -0.0223,  ..., -0.1125,  0.0327,  0.0261]]],\n",
      "       device='cuda:0'), tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0231,  0.0618, -0.0210,  ..., -0.1150,  0.0324,  0.0245],\n",
      "         [-0.0246,  0.0649, -0.0182,  ..., -0.1110,  0.0337,  0.0247],\n",
      "         [-0.0258,  0.0635, -0.0223,  ..., -0.1125,  0.0327,  0.0261]]],\n",
      "       device='cuda:0'))}]}]\n",
      "Step 150 - Last token probs (min/max): 0.0026865871623158455 / 0.09913439303636551\n",
      "Step 200 - past_kv structure:  [{'left': [{'chunk_attn': (tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [ 0.6159,  1.0727, -1.7746,  ...,  0.3929,  0.9731,  3.7231],\n",
      "         [ 0.1919,  2.9730, -1.2751,  ...,  2.0835, -0.1132,  0.4696],\n",
      "         [ 0.0823,  1.1799, -1.3959,  ...,  0.3035, -0.8513,  2.6893]]],\n",
      "       device='cuda:0'), tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [ 0.6159,  1.0727, -1.7746,  ...,  0.3929,  0.9731,  3.7231],\n",
      "         [ 0.1919,  2.9730, -1.2751,  ...,  2.0835, -0.1132,  0.4696],\n",
      "         [ 0.0823,  1.1799, -1.3959,  ...,  0.3035, -0.8513,  2.6893]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'), tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 0.9872,  2.3050,  0.1685,  ...,  2.4957,  0.5888,  2.3382],\n",
      "         [ 0.4214, -0.1296, -1.1855,  ...,  0.6768,  1.2308,  1.5188],\n",
      "         [ 0.9792,  0.7933, -1.0426,  ...,  0.3283,  1.3857,  0.4506]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 0.9872,  2.3050,  0.1685,  ...,  2.4957,  0.5888,  2.3382],\n",
      "         [ 0.4214, -0.1296, -1.1855,  ...,  0.6768,  1.2308,  1.5188],\n",
      "         [ 0.9792,  0.7933, -1.0426,  ...,  0.3283,  1.3857,  0.4506]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9528, -0.5439, -7.3259,  ...,  5.6843,  1.3245, -0.3580],\n",
      "         [-4.8697, -0.5383, -7.4131,  ...,  5.6944,  1.3180, -0.4241],\n",
      "         [-5.0726, -0.5436, -7.4236,  ...,  5.6744,  1.3162, -0.4962]]],\n",
      "       device='cuda:0'), tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9528, -0.5439, -7.3259,  ...,  5.6843,  1.3245, -0.3580],\n",
      "         [-4.8697, -0.5383, -7.4131,  ...,  5.6944,  1.3180, -0.4241],\n",
      "         [-5.0726, -0.5436, -7.4236,  ...,  5.6744,  1.3162, -0.4962]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [-1.4989, -0.6649,  2.0507,  ...,  1.1245,  0.0278,  0.4853],\n",
      "         [-0.3127,  1.2074,  0.2494,  ...,  2.2590, -0.1712,  0.7240],\n",
      "         [-2.1580,  2.1819, -1.4261,  ...,  0.8686,  1.5782,  1.3382]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [-1.4989, -0.6649,  2.0507,  ...,  1.1245,  0.0278,  0.4853],\n",
      "         [-0.3127,  1.2074,  0.2494,  ...,  2.2590, -0.1712,  0.7240],\n",
      "         [-2.1580,  2.1819, -1.4261,  ...,  0.8686,  1.5782,  1.3382]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0463,  1.9545,  1.9754,  ...,  1.4793,  1.3013, -2.7925],\n",
      "         [ 3.0451,  1.9526,  1.9754,  ...,  1.4791,  1.3008, -2.7921],\n",
      "         [ 3.0455,  1.9537,  1.9754,  ...,  1.4797,  1.3025, -2.7927]]],\n",
      "       device='cuda:0'), tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0463,  1.9545,  1.9754,  ...,  1.4793,  1.3013, -2.7925],\n",
      "         [ 3.0451,  1.9526,  1.9754,  ...,  1.4791,  1.3008, -2.7921],\n",
      "         [ 3.0455,  1.9537,  1.9754,  ...,  1.4797,  1.3025, -2.7927]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [-0.6164, -0.3686, -0.7250,  ...,  1.5884, -0.8364, -0.1426],\n",
      "         [-0.3919,  2.1025, -0.6060,  ...,  0.8583,  0.8638, -1.5638],\n",
      "         [ 1.1595,  0.7900,  1.0364,  ...,  0.7707,  0.1309,  1.3128]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [-0.6164, -0.3686, -0.7250,  ...,  1.5884, -0.8364, -0.1426],\n",
      "         [-0.3919,  2.1025, -0.6060,  ...,  0.8583,  0.8638, -1.5638],\n",
      "         [ 1.1595,  0.7900,  1.0364,  ...,  0.7707,  0.1309,  1.3128]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0024,  0.0253,  0.0059,  ..., -0.0810, -0.0675, -0.0008],\n",
      "         [-0.0036,  0.0232,  0.0054,  ..., -0.0831, -0.0696, -0.0007],\n",
      "         [-0.0041,  0.0253,  0.0069,  ..., -0.0842, -0.0715, -0.0010]]],\n",
      "       device='cuda:0'), tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0024,  0.0253,  0.0059,  ..., -0.0810, -0.0675, -0.0008],\n",
      "         [-0.0036,  0.0232,  0.0054,  ..., -0.0831, -0.0696, -0.0007],\n",
      "         [-0.0041,  0.0253,  0.0069,  ..., -0.0842, -0.0715, -0.0010]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [ 0.4432,  2.0085, -1.2046,  ...,  1.8160,  1.3212,  1.6570],\n",
      "         [-0.6565,  0.6877, -0.9909,  ...,  0.1908, -0.4903, -0.2012],\n",
      "         [-0.7544,  0.3269,  1.7035,  ...,  0.9164, -0.3453,  1.9018]]],\n",
      "       device='cuda:0'), tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [ 0.4432,  2.0085, -1.2046,  ...,  1.8160,  1.3212,  1.6570],\n",
      "         [-0.6565,  0.6877, -0.9909,  ...,  0.1908, -0.4903, -0.2012],\n",
      "         [-0.7544,  0.3269,  1.7035,  ...,  0.9164, -0.3453,  1.9018]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'), tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.1683e+00,  8.5312e-01, -1.3954e+00,  ...,  2.6033e+00,\n",
      "          -2.0462e-01,  7.2555e-01],\n",
      "         [ 1.5408e-01,  1.2670e+00, -1.5308e+00,  ...,  1.4449e-01,\n",
      "           1.4119e+00,  7.3201e-02],\n",
      "         [-1.9805e-01,  4.9393e-01,  2.5263e-01,  ..., -7.6322e-01,\n",
      "           4.0509e-01,  2.3945e+00],\n",
      "         ...,\n",
      "         [ 1.7537e-01,  6.2597e-01, -3.9130e-01,  ...,  5.7232e-01,\n",
      "          -1.0218e+00,  6.3196e-01],\n",
      "         [-7.2145e-01, -5.1325e-01,  3.8540e-01,  ..., -1.3133e-01,\n",
      "          -5.6422e-04, -3.2861e-02],\n",
      "         [ 4.8480e-01,  6.8824e-01,  8.8009e-01,  ...,  2.1170e+00,\n",
      "          -8.5804e-01,  8.2247e-01]]], device='cuda:0'), tensor([[[ 1.1683e+00,  8.5312e-01, -1.3954e+00,  ...,  2.6033e+00,\n",
      "          -2.0462e-01,  7.2555e-01],\n",
      "         [ 1.5408e-01,  1.2670e+00, -1.5308e+00,  ...,  1.4449e-01,\n",
      "           1.4119e+00,  7.3201e-02],\n",
      "         [-1.9805e-01,  4.9393e-01,  2.5263e-01,  ..., -7.6322e-01,\n",
      "           4.0509e-01,  2.3945e+00],\n",
      "         ...,\n",
      "         [ 1.7537e-01,  6.2597e-01, -3.9130e-01,  ...,  5.7232e-01,\n",
      "          -1.0218e+00,  6.3196e-01],\n",
      "         [-7.2145e-01, -5.1325e-01,  3.8540e-01,  ..., -1.3133e-01,\n",
      "          -5.6422e-04, -3.2861e-02],\n",
      "         [ 4.8480e-01,  6.8824e-01,  8.8009e-01,  ...,  2.1170e+00,\n",
      "          -8.5804e-01,  8.2247e-01]]], device='cuda:0')), 'logits_attn': (tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.5244, -0.2781, -0.4894,  ...,  0.9699, -0.4213,  0.2365],\n",
      "         [-0.3542, -0.5427, -0.4616,  ...,  1.3432, -0.6795,  0.2331],\n",
      "         [-0.5721, -0.2557, -0.5593,  ...,  1.2949, -0.5703,  0.2225]]],\n",
      "       device='cuda:0'), tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.5244, -0.2781, -0.4894,  ...,  0.9699, -0.4213,  0.2365],\n",
      "         [-0.3542, -0.5427, -0.4616,  ...,  1.3432, -0.6795,  0.2331],\n",
      "         [-0.5721, -0.2557, -0.5593,  ...,  1.2949, -0.5703,  0.2225]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [-0.3575, -0.4564,  0.9642,  ...,  1.3688, -1.2960, -1.3176],\n",
      "         [-0.3646,  0.5827,  0.7393,  ...,  1.4647,  0.4922,  0.4707],\n",
      "         [ 0.3127,  1.0450,  1.4854,  ...,  0.6200, -2.3626,  0.7849]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [-0.3575, -0.4564,  0.9642,  ...,  1.3688, -1.2960, -1.3176],\n",
      "         [-0.3646,  0.5827,  0.7393,  ...,  1.4647,  0.4922,  0.4707],\n",
      "         [ 0.3127,  1.0450,  1.4854,  ...,  0.6200, -2.3626,  0.7849]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3421,  0.3826,  0.0122,  ..., -0.4994,  0.5442, -0.2186],\n",
      "         [ 0.3356,  0.4121,  0.0239,  ..., -0.4893,  0.5608, -0.2366],\n",
      "         [ 0.3386,  0.3874,  0.0268,  ..., -0.4909,  0.5563, -0.2274]]],\n",
      "       device='cuda:0'), tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3421,  0.3826,  0.0122,  ..., -0.4994,  0.5442, -0.2186],\n",
      "         [ 0.3356,  0.4121,  0.0239,  ..., -0.4893,  0.5608, -0.2366],\n",
      "         [ 0.3386,  0.3874,  0.0268,  ..., -0.4909,  0.5563, -0.2274]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.0092,  0.7366,  0.2437,  ...,  1.8991, -0.3161,  1.5599],\n",
      "         [-1.5943, -0.2293,  0.8205,  ...,  0.8111,  1.1128,  1.7240],\n",
      "         [ 0.4992,  1.5861,  0.6171,  ...,  1.0315, -0.3128,  0.7795]]],\n",
      "       device='cuda:0'), tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.0092,  0.7366,  0.2437,  ...,  1.8991, -0.3161,  1.5599],\n",
      "         [-1.5943, -0.2293,  0.8205,  ...,  0.8111,  1.1128,  1.7240],\n",
      "         [ 0.4992,  1.5861,  0.6171,  ...,  1.0315, -0.3128,  0.7795]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0705,  0.0892, -0.0244,  ..., -0.1111, -0.0233, -0.0316],\n",
      "         [ 0.0514,  0.0974, -0.0375,  ..., -0.1118, -0.0022, -0.0264],\n",
      "         [ 0.0649,  0.1030, -0.0355,  ..., -0.1224, -0.0055, -0.0229]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0705,  0.0892, -0.0244,  ..., -0.1111, -0.0233, -0.0316],\n",
      "         [ 0.0514,  0.0974, -0.0375,  ..., -0.1118, -0.0022, -0.0264],\n",
      "         [ 0.0649,  0.1030, -0.0355,  ..., -0.1224, -0.0055, -0.0229]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [-0.8045,  1.5557,  0.4282,  ..., -0.3184, -1.3670,  0.5846],\n",
      "         [-1.0488, -0.5756, -0.4243,  ..., -0.1889, -0.5572, -0.2120],\n",
      "         [ 0.0998,  5.0104, -0.2378,  ...,  1.4869, -1.4948,  2.0942]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [-0.8045,  1.5557,  0.4282,  ..., -0.3184, -1.3670,  0.5846],\n",
      "         [-1.0488, -0.5756, -0.4243,  ..., -0.1889, -0.5572, -0.2120],\n",
      "         [ 0.0998,  5.0104, -0.2378,  ...,  1.4869, -1.4948,  2.0942]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [ 0.3264, -0.7830, -0.2025,  ...,  1.3265, -0.2337, -0.5152],\n",
      "         [-0.1659,  0.7637,  1.2839,  ...,  0.1913,  0.5889, -0.2123],\n",
      "         [ 1.4424,  0.0422, -0.7429,  ...,  0.6544, -0.8710, -0.1858]]],\n",
      "       device='cuda:0'), tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [ 0.3264, -0.7830, -0.2025,  ...,  1.3265, -0.2337, -0.5152],\n",
      "         [-0.1659,  0.7637,  1.2839,  ...,  0.1913,  0.5889, -0.2123],\n",
      "         [ 1.4424,  0.0422, -0.7429,  ...,  0.6544, -0.8710, -0.1858]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-0.3137, -0.0775, -1.9805,  ...,  0.2130, -0.6115, -0.2515],\n",
      "         [-1.7048, -0.2844,  1.4294,  ...,  2.3262, -1.0711,  2.1458],\n",
      "         [-1.0255, -0.0693,  1.0709,  ...,  2.2735,  0.1622,  0.4493]]],\n",
      "       device='cuda:0'), tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-0.3137, -0.0775, -1.9805,  ...,  0.2130, -0.6115, -0.2515],\n",
      "         [-1.7048, -0.2844,  1.4294,  ...,  2.3262, -1.0711,  2.1458],\n",
      "         [-1.0255, -0.0693,  1.0709,  ...,  2.2735,  0.1622,  0.4493]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.2707,  0.5220, -0.2369,  ..., -1.9352, -0.8599,  0.8005],\n",
      "         [-2.7878, -0.4929,  0.5619,  ..., -1.4521, -1.1750,  0.0861],\n",
      "         [-2.7733,  0.2594,  0.7287,  ..., -2.2970, -1.7944,  0.1955]]],\n",
      "       device='cuda:0'), tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.2707,  0.5220, -0.2369,  ..., -1.9352, -0.8599,  0.8005],\n",
      "         [-2.7878, -0.4929,  0.5619,  ..., -1.4521, -1.1750,  0.0861],\n",
      "         [-2.7733,  0.2594,  0.7287,  ..., -2.2970, -1.7944,  0.1955]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 0.0720, -0.5311, -0.4026,  ...,  1.7587, -0.2993,  1.4420],\n",
      "         [ 0.1248, -1.2091, -1.3056,  ...,  0.8848, -0.9874,  1.7269],\n",
      "         [ 0.1350,  0.1880, -0.3264,  ...,  2.2411,  1.0047,  2.3115]]],\n",
      "       device='cuda:0'), tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 0.0720, -0.5311, -0.4026,  ...,  1.7587, -0.2993,  1.4420],\n",
      "         [ 0.1248, -1.2091, -1.3056,  ...,  0.8848, -0.9874,  1.7269],\n",
      "         [ 0.1350,  0.1880, -0.3264,  ...,  2.2411,  1.0047,  2.3115]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 5.8412e-01,  5.1617e+00, -9.3508e-02,  ...,  9.9786e-02,\n",
      "          -7.3548e-01,  2.7650e+00],\n",
      "         [ 5.5439e-01,  5.1754e+00, -3.0827e-02,  ...,  1.1312e-01,\n",
      "          -6.9124e-01,  2.8477e+00],\n",
      "         [ 5.7300e-01,  5.1981e+00, -8.9784e-02,  ...,  1.1032e-01,\n",
      "          -7.3138e-01,  2.8310e+00],\n",
      "         ...,\n",
      "         [ 6.5010e-01,  5.1222e+00, -1.1848e-03,  ...,  8.6716e-02,\n",
      "          -7.7886e-01,  2.7904e+00],\n",
      "         [ 5.7189e-01,  5.1889e+00, -4.2954e-02,  ...,  5.2141e-02,\n",
      "          -7.2335e-01,  2.8288e+00],\n",
      "         [ 5.7265e-01,  5.1187e+00, -3.9896e-02,  ...,  1.1400e-01,\n",
      "          -7.9225e-01,  2.7111e+00]]], device='cuda:0'), tensor([[[ 5.8412e-01,  5.1617e+00, -9.3508e-02,  ...,  9.9786e-02,\n",
      "          -7.3548e-01,  2.7650e+00],\n",
      "         [ 5.5439e-01,  5.1754e+00, -3.0827e-02,  ...,  1.1312e-01,\n",
      "          -6.9124e-01,  2.8477e+00],\n",
      "         [ 5.7300e-01,  5.1981e+00, -8.9784e-02,  ...,  1.1032e-01,\n",
      "          -7.3138e-01,  2.8310e+00],\n",
      "         ...,\n",
      "         [ 6.5010e-01,  5.1222e+00, -1.1848e-03,  ...,  8.6716e-02,\n",
      "          -7.7886e-01,  2.7904e+00],\n",
      "         [ 5.7189e-01,  5.1889e+00, -4.2954e-02,  ...,  5.2141e-02,\n",
      "          -7.2335e-01,  2.8288e+00],\n",
      "         [ 5.7265e-01,  5.1187e+00, -3.9896e-02,  ...,  1.1400e-01,\n",
      "          -7.9225e-01,  2.7111e+00]]], device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [ 0.3887,  0.9644, -0.0125,  ...,  1.6498,  0.1285,  0.7815],\n",
      "         [ 0.5133,  0.2082, -1.1205,  ...,  0.1450,  0.2924, -0.4376],\n",
      "         [-0.0337,  3.1910, -0.3327,  ...,  2.0015, -0.4377,  2.3833]]],\n",
      "       device='cuda:0'), tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [ 0.3887,  0.9644, -0.0125,  ...,  1.6498,  0.1285,  0.7815],\n",
      "         [ 0.5133,  0.2082, -1.1205,  ...,  0.1450,  0.2924, -0.4376],\n",
      "         [-0.0337,  3.1910, -0.3327,  ...,  2.0015, -0.4377,  2.3833]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0741, -0.0395,  0.0570,  ..., -0.0266, -0.0829, -0.0907],\n",
      "         [ 0.0739, -0.0380,  0.0596,  ..., -0.0247, -0.0818, -0.0933],\n",
      "         [ 0.0758, -0.0367,  0.0576,  ..., -0.0248, -0.0813, -0.0918]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0741, -0.0395,  0.0570,  ..., -0.0266, -0.0829, -0.0907],\n",
      "         [ 0.0739, -0.0380,  0.0596,  ..., -0.0247, -0.0818, -0.0933],\n",
      "         [ 0.0758, -0.0367,  0.0576,  ..., -0.0248, -0.0813, -0.0918]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [ 1.9605,  1.0873, -0.5955,  ...,  1.4918, -1.4942,  1.5458],\n",
      "         [-0.7744,  0.4223,  0.3830,  ...,  0.8158,  1.9122,  0.6952],\n",
      "         [ 0.3783,  1.1439,  0.2525,  ...,  0.3480, -0.6408,  1.3402]]],\n",
      "       device='cuda:0'), tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [ 1.9605,  1.0873, -0.5955,  ...,  1.4918, -1.4942,  1.5458],\n",
      "         [-0.7744,  0.4223,  0.3830,  ...,  0.8158,  1.9122,  0.6952],\n",
      "         [ 0.3783,  1.1439,  0.2525,  ...,  0.3480, -0.6408,  1.3402]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [-0.3389,  0.2992, -0.7928,  ...,  0.8608, -0.3739, -1.9722],\n",
      "         [ 1.0650,  1.2941, -1.1146,  ...,  1.8351, -0.2277,  0.8953],\n",
      "         [ 0.1864, -0.5024,  0.6947,  ..., -0.0758, -0.4634, -1.3296]]],\n",
      "       device='cuda:0'), tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [-0.3389,  0.2992, -0.7928,  ...,  0.8608, -0.3739, -1.9722],\n",
      "         [ 1.0650,  1.2941, -1.1146,  ...,  1.8351, -0.2277,  0.8953],\n",
      "         [ 0.1864, -0.5024,  0.6947,  ..., -0.0758, -0.4634, -1.3296]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.7644,  1.3138, -1.0163,  ...,  1.3938, -0.0253,  1.4999],\n",
      "         [ 1.3308,  1.9749, -0.6095,  ...,  2.0628, -0.3610,  0.4956],\n",
      "         [-0.0905,  1.9546,  1.3955,  ...,  2.3081,  0.1922,  1.6255]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.7644,  1.3138, -1.0163,  ...,  1.3938, -0.0253,  1.4999],\n",
      "         [ 1.3308,  1.9749, -0.6095,  ...,  2.0628, -0.3610,  0.4956],\n",
      "         [-0.0905,  1.9546,  1.3955,  ...,  2.3081,  0.1922,  1.6255]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-0.9304,  0.5323, -3.6760,  ...,  1.6548, -3.0021, -1.3012],\n",
      "         [-1.4646,  0.6797, -3.7445,  ...,  1.9361, -3.2630, -1.8320],\n",
      "         [-1.2477,  1.0133, -3.8836,  ...,  1.8905, -3.2289, -1.6120]]],\n",
      "       device='cuda:0'), tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-0.9304,  0.5323, -3.6760,  ...,  1.6548, -3.0021, -1.3012],\n",
      "         [-1.4646,  0.6797, -3.7445,  ...,  1.9361, -3.2630, -1.8320],\n",
      "         [-1.2477,  1.0133, -3.8836,  ...,  1.8905, -3.2289, -1.6120]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-0.1103,  1.0516,  0.0429,  ..., -0.3292,  0.0025,  1.2684],\n",
      "         [ 0.2827, -1.0808,  1.4020,  ..., -0.0647, -0.3031,  1.9953],\n",
      "         [-0.7989,  1.5009,  0.1043,  ...,  1.8339, -1.7498,  1.1239]]],\n",
      "       device='cuda:0'), tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-0.1103,  1.0516,  0.0429,  ..., -0.3292,  0.0025,  1.2684],\n",
      "         [ 0.2827, -1.0808,  1.4020,  ..., -0.0647, -0.3031,  1.9953],\n",
      "         [-0.7989,  1.5009,  0.1043,  ...,  1.8339, -1.7498,  1.1239]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2482, -0.5035, -0.6529,  ...,  0.4968, -2.5947,  0.8530],\n",
      "         [-1.2767, -0.5361, -0.6878,  ...,  0.5032, -2.6090,  0.8517],\n",
      "         [-1.2882, -0.5193, -0.6640,  ...,  0.5118, -2.6164,  0.8428]]],\n",
      "       device='cuda:0'), tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2482, -0.5035, -0.6529,  ...,  0.4968, -2.5947,  0.8530],\n",
      "         [-1.2767, -0.5361, -0.6878,  ...,  0.5032, -2.6090,  0.8517],\n",
      "         [-1.2882, -0.5193, -0.6640,  ...,  0.5118, -2.6164,  0.8428]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [-1.9137,  0.9841,  0.5117,  ...,  0.1367, -0.1602, -0.1327],\n",
      "         [-2.1718,  1.5710,  0.5819,  ...,  1.5222,  0.6893, -0.4409],\n",
      "         [ 1.0809,  1.6404,  1.8024,  ...,  0.5353,  0.4013, -1.6950]]],\n",
      "       device='cuda:0'), tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [-1.9137,  0.9841,  0.5117,  ...,  0.1367, -0.1602, -0.1327],\n",
      "         [-2.1718,  1.5710,  0.5819,  ...,  1.5222,  0.6893, -0.4409],\n",
      "         [ 1.0809,  1.6404,  1.8024,  ...,  0.5353,  0.4013, -1.6950]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0114,  0.1104,  0.0370,  ...,  0.0777, -0.0334, -0.0354],\n",
      "         [ 0.0127,  0.1002,  0.0295,  ...,  0.0743, -0.0343, -0.0396],\n",
      "         [ 0.0101,  0.0994,  0.0355,  ...,  0.0710, -0.0208, -0.0384]]],\n",
      "       device='cuda:0'), tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0114,  0.1104,  0.0370,  ...,  0.0777, -0.0334, -0.0354],\n",
      "         [ 0.0127,  0.1002,  0.0295,  ...,  0.0743, -0.0343, -0.0396],\n",
      "         [ 0.0101,  0.0994,  0.0355,  ...,  0.0710, -0.0208, -0.0384]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 0.3603, -1.8275, -0.4007,  ...,  2.6117, -0.8798,  1.7764],\n",
      "         [-0.9089,  0.8077,  1.1299,  ..., -0.2551,  1.1582,  0.6624],\n",
      "         [ 0.1695,  0.6200,  0.9387,  ...,  0.5566, -0.7232,  2.3507]]],\n",
      "       device='cuda:0'), tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 0.3603, -1.8275, -0.4007,  ...,  2.6117, -0.8798,  1.7764],\n",
      "         [-0.9089,  0.8077,  1.1299,  ..., -0.2551,  1.1582,  0.6624],\n",
      "         [ 0.1695,  0.6200,  0.9387,  ...,  0.5566, -0.7232,  2.3507]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [-0.4011,  0.5293, -0.7883,  ...,  1.6456, -0.7032, -0.5651],\n",
      "         [-0.0578, -0.9838,  0.0234,  ...,  1.3131, -0.1836, -0.5932],\n",
      "         [ 0.8299,  0.5020, -0.8975,  ...,  2.7649, -1.6846, -1.1770]]],\n",
      "       device='cuda:0'), tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [-0.4011,  0.5293, -0.7883,  ...,  1.6456, -0.7032, -0.5651],\n",
      "         [-0.0578, -0.9838,  0.0234,  ...,  1.3131, -0.1836, -0.5932],\n",
      "         [ 0.8299,  0.5020, -0.8975,  ...,  2.7649, -1.6846, -1.1770]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [-1.7370,  1.1861,  0.3009,  ...,  0.2918,  0.9811,  0.9283],\n",
      "         [-0.1531,  1.3310,  0.0131,  ...,  1.1886, -0.1782,  0.8544],\n",
      "         [-0.8848,  1.6012,  0.1924,  ...,  0.0742, -1.3090,  1.1521]]],\n",
      "       device='cuda:0'), tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [-1.7370,  1.1861,  0.3009,  ...,  0.2918,  0.9811,  0.9283],\n",
      "         [-0.1531,  1.3310,  0.0131,  ...,  1.1886, -0.1782,  0.8544],\n",
      "         [-0.8848,  1.6012,  0.1924,  ...,  0.0742, -1.3090,  1.1521]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.4663, -0.4780,  1.5151,  ..., -3.2784,  1.1624, -0.5637],\n",
      "         [-1.9274, -0.8925,  1.7917,  ..., -3.2551,  0.7951, -0.1842],\n",
      "         [-2.3248, -1.2599,  1.8028,  ..., -3.0952,  0.8320, -0.5226]]],\n",
      "       device='cuda:0'), tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.4663, -0.4780,  1.5151,  ..., -3.2784,  1.1624, -0.5637],\n",
      "         [-1.9274, -0.8925,  1.7917,  ..., -3.2551,  0.7951, -0.1842],\n",
      "         [-2.3248, -1.2599,  1.8028,  ..., -3.0952,  0.8320, -0.5226]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [-0.7275,  0.6066,  0.8779,  ..., -0.4733,  0.9741,  1.5294],\n",
      "         [ 0.1883,  1.4787, -0.0228,  ...,  0.1350, -0.7109,  0.7622],\n",
      "         [-0.0582,  1.0504, -0.0228,  ...,  0.2877, -2.2151,  1.7701]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [-0.7275,  0.6066,  0.8779,  ..., -0.4733,  0.9741,  1.5294],\n",
      "         [ 0.1883,  1.4787, -0.0228,  ...,  0.1350, -0.7109,  0.7622],\n",
      "         [-0.0582,  1.0504, -0.0228,  ...,  0.2877, -2.2151,  1.7701]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4447,  1.5210, -0.1693,  ..., -0.3463, -0.0387,  2.3579],\n",
      "         [ 2.4892,  1.5184, -0.2193,  ..., -0.3421, -0.0361,  2.3266],\n",
      "         [ 2.4583,  1.5553, -0.1506,  ..., -0.3687, -0.0637,  2.3869]]],\n",
      "       device='cuda:0'), tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4447,  1.5210, -0.1693,  ..., -0.3463, -0.0387,  2.3579],\n",
      "         [ 2.4892,  1.5184, -0.2193,  ..., -0.3421, -0.0361,  2.3266],\n",
      "         [ 2.4583,  1.5553, -0.1506,  ..., -0.3687, -0.0637,  2.3869]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 0.4734,  0.4776,  2.0903,  ...,  0.5979, -1.4931,  2.1360],\n",
      "         [ 1.5185,  0.4604,  0.0923,  ...,  1.4566, -0.5248,  3.1382],\n",
      "         [-0.8206,  0.5368, -1.0717,  ...,  1.2066, -0.5072,  1.9946]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 0.4734,  0.4776,  2.0903,  ...,  0.5979, -1.4931,  2.1360],\n",
      "         [ 1.5185,  0.4604,  0.0923,  ...,  1.4566, -0.5248,  3.1382],\n",
      "         [-0.8206,  0.5368, -1.0717,  ...,  1.2066, -0.5072,  1.9946]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0215, -0.0012,  0.0257,  ..., -0.0104, -0.0061, -0.0192],\n",
      "         [ 0.0226,  0.0002,  0.0243,  ..., -0.0100, -0.0076, -0.0190],\n",
      "         [ 0.0235, -0.0012,  0.0236,  ..., -0.0102, -0.0063, -0.0192]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0215, -0.0012,  0.0257,  ..., -0.0104, -0.0061, -0.0192],\n",
      "         [ 0.0226,  0.0002,  0.0243,  ..., -0.0100, -0.0076, -0.0190],\n",
      "         [ 0.0235, -0.0012,  0.0236,  ..., -0.0102, -0.0063, -0.0192]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [-2.4054,  1.4284, -0.5559,  ...,  0.4100,  0.1249,  2.6183],\n",
      "         [ 0.9280,  1.7375,  0.1993,  ...,  1.2451, -1.3991,  1.6608],\n",
      "         [ 0.0222,  2.1116, -0.4407,  ...,  0.9826, -0.6017, -0.0319]]],\n",
      "       device='cuda:0'), tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [-2.4054,  1.4284, -0.5559,  ...,  0.4100,  0.1249,  2.6183],\n",
      "         [ 0.9280,  1.7375,  0.1993,  ...,  1.2451, -1.3991,  1.6608],\n",
      "         [ 0.0222,  2.1116, -0.4407,  ...,  0.9826, -0.6017, -0.0319]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.9361, -1.1346, -1.7588,  ..., -0.8028,  0.7360, -1.2353],\n",
      "         [ 2.4636, -0.6185, -1.0468,  ..., -0.7490,  1.2264,  0.3795],\n",
      "         [-0.5446,  0.8465, -1.9038,  ..., -0.7323, -0.0175, -0.4269]]],\n",
      "       device='cuda:0'), tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.9361, -1.1346, -1.7588,  ..., -0.8028,  0.7360, -1.2353],\n",
      "         [ 2.4636, -0.6185, -1.0468,  ..., -0.7490,  1.2264,  0.3795],\n",
      "         [-0.5446,  0.8465, -1.9038,  ..., -0.7323, -0.0175, -0.4269]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [-4.6106e-01,  1.4388e+00,  6.8045e-03,  ...,  1.5706e+00,\n",
      "          -7.5419e-02,  1.3283e+00],\n",
      "         [-1.1049e+00,  1.5493e+00,  6.5417e-01,  ...,  2.5179e+00,\n",
      "          -9.8006e-01,  1.2239e+00],\n",
      "         [-5.7253e-01,  9.7633e-01,  2.1052e-01,  ..., -2.2648e-01,\n",
      "           4.7368e-01,  1.6922e+00]]], device='cuda:0'), tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [-4.6106e-01,  1.4388e+00,  6.8045e-03,  ...,  1.5706e+00,\n",
      "          -7.5419e-02,  1.3283e+00],\n",
      "         [-1.1049e+00,  1.5493e+00,  6.5417e-01,  ...,  2.5179e+00,\n",
      "          -9.8006e-01,  1.2239e+00],\n",
      "         [-5.7253e-01,  9.7633e-01,  2.1052e-01,  ..., -2.2648e-01,\n",
      "           4.7368e-01,  1.6922e+00]]], device='cuda:0')), 'logits_attn': (tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.3024,  3.0845,  5.4976,  ..., -2.0437, -8.1104, -3.5266],\n",
      "         [ 4.9274,  3.0561,  6.1160,  ..., -1.7902, -8.4744, -3.4508],\n",
      "         [ 4.5377,  2.7316,  5.8186,  ..., -2.0358, -7.9662, -3.1170]]],\n",
      "       device='cuda:0'), tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.3024,  3.0845,  5.4976,  ..., -2.0437, -8.1104, -3.5266],\n",
      "         [ 4.9274,  3.0561,  6.1160,  ..., -1.7902, -8.4744, -3.4508],\n",
      "         [ 4.5377,  2.7316,  5.8186,  ..., -2.0358, -7.9662, -3.1170]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.4485,  1.0374,  2.0441,  ...,  0.3800, -0.8868,  0.9585],\n",
      "         [-0.7899,  0.7942, -0.0514,  ...,  1.1054, -0.5953,  0.0198],\n",
      "         [ 1.4061,  1.6022,  0.4811,  ...,  1.1870, -0.1466,  1.5629]]],\n",
      "       device='cuda:0'), tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.4485,  1.0374,  2.0441,  ...,  0.3800, -0.8868,  0.9585],\n",
      "         [-0.7899,  0.7942, -0.0514,  ...,  1.1054, -0.5953,  0.0198],\n",
      "         [ 1.4061,  1.6022,  0.4811,  ...,  1.1870, -0.1466,  1.5629]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5702, -8.7704,  4.8991,  ...,  5.1911,  2.4758,  3.4412],\n",
      "         [ 3.5629, -8.7740,  4.9024,  ...,  5.1874,  2.4739,  3.4389],\n",
      "         [ 3.5673, -8.7691,  4.9074,  ...,  5.1902,  2.4710,  3.4422]]],\n",
      "       device='cuda:0'), tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5702, -8.7704,  4.8991,  ...,  5.1911,  2.4758,  3.4412],\n",
      "         [ 3.5629, -8.7740,  4.9024,  ...,  5.1874,  2.4739,  3.4389],\n",
      "         [ 3.5673, -8.7691,  4.9074,  ...,  5.1902,  2.4710,  3.4422]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [ 0.2819,  0.7053,  0.1219,  ...,  2.1049, -0.3963,  0.2587],\n",
      "         [-1.9202, -1.1172,  0.4214,  ...,  1.8759, -0.3788, -0.1828],\n",
      "         [ 0.3747,  1.4403, -0.7325,  ...,  0.8208,  2.4798,  2.0807]]],\n",
      "       device='cuda:0'), tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [ 0.2819,  0.7053,  0.1219,  ...,  2.1049, -0.3963,  0.2587],\n",
      "         [-1.9202, -1.1172,  0.4214,  ...,  1.8759, -0.3788, -0.1828],\n",
      "         [ 0.3747,  1.4403, -0.7325,  ...,  0.8208,  2.4798,  2.0807]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0019, -0.0030, -0.0666,  ..., -0.0056,  0.0015, -0.0187],\n",
      "         [-0.0017, -0.0026, -0.0662,  ..., -0.0053,  0.0016, -0.0187],\n",
      "         [-0.0020, -0.0034, -0.0662,  ..., -0.0055,  0.0017, -0.0183]]],\n",
      "       device='cuda:0'), tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0019, -0.0030, -0.0666,  ..., -0.0056,  0.0015, -0.0187],\n",
      "         [-0.0017, -0.0026, -0.0662,  ..., -0.0053,  0.0016, -0.0187],\n",
      "         [-0.0020, -0.0034, -0.0662,  ..., -0.0055,  0.0017, -0.0183]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [ 0.3965,  2.1863,  0.5073,  ...,  1.4574, -1.2404,  1.0504],\n",
      "         [-1.9492,  0.6241,  0.0164,  ...,  0.9150,  2.1345,  1.1063],\n",
      "         [-1.4039, -0.8623, -0.5895,  ...,  0.2025,  0.2947, -1.1269]]],\n",
      "       device='cuda:0'), tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [ 0.3965,  2.1863,  0.5073,  ...,  1.4574, -1.2404,  1.0504],\n",
      "         [-1.9492,  0.6241,  0.0164,  ...,  0.9150,  2.1345,  1.1063],\n",
      "         [-1.4039, -0.8623, -0.5895,  ...,  0.2025,  0.2947, -1.1269]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 0.9990, -2.4854, -0.0637,  ...,  0.0530,  0.6544,  0.6608],\n",
      "         [ 2.0382, -0.6567, -1.3724,  ...,  1.5302,  1.8478,  1.0804],\n",
      "         [ 2.6694, -2.2644, -0.4319,  ...,  0.4207,  0.4156,  1.0342]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 0.9990, -2.4854, -0.0637,  ...,  0.0530,  0.6544,  0.6608],\n",
      "         [ 2.0382, -0.6567, -1.3724,  ...,  1.5302,  1.8478,  1.0804],\n",
      "         [ 2.6694, -2.2644, -0.4319,  ...,  0.4207,  0.4156,  1.0342]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [-0.5776,  1.2132, -2.3405,  ...,  0.9500,  0.0480,  1.7099],\n",
      "         [ 0.0647,  0.7629,  0.0431,  ...,  0.0384, -1.2629,  0.9549],\n",
      "         [-0.9529,  2.2102,  0.2454,  ...,  1.2120, -1.0629, -0.3643]]],\n",
      "       device='cuda:0'), tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [-0.5776,  1.2132, -2.3405,  ...,  0.9500,  0.0480,  1.7099],\n",
      "         [ 0.0647,  0.7629,  0.0431,  ...,  0.0384, -1.2629,  0.9549],\n",
      "         [-0.9529,  2.2102,  0.2454,  ...,  1.2120, -1.0629, -0.3643]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.8246, -1.6392, -0.1287,  ..., -0.4896,  2.5234,  1.7080],\n",
      "         [-5.1072, -1.8922, -0.0066,  ..., -0.3104,  2.6953,  1.6203],\n",
      "         [-5.0229, -1.7125,  0.1236,  ..., -0.7715,  2.6117,  1.7872]]],\n",
      "       device='cuda:0'), tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.8246, -1.6392, -0.1287,  ..., -0.4896,  2.5234,  1.7080],\n",
      "         [-5.1072, -1.8922, -0.0066,  ..., -0.3104,  2.6953,  1.6203],\n",
      "         [-5.0229, -1.7125,  0.1236,  ..., -0.7715,  2.6117,  1.7872]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [ 0.7608,  0.2484, -0.4635,  ...,  0.0074, -0.1833,  1.6117],\n",
      "         [ 0.7271,  1.3114,  1.8884,  ...,  0.3904,  1.3868,  1.6504],\n",
      "         [-0.2829,  1.9697, -0.8346,  ...,  1.8922,  1.1328,  2.5050]]],\n",
      "       device='cuda:0'), tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [ 0.7608,  0.2484, -0.4635,  ...,  0.0074, -0.1833,  1.6117],\n",
      "         [ 0.7271,  1.3114,  1.8884,  ...,  0.3904,  1.3868,  1.6504],\n",
      "         [-0.2829,  1.9697, -0.8346,  ...,  1.8922,  1.1328,  2.5050]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0549,  0.2520,  0.4728,  ..., -0.2782,  0.6603, -0.5394],\n",
      "         [ 0.0631,  0.2630,  0.4457,  ..., -0.2445,  0.7331, -0.5760],\n",
      "         [ 0.0381,  0.2818,  0.4721,  ..., -0.2882,  0.6914, -0.5546]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0549,  0.2520,  0.4728,  ..., -0.2782,  0.6603, -0.5394],\n",
      "         [ 0.0631,  0.2630,  0.4457,  ..., -0.2445,  0.7331, -0.5760],\n",
      "         [ 0.0381,  0.2818,  0.4721,  ..., -0.2882,  0.6914, -0.5546]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.2460,  2.3231, -0.5177,  ...,  0.5209, -1.1785, -0.1367],\n",
      "         [ 0.6648,  0.8268, -0.2255,  ...,  2.3296, -0.1965, -0.1332],\n",
      "         [ 0.9446,  0.3784,  1.2022,  ..., -1.6055,  1.5840,  1.2016]]],\n",
      "       device='cuda:0'), tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.2460,  2.3231, -0.5177,  ...,  0.5209, -1.1785, -0.1367],\n",
      "         [ 0.6648,  0.8268, -0.2255,  ...,  2.3296, -0.1965, -0.1332],\n",
      "         [ 0.9446,  0.3784,  1.2022,  ..., -1.6055,  1.5840,  1.2016]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0584, -0.0334,  0.0764,  ...,  0.0466,  0.0747, -0.0196],\n",
      "         [-0.0620, -0.0328,  0.0787,  ...,  0.0477,  0.0757, -0.0201],\n",
      "         [-0.0544, -0.0337,  0.0797,  ...,  0.0516,  0.0818, -0.0185]]],\n",
      "       device='cuda:0'), tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0584, -0.0334,  0.0764,  ...,  0.0466,  0.0747, -0.0196],\n",
      "         [-0.0620, -0.0328,  0.0787,  ...,  0.0477,  0.0757, -0.0201],\n",
      "         [-0.0544, -0.0337,  0.0797,  ...,  0.0516,  0.0818, -0.0185]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [-0.4307,  0.6032, -0.7552,  ...,  2.0664, -0.9558,  2.6510],\n",
      "         [-1.3603,  1.8832, -0.3745,  ...,  1.0970, -2.8912,  2.2682],\n",
      "         [-0.2339,  2.4017,  1.4606,  ...,  2.5871, -0.8590,  1.3460]]],\n",
      "       device='cuda:0'), tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [-0.4307,  0.6032, -0.7552,  ...,  2.0664, -0.9558,  2.6510],\n",
      "         [-1.3603,  1.8832, -0.3745,  ...,  1.0970, -2.8912,  2.2682],\n",
      "         [-0.2339,  2.4017,  1.4606,  ...,  2.5871, -0.8590,  1.3460]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [ 1.7761, -1.3262,  0.3785,  ...,  2.1815,  0.4106,  1.6218],\n",
      "         [-3.4308, -0.9736,  0.3988,  ...,  0.5377,  0.9361,  1.7657],\n",
      "         [-0.3167, -0.9106, -1.6375,  ...,  3.2201,  2.1096,  0.8290]]],\n",
      "       device='cuda:0'), tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [ 1.7761, -1.3262,  0.3785,  ...,  2.1815,  0.4106,  1.6218],\n",
      "         [-3.4308, -0.9736,  0.3988,  ...,  0.5377,  0.9361,  1.7657],\n",
      "         [-0.3167, -0.9106, -1.6375,  ...,  3.2201,  2.1096,  0.8290]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [-1.5509,  1.7879, -1.3272,  ...,  0.0384,  0.7680,  1.0810],\n",
      "         [ 0.3378,  2.5562, -0.1852,  ...,  0.7436, -0.7046,  2.0644],\n",
      "         [ 0.2986,  1.6737, -1.1804,  ...,  0.2554,  0.6555, -0.2245]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [-1.5509,  1.7879, -1.3272,  ...,  0.0384,  0.7680,  1.0810],\n",
      "         [ 0.3378,  2.5562, -0.1852,  ...,  0.7436, -0.7046,  2.0644],\n",
      "         [ 0.2986,  1.6737, -1.1804,  ...,  0.2554,  0.6555, -0.2245]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.2687, -0.0588,  1.3114,  ...,  0.1079,  0.3558,  0.1237],\n",
      "         [ 1.3489, -0.1337,  0.7425,  ...,  0.1509,  0.4684, -0.0046],\n",
      "         [ 1.4125, -0.1941,  0.4913,  ..., -0.0363,  0.5445, -0.2365]]],\n",
      "       device='cuda:0'), tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.2687, -0.0588,  1.3114,  ...,  0.1079,  0.3558,  0.1237],\n",
      "         [ 1.3489, -0.1337,  0.7425,  ...,  0.1509,  0.4684, -0.0046],\n",
      "         [ 1.4125, -0.1941,  0.4913,  ..., -0.0363,  0.5445, -0.2365]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-0.3329,  1.3059, -0.9689,  ...,  0.0645,  0.0650, -0.0192],\n",
      "         [ 0.9078,  1.3315,  0.0205,  ...,  1.6144,  1.5302,  0.7950],\n",
      "         [ 0.5296, -0.3492,  0.2641,  ...,  0.8490, -1.6268,  1.1057]]],\n",
      "       device='cuda:0'), tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-0.3329,  1.3059, -0.9689,  ...,  0.0645,  0.0650, -0.0192],\n",
      "         [ 0.9078,  1.3315,  0.0205,  ...,  1.6144,  1.5302,  0.7950],\n",
      "         [ 0.5296, -0.3492,  0.2641,  ...,  0.8490, -1.6268,  1.1057]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4693,  5.3907,  1.9563,  ...,  4.8118, -1.5210, -0.6784],\n",
      "         [ 2.4547,  5.3715,  1.9618,  ...,  4.8107, -1.4905, -0.6464],\n",
      "         [ 2.4662,  5.3548,  1.9628,  ...,  4.7897, -1.4918, -0.6424]]],\n",
      "       device='cuda:0'), tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4693,  5.3907,  1.9563,  ...,  4.8118, -1.5210, -0.6784],\n",
      "         [ 2.4547,  5.3715,  1.9618,  ...,  4.8107, -1.4905, -0.6464],\n",
      "         [ 2.4662,  5.3548,  1.9628,  ...,  4.7897, -1.4918, -0.6424]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-1.2214, -0.2297,  0.5168,  ...,  0.5624, -1.3398,  1.7919],\n",
      "         [-0.1628,  0.8365, -0.3730,  ...,  1.3042,  0.4272,  2.3271],\n",
      "         [ 0.1018, -0.3524,  0.6273,  ...,  0.1369,  0.1128,  1.1941]]],\n",
      "       device='cuda:0'), tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-1.2214, -0.2297,  0.5168,  ...,  0.5624, -1.3398,  1.7919],\n",
      "         [-0.1628,  0.8365, -0.3730,  ...,  1.3042,  0.4272,  2.3271],\n",
      "         [ 0.1018, -0.3524,  0.6273,  ...,  0.1369,  0.1128,  1.1941]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0220,  0.0625, -0.0210,  ..., -0.1161,  0.0349,  0.0252],\n",
      "         [-0.0272,  0.0627, -0.0184,  ..., -0.1163,  0.0314,  0.0256],\n",
      "         [-0.0258,  0.0621, -0.0203,  ..., -0.1116,  0.0320,  0.0269]]],\n",
      "       device='cuda:0'), tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0220,  0.0625, -0.0210,  ..., -0.1161,  0.0349,  0.0252],\n",
      "         [-0.0272,  0.0627, -0.0184,  ..., -0.1163,  0.0314,  0.0256],\n",
      "         [-0.0258,  0.0621, -0.0203,  ..., -0.1116,  0.0320,  0.0269]]],\n",
      "       device='cuda:0'))}]}]\n",
      "Step 200 - Last token probs (min/max): 0.002458449685946107 / 0.10149881988763809\n",
      "Step 250 - past_kv structure:  [{'left': [{'chunk_attn': (tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [-0.1190,  0.9978, -1.2111,  ...,  2.5506, -1.0747,  0.3911],\n",
      "         [-0.5331,  0.1327,  0.0112,  ...,  2.2460,  1.0294,  0.2650],\n",
      "         [ 0.5949, -0.1051,  0.0852,  ...,  0.2453, -0.2001,  0.2675]]],\n",
      "       device='cuda:0'), tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [-0.1190,  0.9978, -1.2111,  ...,  2.5506, -1.0747,  0.3911],\n",
      "         [-0.5331,  0.1327,  0.0112,  ...,  2.2460,  1.0294,  0.2650],\n",
      "         [ 0.5949, -0.1051,  0.0852,  ...,  0.2453, -0.2001,  0.2675]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'), tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [-0.6557,  0.7522, -0.9239,  ...,  0.9577, -1.2355,  0.5917],\n",
      "         [ 0.1825, -0.2595, -1.2704,  ...,  1.2910, -0.0428,  1.7050],\n",
      "         [ 0.4630, -0.0543,  1.2808,  ..., -0.2044,  0.0512,  0.8269]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [-0.6557,  0.7522, -0.9239,  ...,  0.9577, -1.2355,  0.5917],\n",
      "         [ 0.1825, -0.2595, -1.2704,  ...,  1.2910, -0.0428,  1.7050],\n",
      "         [ 0.4630, -0.0543,  1.2808,  ..., -0.2044,  0.0512,  0.8269]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-5.0165, -0.4275, -7.3542,  ...,  5.5419,  1.3848, -0.4258],\n",
      "         [-5.0508, -0.2982, -7.2394,  ...,  5.5557,  1.3711, -0.2715],\n",
      "         [-5.0219, -0.5612, -7.4144,  ...,  5.7488,  1.2803, -0.3024]]],\n",
      "       device='cuda:0'), tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-5.0165, -0.4275, -7.3542,  ...,  5.5419,  1.3848, -0.4258],\n",
      "         [-5.0508, -0.2982, -7.2394,  ...,  5.5557,  1.3711, -0.2715],\n",
      "         [-5.0219, -0.5612, -7.4144,  ...,  5.7488,  1.2803, -0.3024]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [ 0.0096,  0.8205, -1.2101,  ...,  1.1204,  2.8158,  0.5947],\n",
      "         [ 1.0965,  2.2517,  0.1547,  ...,  0.2579, -0.4916,  1.3295],\n",
      "         [ 1.8612,  1.6711,  0.0171,  ...,  0.8448, -0.7649,  1.9934]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [ 0.0096,  0.8205, -1.2101,  ...,  1.1204,  2.8158,  0.5947],\n",
      "         [ 1.0965,  2.2517,  0.1547,  ...,  0.2579, -0.4916,  1.3295],\n",
      "         [ 1.8612,  1.6711,  0.0171,  ...,  0.8448, -0.7649,  1.9934]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0471,  1.9554,  1.9760,  ...,  1.4772,  1.3013, -2.7924],\n",
      "         [ 3.0470,  1.9541,  1.9745,  ...,  1.4801,  1.3017, -2.7930],\n",
      "         [ 3.0465,  1.9544,  1.9756,  ...,  1.4776,  1.3009, -2.7927]]],\n",
      "       device='cuda:0'), tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0471,  1.9554,  1.9760,  ...,  1.4772,  1.3013, -2.7924],\n",
      "         [ 3.0470,  1.9541,  1.9745,  ...,  1.4801,  1.3017, -2.7930],\n",
      "         [ 3.0465,  1.9544,  1.9756,  ...,  1.4776,  1.3009, -2.7927]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 1.3449,  0.0231, -0.9118,  ...,  0.1667, -0.8239,  1.5555],\n",
      "         [-1.0541,  3.0497,  1.5171,  ...,  2.5820,  0.1493,  0.5648],\n",
      "         [ 0.2337,  0.4533, -0.4005,  ...,  1.3993,  2.7561,  1.2529]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 1.3449,  0.0231, -0.9118,  ...,  0.1667, -0.8239,  1.5555],\n",
      "         [-1.0541,  3.0497,  1.5171,  ...,  2.5820,  0.1493,  0.5648],\n",
      "         [ 0.2337,  0.4533, -0.4005,  ...,  1.3993,  2.7561,  1.2529]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0023,  0.0242,  0.0058,  ..., -0.0830, -0.0685,  0.0021],\n",
      "         [-0.0022,  0.0222,  0.0044,  ..., -0.0827, -0.0687,  0.0016],\n",
      "         [-0.0007,  0.0227,  0.0053,  ..., -0.0835, -0.0679,  0.0008]]],\n",
      "       device='cuda:0'), tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0023,  0.0242,  0.0058,  ..., -0.0830, -0.0685,  0.0021],\n",
      "         [-0.0022,  0.0222,  0.0044,  ..., -0.0827, -0.0687,  0.0016],\n",
      "         [-0.0007,  0.0227,  0.0053,  ..., -0.0835, -0.0679,  0.0008]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [-1.3975,  2.3569, -0.3252,  ...,  0.2425,  0.0502,  1.2637],\n",
      "         [-0.1528,  1.5568,  0.5822,  ...,  1.2843, -0.5872,  1.5611],\n",
      "         [-0.5039, -0.4359,  0.8738,  ..., -0.0897, -0.5100,  3.4678]]],\n",
      "       device='cuda:0'), tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [-1.3975,  2.3569, -0.3252,  ...,  0.2425,  0.0502,  1.2637],\n",
      "         [-0.1528,  1.5568,  0.5822,  ...,  1.2843, -0.5872,  1.5611],\n",
      "         [-0.5039, -0.4359,  0.8738,  ..., -0.0897, -0.5100,  3.4678]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'), tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [ 1.7001,  1.2180, -0.3265,  ..., -0.0916,  1.3643,  0.3947],\n",
      "         [-0.5303,  0.4597, -0.1946,  ...,  2.0720, -0.8573,  2.3085],\n",
      "         [ 0.4886,  1.8659, -0.4831,  ...,  0.9824,  0.1302,  0.9454]]],\n",
      "       device='cuda:0'), tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [ 1.7001,  1.2180, -0.3265,  ..., -0.0916,  1.3643,  0.3947],\n",
      "         [-0.5303,  0.4597, -0.1946,  ...,  2.0720, -0.8573,  2.3085],\n",
      "         [ 0.4886,  1.8659, -0.4831,  ...,  0.9824,  0.1302,  0.9454]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.5517, -0.2832, -0.0421,  ...,  1.4002, -0.5219, -0.2038],\n",
      "         [-1.0675, -0.1758, -0.2529,  ...,  1.3604, -0.3445, -0.0239],\n",
      "         [-0.7550, -0.3706, -0.3443,  ...,  1.3746, -0.4095, -0.0930]]],\n",
      "       device='cuda:0'), tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.5517, -0.2832, -0.0421,  ...,  1.4002, -0.5219, -0.2038],\n",
      "         [-1.0675, -0.1758, -0.2529,  ...,  1.3604, -0.3445, -0.0239],\n",
      "         [-0.7550, -0.3706, -0.3443,  ...,  1.3746, -0.4095, -0.0930]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [-0.2830,  1.8931, -1.3078,  ...,  0.6788, -0.3589,  0.6352],\n",
      "         [ 0.7680,  0.7049,  0.5190,  ...,  0.9026,  1.4610, -1.1621],\n",
      "         [ 1.2182,  1.5679,  0.5855,  ..., -0.3893,  1.8231,  0.7667]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [-0.2830,  1.8931, -1.3078,  ...,  0.6788, -0.3589,  0.6352],\n",
      "         [ 0.7680,  0.7049,  0.5190,  ...,  0.9026,  1.4610, -1.1621],\n",
      "         [ 1.2182,  1.5679,  0.5855,  ..., -0.3893,  1.8231,  0.7667]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3492,  0.3921,  0.0132,  ..., -0.4878,  0.5431, -0.2180],\n",
      "         [ 0.3249,  0.3898,  0.0232,  ..., -0.4964,  0.5423, -0.2052],\n",
      "         [ 0.3354,  0.4043,  0.0451,  ..., -0.4887,  0.5652, -0.2425]]],\n",
      "       device='cuda:0'), tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3492,  0.3921,  0.0132,  ..., -0.4878,  0.5431, -0.2180],\n",
      "         [ 0.3249,  0.3898,  0.0232,  ..., -0.4964,  0.5423, -0.2052],\n",
      "         [ 0.3354,  0.4043,  0.0451,  ..., -0.4887,  0.5652, -0.2425]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [ 0.2415,  2.5494,  3.2857,  ...,  1.7341, -0.4372,  2.1367],\n",
      "         [-1.4047,  1.1617,  0.6816,  ...,  1.8061, -0.3334,  1.2625],\n",
      "         [-0.7144,  2.7254, -0.9618,  ...,  1.4960, -1.1580, -0.9438]]],\n",
      "       device='cuda:0'), tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [ 0.2415,  2.5494,  3.2857,  ...,  1.7341, -0.4372,  2.1367],\n",
      "         [-1.4047,  1.1617,  0.6816,  ...,  1.8061, -0.3334,  1.2625],\n",
      "         [-0.7144,  2.7254, -0.9618,  ...,  1.4960, -1.1580, -0.9438]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0600,  0.0851, -0.0294,  ..., -0.1133, -0.0020, -0.0353],\n",
      "         [ 0.0729,  0.0972, -0.0324,  ..., -0.1218, -0.0106, -0.0246],\n",
      "         [ 0.0688,  0.0917, -0.0234,  ..., -0.1141, -0.0236, -0.0218]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0600,  0.0851, -0.0294,  ..., -0.1133, -0.0020, -0.0353],\n",
      "         [ 0.0729,  0.0972, -0.0324,  ..., -0.1218, -0.0106, -0.0246],\n",
      "         [ 0.0688,  0.0917, -0.0234,  ..., -0.1141, -0.0236, -0.0218]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [-0.5897, -0.7123, -0.8549,  ...,  2.4931, -1.2725,  0.1036],\n",
      "         [ 1.5141,  1.8277, -1.7525,  ...,  0.3699, -0.9254,  1.6017],\n",
      "         [ 0.4899,  0.2706, -1.6899,  ...,  1.4825, -0.0502,  0.5906]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [-0.5897, -0.7123, -0.8549,  ...,  2.4931, -1.2725,  0.1036],\n",
      "         [ 1.5141,  1.8277, -1.7525,  ...,  0.3699, -0.9254,  1.6017],\n",
      "         [ 0.4899,  0.2706, -1.6899,  ...,  1.4825, -0.0502,  0.5906]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [ 0.5589,  0.3039,  0.6587,  ...,  0.6235, -0.9856,  0.4900],\n",
      "         [-0.3761,  0.1376,  0.7370,  ...,  1.6329, -0.1726,  0.0512],\n",
      "         [ 0.0734,  0.6630, -0.5448,  ...,  0.7108,  0.3138,  0.6643]]],\n",
      "       device='cuda:0'), tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [ 0.5589,  0.3039,  0.6587,  ...,  0.6235, -0.9856,  0.4900],\n",
      "         [-0.3761,  0.1376,  0.7370,  ...,  1.6329, -0.1726,  0.0512],\n",
      "         [ 0.0734,  0.6630, -0.5448,  ...,  0.7108,  0.3138,  0.6643]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-0.9492,  0.3209, -0.0304,  ...,  2.5586, -0.0227,  0.8360],\n",
      "         [ 0.8376,  3.5070, -0.1216,  ...,  2.1646, -0.9127,  1.0483],\n",
      "         [-1.8226, -0.1346,  0.7774,  ..., -0.5677,  0.8771,  1.3056]]],\n",
      "       device='cuda:0'), tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-0.9492,  0.3209, -0.0304,  ...,  2.5586, -0.0227,  0.8360],\n",
      "         [ 0.8376,  3.5070, -0.1216,  ...,  2.1646, -0.9127,  1.0483],\n",
      "         [-1.8226, -0.1346,  0.7774,  ..., -0.5677,  0.8771,  1.3056]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-2.6902, -0.5476,  0.4336,  ..., -1.7516, -1.5874,  0.4770],\n",
      "         [-2.6101, -0.1392,  0.5815,  ..., -1.9287, -1.0253,  0.1854],\n",
      "         [-2.5293, -0.2501,  0.0206,  ..., -1.8071, -1.9520,  0.5673]]],\n",
      "       device='cuda:0'), tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-2.6902, -0.5476,  0.4336,  ..., -1.7516, -1.5874,  0.4770],\n",
      "         [-2.6101, -0.1392,  0.5815,  ..., -1.9287, -1.0253,  0.1854],\n",
      "         [-2.5293, -0.2501,  0.0206,  ..., -1.8071, -1.9520,  0.5673]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 0.7784,  1.6909,  0.1223,  ...,  1.6841,  0.0678,  2.3929],\n",
      "         [-1.0429,  0.6319,  0.8185,  ...,  0.6973,  0.9548,  1.1275],\n",
      "         [ 0.1869,  1.5600,  0.2489,  ...,  2.2376, -0.9020,  1.4624]]],\n",
      "       device='cuda:0'), tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 0.7784,  1.6909,  0.1223,  ...,  1.6841,  0.0678,  2.3929],\n",
      "         [-1.0429,  0.6319,  0.8185,  ...,  0.6973,  0.9548,  1.1275],\n",
      "         [ 0.1869,  1.5600,  0.2489,  ...,  2.2376, -0.9020,  1.4624]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.5145,  5.1093, -0.1037,  ...,  0.0879, -0.7273,  2.7869],\n",
      "         [ 0.5243,  5.1174, -0.0735,  ...,  0.1276, -0.7243,  2.8617],\n",
      "         [ 0.6100,  5.1647, -0.0384,  ...,  0.0423, -0.6997,  2.8368]]],\n",
      "       device='cuda:0'), tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.5145,  5.1093, -0.1037,  ...,  0.0879, -0.7273,  2.7869],\n",
      "         [ 0.5243,  5.1174, -0.0735,  ...,  0.1276, -0.7243,  2.8617],\n",
      "         [ 0.6100,  5.1647, -0.0384,  ...,  0.0423, -0.6997,  2.8368]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [-1.2097,  0.6560,  1.6002,  ...,  0.9881, -1.4529, -0.2198],\n",
      "         [ 0.2721,  0.7410, -0.3996,  ...,  2.4842, -0.1296,  3.5448],\n",
      "         [ 1.0590,  0.9818,  0.5851,  ...,  0.4016, -0.2725,  2.6275]]],\n",
      "       device='cuda:0'), tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [-1.2097,  0.6560,  1.6002,  ...,  0.9881, -1.4529, -0.2198],\n",
      "         [ 0.2721,  0.7410, -0.3996,  ...,  2.4842, -0.1296,  3.5448],\n",
      "         [ 1.0590,  0.9818,  0.5851,  ...,  0.4016, -0.2725,  2.6275]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0766, -0.0377,  0.0597,  ..., -0.0288, -0.0838, -0.0933],\n",
      "         [ 0.0763, -0.0391,  0.0566,  ..., -0.0273, -0.0799, -0.0923],\n",
      "         [ 0.0753, -0.0395,  0.0587,  ..., -0.0291, -0.0814, -0.0932]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0766, -0.0377,  0.0597,  ..., -0.0288, -0.0838, -0.0933],\n",
      "         [ 0.0763, -0.0391,  0.0566,  ..., -0.0273, -0.0799, -0.0923],\n",
      "         [ 0.0753, -0.0395,  0.0587,  ..., -0.0291, -0.0814, -0.0932]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [-1.7005,  0.5754,  0.8006,  ...,  0.1894,  2.0991,  1.8057],\n",
      "         [-1.3995,  2.2608,  0.2162,  ...,  0.5475,  0.5002,  1.7002],\n",
      "         [-1.4358, -1.5879, -0.7592,  ...,  1.9289, -0.3171,  1.7583]]],\n",
      "       device='cuda:0'), tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [-1.7005,  0.5754,  0.8006,  ...,  0.1894,  2.0991,  1.8057],\n",
      "         [-1.3995,  2.2608,  0.2162,  ...,  0.5475,  0.5002,  1.7002],\n",
      "         [-1.4358, -1.5879, -0.7592,  ...,  1.9289, -0.3171,  1.7583]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [ 0.1827,  0.0432, -1.3988,  ...,  0.3175, -0.4109, -0.4216],\n",
      "         [-0.5537,  0.3527,  0.9356,  ...,  1.2636, -0.1332,  1.5042],\n",
      "         [ 0.9511,  0.1017, -0.1370,  ..., -0.8176,  0.3164,  0.3268]]],\n",
      "       device='cuda:0'), tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [ 0.1827,  0.0432, -1.3988,  ...,  0.3175, -0.4109, -0.4216],\n",
      "         [-0.5537,  0.3527,  0.9356,  ...,  1.2636, -0.1332,  1.5042],\n",
      "         [ 0.9511,  0.1017, -0.1370,  ..., -0.8176,  0.3164,  0.3268]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.4282,  0.8103,  0.0640,  ...,  1.8608,  0.8175,  0.7618],\n",
      "         [-1.2073,  1.3849,  0.4869,  ...,  1.7464,  1.7099,  1.8392],\n",
      "         [-1.3566, -0.0305, -0.6688,  ...,  2.2248,  1.1513,  1.2855]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.4282,  0.8103,  0.0640,  ...,  1.8608,  0.8175,  0.7618],\n",
      "         [-1.2073,  1.3849,  0.4869,  ...,  1.7464,  1.7099,  1.8392],\n",
      "         [-1.3566, -0.0305, -0.6688,  ...,  2.2248,  1.1513,  1.2855]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.3461,  0.5067, -3.8890,  ...,  1.8036, -3.4920, -1.3677],\n",
      "         [-1.3952,  0.8768, -3.7150,  ...,  1.3340, -2.9934, -1.8197],\n",
      "         [-1.1964,  0.7106, -3.9657,  ...,  1.3945, -3.2796, -1.5222]]],\n",
      "       device='cuda:0'), tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.3461,  0.5067, -3.8890,  ...,  1.8036, -3.4920, -1.3677],\n",
      "         [-1.3952,  0.8768, -3.7150,  ...,  1.3340, -2.9934, -1.8197],\n",
      "         [-1.1964,  0.7106, -3.9657,  ...,  1.3945, -3.2796, -1.5222]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-1.0630,  0.9572,  0.1775,  ...,  0.3468, -0.9840,  1.5646],\n",
      "         [ 0.5831,  1.0703, -0.9024,  ...,  0.5533, -2.9192,  1.4245],\n",
      "         [ 0.0307,  0.1533,  0.1458,  ...,  1.8754,  2.3450, -0.2857]]],\n",
      "       device='cuda:0'), tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-1.0630,  0.9572,  0.1775,  ...,  0.3468, -0.9840,  1.5646],\n",
      "         [ 0.5831,  1.0703, -0.9024,  ...,  0.5533, -2.9192,  1.4245],\n",
      "         [ 0.0307,  0.1533,  0.1458,  ...,  1.8754,  2.3450, -0.2857]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2881, -0.4982, -0.6802,  ...,  0.5408, -2.5791,  0.7717],\n",
      "         [-1.3062, -0.4783, -0.6824,  ...,  0.5009, -2.5890,  0.7650],\n",
      "         [-1.2962, -0.5274, -0.6769,  ...,  0.5279, -2.6242,  0.8178]]],\n",
      "       device='cuda:0'), tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2881, -0.4982, -0.6802,  ...,  0.5408, -2.5791,  0.7717],\n",
      "         [-1.3062, -0.4783, -0.6824,  ...,  0.5009, -2.5890,  0.7650],\n",
      "         [-1.2962, -0.5274, -0.6769,  ...,  0.5279, -2.6242,  0.8178]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [-1.7930,  3.0110,  1.2559,  ...,  1.5954, -1.0037,  1.3904],\n",
      "         [ 0.2114, -0.4905,  0.0054,  ...,  0.0213, -0.3605, -0.5709],\n",
      "         [-1.9091,  1.0549, -0.6921,  ...,  0.8760,  0.2279,  1.1977]]],\n",
      "       device='cuda:0'), tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [-1.7930,  3.0110,  1.2559,  ...,  1.5954, -1.0037,  1.3904],\n",
      "         [ 0.2114, -0.4905,  0.0054,  ...,  0.0213, -0.3605, -0.5709],\n",
      "         [-1.9091,  1.0549, -0.6921,  ...,  0.8760,  0.2279,  1.1977]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0192,  0.1140,  0.0354,  ...,  0.0746, -0.0340, -0.0345],\n",
      "         [ 0.0175,  0.1159,  0.0325,  ...,  0.0730, -0.0280, -0.0370],\n",
      "         [ 0.0155,  0.1090,  0.0319,  ...,  0.0746, -0.0281, -0.0323]]],\n",
      "       device='cuda:0'), tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0192,  0.1140,  0.0354,  ...,  0.0746, -0.0340, -0.0345],\n",
      "         [ 0.0175,  0.1159,  0.0325,  ...,  0.0730, -0.0280, -0.0370],\n",
      "         [ 0.0155,  0.1090,  0.0319,  ...,  0.0746, -0.0281, -0.0323]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [-1.0538,  1.7459,  1.2820,  ...,  1.2202,  0.6217,  1.3041],\n",
      "         [ 0.4724, -0.3730, -0.1483,  ...,  0.9991,  1.1855,  0.1786],\n",
      "         [ 1.3069,  0.4304, -0.2662,  ...,  2.0311, -1.2748,  3.2413]]],\n",
      "       device='cuda:0'), tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [-1.0538,  1.7459,  1.2820,  ...,  1.2202,  0.6217,  1.3041],\n",
      "         [ 0.4724, -0.3730, -0.1483,  ...,  0.9991,  1.1855,  0.1786],\n",
      "         [ 1.3069,  0.4304, -0.2662,  ...,  2.0311, -1.2748,  3.2413]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [-0.9987,  0.0398,  1.6259,  ..., -0.5377, -1.2322,  0.1791],\n",
      "         [-0.9191,  0.7906,  0.0537,  ...,  0.8398, -0.7459, -0.3771],\n",
      "         [ 0.7939, -1.2631,  0.6778,  ..., -1.0858,  0.9838,  1.4923]]],\n",
      "       device='cuda:0'), tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [-0.9987,  0.0398,  1.6259,  ..., -0.5377, -1.2322,  0.1791],\n",
      "         [-0.9191,  0.7906,  0.0537,  ...,  0.8398, -0.7459, -0.3771],\n",
      "         [ 0.7939, -1.2631,  0.6778,  ..., -1.0858,  0.9838,  1.4923]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [ 0.8723,  0.4204, -2.5707,  ...,  1.8929, -1.2835,  0.7253],\n",
      "         [-0.7532,  1.2689,  0.1432,  ...,  1.0526,  1.4857, -0.1648],\n",
      "         [-0.3977,  2.0198, -0.2628,  ...,  2.3605,  0.2572,  1.2966]]],\n",
      "       device='cuda:0'), tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [ 0.8723,  0.4204, -2.5707,  ...,  1.8929, -1.2835,  0.7253],\n",
      "         [-0.7532,  1.2689,  0.1432,  ...,  1.0526,  1.4857, -0.1648],\n",
      "         [-0.3977,  2.0198, -0.2628,  ...,  2.3605,  0.2572,  1.2966]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.2935, -0.7760,  1.2891,  ..., -2.8253,  0.8431, -0.5727],\n",
      "         [-2.2940, -0.7319,  1.5743,  ..., -3.0897,  1.1685, -0.4699],\n",
      "         [-2.1217, -1.2671,  1.5350,  ..., -2.8994,  1.3126, -0.1537]]],\n",
      "       device='cuda:0'), tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.2935, -0.7760,  1.2891,  ..., -2.8253,  0.8431, -0.5727],\n",
      "         [-2.2940, -0.7319,  1.5743,  ..., -3.0897,  1.1685, -0.4699],\n",
      "         [-2.1217, -1.2671,  1.5350,  ..., -2.8994,  1.3126, -0.1537]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [-0.7514,  0.5172,  0.2054,  ...,  1.5254,  1.8018, -0.4277],\n",
      "         [ 1.0543,  0.3949, -0.0138,  ...,  1.0322, -0.5592,  0.7687],\n",
      "         [-0.6358,  0.1999,  0.4482,  ...,  0.4005, -0.4140,  0.6120]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [-0.7514,  0.5172,  0.2054,  ...,  1.5254,  1.8018, -0.4277],\n",
      "         [ 1.0543,  0.3949, -0.0138,  ...,  1.0322, -0.5592,  0.7687],\n",
      "         [-0.6358,  0.1999,  0.4482,  ...,  0.4005, -0.4140,  0.6120]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4354,  1.5419, -0.1616,  ..., -0.3579, -0.0926,  2.3938],\n",
      "         [ 2.3988,  1.5609, -0.1935,  ..., -0.4065, -0.0214,  2.3548],\n",
      "         [ 2.4069,  1.5743, -0.1493,  ..., -0.3887, -0.0282,  2.4342]]],\n",
      "       device='cuda:0'), tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4354,  1.5419, -0.1616,  ..., -0.3579, -0.0926,  2.3938],\n",
      "         [ 2.3988,  1.5609, -0.1935,  ..., -0.4065, -0.0214,  2.3548],\n",
      "         [ 2.4069,  1.5743, -0.1493,  ..., -0.3887, -0.0282,  2.4342]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 0.2500,  2.6938, -1.8304,  ...,  0.7505,  0.1013, -0.9076],\n",
      "         [-0.2228,  3.1935, -0.7217,  ...,  1.8995,  0.2675,  0.8441],\n",
      "         [-0.6544,  1.9980, -0.0614,  ...,  0.7478,  0.6568,  1.1730]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 0.2500,  2.6938, -1.8304,  ...,  0.7505,  0.1013, -0.9076],\n",
      "         [-0.2228,  3.1935, -0.7217,  ...,  1.8995,  0.2675,  0.8441],\n",
      "         [-0.6544,  1.9980, -0.0614,  ...,  0.7478,  0.6568,  1.1730]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0217, -0.0010,  0.0234,  ..., -0.0096, -0.0070, -0.0183],\n",
      "         [ 0.0235, -0.0020,  0.0233,  ..., -0.0107, -0.0058, -0.0178],\n",
      "         [ 0.0223, -0.0003,  0.0222,  ..., -0.0101, -0.0069, -0.0188]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0217, -0.0010,  0.0234,  ..., -0.0096, -0.0070, -0.0183],\n",
      "         [ 0.0235, -0.0020,  0.0233,  ..., -0.0107, -0.0058, -0.0178],\n",
      "         [ 0.0223, -0.0003,  0.0222,  ..., -0.0101, -0.0069, -0.0188]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [-0.5895,  0.6398, -0.1155,  ..., -0.5208, -1.4521,  0.6655],\n",
      "         [ 1.0897, -0.2098, -0.0622,  ...,  1.6426, -0.1117,  0.2976],\n",
      "         [ 0.0329,  1.2918,  1.2821,  ...,  1.6749,  0.4716,  1.4511]]],\n",
      "       device='cuda:0'), tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [-0.5895,  0.6398, -0.1155,  ..., -0.5208, -1.4521,  0.6655],\n",
      "         [ 1.0897, -0.2098, -0.0622,  ...,  1.6426, -0.1117,  0.2976],\n",
      "         [ 0.0329,  1.2918,  1.2821,  ...,  1.6749,  0.4716,  1.4511]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.3021,  0.7092, -1.3483,  ..., -1.3825, -0.4132, -0.4329],\n",
      "         [ 1.3300, -1.9847, -1.2707,  ..., -0.1329,  0.7718,  0.0799],\n",
      "         [-0.4653,  2.4979,  0.1797,  ...,  1.0113, -0.6964, -0.2188]]],\n",
      "       device='cuda:0'), tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.3021,  0.7092, -1.3483,  ..., -1.3825, -0.4132, -0.4329],\n",
      "         [ 1.3300, -1.9847, -1.2707,  ..., -0.1329,  0.7718,  0.0799],\n",
      "         [-0.4653,  2.4979,  0.1797,  ...,  1.0113, -0.6964, -0.2188]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 1.1751e+00,  4.4604e-01,  1.7995e-01,  ...,  2.7330e-01,\n",
      "          -9.9122e-02,  1.7951e+00],\n",
      "         [ 2.4973e-01,  2.1021e-01, -4.2720e-01,  ...,  2.6839e+00,\n",
      "           4.0048e-01,  1.7301e-01],\n",
      "         [ 1.0402e-02,  8.9785e-01,  2.1565e+00,  ...,  1.5428e+00,\n",
      "          -8.0254e-01,  2.8105e-03]]], device='cuda:0'), tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 1.1751e+00,  4.4604e-01,  1.7995e-01,  ...,  2.7330e-01,\n",
      "          -9.9122e-02,  1.7951e+00],\n",
      "         [ 2.4973e-01,  2.1021e-01, -4.2720e-01,  ...,  2.6839e+00,\n",
      "           4.0048e-01,  1.7301e-01],\n",
      "         [ 1.0402e-02,  8.9785e-01,  2.1565e+00,  ...,  1.5428e+00,\n",
      "          -8.0254e-01,  2.8105e-03]]], device='cuda:0')), 'logits_attn': (tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.4386,  3.3902,  5.9410,  ..., -1.9837, -8.4180, -3.3709],\n",
      "         [ 4.7687,  3.1147,  5.7292,  ..., -2.0225, -8.4796, -3.4766],\n",
      "         [ 4.8880,  2.8317,  5.9498,  ..., -2.1699, -8.6607, -3.6112]]],\n",
      "       device='cuda:0'), tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.4386,  3.3902,  5.9410,  ..., -1.9837, -8.4180, -3.3709],\n",
      "         [ 4.7687,  3.1147,  5.7292,  ..., -2.0225, -8.4796, -3.4766],\n",
      "         [ 4.8880,  2.8317,  5.9498,  ..., -2.1699, -8.6607, -3.6112]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.4796,  2.1251, -0.6649,  ...,  0.7691,  1.3867,  0.7612],\n",
      "         [ 0.0209,  2.0087, -0.1137,  ...,  1.0482,  0.4740,  2.0720],\n",
      "         [-0.2045,  0.7983, -0.8600,  ...,  1.0150,  0.7715,  0.3613]]],\n",
      "       device='cuda:0'), tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.4796,  2.1251, -0.6649,  ...,  0.7691,  1.3867,  0.7612],\n",
      "         [ 0.0209,  2.0087, -0.1137,  ...,  1.0482,  0.4740,  2.0720],\n",
      "         [-0.2045,  0.7983, -0.8600,  ...,  1.0150,  0.7715,  0.3613]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5725, -8.7672,  4.9044,  ...,  5.1914,  2.4790,  3.4370],\n",
      "         [ 3.5725, -8.7708,  4.9033,  ...,  5.1953,  2.4734,  3.4417],\n",
      "         [ 3.5760, -8.7711,  4.9053,  ...,  5.1933,  2.4847,  3.4452]]],\n",
      "       device='cuda:0'), tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5725, -8.7672,  4.9044,  ...,  5.1914,  2.4790,  3.4370],\n",
      "         [ 3.5725, -8.7708,  4.9033,  ...,  5.1953,  2.4734,  3.4417],\n",
      "         [ 3.5760, -8.7711,  4.9053,  ...,  5.1933,  2.4847,  3.4452]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 6.7053e-01,  1.7680e+00,  1.1601e+00,  ...,  2.0022e+00,\n",
      "          -7.7514e-02,  1.3642e+00],\n",
      "         [-1.9365e+00,  6.9702e-01, -5.2527e-01,  ..., -6.9341e-01,\n",
      "          -8.3838e-01,  2.9927e+00],\n",
      "         [-9.4992e-01,  1.0665e+00,  5.5727e-01,  ..., -6.1645e-01,\n",
      "          -8.0557e-01,  1.1445e+00],\n",
      "         ...,\n",
      "         [-1.9955e+00,  1.8378e+00, -9.9884e-01,  ..., -3.6586e-01,\n",
      "          -6.5767e-01,  1.9801e+00],\n",
      "         [-1.2477e-03,  3.7741e-01, -2.0954e+00,  ...,  1.2535e+00,\n",
      "          -5.5139e-01,  6.2097e-01],\n",
      "         [ 5.9082e-01,  4.6068e-01,  6.4044e-01,  ...,  4.6190e-01,\n",
      "           1.1978e+00, -9.3794e-02]]], device='cuda:0'), tensor([[[ 6.7053e-01,  1.7680e+00,  1.1601e+00,  ...,  2.0022e+00,\n",
      "          -7.7514e-02,  1.3642e+00],\n",
      "         [-1.9365e+00,  6.9702e-01, -5.2527e-01,  ..., -6.9341e-01,\n",
      "          -8.3838e-01,  2.9927e+00],\n",
      "         [-9.4992e-01,  1.0665e+00,  5.5727e-01,  ..., -6.1645e-01,\n",
      "          -8.0557e-01,  1.1445e+00],\n",
      "         ...,\n",
      "         [-1.9955e+00,  1.8378e+00, -9.9884e-01,  ..., -3.6586e-01,\n",
      "          -6.5767e-01,  1.9801e+00],\n",
      "         [-1.2477e-03,  3.7741e-01, -2.0954e+00,  ...,  1.2535e+00,\n",
      "          -5.5139e-01,  6.2097e-01],\n",
      "         [ 5.9082e-01,  4.6068e-01,  6.4044e-01,  ...,  4.6190e-01,\n",
      "           1.1978e+00, -9.3794e-02]]], device='cuda:0')), 'logits_attn': (tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0017, -0.0032, -0.0672,  ..., -0.0056,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0031, -0.0666,  ..., -0.0054,  0.0023, -0.0189],\n",
      "         [-0.0021, -0.0032, -0.0662,  ..., -0.0053,  0.0012, -0.0184]]],\n",
      "       device='cuda:0'), tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0017, -0.0032, -0.0672,  ..., -0.0056,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0031, -0.0666,  ..., -0.0054,  0.0023, -0.0189],\n",
      "         [-0.0021, -0.0032, -0.0662,  ..., -0.0053,  0.0012, -0.0184]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [ 0.6258, -0.1161,  0.2068,  ...,  2.2489,  1.7484,  0.0621],\n",
      "         [-0.0595,  0.8153,  1.7369,  ...,  1.8262,  0.2283, -0.4620],\n",
      "         [ 0.3693,  1.8286,  2.5909,  ..., -0.0858,  0.4932,  0.1980]]],\n",
      "       device='cuda:0'), tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [ 0.6258, -0.1161,  0.2068,  ...,  2.2489,  1.7484,  0.0621],\n",
      "         [-0.0595,  0.8153,  1.7369,  ...,  1.8262,  0.2283, -0.4620],\n",
      "         [ 0.3693,  1.8286,  2.5909,  ..., -0.0858,  0.4932,  0.1980]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 1.7725, -1.1347, -1.4463,  ...,  0.7428,  0.2874,  1.4129],\n",
      "         [ 3.7257, -2.2049, -0.2315,  ...,  0.6605,  0.7891,  2.2566],\n",
      "         [ 0.3796, -1.8664, -0.0684,  ...,  0.5033,  1.2569,  1.9529]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 1.7725, -1.1347, -1.4463,  ...,  0.7428,  0.2874,  1.4129],\n",
      "         [ 3.7257, -2.2049, -0.2315,  ...,  0.6605,  0.7891,  2.2566],\n",
      "         [ 0.3796, -1.8664, -0.0684,  ...,  0.5033,  1.2569,  1.9529]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [ 0.9673, -0.4170,  1.0010,  ...,  1.1316,  0.1117,  0.1560],\n",
      "         [-2.0782,  3.3792,  1.3183,  ...,  0.2648,  0.8228,  0.2480],\n",
      "         [ 0.1909,  1.9145, -0.3984,  ...,  1.5121, -0.2496,  1.2630]]],\n",
      "       device='cuda:0'), tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [ 0.9673, -0.4170,  1.0010,  ...,  1.1316,  0.1117,  0.1560],\n",
      "         [-2.0782,  3.3792,  1.3183,  ...,  0.2648,  0.8228,  0.2480],\n",
      "         [ 0.1909,  1.9145, -0.3984,  ...,  1.5121, -0.2496,  1.2630]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.9432, -1.6820,  0.1712,  ..., -0.5544,  2.6673,  1.9578],\n",
      "         [-4.8406, -1.5963, -0.0051,  ..., -0.4034,  2.8368,  1.9120],\n",
      "         [-4.8785, -2.0887, -0.0200,  ..., -0.2987,  2.7241,  1.8987]]],\n",
      "       device='cuda:0'), tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.9432, -1.6820,  0.1712,  ..., -0.5544,  2.6673,  1.9578],\n",
      "         [-4.8406, -1.5963, -0.0051,  ..., -0.4034,  2.8368,  1.9120],\n",
      "         [-4.8785, -2.0887, -0.0200,  ..., -0.2987,  2.7241,  1.8987]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [ 0.0867,  0.4857, -0.6018,  ...,  2.8736, -1.1083, -0.3777],\n",
      "         [-0.2375,  2.2240,  0.5039,  ...,  2.4771,  0.3446,  0.9077],\n",
      "         [-0.6080,  1.4957, -0.4834,  ...,  2.0861, -1.0655,  1.1335]]],\n",
      "       device='cuda:0'), tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [ 0.0867,  0.4857, -0.6018,  ...,  2.8736, -1.1083, -0.3777],\n",
      "         [-0.2375,  2.2240,  0.5039,  ...,  2.4771,  0.3446,  0.9077],\n",
      "         [-0.6080,  1.4957, -0.4834,  ...,  2.0861, -1.0655,  1.1335]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0334,  0.2547,  0.4874,  ..., -0.3133,  0.6691, -0.6253],\n",
      "         [ 0.0146,  0.2354,  0.4780,  ..., -0.2925,  0.7426, -0.5566],\n",
      "         [ 0.0144,  0.2331,  0.4349,  ..., -0.3092,  0.7151, -0.5557]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0334,  0.2547,  0.4874,  ..., -0.3133,  0.6691, -0.6253],\n",
      "         [ 0.0146,  0.2354,  0.4780,  ..., -0.2925,  0.7426, -0.5566],\n",
      "         [ 0.0144,  0.2331,  0.4349,  ..., -0.3092,  0.7151, -0.5557]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.1394,  1.0643, -0.1334,  ...,  1.7272, -0.1287, -0.0901],\n",
      "         [-0.5129,  1.4609, -0.4999,  ...,  2.1661,  0.5620,  1.6456],\n",
      "         [ 0.1075,  1.5691,  0.6650,  ...,  1.8831, -0.3128,  1.1174]]],\n",
      "       device='cuda:0'), tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.1394,  1.0643, -0.1334,  ...,  1.7272, -0.1287, -0.0901],\n",
      "         [-0.5129,  1.4609, -0.4999,  ...,  2.1661,  0.5620,  1.6456],\n",
      "         [ 0.1075,  1.5691,  0.6650,  ...,  1.8831, -0.3128,  1.1174]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0543, -0.0347,  0.0781,  ...,  0.0567,  0.0763, -0.0205],\n",
      "         [-0.0616, -0.0320,  0.0823,  ...,  0.0502,  0.0800, -0.0170],\n",
      "         [-0.0593, -0.0322,  0.0772,  ...,  0.0538,  0.0791, -0.0182]]],\n",
      "       device='cuda:0'), tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0543, -0.0347,  0.0781,  ...,  0.0567,  0.0763, -0.0205],\n",
      "         [-0.0616, -0.0320,  0.0823,  ...,  0.0502,  0.0800, -0.0170],\n",
      "         [-0.0593, -0.0322,  0.0772,  ...,  0.0538,  0.0791, -0.0182]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [ 0.9573,  0.2009, -0.7880,  ...,  0.0764, -0.3760, -0.1281],\n",
      "         [ 0.0277,  0.8335,  0.4182,  ...,  1.6713,  3.2434,  1.4751],\n",
      "         [-1.0712,  1.2003,  0.0466,  ..., -0.4887, -0.3115,  0.4672]]],\n",
      "       device='cuda:0'), tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [ 0.9573,  0.2009, -0.7880,  ...,  0.0764, -0.3760, -0.1281],\n",
      "         [ 0.0277,  0.8335,  0.4182,  ...,  1.6713,  3.2434,  1.4751],\n",
      "         [-1.0712,  1.2003,  0.0466,  ..., -0.4887, -0.3115,  0.4672]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [ 0.3728,  0.6588, -0.3233,  ...,  2.7630,  1.4852, -0.3413],\n",
      "         [-0.6984, -1.6151, -1.6948,  ...,  2.5729,  1.6799,  0.4019],\n",
      "         [-2.4310, -2.0165, -0.8156,  ...,  0.6173,  1.3059, -0.7889]]],\n",
      "       device='cuda:0'), tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [ 0.3728,  0.6588, -0.3233,  ...,  2.7630,  1.4852, -0.3413],\n",
      "         [-0.6984, -1.6151, -1.6948,  ...,  2.5729,  1.6799,  0.4019],\n",
      "         [-2.4310, -2.0165, -0.8156,  ...,  0.6173,  1.3059, -0.7889]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [ 0.6705,  0.3120, -0.0042,  ...,  1.6829, -0.7049,  0.7286],\n",
      "         [-0.3229,  2.0890,  0.5304,  ...,  2.4011, -0.8463,  0.8240],\n",
      "         [ 1.4055,  2.5046,  0.9847,  ...,  1.7101,  0.8546,  1.7187]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [ 0.6705,  0.3120, -0.0042,  ...,  1.6829, -0.7049,  0.7286],\n",
      "         [-0.3229,  2.0890,  0.5304,  ...,  2.4011, -0.8463,  0.8240],\n",
      "         [ 1.4055,  2.5046,  0.9847,  ...,  1.7101,  0.8546,  1.7187]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.0969, -0.0269,  0.6869,  ...,  0.1600,  0.5137,  0.1774],\n",
      "         [ 1.1909,  0.0228,  0.6032,  ...,  0.0762,  0.2485,  0.0865],\n",
      "         [ 1.0102,  0.0620,  1.0626,  ...,  0.2919,  0.3589,  0.1775]]],\n",
      "       device='cuda:0'), tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.0969, -0.0269,  0.6869,  ...,  0.1600,  0.5137,  0.1774],\n",
      "         [ 1.1909,  0.0228,  0.6032,  ...,  0.0762,  0.2485,  0.0865],\n",
      "         [ 1.0102,  0.0620,  1.0626,  ...,  0.2919,  0.3589,  0.1775]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [ 0.1345,  1.1916, -0.1567,  ...,  0.8173,  1.7525, -0.2687],\n",
      "         [ 0.9463,  0.7559,  0.0931,  ...,  2.4683, -2.9226, -0.3232],\n",
      "         [-0.0960,  1.0479, -0.1868,  ...,  1.7540,  0.3808,  1.8715]]],\n",
      "       device='cuda:0'), tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [ 0.1345,  1.1916, -0.1567,  ...,  0.8173,  1.7525, -0.2687],\n",
      "         [ 0.9463,  0.7559,  0.0931,  ...,  2.4683, -2.9226, -0.3232],\n",
      "         [-0.0960,  1.0479, -0.1868,  ...,  1.7540,  0.3808,  1.8715]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4879,  5.3620,  1.9531,  ...,  4.8310, -1.5171, -0.6587],\n",
      "         [ 2.4679,  5.4069,  1.9573,  ...,  4.8176, -1.5081, -0.6621],\n",
      "         [ 2.4777,  5.3901,  1.9208,  ...,  4.8168, -1.5207, -0.6440]]],\n",
      "       device='cuda:0'), tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4879,  5.3620,  1.9531,  ...,  4.8310, -1.5171, -0.6587],\n",
      "         [ 2.4679,  5.4069,  1.9573,  ...,  4.8176, -1.5081, -0.6621],\n",
      "         [ 2.4777,  5.3901,  1.9208,  ...,  4.8168, -1.5207, -0.6440]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-0.5420,  0.9760,  0.2761,  ...,  0.7020, -0.7219,  0.7574],\n",
      "         [ 1.5335,  0.3049, -1.0174,  ...,  2.1242,  0.6037,  1.6354],\n",
      "         [-0.0487,  0.4071,  0.7777,  ...,  1.5211, -1.3605, -0.4331]]],\n",
      "       device='cuda:0'), tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-0.5420,  0.9760,  0.2761,  ...,  0.7020, -0.7219,  0.7574],\n",
      "         [ 1.5335,  0.3049, -1.0174,  ...,  2.1242,  0.6037,  1.6354],\n",
      "         [-0.0487,  0.4071,  0.7777,  ...,  1.5211, -1.3605, -0.4331]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0243,  0.0677, -0.0190,  ..., -0.1129,  0.0318,  0.0305],\n",
      "         [-0.0257,  0.0637, -0.0223,  ..., -0.1124,  0.0328,  0.0261],\n",
      "         [-0.0225,  0.0652, -0.0224,  ..., -0.1140,  0.0335,  0.0256]]],\n",
      "       device='cuda:0'), tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0243,  0.0677, -0.0190,  ..., -0.1129,  0.0318,  0.0305],\n",
      "         [-0.0257,  0.0637, -0.0223,  ..., -0.1124,  0.0328,  0.0261],\n",
      "         [-0.0225,  0.0652, -0.0224,  ..., -0.1140,  0.0335,  0.0256]]],\n",
      "       device='cuda:0'))}]}]\n",
      "Step 250 - Last token probs (min/max): 0.0028469425160437822 / 0.0723516047000885\n",
      "Step 300 - past_kv structure:  [{'left': [{'chunk_attn': (tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [ 1.6662,  3.3953,  0.0685,  ...,  2.2091, -0.1772, -0.3169],\n",
      "         [ 0.1607,  0.7518,  1.2585,  ...,  0.0732, -1.5820,  0.7505]]],\n",
      "       device='cuda:0'), tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [ 1.6662,  3.3953,  0.0685,  ...,  2.2091, -0.1772, -0.3169],\n",
      "         [ 0.1607,  0.7518,  1.2585,  ...,  0.0732, -1.5820,  0.7505]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'), tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [-0.8892,  2.6107, -0.1513,  ...,  1.0049, -1.1986,  0.4079],\n",
      "         [-0.0290,  0.0193, -1.3045,  ...,  1.5266,  0.4274,  0.8948]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [-0.8892,  2.6107, -0.1513,  ...,  1.0049, -1.1986,  0.4079],\n",
      "         [-0.0290,  0.0193, -1.3045,  ...,  1.5266,  0.4274,  0.8948]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9055, -0.4981, -7.3214,  ...,  5.7130,  1.1459, -0.1480],\n",
      "         [-5.0772, -0.5461, -7.3360,  ...,  5.7277,  1.4144, -0.5340],\n",
      "         [-4.9924, -0.4843, -7.3548,  ...,  5.7467,  1.1820, -0.3206]]],\n",
      "       device='cuda:0'), tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9055, -0.4981, -7.3214,  ...,  5.7130,  1.1459, -0.1480],\n",
      "         [-5.0772, -0.5461, -7.3360,  ...,  5.7277,  1.4144, -0.5340],\n",
      "         [-4.9924, -0.4843, -7.3548,  ...,  5.7467,  1.1820, -0.3206]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.2950,  0.5404, -1.0334,  ...,  1.1613, -0.3869, -0.8497],\n",
      "         [-0.4315,  2.1607, -0.6633,  ...,  2.7256,  2.1892,  0.2594]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.2950,  0.5404, -1.0334,  ...,  1.1613, -0.3869, -0.8497],\n",
      "         [-0.4315,  2.1607, -0.6633,  ...,  2.7256,  2.1892,  0.2594]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0473,  1.9545,  1.9756,  ...,  1.4806,  1.3014, -2.7926],\n",
      "         [ 3.0463,  1.9543,  1.9758,  ...,  1.4776,  1.3011, -2.7926],\n",
      "         [ 3.0472,  1.9535,  1.9751,  ...,  1.4785,  1.3009, -2.7930]]],\n",
      "       device='cuda:0'), tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0473,  1.9545,  1.9756,  ...,  1.4806,  1.3014, -2.7926],\n",
      "         [ 3.0463,  1.9543,  1.9758,  ...,  1.4776,  1.3011, -2.7926],\n",
      "         [ 3.0472,  1.9535,  1.9751,  ...,  1.4785,  1.3009, -2.7930]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [-1.1630,  0.3134, -0.5321,  ..., -0.5856,  0.7223,  2.0555],\n",
      "         [ 0.1902,  1.3839, -0.4717,  ...,  1.3093,  0.8697,  0.0060]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [-1.1630,  0.3134, -0.5321,  ..., -0.5856,  0.7223,  2.0555],\n",
      "         [ 0.1902,  1.3839, -0.4717,  ...,  1.3093,  0.8697,  0.0060]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0035,  0.0250,  0.0054,  ..., -0.0813, -0.0665,  0.0023],\n",
      "         [-0.0038,  0.0241,  0.0074,  ..., -0.0848, -0.0676,  0.0002],\n",
      "         [-0.0017,  0.0230,  0.0052,  ..., -0.0838, -0.0685, -0.0006]]],\n",
      "       device='cuda:0'), tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0035,  0.0250,  0.0054,  ..., -0.0813, -0.0665,  0.0023],\n",
      "         [-0.0038,  0.0241,  0.0074,  ..., -0.0848, -0.0676,  0.0002],\n",
      "         [-0.0017,  0.0230,  0.0052,  ..., -0.0838, -0.0685, -0.0006]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-3.2473,  1.1197,  0.5983,  ...,  0.5441,  0.0879,  0.8520],\n",
      "         [ 0.6780,  1.2652, -0.5883,  ...,  2.2839, -0.3383,  1.5294]]],\n",
      "       device='cuda:0'), tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-3.2473,  1.1197,  0.5983,  ...,  0.5441,  0.0879,  0.8520],\n",
      "         [ 0.6780,  1.2652, -0.5883,  ...,  2.2839, -0.3383,  1.5294]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'), tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.7349,  3.0585,  1.5288,  ...,  0.0314, -0.3393,  1.7227],\n",
      "         [ 1.1984,  0.7685,  1.3623,  ...,  0.5980,  0.0761, -0.0835]]],\n",
      "       device='cuda:0'), tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.7349,  3.0585,  1.5288,  ...,  0.0314, -0.3393,  1.7227],\n",
      "         [ 1.1984,  0.7685,  1.3623,  ...,  0.5980,  0.0761, -0.0835]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.9513, -0.2516, -0.2902,  ...,  1.0696, -0.4736,  0.1362],\n",
      "         [-0.8843, -0.3166, -0.2580,  ...,  1.0823, -0.3461,  0.2228],\n",
      "         [-0.5990, -0.3137, -0.0925,  ...,  1.3456, -0.4093, -0.2503]]],\n",
      "       device='cuda:0'), tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.9513, -0.2516, -0.2902,  ...,  1.0696, -0.4736,  0.1362],\n",
      "         [-0.8843, -0.3166, -0.2580,  ...,  1.0823, -0.3461,  0.2228],\n",
      "         [-0.5990, -0.3137, -0.0925,  ...,  1.3456, -0.4093, -0.2503]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [ 1.2321,  0.6133,  0.7510,  ...,  1.4225,  0.8851,  2.2801],\n",
      "         [ 2.1516,  0.4597, -0.0622,  ...,  0.4960, -1.0764,  0.0094]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [ 1.2321,  0.6133,  0.7510,  ...,  1.4225,  0.8851,  2.2801],\n",
      "         [ 2.1516,  0.4597, -0.0622,  ...,  0.4960, -1.0764,  0.0094]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3411,  0.3985,  0.0058,  ..., -0.4771,  0.5586, -0.2056],\n",
      "         [ 0.3529,  0.3913,  0.0279,  ..., -0.4889,  0.5363, -0.2117],\n",
      "         [ 0.3357,  0.4083,  0.0256,  ..., -0.4845,  0.5424, -0.2213]]],\n",
      "       device='cuda:0'), tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3411,  0.3985,  0.0058,  ..., -0.4771,  0.5586, -0.2056],\n",
      "         [ 0.3529,  0.3913,  0.0279,  ..., -0.4889,  0.5363, -0.2117],\n",
      "         [ 0.3357,  0.4083,  0.0256,  ..., -0.4845,  0.5424, -0.2213]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-1.9608,  0.7482, -0.1389,  ...,  1.5422, -1.5002,  2.1131],\n",
      "         [-0.6356,  1.0589, -0.4374,  ..., -0.8746, -0.7399, -0.2446]]],\n",
      "       device='cuda:0'), tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-1.9608,  0.7482, -0.1389,  ...,  1.5422, -1.5002,  2.1131],\n",
      "         [-0.6356,  1.0589, -0.4374,  ..., -0.8746, -0.7399, -0.2446]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0667,  0.0953, -0.0437,  ..., -0.1157, -0.0260, -0.0222],\n",
      "         [ 0.0641,  0.0958, -0.0246,  ..., -0.1291, -0.0180, -0.0328],\n",
      "         [ 0.0746,  0.1089, -0.0290,  ..., -0.1022, -0.0330, -0.0386]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0667,  0.0953, -0.0437,  ..., -0.1157, -0.0260, -0.0222],\n",
      "         [ 0.0641,  0.0958, -0.0246,  ..., -0.1291, -0.0180, -0.0328],\n",
      "         [ 0.0746,  0.1089, -0.0290,  ..., -0.1022, -0.0330, -0.0386]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [-0.2280,  0.4469, -1.0935,  ...,  1.6912,  0.9744,  0.0689],\n",
      "         [-1.2036,  1.8678, -1.2365,  ...,  0.3284, -1.0511,  2.3357]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [-0.2280,  0.4469, -1.0935,  ...,  1.6912,  0.9744,  0.0689],\n",
      "         [-1.2036,  1.8678, -1.2365,  ...,  0.3284, -1.0511,  2.3357]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [ 1.0092,  0.3769,  0.1859,  ...,  0.3799, -0.2736, -0.5657],\n",
      "         [-1.1607, -0.1247, -0.4052,  ...,  2.1471, -0.9587, -0.5247],\n",
      "         [-1.1752, -1.2262, -0.6862,  ...,  0.8856, -0.9164,  0.1467]]],\n",
      "       device='cuda:0'), tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [ 1.0092,  0.3769,  0.1859,  ...,  0.3799, -0.2736, -0.5657],\n",
      "         [-1.1607, -0.1247, -0.4052,  ...,  2.1471, -0.9587, -0.5247],\n",
      "         [-1.1752, -1.2262, -0.6862,  ...,  0.8856, -0.9164,  0.1467]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [ 0.5094,  3.2677, -0.6425,  ...,  1.0803,  0.4022,  0.9373],\n",
      "         [ 1.2316,  1.4238,  1.8164,  ...,  0.6005,  0.1095,  1.1426]]],\n",
      "       device='cuda:0'), tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [ 0.5094,  3.2677, -0.6425,  ...,  1.0803,  0.4022,  0.9373],\n",
      "         [ 1.2316,  1.4238,  1.8164,  ...,  0.6005,  0.1095,  1.1426]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.2464, -0.0466,  0.4979,  ..., -1.5942, -1.5732, -0.0819],\n",
      "         [-3.0011, -0.1428,  0.8993,  ..., -2.0027, -1.1798,  0.4528],\n",
      "         [-2.8772, -0.3830,  0.2175,  ..., -2.3355, -1.2075,  0.3944]]],\n",
      "       device='cuda:0'), tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.2464, -0.0466,  0.4979,  ..., -1.5942, -1.5732, -0.0819],\n",
      "         [-3.0011, -0.1428,  0.8993,  ..., -2.0027, -1.1798,  0.4528],\n",
      "         [-2.8772, -0.3830,  0.2175,  ..., -2.3355, -1.2075,  0.3944]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.3925,  0.7824, -2.0396,  ...,  0.9459,  0.5480,  3.7686],\n",
      "         [-1.3172,  0.0507,  0.5884,  ...,  4.9050,  1.0903,  1.0830]]],\n",
      "       device='cuda:0'), tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.3925,  0.7824, -2.0396,  ...,  0.9459,  0.5480,  3.7686],\n",
      "         [-1.3172,  0.0507,  0.5884,  ...,  4.9050,  1.0903,  1.0830]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.5988,  5.1835, -0.0239,  ...,  0.1196, -0.6982,  2.8205],\n",
      "         [ 0.5208,  5.2176, -0.0825,  ...,  0.0882, -0.7141,  2.8439],\n",
      "         [ 0.5865,  5.1812,  0.0067,  ...,  0.1067, -0.7205,  2.8273]]],\n",
      "       device='cuda:0'), tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.5988,  5.1835, -0.0239,  ...,  0.1196, -0.6982,  2.8205],\n",
      "         [ 0.5208,  5.2176, -0.0825,  ...,  0.0882, -0.7141,  2.8439],\n",
      "         [ 0.5865,  5.1812,  0.0067,  ...,  0.1067, -0.7205,  2.8273]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [-0.3198, -1.5995,  0.5799,  ...,  0.9340, -0.1444,  1.3828],\n",
      "         [ 0.5882,  0.0861, -1.7399,  ...,  2.0987, -0.8806,  2.1386]]],\n",
      "       device='cuda:0'), tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [-0.3198, -1.5995,  0.5799,  ...,  0.9340, -0.1444,  1.3828],\n",
      "         [ 0.5882,  0.0861, -1.7399,  ...,  2.0987, -0.8806,  2.1386]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0747, -0.0393,  0.0583,  ..., -0.0276, -0.0830, -0.0932],\n",
      "         [ 0.0772, -0.0379,  0.0584,  ..., -0.0267, -0.0832, -0.0911],\n",
      "         [ 0.0769, -0.0386,  0.0569,  ..., -0.0257, -0.0835, -0.0909]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0747, -0.0393,  0.0583,  ..., -0.0276, -0.0830, -0.0932],\n",
      "         [ 0.0772, -0.0379,  0.0584,  ..., -0.0267, -0.0832, -0.0911],\n",
      "         [ 0.0769, -0.0386,  0.0569,  ..., -0.0257, -0.0835, -0.0909]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [-1.0542,  1.3692,  0.0616,  ..., -0.9247,  0.6843,  1.3505],\n",
      "         [ 0.9185,  0.3354, -0.6915,  ...,  0.4035,  1.7390,  0.2270]]],\n",
      "       device='cuda:0'), tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [-1.0542,  1.3692,  0.0616,  ..., -0.9247,  0.6843,  1.3505],\n",
      "         [ 0.9185,  0.3354, -0.6915,  ...,  0.4035,  1.7390,  0.2270]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [-0.1020,  0.2327, -0.7839,  ..., -1.7454, -0.8367,  0.0112],\n",
      "         [-0.8151, -1.5380,  1.0478,  ...,  1.0267,  1.2653,  0.2833],\n",
      "         [-1.4276, -0.6614,  0.5468,  ...,  0.4993,  1.3605,  0.1043]]],\n",
      "       device='cuda:0'), tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [-0.1020,  0.2327, -0.7839,  ..., -1.7454, -0.8367,  0.0112],\n",
      "         [-0.8151, -1.5380,  1.0478,  ...,  1.0267,  1.2653,  0.2833],\n",
      "         [-1.4276, -0.6614,  0.5468,  ...,  0.4993,  1.3605,  0.1043]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [ 0.3936,  1.0668, -0.3839,  ..., -0.4782, -0.1000,  1.2989],\n",
      "         [ 1.4558,  0.1476,  0.4955,  ..., -0.5686,  0.8276, -0.3571]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [ 0.3936,  1.0668, -0.3839,  ..., -0.4782, -0.1000,  1.2989],\n",
      "         [ 1.4558,  0.1476,  0.4955,  ..., -0.5686,  0.8276, -0.3571]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.2586,  0.4787, -3.7586,  ...,  1.9324, -3.1569, -1.5794],\n",
      "         [-1.2227,  0.5310, -3.6700,  ...,  1.6102, -3.2728, -1.4638],\n",
      "         [-1.3680,  0.5258, -3.7323,  ...,  1.8966, -3.4426, -1.6580]]],\n",
      "       device='cuda:0'), tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.2586,  0.4787, -3.7586,  ...,  1.9324, -3.1569, -1.5794],\n",
      "         [-1.2227,  0.5310, -3.6700,  ...,  1.6102, -3.2728, -1.4638],\n",
      "         [-1.3680,  0.5258, -3.7323,  ...,  1.8966, -3.4426, -1.6580]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 2.2269,  1.2068,  0.6746,  ...,  0.1131, -0.4901,  1.2450],\n",
      "         [ 1.1456,  1.3091, -1.6577,  ..., -1.4254, -0.0577,  0.6662]]],\n",
      "       device='cuda:0'), tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 2.2269,  1.2068,  0.6746,  ...,  0.1131, -0.4901,  1.2450],\n",
      "         [ 1.1456,  1.3091, -1.6577,  ..., -1.4254, -0.0577,  0.6662]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.3015, -0.4874, -0.6785,  ...,  0.4896, -2.5939,  0.8092],\n",
      "         [-1.2804, -0.5208, -0.7046,  ...,  0.5061, -2.6060,  0.8518],\n",
      "         [-1.2947, -0.4813, -0.6819,  ...,  0.5059, -2.5579,  0.8213]]],\n",
      "       device='cuda:0'), tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.3015, -0.4874, -0.6785,  ...,  0.4896, -2.5939,  0.8092],\n",
      "         [-1.2804, -0.5208, -0.7046,  ...,  0.5061, -2.6060,  0.8518],\n",
      "         [-1.2947, -0.4813, -0.6819,  ...,  0.5059, -2.5579,  0.8213]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [ 1.2647,  2.0052, -0.0086,  ...,  0.8003, -1.2459, -0.0515],\n",
      "         [ 0.5317,  1.1354, -0.2805,  ...,  0.4617, -0.8123,  2.0040]]],\n",
      "       device='cuda:0'), tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [ 1.2647,  2.0052, -0.0086,  ...,  0.8003, -1.2459, -0.0515],\n",
      "         [ 0.5317,  1.1354, -0.2805,  ...,  0.4617, -0.8123,  2.0040]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0063,  0.1079,  0.0337,  ...,  0.0642, -0.0263, -0.0224],\n",
      "         [ 0.0109,  0.1090,  0.0318,  ...,  0.0727, -0.0212, -0.0364],\n",
      "         [ 0.0142,  0.1074,  0.0354,  ...,  0.0679, -0.0249, -0.0326]]],\n",
      "       device='cuda:0'), tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0063,  0.1079,  0.0337,  ...,  0.0642, -0.0263, -0.0224],\n",
      "         [ 0.0109,  0.1090,  0.0318,  ...,  0.0727, -0.0212, -0.0364],\n",
      "         [ 0.0142,  0.1074,  0.0354,  ...,  0.0679, -0.0249, -0.0326]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [-0.3815, -0.1591,  1.1690,  ...,  1.1440, -0.5472,  1.3250],\n",
      "         [-1.3027,  0.5755,  0.5142,  ...,  1.1110,  0.3262,  2.4267]]],\n",
      "       device='cuda:0'), tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [-0.3815, -0.1591,  1.1690,  ...,  1.1440, -0.5472,  1.3250],\n",
      "         [-1.3027,  0.5755,  0.5142,  ...,  1.1110,  0.3262,  2.4267]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [ 0.7147,  0.6682,  0.7792,  ...,  0.3648, -0.5020, -0.5050],\n",
      "         [ 0.4308, -0.4014,  1.2453,  ...,  1.2211,  0.0494, -1.7333],\n",
      "         [-0.0748, -0.0671,  0.9426,  ...,  0.3354, -0.6818, -0.6937]]],\n",
      "       device='cuda:0'), tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [ 0.7147,  0.6682,  0.7792,  ...,  0.3648, -0.5020, -0.5050],\n",
      "         [ 0.4308, -0.4014,  1.2453,  ...,  1.2211,  0.0494, -1.7333],\n",
      "         [-0.0748, -0.0671,  0.9426,  ...,  0.3354, -0.6818, -0.6937]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.3207, -0.0265, -0.3837,  ..., -0.6703,  1.3814,  0.8926],\n",
      "         [ 1.2074,  1.3253, -0.3546,  ...,  1.7789, -0.6585,  3.4556]]],\n",
      "       device='cuda:0'), tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.3207, -0.0265, -0.3837,  ..., -0.6703,  1.3814,  0.8926],\n",
      "         [ 1.2074,  1.3253, -0.3546,  ...,  1.7789, -0.6585,  3.4556]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.5546, -0.8916,  1.6793,  ..., -2.7897,  0.6647, -0.7413],\n",
      "         [-2.3031, -0.7680,  1.4371,  ..., -2.9583,  0.8951, -0.4140],\n",
      "         [-2.1035, -1.4319,  2.0335,  ..., -3.2998,  0.9346, -0.2905]]],\n",
      "       device='cuda:0'), tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.5546, -0.8916,  1.6793,  ..., -2.7897,  0.6647, -0.7413],\n",
      "         [-2.3031, -0.7680,  1.4371,  ..., -2.9583,  0.8951, -0.4140],\n",
      "         [-2.1035, -1.4319,  2.0335,  ..., -3.2998,  0.9346, -0.2905]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [ 1.7332,  1.2407, -1.3804,  ...,  1.4405,  0.0448,  1.1446],\n",
      "         [-0.5420, -0.1827,  0.3341,  ...,  2.6605, -0.8229,  0.7433]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [ 1.7332,  1.2407, -1.3804,  ...,  1.4405,  0.0448,  1.1446],\n",
      "         [-0.5420, -0.1827,  0.3341,  ...,  2.6605, -0.8229,  0.7433]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4497,  1.5167, -0.1520,  ..., -0.3549, -0.0488,  2.3986],\n",
      "         [ 2.4557,  1.5542, -0.1588,  ..., -0.3719, -0.0537,  2.3891],\n",
      "         [ 2.4120,  1.5184, -0.1825,  ..., -0.3861, -0.0131,  2.3371]]],\n",
      "       device='cuda:0'), tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4497,  1.5167, -0.1520,  ..., -0.3549, -0.0488,  2.3986],\n",
      "         [ 2.4557,  1.5542, -0.1588,  ..., -0.3719, -0.0537,  2.3891],\n",
      "         [ 2.4120,  1.5184, -0.1825,  ..., -0.3861, -0.0131,  2.3371]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [ 0.5220,  0.7181, -0.8163,  ...,  1.1085, -1.0427,  0.7824],\n",
      "         [-0.3390,  0.9175,  0.6832,  ...,  0.3470,  1.0542,  1.9059]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [ 0.5220,  0.7181, -0.8163,  ...,  1.1085, -1.0427,  0.7824],\n",
      "         [-0.3390,  0.9175,  0.6832,  ...,  0.3470,  1.0542,  1.9059]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0213, -0.0015,  0.0238,  ..., -0.0101, -0.0072, -0.0190],\n",
      "         [ 0.0229, -0.0012,  0.0236,  ..., -0.0094, -0.0062, -0.0193],\n",
      "         [ 0.0222, -0.0014,  0.0233,  ..., -0.0114, -0.0069, -0.0188]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0213, -0.0015,  0.0238,  ..., -0.0101, -0.0072, -0.0190],\n",
      "         [ 0.0229, -0.0012,  0.0236,  ..., -0.0094, -0.0062, -0.0193],\n",
      "         [ 0.0222, -0.0014,  0.0233,  ..., -0.0114, -0.0069, -0.0188]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.8712,  0.5559,  0.2325,  ...,  0.3008,  1.6265,  1.7888],\n",
      "         [ 1.1826,  2.1944,  1.0990,  ...,  0.2679, -0.3627,  1.6209]]],\n",
      "       device='cuda:0'), tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.8712,  0.5559,  0.2325,  ...,  0.3008,  1.6265,  1.7888],\n",
      "         [ 1.1826,  2.1944,  1.0990,  ...,  0.2679, -0.3627,  1.6209]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.3516, -1.2142, -0.1696,  ...,  1.2202,  0.5131, -0.8518],\n",
      "         [ 1.0136, -0.1939, -1.4800,  ...,  0.4383,  0.4932,  0.1706],\n",
      "         [ 1.2364,  0.3649, -0.9905,  ..., -1.5405, -1.2443,  0.6515]]],\n",
      "       device='cuda:0'), tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.3516, -1.2142, -0.1696,  ...,  1.2202,  0.5131, -0.8518],\n",
      "         [ 1.0136, -0.1939, -1.4800,  ...,  0.4383,  0.4932,  0.1706],\n",
      "         [ 1.2364,  0.3649, -0.9905,  ..., -1.5405, -1.2443,  0.6515]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [-3.4933e-01,  1.2840e+00,  1.9308e+00,  ...,  1.8504e+00,\n",
      "          -2.3331e-01, -9.8528e-01],\n",
      "         [ 5.1069e-01,  1.3038e+00, -3.5126e-01,  ...,  1.7077e+00,\n",
      "           4.1541e-01,  1.7796e+00]]], device='cuda:0'), tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [-3.4933e-01,  1.2840e+00,  1.9308e+00,  ...,  1.8504e+00,\n",
      "          -2.3331e-01, -9.8528e-01],\n",
      "         [ 5.1069e-01,  1.3038e+00, -3.5126e-01,  ...,  1.7077e+00,\n",
      "           4.1541e-01,  1.7796e+00]]], device='cuda:0')), 'logits_attn': (tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.8406,  2.9922,  5.9853,  ..., -2.0706, -8.1923, -3.2801],\n",
      "         [ 4.8862,  2.9395,  5.9241,  ..., -1.9317, -8.3156, -3.5306],\n",
      "         [ 4.9417,  2.8822,  5.8727,  ..., -1.8792, -8.2225, -3.3595]]],\n",
      "       device='cuda:0'), tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.8406,  2.9922,  5.9853,  ..., -2.0706, -8.1923, -3.2801],\n",
      "         [ 4.8862,  2.9395,  5.9241,  ..., -1.9317, -8.3156, -3.5306],\n",
      "         [ 4.9417,  2.8822,  5.8727,  ..., -1.8792, -8.2225, -3.3595]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 0.6834,  0.2599, -0.3449,  ...,  1.0841, -1.1985,  0.9514],\n",
      "         [-0.8290,  1.2752, -0.1105,  ...,  0.7394,  0.1308,  0.3132]]],\n",
      "       device='cuda:0'), tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 0.6834,  0.2599, -0.3449,  ...,  1.0841, -1.1985,  0.9514],\n",
      "         [-0.8290,  1.2752, -0.1105,  ...,  0.7394,  0.1308,  0.3132]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5719, -8.7702,  4.9044,  ...,  5.1942,  2.4873,  3.4505],\n",
      "         [ 3.5652, -8.7662,  4.9040,  ...,  5.1881,  2.4807,  3.4391],\n",
      "         [ 3.5734, -8.7656,  4.9032,  ...,  5.1908,  2.4822,  3.4468]]],\n",
      "       device='cuda:0'), tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5719, -8.7702,  4.9044,  ...,  5.1942,  2.4873,  3.4505],\n",
      "         [ 3.5652, -8.7662,  4.9040,  ...,  5.1881,  2.4807,  3.4391],\n",
      "         [ 3.5734, -8.7656,  4.9032,  ...,  5.1908,  2.4822,  3.4468]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-0.1056,  0.8401,  0.9699,  ...,  0.1891,  1.0006,  1.7575],\n",
      "         [-0.5087,  1.0845, -0.9887,  ...,  0.8969, -1.4975, -0.2630]]],\n",
      "       device='cuda:0'), tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-0.1056,  0.8401,  0.9699,  ...,  0.1891,  1.0006,  1.7575],\n",
      "         [-0.5087,  1.0845, -0.9887,  ...,  0.8969, -1.4975, -0.2630]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0019, -0.0033, -0.0661,  ..., -0.0053,  0.0017, -0.0186],\n",
      "         [-0.0022, -0.0031, -0.0668,  ..., -0.0050,  0.0016, -0.0191],\n",
      "         [-0.0021, -0.0031, -0.0663,  ..., -0.0054,  0.0016, -0.0185]]],\n",
      "       device='cuda:0'), tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0019, -0.0033, -0.0661,  ..., -0.0053,  0.0017, -0.0186],\n",
      "         [-0.0022, -0.0031, -0.0668,  ..., -0.0050,  0.0016, -0.0191],\n",
      "         [-0.0021, -0.0031, -0.0663,  ..., -0.0054,  0.0016, -0.0185]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 0.3563,  1.9666, -2.0105,  ...,  2.9782, -0.2654,  1.6426],\n",
      "         [-0.0888, -0.5515,  0.5948,  ...,  1.8037, -1.1436,  0.2489]]],\n",
      "       device='cuda:0'), tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 0.3563,  1.9666, -2.0105,  ...,  2.9782, -0.2654,  1.6426],\n",
      "         [-0.0888, -0.5515,  0.5948,  ...,  1.8037, -1.1436,  0.2489]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 2.2747, -0.4166, -0.6319,  ...,  1.2050,  1.4825,  1.2025],\n",
      "         [ 2.1953, -2.5985, -0.7909,  ...,  0.3068,  1.1712,  1.5170],\n",
      "         [-0.5273, -1.9664, -1.1666,  ..., -0.7661,  0.9725,  1.8507]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 2.2747, -0.4166, -0.6319,  ...,  1.2050,  1.4825,  1.2025],\n",
      "         [ 2.1953, -2.5985, -0.7909,  ...,  0.3068,  1.1712,  1.5170],\n",
      "         [-0.5273, -1.9664, -1.1666,  ..., -0.7661,  0.9725,  1.8507]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [-0.1740,  1.2565,  0.0583,  ...,  1.1957,  0.2084,  2.2233],\n",
      "         [ 2.0301,  1.8460,  1.9721,  ...,  2.9125, -0.5044,  3.4829]]],\n",
      "       device='cuda:0'), tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [-0.1740,  1.2565,  0.0583,  ...,  1.1957,  0.2084,  2.2233],\n",
      "         [ 2.0301,  1.8460,  1.9721,  ...,  2.9125, -0.5044,  3.4829]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.7830, -2.0050,  0.0659,  ..., -0.2151,  2.8755,  1.5845],\n",
      "         [-5.0360, -1.7609,  0.1268,  ..., -0.5190,  2.7630,  1.7317],\n",
      "         [-4.9180, -1.8125, -0.1498,  ..., -0.6561,  2.4250,  2.0822]]],\n",
      "       device='cuda:0'), tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.7830, -2.0050,  0.0659,  ..., -0.2151,  2.8755,  1.5845],\n",
      "         [-5.0360, -1.7609,  0.1268,  ..., -0.5190,  2.7630,  1.7317],\n",
      "         [-4.9180, -1.8125, -0.1498,  ..., -0.6561,  2.4250,  2.0822]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [ 1.2361,  0.6268, -1.4821,  ..., -0.8504,  1.1644,  0.0805],\n",
      "         [ 0.6701,  1.4765,  1.0389,  ..., -1.6825,  0.7954, -1.4264]]],\n",
      "       device='cuda:0'), tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [ 1.2361,  0.6268, -1.4821,  ..., -0.8504,  1.1644,  0.0805],\n",
      "         [ 0.6701,  1.4765,  1.0389,  ..., -1.6825,  0.7954, -1.4264]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0294,  0.2554,  0.5023,  ..., -0.2806,  0.7165, -0.6035],\n",
      "         [ 0.0415,  0.1927,  0.5196,  ..., -0.3578,  0.6496, -0.5829],\n",
      "         [ 0.0124,  0.2363,  0.5001,  ..., -0.2803,  0.7104, -0.5876]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0294,  0.2554,  0.5023,  ..., -0.2806,  0.7165, -0.6035],\n",
      "         [ 0.0415,  0.1927,  0.5196,  ..., -0.3578,  0.6496, -0.5829],\n",
      "         [ 0.0124,  0.2363,  0.5001,  ..., -0.2803,  0.7104, -0.5876]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 1.8218, -0.3742,  0.8150,  ..., -0.3860,  1.1411,  0.6029],\n",
      "         [ 0.2132,  0.6483,  1.0610,  ...,  1.2588,  0.3906,  0.2853]]],\n",
      "       device='cuda:0'), tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 1.8218, -0.3742,  0.8150,  ..., -0.3860,  1.1411,  0.6029],\n",
      "         [ 0.2132,  0.6483,  1.0610,  ...,  1.2588,  0.3906,  0.2853]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0539, -0.0320,  0.0804,  ...,  0.0543,  0.0724, -0.0212],\n",
      "         [-0.0560, -0.0374,  0.0798,  ...,  0.0528,  0.0788, -0.0172],\n",
      "         [-0.0540, -0.0241,  0.0757,  ...,  0.0555,  0.0794, -0.0170]]],\n",
      "       device='cuda:0'), tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0539, -0.0320,  0.0804,  ...,  0.0543,  0.0724, -0.0212],\n",
      "         [-0.0560, -0.0374,  0.0798,  ...,  0.0528,  0.0788, -0.0172],\n",
      "         [-0.0540, -0.0241,  0.0757,  ...,  0.0555,  0.0794, -0.0170]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-1.8969,  0.4410,  0.9924,  ...,  1.4318,  1.7334,  1.6235],\n",
      "         [-0.1605,  0.9679,  0.4269,  ...,  0.4129, -1.0676,  0.6398]]],\n",
      "       device='cuda:0'), tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-1.8969,  0.4410,  0.9924,  ...,  1.4318,  1.7334,  1.6235],\n",
      "         [-0.1605,  0.9679,  0.4269,  ...,  0.4129, -1.0676,  0.6398]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [-3.8381, -1.1633,  0.1167,  ...,  1.6679,  1.0207, -1.1462],\n",
      "         [-0.4851, -1.1637, -0.7419,  ...,  2.0115,  1.7822, -0.8599],\n",
      "         [ 2.0707,  0.0190,  0.3616,  ...,  1.4052,  1.6459, -1.1578]]],\n",
      "       device='cuda:0'), tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [-3.8381, -1.1633,  0.1167,  ...,  1.6679,  1.0207, -1.1462],\n",
      "         [-0.4851, -1.1637, -0.7419,  ...,  2.0115,  1.7822, -0.8599],\n",
      "         [ 2.0707,  0.0190,  0.3616,  ...,  1.4052,  1.6459, -1.1578]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [ 0.3385,  0.6829, -0.1047,  ...,  0.9157,  0.2745,  0.0133],\n",
      "         [ 0.3865,  0.9801,  1.3845,  ...,  2.5473,  0.2784,  0.8636]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [ 0.3385,  0.6829, -0.1047,  ...,  0.9157,  0.2745,  0.0133],\n",
      "         [ 0.3865,  0.9801,  1.3845,  ...,  2.5473,  0.2784,  0.8636]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.2935, -0.1054,  0.9103,  ...,  0.2754,  0.4478,  0.0989],\n",
      "         [ 1.1302, -0.0366,  0.5967,  ..., -0.0921,  0.5469,  0.2350],\n",
      "         [ 0.8227,  0.0655,  0.7852,  ..., -0.0240,  0.1574,  0.1678]]],\n",
      "       device='cuda:0'), tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.2935, -0.1054,  0.9103,  ...,  0.2754,  0.4478,  0.0989],\n",
      "         [ 1.1302, -0.0366,  0.5967,  ..., -0.0921,  0.5469,  0.2350],\n",
      "         [ 0.8227,  0.0655,  0.7852,  ..., -0.0240,  0.1574,  0.1678]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-1.3050,  0.8490,  0.7935,  ...,  1.6024, -1.2659,  0.8554],\n",
      "         [-0.9668,  1.2849, -0.8939,  ...,  2.5643, -0.6203,  1.6641]]],\n",
      "       device='cuda:0'), tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-1.3050,  0.8490,  0.7935,  ...,  1.6024, -1.2659,  0.8554],\n",
      "         [-0.9668,  1.2849, -0.8939,  ...,  2.5643, -0.6203,  1.6641]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4959,  5.3841,  1.9737,  ...,  4.8299, -1.5139, -0.6695],\n",
      "         [ 2.5173,  5.3723,  1.9436,  ...,  4.8074, -1.5245, -0.6625],\n",
      "         [ 2.4778,  5.3951,  1.9644,  ...,  4.8084, -1.5227, -0.6455]]],\n",
      "       device='cuda:0'), tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4959,  5.3841,  1.9737,  ...,  4.8299, -1.5139, -0.6695],\n",
      "         [ 2.5173,  5.3723,  1.9436,  ...,  4.8074, -1.5245, -0.6625],\n",
      "         [ 2.4778,  5.3951,  1.9644,  ...,  4.8084, -1.5227, -0.6455]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [ 0.1654,  0.9710, -1.0519,  ...,  1.3441,  0.3761,  0.9613],\n",
      "         [ 0.7838,  0.4250, -1.2347,  ...,  0.5666,  0.6994,  2.2934]]],\n",
      "       device='cuda:0'), tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [ 0.1654,  0.9710, -1.0519,  ...,  1.3441,  0.3761,  0.9613],\n",
      "         [ 0.7838,  0.4250, -1.2347,  ...,  0.5666,  0.6994,  2.2934]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0239,  0.0633, -0.0200,  ..., -0.1135,  0.0328,  0.0267],\n",
      "         [-0.0253,  0.0633, -0.0197,  ..., -0.1156,  0.0303,  0.0266],\n",
      "         [-0.0213,  0.0650, -0.0227,  ..., -0.1136,  0.0328,  0.0308]]],\n",
      "       device='cuda:0'), tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0239,  0.0633, -0.0200,  ..., -0.1135,  0.0328,  0.0267],\n",
      "         [-0.0253,  0.0633, -0.0197,  ..., -0.1156,  0.0303,  0.0266],\n",
      "         [-0.0213,  0.0650, -0.0227,  ..., -0.1136,  0.0328,  0.0308]]],\n",
      "       device='cuda:0'))}]}]\n",
      "Step 300 - Last token probs (min/max): 0.0020764300134032965 / 0.09844120591878891\n",
      "Step 350 - past_kv structure:  [{'left': [{'chunk_attn': (tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [-0.2696,  0.0055,  2.7146,  ...,  1.8069,  0.3528,  1.7483],\n",
      "         [ 1.1471,  1.2123, -0.6648,  ...,  1.3319, -1.1453,  1.4774],\n",
      "         [ 0.0945,  0.7944, -2.1745,  ..., -1.6812, -1.3109,  1.6981]]],\n",
      "       device='cuda:0'), tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [-0.2696,  0.0055,  2.7146,  ...,  1.8069,  0.3528,  1.7483],\n",
      "         [ 1.1471,  1.2123, -0.6648,  ...,  1.3319, -1.1453,  1.4774],\n",
      "         [ 0.0945,  0.7944, -2.1745,  ..., -1.6812, -1.3109,  1.6981]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'), tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 1.5711,  1.5998,  0.9535,  ...,  1.0348,  0.1569,  0.7575],\n",
      "         [ 0.1053,  1.4807,  0.6940,  ...,  0.4129,  1.7217,  0.8705],\n",
      "         [ 0.3244,  0.7365, -0.8367,  ...,  1.5703, -0.4689,  0.5086]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 1.5711,  1.5998,  0.9535,  ...,  1.0348,  0.1569,  0.7575],\n",
      "         [ 0.1053,  1.4807,  0.6940,  ...,  0.4129,  1.7217,  0.8705],\n",
      "         [ 0.3244,  0.7365, -0.8367,  ...,  1.5703, -0.4689,  0.5086]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-5.1035, -0.4625, -7.2529,  ...,  5.6136,  1.3203, -0.5635],\n",
      "         [-5.0011, -0.3405, -7.2964,  ...,  5.5382,  1.3053, -0.3221],\n",
      "         [-4.9557, -0.5144, -7.4265,  ...,  5.7146,  1.2143, -0.3990]]],\n",
      "       device='cuda:0'), tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-5.1035, -0.4625, -7.2529,  ...,  5.6136,  1.3203, -0.5635],\n",
      "         [-5.0011, -0.3405, -7.2964,  ...,  5.5382,  1.3053, -0.3221],\n",
      "         [-4.9557, -0.5144, -7.4265,  ...,  5.7146,  1.2143, -0.3990]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [ 0.0943,  0.2451, -0.3060,  ...,  1.5655,  0.5932, -0.6508],\n",
      "         [-2.6341,  1.1095, -0.8551,  ...,  1.9091, -0.2144, -0.1089],\n",
      "         [-0.0114,  1.7914, -0.2840,  ...,  1.0468, -0.8037,  2.1255]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [ 0.0943,  0.2451, -0.3060,  ...,  1.5655,  0.5932, -0.6508],\n",
      "         [-2.6341,  1.1095, -0.8551,  ...,  1.9091, -0.2144, -0.1089],\n",
      "         [-0.0114,  1.7914, -0.2840,  ...,  1.0468, -0.8037,  2.1255]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0470,  1.9535,  1.9749,  ...,  1.4798,  1.3020, -2.7921],\n",
      "         [ 3.0465,  1.9557,  1.9751,  ...,  1.4804,  1.3022, -2.7942],\n",
      "         [ 3.0470,  1.9533,  1.9749,  ...,  1.4803,  1.3014, -2.7930]]],\n",
      "       device='cuda:0'), tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0470,  1.9535,  1.9749,  ...,  1.4798,  1.3020, -2.7921],\n",
      "         [ 3.0465,  1.9557,  1.9751,  ...,  1.4804,  1.3022, -2.7942],\n",
      "         [ 3.0470,  1.9533,  1.9749,  ...,  1.4803,  1.3014, -2.7930]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 0.5845,  1.7644,  0.9689,  ...,  1.1628, -1.3667,  0.8998],\n",
      "         [-0.4636, -0.3201,  0.5472,  ...,  1.2853, -1.3222,  1.0996],\n",
      "         [ 1.3764,  0.4580, -0.8346,  ...,  0.8633, -0.4625,  1.1101]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 0.5845,  1.7644,  0.9689,  ...,  1.1628, -1.3667,  0.8998],\n",
      "         [-0.4636, -0.3201,  0.5472,  ...,  1.2853, -1.3222,  1.0996],\n",
      "         [ 1.3764,  0.4580, -0.8346,  ...,  0.8633, -0.4625,  1.1101]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0022,  0.0240,  0.0059,  ..., -0.0797, -0.0701, -0.0001],\n",
      "         [-0.0038,  0.0263,  0.0044,  ..., -0.0830, -0.0709,  0.0017],\n",
      "         [-0.0025,  0.0243,  0.0056,  ..., -0.0824, -0.0687,  0.0002]]],\n",
      "       device='cuda:0'), tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0022,  0.0240,  0.0059,  ..., -0.0797, -0.0701, -0.0001],\n",
      "         [-0.0038,  0.0263,  0.0044,  ..., -0.0830, -0.0709,  0.0017],\n",
      "         [-0.0025,  0.0243,  0.0056,  ..., -0.0824, -0.0687,  0.0002]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [-0.0707, -0.9073, -0.8652,  ...,  2.4896,  0.8148,  1.9497],\n",
      "         [-0.3750,  1.3069,  1.0308,  ...,  2.4506, -1.2103,  1.5754],\n",
      "         [-0.1019,  0.6334, -2.2093,  ...,  0.4147,  0.8254,  1.9561]]],\n",
      "       device='cuda:0'), tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [-0.0707, -0.9073, -0.8652,  ...,  2.4896,  0.8148,  1.9497],\n",
      "         [-0.3750,  1.3069,  1.0308,  ...,  2.4506, -1.2103,  1.5754],\n",
      "         [-0.1019,  0.6334, -2.2093,  ...,  0.4147,  0.8254,  1.9561]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'), tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [-1.2904,  0.6542, -1.0400,  ...,  1.0293,  0.9140, -0.1222],\n",
      "         [-0.4330, -0.6818, -0.2817,  ...,  0.1321, -1.0315,  2.2309],\n",
      "         [ 0.8420, -0.1820, -1.2103,  ...,  2.7074, -0.5434,  0.9720]]],\n",
      "       device='cuda:0'), tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [-1.2904,  0.6542, -1.0400,  ...,  1.0293,  0.9140, -0.1222],\n",
      "         [-0.4330, -0.6818, -0.2817,  ...,  0.1321, -1.0315,  2.2309],\n",
      "         [ 0.8420, -0.1820, -1.2103,  ...,  2.7074, -0.5434,  0.9720]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.9264, -0.3328, -0.5067,  ...,  1.2427, -0.3819, -0.0825],\n",
      "         [-1.0652, -0.3604, -0.3313,  ...,  1.2828, -0.4509,  0.1847],\n",
      "         [-0.5039, -0.2429, -0.3885,  ...,  1.0667, -0.4452,  0.0461]]],\n",
      "       device='cuda:0'), tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.9264, -0.3328, -0.5067,  ...,  1.2427, -0.3819, -0.0825],\n",
      "         [-1.0652, -0.3604, -0.3313,  ...,  1.2828, -0.4509,  0.1847],\n",
      "         [-0.5039, -0.2429, -0.3885,  ...,  1.0667, -0.4452,  0.0461]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [-0.9453,  2.1662,  0.4243,  ...,  1.6370, -0.4332,  0.1872],\n",
      "         [-1.6611,  1.1990, -2.1301,  ...,  2.1853,  0.0818,  2.2077],\n",
      "         [-0.2403,  2.7217,  0.8127,  ...,  2.4324, -1.7175,  1.9683]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [-0.9453,  2.1662,  0.4243,  ...,  1.6370, -0.4332,  0.1872],\n",
      "         [-1.6611,  1.1990, -2.1301,  ...,  2.1853,  0.0818,  2.2077],\n",
      "         [-0.2403,  2.7217,  0.8127,  ...,  2.4324, -1.7175,  1.9683]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3426,  0.4070,  0.0177,  ..., -0.4991,  0.5683, -0.2232],\n",
      "         [ 0.3424,  0.3906,  0.0200,  ..., -0.4896,  0.5616, -0.2193],\n",
      "         [ 0.3334,  0.3867,  0.0283,  ..., -0.4919,  0.5397, -0.2160]]],\n",
      "       device='cuda:0'), tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3426,  0.4070,  0.0177,  ..., -0.4991,  0.5683, -0.2232],\n",
      "         [ 0.3424,  0.3906,  0.0200,  ..., -0.4896,  0.5616, -0.2193],\n",
      "         [ 0.3334,  0.3867,  0.0283,  ..., -0.4919,  0.5397, -0.2160]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-1.1952, -0.0819, -0.1196,  ...,  2.4347,  1.6244, -0.5786],\n",
      "         [-1.6875,  0.4987,  0.2292,  ...,  1.9502,  0.3871,  1.7634],\n",
      "         [ 0.0644,  2.6448,  1.8610,  ...,  1.2241, -0.4929, -0.1090]]],\n",
      "       device='cuda:0'), tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-1.1952, -0.0819, -0.1196,  ...,  2.4347,  1.6244, -0.5786],\n",
      "         [-1.6875,  0.4987,  0.2292,  ...,  1.9502,  0.3871,  1.7634],\n",
      "         [ 0.0644,  2.6448,  1.8610,  ...,  1.2241, -0.4929, -0.1090]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0570,  0.0835, -0.0268,  ..., -0.1145, -0.0129, -0.0214],\n",
      "         [ 0.0721,  0.0871, -0.0468,  ..., -0.1123, -0.0153, -0.0276],\n",
      "         [ 0.0637,  0.1069, -0.0422,  ..., -0.1290, -0.0218, -0.0272]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0570,  0.0835, -0.0268,  ..., -0.1145, -0.0129, -0.0214],\n",
      "         [ 0.0721,  0.0871, -0.0468,  ..., -0.1123, -0.0153, -0.0276],\n",
      "         [ 0.0637,  0.1069, -0.0422,  ..., -0.1290, -0.0218, -0.0272]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [ 0.4084,  0.1694, -0.0362,  ..., -1.2063, -0.8843,  0.4412],\n",
      "         [-0.3517,  1.3178,  1.6124,  ...,  1.1849, -0.7424, -1.2569],\n",
      "         [-0.7764, -0.8211,  0.6067,  ...,  0.6400,  0.5213, -0.2162]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [ 0.4084,  0.1694, -0.0362,  ..., -1.2063, -0.8843,  0.4412],\n",
      "         [-0.3517,  1.3178,  1.6124,  ...,  1.1849, -0.7424, -1.2569],\n",
      "         [-0.7764, -0.8211,  0.6067,  ...,  0.6400,  0.5213, -0.2162]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [-1.2532, -1.4164,  1.4821,  ...,  0.8288,  0.5726, -0.2765],\n",
      "         [ 0.1465, -1.2326,  0.3087,  ...,  1.9966,  0.0842,  0.3444],\n",
      "         [ 0.7656,  1.1557,  0.8554,  ..., -0.8682,  1.0483,  0.3257]]],\n",
      "       device='cuda:0'), tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [-1.2532, -1.4164,  1.4821,  ...,  0.8288,  0.5726, -0.2765],\n",
      "         [ 0.1465, -1.2326,  0.3087,  ...,  1.9966,  0.0842,  0.3444],\n",
      "         [ 0.7656,  1.1557,  0.8554,  ..., -0.8682,  1.0483,  0.3257]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [ 0.8432, -0.4472, -0.8512,  ..., -1.2529,  0.4169,  0.8360],\n",
      "         [-0.5334,  3.4035, -0.3679,  ...,  1.4274,  1.4478,  0.5857],\n",
      "         [ 0.3629,  0.8741, -0.5620,  ...,  0.2454, -0.0345,  0.2443]]],\n",
      "       device='cuda:0'), tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [ 0.8432, -0.4472, -0.8512,  ..., -1.2529,  0.4169,  0.8360],\n",
      "         [-0.5334,  3.4035, -0.3679,  ...,  1.4274,  1.4478,  0.5857],\n",
      "         [ 0.3629,  0.8741, -0.5620,  ...,  0.2454, -0.0345,  0.2443]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-2.7568, -0.1931,  0.4660,  ..., -1.6610, -1.5939, -0.1595],\n",
      "         [-2.9698,  0.0676,  0.6930,  ..., -2.1978, -1.5572,  0.2866],\n",
      "         [-3.0615, -0.8271,  0.3538,  ..., -1.4393, -1.1503,  0.3621]]],\n",
      "       device='cuda:0'), tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-2.7568, -0.1931,  0.4660,  ..., -1.6610, -1.5939, -0.1595],\n",
      "         [-2.9698,  0.0676,  0.6930,  ..., -2.1978, -1.5572,  0.2866],\n",
      "         [-3.0615, -0.8271,  0.3538,  ..., -1.4393, -1.1503,  0.3621]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [-0.5551,  2.5472, -0.3751,  ..., -0.3593,  0.2628,  1.3211],\n",
      "         [-0.5648, -0.3877, -0.1052,  ..., -0.0137,  0.4596,  1.0841],\n",
      "         [ 0.5277,  0.6800, -1.2182,  ...,  0.6090, -0.9892,  1.3186]]],\n",
      "       device='cuda:0'), tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [-0.5551,  2.5472, -0.3751,  ..., -0.3593,  0.2628,  1.3211],\n",
      "         [-0.5648, -0.3877, -0.1052,  ..., -0.0137,  0.4596,  1.0841],\n",
      "         [ 0.5277,  0.6800, -1.2182,  ...,  0.6090, -0.9892,  1.3186]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 5.8412e-01,  5.1617e+00, -9.3508e-02,  ...,  9.9786e-02,\n",
      "          -7.3548e-01,  2.7650e+00],\n",
      "         [ 5.5439e-01,  5.1754e+00, -3.0827e-02,  ...,  1.1312e-01,\n",
      "          -6.9124e-01,  2.8477e+00],\n",
      "         [ 5.7300e-01,  5.1981e+00, -8.9784e-02,  ...,  1.1032e-01,\n",
      "          -7.3138e-01,  2.8310e+00],\n",
      "         ...,\n",
      "         [ 5.3855e-01,  5.0670e+00, -4.2832e-02,  ...,  1.6616e-01,\n",
      "          -7.6640e-01,  2.8537e+00],\n",
      "         [ 5.6573e-01,  5.0920e+00,  3.4198e-03,  ...,  1.4710e-01,\n",
      "          -6.1321e-01,  2.7303e+00],\n",
      "         [ 6.1610e-01,  5.1030e+00, -3.8995e-02,  ...,  1.3944e-01,\n",
      "          -6.5126e-01,  2.8094e+00]]], device='cuda:0'), tensor([[[ 5.8412e-01,  5.1617e+00, -9.3508e-02,  ...,  9.9786e-02,\n",
      "          -7.3548e-01,  2.7650e+00],\n",
      "         [ 5.5439e-01,  5.1754e+00, -3.0827e-02,  ...,  1.1312e-01,\n",
      "          -6.9124e-01,  2.8477e+00],\n",
      "         [ 5.7300e-01,  5.1981e+00, -8.9784e-02,  ...,  1.1032e-01,\n",
      "          -7.3138e-01,  2.8310e+00],\n",
      "         ...,\n",
      "         [ 5.3855e-01,  5.0670e+00, -4.2832e-02,  ...,  1.6616e-01,\n",
      "          -7.6640e-01,  2.8537e+00],\n",
      "         [ 5.6573e-01,  5.0920e+00,  3.4198e-03,  ...,  1.4710e-01,\n",
      "          -6.1321e-01,  2.7303e+00],\n",
      "         [ 6.1610e-01,  5.1030e+00, -3.8995e-02,  ...,  1.3944e-01,\n",
      "          -6.5126e-01,  2.8094e+00]]], device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [ 0.9881,  2.3963, -1.0931,  ..., -1.0804,  0.7619,  1.4808],\n",
      "         [-0.4222,  1.2461,  0.7840,  ..., -0.2710,  0.8477,  1.7840],\n",
      "         [ 0.4631,  0.8244, -0.3916,  ...,  0.7194,  2.7029,  1.9943]]],\n",
      "       device='cuda:0'), tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [ 0.9881,  2.3963, -1.0931,  ..., -1.0804,  0.7619,  1.4808],\n",
      "         [-0.4222,  1.2461,  0.7840,  ..., -0.2710,  0.8477,  1.7840],\n",
      "         [ 0.4631,  0.8244, -0.3916,  ...,  0.7194,  2.7029,  1.9943]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0751, -0.0402,  0.0585,  ..., -0.0261, -0.0821, -0.0916],\n",
      "         [ 0.0740, -0.0372,  0.0565,  ..., -0.0289, -0.0836, -0.0935],\n",
      "         [ 0.0770, -0.0371,  0.0595,  ..., -0.0281, -0.0805, -0.0933]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0751, -0.0402,  0.0585,  ..., -0.0261, -0.0821, -0.0916],\n",
      "         [ 0.0740, -0.0372,  0.0565,  ..., -0.0289, -0.0836, -0.0935],\n",
      "         [ 0.0770, -0.0371,  0.0595,  ..., -0.0281, -0.0805, -0.0933]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [-0.7432,  0.8153, -0.7764,  ...,  1.2324,  1.6511,  2.2664],\n",
      "         [-0.7800,  1.8678, -1.4704,  ..., -0.3986, -1.6516,  1.3191],\n",
      "         [-1.2344,  1.1624, -1.2385,  ..., -0.4601, -0.2729, -0.0542]]],\n",
      "       device='cuda:0'), tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [-0.7432,  0.8153, -0.7764,  ...,  1.2324,  1.6511,  2.2664],\n",
      "         [-0.7800,  1.8678, -1.4704,  ..., -0.3986, -1.6516,  1.3191],\n",
      "         [-1.2344,  1.1624, -1.2385,  ..., -0.4601, -0.2729, -0.0542]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [ 0.6998,  1.1869,  0.5438,  ...,  2.6275,  0.0213,  1.4950],\n",
      "         [-0.6487, -0.2541, -0.1592,  ..., -0.0478,  0.9964, -0.7510],\n",
      "         [ 0.3084,  1.3057,  0.0461,  ..., -0.0780, -0.6423,  0.5375]]],\n",
      "       device='cuda:0'), tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [ 0.6998,  1.1869,  0.5438,  ...,  2.6275,  0.0213,  1.4950],\n",
      "         [-0.6487, -0.2541, -0.1592,  ..., -0.0478,  0.9964, -0.7510],\n",
      "         [ 0.3084,  1.3057,  0.0461,  ..., -0.0780, -0.6423,  0.5375]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.0133,  0.5869, -1.1199,  ...,  1.5574,  0.2437,  2.6512],\n",
      "         [-1.2766,  1.8080, -0.6832,  ...,  3.1328,  0.1688,  0.7393],\n",
      "         [-0.7622,  0.4478,  0.8183,  ...,  0.8874, -0.0554,  1.2556]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.0133,  0.5869, -1.1199,  ...,  1.5574,  0.2437,  2.6512],\n",
      "         [-1.2766,  1.8080, -0.6832,  ...,  3.1328,  0.1688,  0.7393],\n",
      "         [-0.7622,  0.4478,  0.8183,  ...,  0.8874, -0.0554,  1.2556]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.2692,  0.8634, -3.8237,  ...,  1.8030, -2.9776, -1.6133],\n",
      "         [-1.3641,  0.8351, -3.9948,  ...,  1.3324, -2.9426, -1.5281],\n",
      "         [-1.3499,  0.7803, -3.7664,  ...,  1.6900, -3.1651, -1.4547]]],\n",
      "       device='cuda:0'), tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.2692,  0.8634, -3.8237,  ...,  1.8030, -2.9776, -1.6133],\n",
      "         [-1.3641,  0.8351, -3.9948,  ...,  1.3324, -2.9426, -1.5281],\n",
      "         [-1.3499,  0.7803, -3.7664,  ...,  1.6900, -3.1651, -1.4547]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-1.7369,  1.0596, -1.1675,  ..., -0.2731,  0.1893,  1.0472],\n",
      "         [ 0.4979,  1.4940, -1.0047,  ...,  1.5400,  0.5129, -0.2309],\n",
      "         [ 0.0953,  0.7706, -0.2406,  ...,  0.2070,  0.7085,  0.1344]]],\n",
      "       device='cuda:0'), tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-1.7369,  1.0596, -1.1675,  ..., -0.2731,  0.1893,  1.0472],\n",
      "         [ 0.4979,  1.4940, -1.0047,  ...,  1.5400,  0.5129, -0.2309],\n",
      "         [ 0.0953,  0.7706, -0.2406,  ...,  0.2070,  0.7085,  0.1344]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2776, -0.5138, -0.6699,  ...,  0.5244, -2.6153,  0.8397],\n",
      "         [-1.2343, -0.4998, -0.6681,  ...,  0.5409, -2.5494,  0.8151],\n",
      "         [-1.3241, -0.4955, -0.6777,  ...,  0.5381, -2.5335,  0.7581]]],\n",
      "       device='cuda:0'), tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2776, -0.5138, -0.6699,  ...,  0.5244, -2.6153,  0.8397],\n",
      "         [-1.2343, -0.4998, -0.6681,  ...,  0.5409, -2.5494,  0.8151],\n",
      "         [-1.3241, -0.4955, -0.6777,  ...,  0.5381, -2.5335,  0.7581]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [ 0.4863,  2.1035,  0.3536,  ...,  0.2245,  1.4820,  0.5925],\n",
      "         [ 0.7455,  1.8802, -0.3807,  ...,  1.0705, -0.7636,  1.8818],\n",
      "         [-0.6752,  1.3208,  0.8758,  ...,  0.9824, -0.1681, -0.2109]]],\n",
      "       device='cuda:0'), tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [ 0.4863,  2.1035,  0.3536,  ...,  0.2245,  1.4820,  0.5925],\n",
      "         [ 0.7455,  1.8802, -0.3807,  ...,  1.0705, -0.7636,  1.8818],\n",
      "         [-0.6752,  1.3208,  0.8758,  ...,  0.9824, -0.1681, -0.2109]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0156,  0.1064,  0.0345,  ...,  0.0606, -0.0355, -0.0382],\n",
      "         [ 0.0168,  0.1209,  0.0359,  ...,  0.0755, -0.0315, -0.0320],\n",
      "         [ 0.0064,  0.1071,  0.0273,  ...,  0.0760, -0.0190, -0.0279]]],\n",
      "       device='cuda:0'), tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0156,  0.1064,  0.0345,  ...,  0.0606, -0.0355, -0.0382],\n",
      "         [ 0.0168,  0.1209,  0.0359,  ...,  0.0755, -0.0315, -0.0320],\n",
      "         [ 0.0064,  0.1071,  0.0273,  ...,  0.0760, -0.0190, -0.0279]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 0.7945, -0.0199,  0.2989,  ...,  0.9558, -0.1320,  0.6722],\n",
      "         [-2.4441,  0.0815, -0.1207,  ...,  0.5630,  0.4145,  0.9973],\n",
      "         [ 1.5634,  2.6464,  0.4141,  ...,  0.3954,  0.0313,  0.5825]]],\n",
      "       device='cuda:0'), tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 0.7945, -0.0199,  0.2989,  ...,  0.9558, -0.1320,  0.6722],\n",
      "         [-2.4441,  0.0815, -0.1207,  ...,  0.5630,  0.4145,  0.9973],\n",
      "         [ 1.5634,  2.6464,  0.4141,  ...,  0.3954,  0.0313,  0.5825]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [ 0.5407,  0.4374,  0.8314,  ...,  2.1209, -0.7417, -0.2504],\n",
      "         [-0.1871,  1.8780, -1.9824,  ...,  2.0780, -0.5233, -0.7281],\n",
      "         [-0.7148,  0.6004,  0.4578,  ...,  1.4096, -0.6658, -2.1643]]],\n",
      "       device='cuda:0'), tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [ 0.5407,  0.4374,  0.8314,  ...,  2.1209, -0.7417, -0.2504],\n",
      "         [-0.1871,  1.8780, -1.9824,  ...,  2.0780, -0.5233, -0.7281],\n",
      "         [-0.7148,  0.6004,  0.4578,  ...,  1.4096, -0.6658, -2.1643]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [ 0.6154,  1.4145, -0.6100,  ...,  0.6286,  0.3539,  1.5786],\n",
      "         [-1.0973,  1.7839,  0.4679,  ...,  0.7426,  0.7327,  2.4701],\n",
      "         [-0.3249, -0.8798,  1.1339,  ...,  1.6865,  1.1034,  0.0714]]],\n",
      "       device='cuda:0'), tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [ 0.6154,  1.4145, -0.6100,  ...,  0.6286,  0.3539,  1.5786],\n",
      "         [-1.0973,  1.7839,  0.4679,  ...,  0.7426,  0.7327,  2.4701],\n",
      "         [-0.3249, -0.8798,  1.1339,  ...,  1.6865,  1.1034,  0.0714]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.4973, -1.1275,  1.5990,  ..., -3.2919,  0.6370, -0.7389],\n",
      "         [-2.4673, -0.8103,  1.6060,  ..., -3.0103,  0.7369, -0.7695],\n",
      "         [-2.0794, -0.9490,  1.6570,  ..., -2.9208,  0.6659, -0.6246]]],\n",
      "       device='cuda:0'), tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.4973, -1.1275,  1.5990,  ..., -3.2919,  0.6370, -0.7389],\n",
      "         [-2.4673, -0.8103,  1.6060,  ..., -3.0103,  0.7369, -0.7695],\n",
      "         [-2.0794, -0.9490,  1.6570,  ..., -2.9208,  0.6659, -0.6246]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [ 0.4819, -0.0842,  0.6043,  ...,  1.2570, -0.2681,  1.2266],\n",
      "         [ 0.9486,  1.8959,  1.4220,  ...,  1.6988, -1.0488,  0.5058],\n",
      "         [ 0.6783,  1.6406,  1.8567,  ..., -0.0654, -0.4891,  0.9150]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [ 0.4819, -0.0842,  0.6043,  ...,  1.2570, -0.2681,  1.2266],\n",
      "         [ 0.9486,  1.8959,  1.4220,  ...,  1.6988, -1.0488,  0.5058],\n",
      "         [ 0.6783,  1.6406,  1.8567,  ..., -0.0654, -0.4891,  0.9150]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.3881,  1.5693, -0.1494,  ..., -0.3924, -0.0650,  2.3803],\n",
      "         [ 2.4059,  1.5305, -0.1689,  ..., -0.4038, -0.0422,  2.3679],\n",
      "         [ 2.4254,  1.5662, -0.1496,  ..., -0.3458, -0.0476,  2.3820]]],\n",
      "       device='cuda:0'), tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.3881,  1.5693, -0.1494,  ..., -0.3924, -0.0650,  2.3803],\n",
      "         [ 2.4059,  1.5305, -0.1689,  ..., -0.4038, -0.0422,  2.3679],\n",
      "         [ 2.4254,  1.5662, -0.1496,  ..., -0.3458, -0.0476,  2.3820]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 2.5471,  2.2035, -0.5422,  ...,  1.8094, -0.8719,  3.0728],\n",
      "         [-1.7380,  2.1941, -0.9864,  ..., -1.1579, -0.1867,  0.5002],\n",
      "         [ 1.2770,  1.5612, -2.3534,  ...,  0.7220, -2.4470,  0.0553]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 2.5471,  2.2035, -0.5422,  ...,  1.8094, -0.8719,  3.0728],\n",
      "         [-1.7380,  2.1941, -0.9864,  ..., -1.1579, -0.1867,  0.5002],\n",
      "         [ 1.2770,  1.5612, -2.3534,  ...,  0.7220, -2.4470,  0.0553]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0221, -0.0009,  0.0245,  ..., -0.0100, -0.0057, -0.0183],\n",
      "         [ 0.0218, -0.0001,  0.0236,  ..., -0.0089, -0.0064, -0.0189],\n",
      "         [ 0.0223, -0.0019,  0.0241,  ..., -0.0106, -0.0062, -0.0182]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0221, -0.0009,  0.0245,  ..., -0.0100, -0.0057, -0.0183],\n",
      "         [ 0.0218, -0.0001,  0.0236,  ..., -0.0089, -0.0064, -0.0189],\n",
      "         [ 0.0223, -0.0019,  0.0241,  ..., -0.0106, -0.0062, -0.0182]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [-0.3497,  0.8484,  1.1130,  ..., -0.0526,  0.1253,  2.6513],\n",
      "         [ 0.7227,  2.7661, -1.4877,  ...,  0.4334, -0.1253,  0.3001],\n",
      "         [ 1.0521, -0.2341, -0.2699,  ...,  1.1907, -0.6000,  0.6110]]],\n",
      "       device='cuda:0'), tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [-0.3497,  0.8484,  1.1130,  ..., -0.0526,  0.1253,  2.6513],\n",
      "         [ 0.7227,  2.7661, -1.4877,  ...,  0.4334, -0.1253,  0.3001],\n",
      "         [ 1.0521, -0.2341, -0.2699,  ...,  1.1907, -0.6000,  0.6110]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.3947,  0.3689, -0.5131,  ...,  0.8974, -0.0546, -1.5354],\n",
      "         [-2.2389, -0.7170, -0.4979,  ..., -0.0631,  1.1498, -0.5748],\n",
      "         [ 0.3096, -0.4762, -0.9522,  ..., -0.3519, -0.1535, -0.6138]]],\n",
      "       device='cuda:0'), tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.3947,  0.3689, -0.5131,  ...,  0.8974, -0.0546, -1.5354],\n",
      "         [-2.2389, -0.7170, -0.4979,  ..., -0.0631,  1.1498, -0.5748],\n",
      "         [ 0.3096, -0.4762, -0.9522,  ..., -0.3519, -0.1535, -0.6138]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 8.6931e-01, -3.3488e-01, -3.3933e-01,  ...,  2.2414e+00,\n",
      "          -3.3202e-01,  1.4454e+00],\n",
      "         [ 1.5054e+00,  1.2043e+00, -9.3633e-01,  ...,  2.2650e-01,\n",
      "           1.2867e+00,  1.4936e+00],\n",
      "         [ 1.0885e+00,  2.9663e-01,  5.6834e-01,  ...,  1.8635e+00,\n",
      "           3.8787e-01,  1.0019e+00]]], device='cuda:0'), tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 8.6931e-01, -3.3488e-01, -3.3933e-01,  ...,  2.2414e+00,\n",
      "          -3.3202e-01,  1.4454e+00],\n",
      "         [ 1.5054e+00,  1.2043e+00, -9.3633e-01,  ...,  2.2650e-01,\n",
      "           1.2867e+00,  1.4936e+00],\n",
      "         [ 1.0885e+00,  2.9663e-01,  5.6834e-01,  ...,  1.8635e+00,\n",
      "           3.8787e-01,  1.0019e+00]]], device='cuda:0')), 'logits_attn': (tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.6980,  2.8850,  5.9474,  ..., -1.8661, -8.4280, -3.5468],\n",
      "         [ 4.7512,  3.0442,  5.5078,  ..., -2.1113, -8.3719, -3.3394],\n",
      "         [ 4.6572,  3.0693,  5.8468,  ..., -2.0763, -8.3340, -3.5659]]],\n",
      "       device='cuda:0'), tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.6980,  2.8850,  5.9474,  ..., -1.8661, -8.4280, -3.5468],\n",
      "         [ 4.7512,  3.0442,  5.5078,  ..., -2.1113, -8.3719, -3.3394],\n",
      "         [ 4.6572,  3.0693,  5.8468,  ..., -2.0763, -8.3340, -3.5659]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.4779, -0.2201, -0.0627,  ...,  2.2032, -0.0734, -0.4343],\n",
      "         [ 0.8170,  1.5748, -0.6445,  ...,  1.8773, -0.0363,  1.4668],\n",
      "         [ 0.7188, -0.0378, -0.0450,  ...,  0.8795,  0.9351,  1.2149]]],\n",
      "       device='cuda:0'), tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.4779, -0.2201, -0.0627,  ...,  2.2032, -0.0734, -0.4343],\n",
      "         [ 0.8170,  1.5748, -0.6445,  ...,  1.8773, -0.0363,  1.4668],\n",
      "         [ 0.7188, -0.0378, -0.0450,  ...,  0.8795,  0.9351,  1.2149]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5777, -8.7642,  4.8982,  ...,  5.1976,  2.4857,  3.4406],\n",
      "         [ 3.5722, -8.7693,  4.9012,  ...,  5.1923,  2.4804,  3.4371],\n",
      "         [ 3.5748, -8.7719,  4.9042,  ...,  5.1906,  2.4869,  3.4402]]],\n",
      "       device='cuda:0'), tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5777, -8.7642,  4.8982,  ...,  5.1976,  2.4857,  3.4406],\n",
      "         [ 3.5722, -8.7693,  4.9012,  ...,  5.1923,  2.4804,  3.4371],\n",
      "         [ 3.5748, -8.7719,  4.9042,  ...,  5.1906,  2.4869,  3.4402]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [-0.4067,  1.7966, -1.5688,  ...,  1.3930,  0.4954,  1.4853],\n",
      "         [-1.6032, -0.4965, -0.6508,  ...,  1.9993,  1.2611,  0.3670],\n",
      "         [ 0.2196,  0.9378,  0.1257,  ...,  1.9003,  0.1507,  2.0620]]],\n",
      "       device='cuda:0'), tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [-0.4067,  1.7966, -1.5688,  ...,  1.3930,  0.4954,  1.4853],\n",
      "         [-1.6032, -0.4965, -0.6508,  ...,  1.9993,  1.2611,  0.3670],\n",
      "         [ 0.2196,  0.9378,  0.1257,  ...,  1.9003,  0.1507,  2.0620]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0015, -0.0028, -0.0663,  ..., -0.0052,  0.0012, -0.0186],\n",
      "         [-0.0018, -0.0032, -0.0665,  ..., -0.0057,  0.0020, -0.0188],\n",
      "         [-0.0015, -0.0032, -0.0662,  ..., -0.0053,  0.0022, -0.0190]]],\n",
      "       device='cuda:0'), tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0015, -0.0028, -0.0663,  ..., -0.0052,  0.0012, -0.0186],\n",
      "         [-0.0018, -0.0032, -0.0665,  ..., -0.0057,  0.0020, -0.0188],\n",
      "         [-0.0015, -0.0032, -0.0662,  ..., -0.0053,  0.0022, -0.0190]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [-0.1399, -0.3911, -1.4342,  ..., -0.2461,  0.7315,  0.7684],\n",
      "         [ 0.5744, -0.0261, -0.3127,  ...,  1.1396,  2.7778, -1.7939],\n",
      "         [ 0.8136,  0.8436,  1.1846,  ...,  2.2281,  0.8120,  0.4172]]],\n",
      "       device='cuda:0'), tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [-0.1399, -0.3911, -1.4342,  ..., -0.2461,  0.7315,  0.7684],\n",
      "         [ 0.5744, -0.0261, -0.3127,  ...,  1.1396,  2.7778, -1.7939],\n",
      "         [ 0.8136,  0.8436,  1.1846,  ...,  2.2281,  0.8120,  0.4172]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 1.8144, -0.5378, -0.2293,  ...,  0.9575,  0.4779,  1.5830],\n",
      "         [ 0.9137, -2.5975, -1.5960,  ...,  1.1417,  1.8981,  2.2455],\n",
      "         [ 3.0102, -1.4605, -0.2363,  ...,  1.0682,  1.9750,  0.6146]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 1.8144, -0.5378, -0.2293,  ...,  0.9575,  0.4779,  1.5830],\n",
      "         [ 0.9137, -2.5975, -1.5960,  ...,  1.1417,  1.8981,  2.2455],\n",
      "         [ 3.0102, -1.4605, -0.2363,  ...,  1.0682,  1.9750,  0.6146]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [-0.0092,  1.5003,  0.9975,  ...,  1.5340,  0.1083, -0.1907],\n",
      "         [ 1.0178,  0.0137,  0.3398,  ...,  0.8429, -0.6427,  0.8140],\n",
      "         [-0.4368,  1.5229,  0.4408,  ...,  0.6101, -2.3580, -0.1190]]],\n",
      "       device='cuda:0'), tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [-0.0092,  1.5003,  0.9975,  ...,  1.5340,  0.1083, -0.1907],\n",
      "         [ 1.0178,  0.0137,  0.3398,  ...,  0.8429, -0.6427,  0.8140],\n",
      "         [-0.4368,  1.5229,  0.4408,  ...,  0.6101, -2.3580, -0.1190]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.9622, -1.3964,  0.2103,  ..., -0.3796,  3.2023,  1.8758],\n",
      "         [-4.8591, -1.5262, -0.0143,  ..., -0.7160,  2.8642,  1.8221],\n",
      "         [-4.8507, -1.8268,  0.1197,  ..., -0.5460,  2.8205,  1.8998]]],\n",
      "       device='cuda:0'), tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.9622, -1.3964,  0.2103,  ..., -0.3796,  3.2023,  1.8758],\n",
      "         [-4.8591, -1.5262, -0.0143,  ..., -0.7160,  2.8642,  1.8221],\n",
      "         [-4.8507, -1.8268,  0.1197,  ..., -0.5460,  2.8205,  1.8998]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [ 0.0917,  1.0769, -0.2178,  ...,  1.9242,  1.0894,  2.2659],\n",
      "         [-1.6198,  0.3982,  2.4920,  ...,  1.3933, -1.1429,  0.4872],\n",
      "         [ 1.4519,  1.3103,  1.2809,  ...,  2.6056, -1.3190,  1.6048]]],\n",
      "       device='cuda:0'), tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [ 0.0917,  1.0769, -0.2178,  ...,  1.9242,  1.0894,  2.2659],\n",
      "         [-1.6198,  0.3982,  2.4920,  ...,  1.3933, -1.1429,  0.4872],\n",
      "         [ 1.4519,  1.3103,  1.2809,  ...,  2.6056, -1.3190,  1.6048]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0231,  0.1848,  0.4851,  ..., -0.3177,  0.7309, -0.6040],\n",
      "         [ 0.0242,  0.2915,  0.5006,  ..., -0.2738,  0.7059, -0.5211],\n",
      "         [ 0.0291,  0.2278,  0.4801,  ..., -0.3037,  0.7452, -0.5684]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0231,  0.1848,  0.4851,  ..., -0.3177,  0.7309, -0.6040],\n",
      "         [ 0.0242,  0.2915,  0.5006,  ..., -0.2738,  0.7059, -0.5211],\n",
      "         [ 0.0291,  0.2278,  0.4801,  ..., -0.3037,  0.7452, -0.5684]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.8131,  2.5660, -0.8092,  ..., -0.1190, -1.0696,  0.3201],\n",
      "         [-0.3324,  1.6020, -0.1374,  ...,  0.3841, -0.7718,  3.0090],\n",
      "         [-1.4339,  1.6233, -0.1448,  ..., -0.9475, -0.7145,  0.7776]]],\n",
      "       device='cuda:0'), tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.8131,  2.5660, -0.8092,  ..., -0.1190, -1.0696,  0.3201],\n",
      "         [-0.3324,  1.6020, -0.1374,  ...,  0.3841, -0.7718,  3.0090],\n",
      "         [-1.4339,  1.6233, -0.1448,  ..., -0.9475, -0.7145,  0.7776]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0578, -0.0350,  0.0806,  ...,  0.0507,  0.0747, -0.0128],\n",
      "         [-0.0605, -0.0378,  0.0791,  ...,  0.0534,  0.0801, -0.0169],\n",
      "         [-0.0550, -0.0318,  0.0810,  ...,  0.0551,  0.0827, -0.0219]]],\n",
      "       device='cuda:0'), tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0578, -0.0350,  0.0806,  ...,  0.0507,  0.0747, -0.0128],\n",
      "         [-0.0605, -0.0378,  0.0791,  ...,  0.0534,  0.0801, -0.0169],\n",
      "         [-0.0550, -0.0318,  0.0810,  ...,  0.0551,  0.0827, -0.0219]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [-0.0987,  0.2148, -0.9987,  ...,  3.3892, -0.9026,  0.8367],\n",
      "         [-0.3636, -1.4098, -0.3689,  ..., -1.4093, -1.2500,  1.6864],\n",
      "         [-0.2851,  1.9893, -0.4858,  ..., -0.1404, -0.5124,  0.2236]]],\n",
      "       device='cuda:0'), tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [-0.0987,  0.2148, -0.9987,  ...,  3.3892, -0.9026,  0.8367],\n",
      "         [-0.3636, -1.4098, -0.3689,  ..., -1.4093, -1.2500,  1.6864],\n",
      "         [-0.2851,  1.9893, -0.4858,  ..., -0.1404, -0.5124,  0.2236]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [-0.0370, -0.8653,  0.3879,  ...,  1.4128,  0.6078, -0.7716],\n",
      "         [-1.1786, -1.1314,  0.7113,  ...,  2.8053,  1.9146, -1.1005],\n",
      "         [-1.0222, -1.0100,  0.3992,  ...,  3.6699,  0.8590,  0.2218]]],\n",
      "       device='cuda:0'), tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [-0.0370, -0.8653,  0.3879,  ...,  1.4128,  0.6078, -0.7716],\n",
      "         [-1.1786, -1.1314,  0.7113,  ...,  2.8053,  1.9146, -1.1005],\n",
      "         [-1.0222, -1.0100,  0.3992,  ...,  3.6699,  0.8590,  0.2218]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [-1.0480, -1.5482,  1.2456,  ...,  2.3372,  0.3368, -0.4382],\n",
      "         [-1.2866,  1.9570, -0.6511,  ...,  0.4523, -1.5274,  2.9027],\n",
      "         [-1.0337,  1.6767, -0.8788,  ..., -0.5531,  1.5548,  1.6416]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [-1.0480, -1.5482,  1.2456,  ...,  2.3372,  0.3368, -0.4382],\n",
      "         [-1.2866,  1.9570, -0.6511,  ...,  0.4523, -1.5274,  2.9027],\n",
      "         [-1.0337,  1.6767, -0.8788,  ..., -0.5531,  1.5548,  1.6416]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.3135, -0.1495,  1.1385,  ..., -0.0543,  0.5742,  0.0426],\n",
      "         [ 1.0307, -0.2905,  0.5465,  ...,  0.2623,  0.2542, -0.0230],\n",
      "         [ 0.9928, -0.0319,  0.8657,  ...,  0.1457,  0.3516,  0.3617]]],\n",
      "       device='cuda:0'), tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.3135, -0.1495,  1.1385,  ..., -0.0543,  0.5742,  0.0426],\n",
      "         [ 1.0307, -0.2905,  0.5465,  ...,  0.2623,  0.2542, -0.0230],\n",
      "         [ 0.9928, -0.0319,  0.8657,  ...,  0.1457,  0.3516,  0.3617]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [ 0.3752,  2.2917,  1.2036,  ...,  0.8136,  0.5229,  1.5727],\n",
      "         [-1.0098, -0.5848,  1.2738,  ...,  3.2230,  1.0085,  1.2871],\n",
      "         [-0.6700,  0.1743,  0.4443,  ...,  1.0630, -0.9039,  0.3673]]],\n",
      "       device='cuda:0'), tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [ 0.3752,  2.2917,  1.2036,  ...,  0.8136,  0.5229,  1.5727],\n",
      "         [-1.0098, -0.5848,  1.2738,  ...,  3.2230,  1.0085,  1.2871],\n",
      "         [-0.6700,  0.1743,  0.4443,  ...,  1.0630, -0.9039,  0.3673]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4478,  5.3998,  1.9885,  ...,  4.7914, -1.4970, -0.6465],\n",
      "         [ 2.4860,  5.3514,  1.9392,  ...,  4.8148, -1.5199, -0.6754],\n",
      "         [ 2.4565,  5.3985,  1.9726,  ...,  4.7944, -1.5134, -0.6782]]],\n",
      "       device='cuda:0'), tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4478,  5.3998,  1.9885,  ...,  4.7914, -1.4970, -0.6465],\n",
      "         [ 2.4860,  5.3514,  1.9392,  ...,  4.8148, -1.5199, -0.6754],\n",
      "         [ 2.4565,  5.3985,  1.9726,  ...,  4.7944, -1.5134, -0.6782]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [ 1.3329, -0.9821, -0.2860,  ...,  0.9064, -0.4598,  1.3789],\n",
      "         [-0.0556,  2.3915,  0.0811,  ...,  0.6318,  0.6099, -1.2814],\n",
      "         [ 0.2080, -0.0077, -1.0196,  ...,  1.3653, -0.0464, -0.1130]]],\n",
      "       device='cuda:0'), tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [ 1.3329, -0.9821, -0.2860,  ...,  0.9064, -0.4598,  1.3789],\n",
      "         [-0.0556,  2.3915,  0.0811,  ...,  0.6318,  0.6099, -1.2814],\n",
      "         [ 0.2080, -0.0077, -1.0196,  ...,  1.3653, -0.0464, -0.1130]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0232,  0.0636, -0.0198,  ..., -0.1114,  0.0331,  0.0239],\n",
      "         [-0.0231,  0.0630, -0.0193,  ..., -0.1131,  0.0320,  0.0251],\n",
      "         [-0.0251,  0.0641, -0.0231,  ..., -0.1162,  0.0336,  0.0274]]],\n",
      "       device='cuda:0'), tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0232,  0.0636, -0.0198,  ..., -0.1114,  0.0331,  0.0239],\n",
      "         [-0.0231,  0.0630, -0.0193,  ..., -0.1131,  0.0320,  0.0251],\n",
      "         [-0.0251,  0.0641, -0.0231,  ..., -0.1162,  0.0336,  0.0274]]],\n",
      "       device='cuda:0'))}]}]\n",
      "Step 350 - Last token probs (min/max): 0.0036721774376928806 / 0.057288721203804016\n",
      "Step 400 - past_kv structure:  [{'left': [{'chunk_attn': (tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [ 1.6586,  0.6128,  1.0144,  ..., -0.0168,  0.7315, -0.7497],\n",
      "         [ 0.5368, -0.0673,  1.1138,  ...,  0.2633,  1.3010,  1.2752],\n",
      "         [-2.0497,  0.3575, -0.8248,  ..., -0.4756, -1.4745,  2.2528]]],\n",
      "       device='cuda:0'), tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [ 1.6586,  0.6128,  1.0144,  ..., -0.0168,  0.7315, -0.7497],\n",
      "         [ 0.5368, -0.0673,  1.1138,  ...,  0.2633,  1.3010,  1.2752],\n",
      "         [-2.0497,  0.3575, -0.8248,  ..., -0.4756, -1.4745,  2.2528]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'), tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [-0.6290, -0.3874,  2.1205,  ...,  0.7743,  1.9196,  1.2393],\n",
      "         [-0.0671,  1.8145,  1.3763,  ...,  3.5208,  1.1697,  0.8584],\n",
      "         [ 0.3212,  0.4691,  0.3471,  ...,  1.1076, -0.5276,  2.9425]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [-0.6290, -0.3874,  2.1205,  ...,  0.7743,  1.9196,  1.2393],\n",
      "         [-0.0671,  1.8145,  1.3763,  ...,  3.5208,  1.1697,  0.8584],\n",
      "         [ 0.3212,  0.4691,  0.3471,  ...,  1.1076, -0.5276,  2.9425]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9684, -0.4074, -7.1997,  ...,  5.5813,  1.3304, -0.3851],\n",
      "         [-4.9423, -0.3447, -7.2453,  ...,  5.5522,  1.2921, -0.4276],\n",
      "         [-4.9281, -0.3902, -7.2784,  ...,  5.6536,  1.2701, -0.3434]]],\n",
      "       device='cuda:0'), tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9684, -0.4074, -7.1997,  ...,  5.5813,  1.3304, -0.3851],\n",
      "         [-4.9423, -0.3447, -7.2453,  ...,  5.5522,  1.2921, -0.4276],\n",
      "         [-4.9281, -0.3902, -7.2784,  ...,  5.6536,  1.2701, -0.3434]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [ 0.0845,  0.3043,  0.0293,  ...,  1.3044,  1.1350,  0.8578],\n",
      "         [ 1.1487,  2.3069,  1.7768,  ...,  1.6875, -0.9756,  0.9217],\n",
      "         [-0.0615,  1.5844, -0.2271,  ...,  0.9042,  0.8783,  1.6147]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [ 0.0845,  0.3043,  0.0293,  ...,  1.3044,  1.1350,  0.8578],\n",
      "         [ 1.1487,  2.3069,  1.7768,  ...,  1.6875, -0.9756,  0.9217],\n",
      "         [-0.0615,  1.5844, -0.2271,  ...,  0.9042,  0.8783,  1.6147]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0465,  1.9572,  1.9767,  ...,  1.4795,  1.3036, -2.7932],\n",
      "         [ 3.0452,  1.9533,  1.9739,  ...,  1.4779,  1.3010, -2.7930],\n",
      "         [ 3.0464,  1.9529,  1.9759,  ...,  1.4802,  1.3006, -2.7932]]],\n",
      "       device='cuda:0'), tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0465,  1.9572,  1.9767,  ...,  1.4795,  1.3036, -2.7932],\n",
      "         [ 3.0452,  1.9533,  1.9739,  ...,  1.4779,  1.3010, -2.7930],\n",
      "         [ 3.0464,  1.9529,  1.9759,  ...,  1.4802,  1.3006, -2.7932]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 1.8613,  0.6258, -0.1629,  ...,  0.4846,  0.3004,  0.7457],\n",
      "         [-0.5692,  2.4703, -0.8929,  ...,  0.5737, -0.1069,  1.9254],\n",
      "         [ 1.4366,  1.0848, -0.2089,  ..., -0.0852,  0.1952,  2.3277]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 1.8613,  0.6258, -0.1629,  ...,  0.4846,  0.3004,  0.7457],\n",
      "         [-0.5692,  2.4703, -0.8929,  ...,  0.5737, -0.1069,  1.9254],\n",
      "         [ 1.4366,  1.0848, -0.2089,  ..., -0.0852,  0.1952,  2.3277]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-3.5482e-03,  2.6839e-02, -1.4616e-04,  ..., -8.2464e-02,\n",
      "          -6.2248e-02,  3.5648e-03],\n",
      "         [-2.6049e-03,  2.2181e-02,  5.2032e-03,  ..., -8.3641e-02,\n",
      "          -6.9335e-02, -1.3907e-03],\n",
      "         [-2.6747e-03,  2.2022e-02,  3.8474e-03,  ..., -8.4008e-02,\n",
      "          -6.9436e-02, -2.3258e-04],\n",
      "         ...,\n",
      "         [-3.2759e-03,  2.3306e-02,  5.6249e-03,  ..., -8.2400e-02,\n",
      "          -6.9509e-02, -3.8024e-05],\n",
      "         [-1.8769e-03,  2.3659e-02,  6.8804e-03,  ..., -8.2460e-02,\n",
      "          -6.8024e-02,  1.6005e-03],\n",
      "         [-1.7722e-03,  2.4228e-02,  4.8854e-03,  ..., -8.1928e-02,\n",
      "          -6.8049e-02,  1.3958e-03]]], device='cuda:0'), tensor([[[-3.5482e-03,  2.6839e-02, -1.4616e-04,  ..., -8.2464e-02,\n",
      "          -6.2248e-02,  3.5648e-03],\n",
      "         [-2.6049e-03,  2.2181e-02,  5.2032e-03,  ..., -8.3641e-02,\n",
      "          -6.9335e-02, -1.3907e-03],\n",
      "         [-2.6747e-03,  2.2022e-02,  3.8474e-03,  ..., -8.4008e-02,\n",
      "          -6.9436e-02, -2.3258e-04],\n",
      "         ...,\n",
      "         [-3.2759e-03,  2.3306e-02,  5.6249e-03,  ..., -8.2400e-02,\n",
      "          -6.9509e-02, -3.8024e-05],\n",
      "         [-1.8769e-03,  2.3659e-02,  6.8804e-03,  ..., -8.2460e-02,\n",
      "          -6.8024e-02,  1.6005e-03],\n",
      "         [-1.7722e-03,  2.4228e-02,  4.8854e-03,  ..., -8.1928e-02,\n",
      "          -6.8049e-02,  1.3958e-03]]], device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [ 0.6788,  0.4077, -0.0140,  ...,  1.3038, -1.3984,  1.5348],\n",
      "         [-1.0739,  0.6164, -1.3272,  ...,  2.7016,  0.8675,  0.2868],\n",
      "         [-0.2069,  1.4114,  0.5428,  ...,  3.8500, -0.4840,  0.6255]]],\n",
      "       device='cuda:0'), tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [ 0.6788,  0.4077, -0.0140,  ...,  1.3038, -1.3984,  1.5348],\n",
      "         [-1.0739,  0.6164, -1.3272,  ...,  2.7016,  0.8675,  0.2868],\n",
      "         [-0.2069,  1.4114,  0.5428,  ...,  3.8500, -0.4840,  0.6255]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'), tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [ 0.5702,  0.9998, -0.5013,  ...,  1.5366,  0.3173, -0.1366],\n",
      "         [-1.2845,  1.6649, -1.3089,  ..., -0.1436, -0.3605,  0.7022],\n",
      "         [-0.0211,  1.5176,  1.0572,  ...,  0.9023,  1.6843, -0.0386]]],\n",
      "       device='cuda:0'), tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [ 0.5702,  0.9998, -0.5013,  ...,  1.5366,  0.3173, -0.1366],\n",
      "         [-1.2845,  1.6649, -1.3089,  ..., -0.1436, -0.3605,  0.7022],\n",
      "         [-0.0211,  1.5176,  1.0572,  ...,  0.9023,  1.6843, -0.0386]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.6512, -0.2878, -0.1714,  ...,  1.2738, -0.4176, -0.0467],\n",
      "         [-0.6391, -0.3882, -0.1019,  ...,  1.0678, -0.5569, -0.0284],\n",
      "         [-0.9225, -0.3562, -0.0451,  ...,  1.3028, -0.3115,  0.1979]]],\n",
      "       device='cuda:0'), tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-0.6512, -0.2878, -0.1714,  ...,  1.2738, -0.4176, -0.0467],\n",
      "         [-0.6391, -0.3882, -0.1019,  ...,  1.0678, -0.5569, -0.0284],\n",
      "         [-0.9225, -0.3562, -0.0451,  ...,  1.3028, -0.3115,  0.1979]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [ 1.5542, -1.4580, -1.0779,  ...,  1.1601, -1.0525,  0.7404],\n",
      "         [ 0.5459,  0.2493, -1.4935,  ...,  1.0661, -0.2949,  0.9509],\n",
      "         [-0.5378,  0.3613, -0.0159,  ...,  1.2645, -1.9977,  1.2427]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [ 1.5542, -1.4580, -1.0779,  ...,  1.1601, -1.0525,  0.7404],\n",
      "         [ 0.5459,  0.2493, -1.4935,  ...,  1.0661, -0.2949,  0.9509],\n",
      "         [-0.5378,  0.3613, -0.0159,  ...,  1.2645, -1.9977,  1.2427]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3359,  0.3994,  0.0302,  ..., -0.5002,  0.5558, -0.2219],\n",
      "         [ 0.3386,  0.3873,  0.0404,  ..., -0.4885,  0.5673, -0.2355],\n",
      "         [ 0.3236,  0.4046,  0.0439,  ..., -0.4932,  0.5754, -0.2313]]],\n",
      "       device='cuda:0'), tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3359,  0.3994,  0.0302,  ..., -0.5002,  0.5558, -0.2219],\n",
      "         [ 0.3386,  0.3873,  0.0404,  ..., -0.4885,  0.5673, -0.2355],\n",
      "         [ 0.3236,  0.4046,  0.0439,  ..., -0.4932,  0.5754, -0.2313]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.3020,  1.6202,  0.8683,  ...,  0.7236,  0.7388,  2.2735],\n",
      "         [-0.9913, -0.6125,  0.2165,  ...,  1.1395,  1.5056,  1.9124],\n",
      "         [-0.2294,  1.8924,  1.1521,  ...,  1.1405,  2.2362,  1.4436]]],\n",
      "       device='cuda:0'), tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [-0.3020,  1.6202,  0.8683,  ...,  0.7236,  0.7388,  2.2735],\n",
      "         [-0.9913, -0.6125,  0.2165,  ...,  1.1395,  1.5056,  1.9124],\n",
      "         [-0.2294,  1.8924,  1.1521,  ...,  1.1405,  2.2362,  1.4436]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0660,  0.1098, -0.0410,  ..., -0.1173, -0.0242, -0.0394],\n",
      "         [ 0.0617,  0.0885, -0.0397,  ..., -0.1224, -0.0067, -0.0312],\n",
      "         [ 0.0701,  0.0745, -0.0259,  ..., -0.1217, -0.0096, -0.0318]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0660,  0.1098, -0.0410,  ..., -0.1173, -0.0242, -0.0394],\n",
      "         [ 0.0617,  0.0885, -0.0397,  ..., -0.1224, -0.0067, -0.0312],\n",
      "         [ 0.0701,  0.0745, -0.0259,  ..., -0.1217, -0.0096, -0.0318]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [ 0.7315,  0.0925, -0.4485,  ...,  0.8910, -0.0714,  0.3068],\n",
      "         [-0.3402, -1.7111, -1.0749,  ...,  2.2431,  0.8619,  0.4913],\n",
      "         [ 0.0145,  2.1382,  1.1205,  ..., -0.4022,  1.7263,  1.4305]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [ 0.7315,  0.0925, -0.4485,  ...,  0.8910, -0.0714,  0.3068],\n",
      "         [-0.3402, -1.7111, -1.0749,  ...,  2.2431,  0.8619,  0.4913],\n",
      "         [ 0.0145,  2.1382,  1.1205,  ..., -0.4022,  1.7263,  1.4305]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [-0.6812, -0.0899, -0.4678,  ...,  0.3615,  0.0291,  0.8461],\n",
      "         [-0.8999, -1.2844,  0.5072,  ...,  0.5268, -1.1642, -0.1680],\n",
      "         [ 1.5045,  0.5921,  0.0212,  ..., -0.0481, -0.3385, -0.8453]]],\n",
      "       device='cuda:0'), tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [-0.6812, -0.0899, -0.4678,  ...,  0.3615,  0.0291,  0.8461],\n",
      "         [-0.8999, -1.2844,  0.5072,  ...,  0.5268, -1.1642, -0.1680],\n",
      "         [ 1.5045,  0.5921,  0.0212,  ..., -0.0481, -0.3385, -0.8453]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [ 0.0425,  0.6587,  1.6742,  ...,  3.0249, -0.5444,  1.8701],\n",
      "         [ 1.4550, -1.0100,  2.9845,  ...,  1.8145,  0.2797,  0.0952],\n",
      "         [ 2.1964,  1.0030,  0.1121,  ...,  0.1853, -0.0761,  2.9577]]],\n",
      "       device='cuda:0'), tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [ 0.0425,  0.6587,  1.6742,  ...,  3.0249, -0.5444,  1.8701],\n",
      "         [ 1.4550, -1.0100,  2.9845,  ...,  1.8145,  0.2797,  0.0952],\n",
      "         [ 2.1964,  1.0030,  0.1121,  ...,  0.1853, -0.0761,  2.9577]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.0646,  0.0547,  0.8224,  ..., -1.5074, -2.1371,  0.2700],\n",
      "         [-3.0935,  0.4143,  0.0829,  ..., -1.8169, -0.9645,  0.1710],\n",
      "         [-3.3245, -0.6558,  0.8609,  ..., -1.7935, -1.4709,  0.1403]]],\n",
      "       device='cuda:0'), tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.0646,  0.0547,  0.8224,  ..., -1.5074, -2.1371,  0.2700],\n",
      "         [-3.0935,  0.4143,  0.0829,  ..., -1.8169, -0.9645,  0.1710],\n",
      "         [-3.3245, -0.6558,  0.8609,  ..., -1.7935, -1.4709,  0.1403]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [-0.9824,  0.1481,  0.4228,  ...,  1.3224,  0.1185,  1.5177],\n",
      "         [-0.1464,  1.5219,  0.2521,  ...,  2.4334, -1.1203,  0.4350],\n",
      "         [ 1.3904, -0.5316, -0.5007,  ...,  1.9610, -1.2287,  0.6481]]],\n",
      "       device='cuda:0'), tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [-0.9824,  0.1481,  0.4228,  ...,  1.3224,  0.1185,  1.5177],\n",
      "         [-0.1464,  1.5219,  0.2521,  ...,  2.4334, -1.1203,  0.4350],\n",
      "         [ 1.3904, -0.5316, -0.5007,  ...,  1.9610, -1.2287,  0.6481]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.6213,  5.0012,  0.0469,  ...,  0.1184, -0.7984,  2.8177],\n",
      "         [ 0.5125,  5.1331, -0.0982,  ...,  0.0872, -0.6797,  2.8575],\n",
      "         [ 0.6125,  5.1206, -0.0482,  ...,  0.0870, -0.7239,  2.7992]]],\n",
      "       device='cuda:0'), tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.6213,  5.0012,  0.0469,  ...,  0.1184, -0.7984,  2.8177],\n",
      "         [ 0.5125,  5.1331, -0.0982,  ...,  0.0872, -0.6797,  2.8575],\n",
      "         [ 0.6125,  5.1206, -0.0482,  ...,  0.0870, -0.7239,  2.7992]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [-1.2044,  2.0250, -0.2179,  ...,  1.9380, -1.4753,  1.2872],\n",
      "         [ 1.5423,  1.3695,  0.2024,  ...,  1.1263, -0.1566,  0.4851],\n",
      "         [ 0.9741,  1.4629, -0.7050,  ...,  1.5009, -1.9216,  0.0498]]],\n",
      "       device='cuda:0'), tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [-1.2044,  2.0250, -0.2179,  ...,  1.9380, -1.4753,  1.2872],\n",
      "         [ 1.5423,  1.3695,  0.2024,  ...,  1.1263, -0.1566,  0.4851],\n",
      "         [ 0.9741,  1.4629, -0.7050,  ...,  1.5009, -1.9216,  0.0498]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0758, -0.0383,  0.0596,  ..., -0.0270, -0.0802, -0.0931],\n",
      "         [ 0.0765, -0.0364,  0.0563,  ..., -0.0253, -0.0850, -0.0920],\n",
      "         [ 0.0759, -0.0382,  0.0581,  ..., -0.0289, -0.0833, -0.0920]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0758, -0.0383,  0.0596,  ..., -0.0270, -0.0802, -0.0931],\n",
      "         [ 0.0765, -0.0364,  0.0563,  ..., -0.0253, -0.0850, -0.0920],\n",
      "         [ 0.0759, -0.0382,  0.0581,  ..., -0.0289, -0.0833, -0.0920]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [ 1.1958,  1.6627, -0.7081,  ...,  4.0823, -0.7704,  1.9048],\n",
      "         [ 0.0334,  0.8205,  0.9931,  ...,  1.9460,  1.0490,  2.9201],\n",
      "         [ 1.1267,  2.0171, -0.1890,  ...,  1.6493, -0.0297, -0.2860]]],\n",
      "       device='cuda:0'), tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [ 1.1958,  1.6627, -0.7081,  ...,  4.0823, -0.7704,  1.9048],\n",
      "         [ 0.0334,  0.8205,  0.9931,  ...,  1.9460,  1.0490,  2.9201],\n",
      "         [ 1.1267,  2.0171, -0.1890,  ...,  1.6493, -0.0297, -0.2860]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-5.4032e-01,  3.0297e-01, -2.7890e-01,  ..., -1.8354e-01,\n",
      "           7.0934e-01, -9.0582e-01],\n",
      "         [-1.2190e+00,  1.2312e-01, -5.1670e-01,  ...,  4.6898e-01,\n",
      "          -1.7459e+00, -1.2351e+00],\n",
      "         [-6.4821e-01,  8.6965e-02,  2.3807e-01,  ...,  5.8893e-01,\n",
      "          -3.3013e-01,  4.7723e-01],\n",
      "         ...,\n",
      "         [-2.0880e-03,  5.7573e-01,  2.6053e-01,  ...,  1.1197e+00,\n",
      "           1.5634e-02, -7.6028e-02],\n",
      "         [-4.1476e-01, -9.4748e-01, -7.4852e-01,  ...,  2.1401e+00,\n",
      "           1.2560e+00,  1.3970e+00],\n",
      "         [ 1.0859e+00,  1.7951e+00, -4.4907e-01,  ..., -3.3908e-01,\n",
      "          -5.8226e-01, -7.8668e-01]]], device='cuda:0'), tensor([[[-5.4032e-01,  3.0297e-01, -2.7890e-01,  ..., -1.8354e-01,\n",
      "           7.0934e-01, -9.0582e-01],\n",
      "         [-1.2190e+00,  1.2312e-01, -5.1670e-01,  ...,  4.6898e-01,\n",
      "          -1.7459e+00, -1.2351e+00],\n",
      "         [-6.4821e-01,  8.6965e-02,  2.3807e-01,  ...,  5.8893e-01,\n",
      "          -3.3013e-01,  4.7723e-01],\n",
      "         ...,\n",
      "         [-2.0880e-03,  5.7573e-01,  2.6053e-01,  ...,  1.1197e+00,\n",
      "           1.5634e-02, -7.6028e-02],\n",
      "         [-4.1476e-01, -9.4748e-01, -7.4852e-01,  ...,  2.1401e+00,\n",
      "           1.2560e+00,  1.3970e+00],\n",
      "         [ 1.0859e+00,  1.7951e+00, -4.4907e-01,  ..., -3.3908e-01,\n",
      "          -5.8226e-01, -7.8668e-01]]], device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 1.8552,  0.6184, -1.0395,  ...,  0.4867, -0.6796, -0.1911],\n",
      "         [-0.2146,  0.5029, -0.0201,  ...,  1.1974, -0.2169,  0.8882],\n",
      "         [-0.2603,  1.2171, -1.8479,  ..., -0.2356, -1.9889,  1.2555]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 1.8552,  0.6184, -1.0395,  ...,  0.4867, -0.6796, -0.1911],\n",
      "         [-0.2146,  0.5029, -0.0201,  ...,  1.1974, -0.2169,  0.8882],\n",
      "         [-0.2603,  1.2171, -1.8479,  ..., -0.2356, -1.9889,  1.2555]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.4478,  0.5801, -3.9702,  ...,  1.7454, -3.4212, -1.5404],\n",
      "         [-1.5323,  0.0446, -3.5835,  ...,  1.8497, -3.1011, -1.3137],\n",
      "         [-1.2082,  0.8522, -3.8828,  ...,  1.6361, -3.2647, -1.7362]]],\n",
      "       device='cuda:0'), tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.4478,  0.5801, -3.9702,  ...,  1.7454, -3.4212, -1.5404],\n",
      "         [-1.5323,  0.0446, -3.5835,  ...,  1.8497, -3.1011, -1.3137],\n",
      "         [-1.2082,  0.8522, -3.8828,  ...,  1.6361, -3.2647, -1.7362]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [ 0.4714,  1.2261,  2.2793,  ...,  1.3148,  1.1862,  1.4444],\n",
      "         [ 2.2145, -0.8802, -0.3198,  ...,  1.3654, -0.3255,  0.1158],\n",
      "         [ 0.0999, -0.3250, -0.4963,  ...,  2.7057,  2.7520,  0.6587]]],\n",
      "       device='cuda:0'), tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [ 0.4714,  1.2261,  2.2793,  ...,  1.3148,  1.1862,  1.4444],\n",
      "         [ 2.2145, -0.8802, -0.3198,  ...,  1.3654, -0.3255,  0.1158],\n",
      "         [ 0.0999, -0.3250, -0.4963,  ...,  2.7057,  2.7520,  0.6587]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2608, -0.5143, -0.6724,  ...,  0.5268, -2.5983,  0.8294],\n",
      "         [-1.2944, -0.5277, -0.6785,  ...,  0.5338, -2.5903,  0.8425],\n",
      "         [-1.3102, -0.4887, -0.6855,  ...,  0.5086, -2.5837,  0.7937]]],\n",
      "       device='cuda:0'), tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2608, -0.5143, -0.6724,  ...,  0.5268, -2.5983,  0.8294],\n",
      "         [-1.2944, -0.5277, -0.6785,  ...,  0.5338, -2.5903,  0.8425],\n",
      "         [-1.3102, -0.4887, -0.6855,  ...,  0.5086, -2.5837,  0.7937]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [-0.1308,  2.6451,  0.9442,  ...,  0.0391,  0.3637,  1.7614],\n",
      "         [ 0.9220,  2.5272,  0.6091,  ...,  1.5551,  2.1635,  0.6333],\n",
      "         [-1.3795,  0.2406,  1.1802,  ...,  1.5335,  1.9258,  0.2426]]],\n",
      "       device='cuda:0'), tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [-0.1308,  2.6451,  0.9442,  ...,  0.0391,  0.3637,  1.7614],\n",
      "         [ 0.9220,  2.5272,  0.6091,  ...,  1.5551,  2.1635,  0.6333],\n",
      "         [-1.3795,  0.2406,  1.1802,  ...,  1.5335,  1.9258,  0.2426]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0141,  0.1101,  0.0314,  ...,  0.0714, -0.0357, -0.0367],\n",
      "         [ 0.0100,  0.1107,  0.0404,  ...,  0.0730, -0.0096, -0.0336],\n",
      "         [ 0.0164,  0.1129,  0.0420,  ...,  0.0708, -0.0264, -0.0377]]],\n",
      "       device='cuda:0'), tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0141,  0.1101,  0.0314,  ...,  0.0714, -0.0357, -0.0367],\n",
      "         [ 0.0100,  0.1107,  0.0404,  ...,  0.0730, -0.0096, -0.0336],\n",
      "         [ 0.0164,  0.1129,  0.0420,  ...,  0.0708, -0.0264, -0.0377]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 0.3571,  0.3106, -1.2912,  ...,  0.1298,  1.2596,  1.4950],\n",
      "         [-1.2075,  0.9341, -0.9499,  ...,  1.1143,  0.1715, -0.4444],\n",
      "         [-0.2614,  1.4410, -0.8118,  ...,  1.2802, -0.1166,  1.5517]]],\n",
      "       device='cuda:0'), tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 0.3571,  0.3106, -1.2912,  ...,  0.1298,  1.2596,  1.4950],\n",
      "         [-1.2075,  0.9341, -0.9499,  ...,  1.1143,  0.1715, -0.4444],\n",
      "         [-0.2614,  1.4410, -0.8118,  ...,  1.2802, -0.1166,  1.5517]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [ 0.2969,  0.0507, -1.2239,  ...,  1.9358,  0.5400, -1.9449],\n",
      "         [-0.2030, -0.7218, -0.8148,  ...,  1.7543, -0.8828,  1.2319],\n",
      "         [ 0.5175, -0.3412,  1.4713,  ...,  1.2236, -0.7678, -1.0576]]],\n",
      "       device='cuda:0'), tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [ 0.2969,  0.0507, -1.2239,  ...,  1.9358,  0.5400, -1.9449],\n",
      "         [-0.2030, -0.7218, -0.8148,  ...,  1.7543, -0.8828,  1.2319],\n",
      "         [ 0.5175, -0.3412,  1.4713,  ...,  1.2236, -0.7678, -1.0576]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [ 1.8980,  0.8370,  0.2756,  ...,  1.6000, -0.1010,  0.7275],\n",
      "         [-0.3833,  0.5838, -0.3481,  ...,  0.0899, -0.7030,  0.3372],\n",
      "         [ 0.0228,  0.5601, -0.2903,  ...,  0.5073, -2.0030,  0.1084]]],\n",
      "       device='cuda:0'), tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [ 1.8980,  0.8370,  0.2756,  ...,  1.6000, -0.1010,  0.7275],\n",
      "         [-0.3833,  0.5838, -0.3481,  ...,  0.0899, -0.7030,  0.3372],\n",
      "         [ 0.0228,  0.5601, -0.2903,  ...,  0.5073, -2.0030,  0.1084]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.0277, -1.2110,  1.8634,  ..., -2.9312,  0.8120, -0.5387],\n",
      "         [-2.6298, -0.8023,  1.5974,  ..., -3.2480,  0.7046, -0.3963],\n",
      "         [-2.1694, -0.8474,  1.5328,  ..., -3.0871,  0.7832, -0.7122]]],\n",
      "       device='cuda:0'), tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.0277, -1.2110,  1.8634,  ..., -2.9312,  0.8120, -0.5387],\n",
      "         [-2.6298, -0.8023,  1.5974,  ..., -3.2480,  0.7046, -0.3963],\n",
      "         [-2.1694, -0.8474,  1.5328,  ..., -3.0871,  0.7832, -0.7122]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [-1.7666,  1.5551,  0.9046,  ...,  0.6868,  0.4395,  2.4698],\n",
      "         [ 0.0813,  0.4251, -0.0702,  ...,  0.3437, -1.0339,  0.4422],\n",
      "         [ 1.4774,  0.2975,  0.9374,  ...,  1.4492,  1.0125,  2.3092]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [-1.7666,  1.5551,  0.9046,  ...,  0.6868,  0.4395,  2.4698],\n",
      "         [ 0.0813,  0.4251, -0.0702,  ...,  0.3437, -1.0339,  0.4422],\n",
      "         [ 1.4774,  0.2975,  0.9374,  ...,  1.4492,  1.0125,  2.3092]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4562,  1.5408, -0.1346,  ..., -0.3470, -0.0471,  2.3675],\n",
      "         [ 2.4659,  1.5684, -0.1382,  ..., -0.3237, -0.0822,  2.3762],\n",
      "         [ 2.4719,  1.5356, -0.0997,  ..., -0.3243, -0.0646,  2.3807]]],\n",
      "       device='cuda:0'), tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4562,  1.5408, -0.1346,  ..., -0.3470, -0.0471,  2.3675],\n",
      "         [ 2.4659,  1.5684, -0.1382,  ..., -0.3237, -0.0822,  2.3762],\n",
      "         [ 2.4719,  1.5356, -0.0997,  ..., -0.3243, -0.0646,  2.3807]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 2.8274,  0.4952, -1.0841,  ...,  1.9543,  0.6512,  1.0727],\n",
      "         [ 0.1647,  1.9452,  0.2208,  ..., -0.5346,  1.0420,  1.1333],\n",
      "         [ 1.8874,  1.6306, -0.5794,  ...,  1.0505,  0.1394,  0.7129]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 2.8274,  0.4952, -1.0841,  ...,  1.9543,  0.6512,  1.0727],\n",
      "         [ 0.1647,  1.9452,  0.2208,  ..., -0.5346,  1.0420,  1.1333],\n",
      "         [ 1.8874,  1.6306, -0.5794,  ...,  1.0505,  0.1394,  0.7129]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0228, -0.0002,  0.0225,  ..., -0.0101, -0.0060, -0.0186],\n",
      "         [ 0.0228, -0.0018,  0.0236,  ..., -0.0109, -0.0073, -0.0176],\n",
      "         [ 0.0233, -0.0010,  0.0239,  ..., -0.0115, -0.0080, -0.0194]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0228, -0.0002,  0.0225,  ..., -0.0101, -0.0060, -0.0186],\n",
      "         [ 0.0228, -0.0018,  0.0236,  ..., -0.0109, -0.0073, -0.0176],\n",
      "         [ 0.0233, -0.0010,  0.0239,  ..., -0.0115, -0.0080, -0.0194]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [ 0.3972,  0.7825, -0.2200,  ...,  1.6760,  0.2775,  0.3049],\n",
      "         [-0.5515, -0.1442, -0.7014,  ..., -0.1107,  1.2126, -1.0937],\n",
      "         [-0.8313,  1.6666, -0.1858,  ...,  1.3449,  0.1141,  1.8689]]],\n",
      "       device='cuda:0'), tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [ 0.3972,  0.7825, -0.2200,  ...,  1.6760,  0.2775,  0.3049],\n",
      "         [-0.5515, -0.1442, -0.7014,  ..., -0.1107,  1.2126, -1.0937],\n",
      "         [-0.8313,  1.6666, -0.1858,  ...,  1.3449,  0.1141,  1.8689]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.1918, -0.1090, -0.4133,  ...,  0.4016, -0.9235,  0.2711],\n",
      "         [ 2.2221, -0.3002, -2.3054,  ..., -0.7427,  0.7918, -0.6694],\n",
      "         [ 1.0397, -0.9392, -1.3940,  ..., -0.0464, -0.6367, -0.2154]]],\n",
      "       device='cuda:0'), tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.1918, -0.1090, -0.4133,  ...,  0.4016, -0.9235,  0.2711],\n",
      "         [ 2.2221, -0.3002, -2.3054,  ..., -0.7427,  0.7918, -0.6694],\n",
      "         [ 1.0397, -0.9392, -1.3940,  ..., -0.0464, -0.6367, -0.2154]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 1.2361e+00,  2.7127e-01, -2.9321e-01,  ..., -2.0109e-01,\n",
      "          -1.2142e+00,  2.9986e-01],\n",
      "         [ 4.1158e-01,  1.8964e+00, -7.0630e-01,  ...,  1.5088e+00,\n",
      "           9.1370e-01,  3.0234e+00],\n",
      "         [-1.0257e+00,  2.7007e-01, -9.4374e-01,  ...,  1.1279e-01,\n",
      "           1.0029e+00,  2.2277e-01]]], device='cuda:0'), tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 1.2361e+00,  2.7127e-01, -2.9321e-01,  ..., -2.0109e-01,\n",
      "          -1.2142e+00,  2.9986e-01],\n",
      "         [ 4.1158e-01,  1.8964e+00, -7.0630e-01,  ...,  1.5088e+00,\n",
      "           9.1370e-01,  3.0234e+00],\n",
      "         [-1.0257e+00,  2.7007e-01, -9.4374e-01,  ...,  1.1279e-01,\n",
      "           1.0029e+00,  2.2277e-01]]], device='cuda:0')), 'logits_attn': (tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.9157,  3.2883,  6.2393,  ..., -2.3435, -8.6826, -3.4593],\n",
      "         [ 4.4844,  3.1707,  5.9270,  ..., -2.2997, -8.5747, -3.4462],\n",
      "         [ 4.9288,  3.0686,  6.0099,  ..., -2.1571, -8.4662, -3.3982]]],\n",
      "       device='cuda:0'), tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.9157,  3.2883,  6.2393,  ..., -2.3435, -8.6826, -3.4593],\n",
      "         [ 4.4844,  3.1707,  5.9270,  ..., -2.2997, -8.5747, -3.4462],\n",
      "         [ 4.9288,  3.0686,  6.0099,  ..., -2.1571, -8.4662, -3.3982]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.9737, -0.9533, -0.7005,  ...,  2.6301,  1.3627,  2.1500],\n",
      "         [-1.9101, -0.3774,  0.2660,  ...,  1.0798,  0.3464,  0.6601],\n",
      "         [-1.1914, -0.1770,  0.7906,  ..., -0.6219, -0.9922,  1.9965]]],\n",
      "       device='cuda:0'), tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [-0.9737, -0.9533, -0.7005,  ...,  2.6301,  1.3627,  2.1500],\n",
      "         [-1.9101, -0.3774,  0.2660,  ...,  1.0798,  0.3464,  0.6601],\n",
      "         [-1.1914, -0.1770,  0.7906,  ..., -0.6219, -0.9922,  1.9965]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5696, -8.7713,  4.8956,  ...,  5.2013,  2.4786,  3.4454],\n",
      "         [ 3.5674, -8.7711,  4.9043,  ...,  5.1916,  2.4832,  3.4414],\n",
      "         [ 3.5713, -8.7675,  4.9021,  ...,  5.1927,  2.4814,  3.4384]]],\n",
      "       device='cuda:0'), tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5696, -8.7713,  4.8956,  ...,  5.2013,  2.4786,  3.4454],\n",
      "         [ 3.5674, -8.7711,  4.9043,  ...,  5.1916,  2.4832,  3.4414],\n",
      "         [ 3.5713, -8.7675,  4.9021,  ...,  5.1927,  2.4814,  3.4384]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [-0.5963,  1.4429,  0.8033,  ...,  2.0888,  0.9127,  1.2689],\n",
      "         [ 0.4852,  1.2642,  0.1028,  ...,  1.4232,  0.0844,  0.4427],\n",
      "         [ 0.1696,  1.2740, -0.1099,  ...,  1.2081, -1.3492,  2.1223]]],\n",
      "       device='cuda:0'), tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [-0.5963,  1.4429,  0.8033,  ...,  2.0888,  0.9127,  1.2689],\n",
      "         [ 0.4852,  1.2642,  0.1028,  ...,  1.4232,  0.0844,  0.4427],\n",
      "         [ 0.1696,  1.2740, -0.1099,  ...,  1.2081, -1.3492,  2.1223]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0018, -0.0032, -0.0664,  ..., -0.0056,  0.0015, -0.0190],\n",
      "         [-0.0018, -0.0031, -0.0664,  ..., -0.0055,  0.0014, -0.0186],\n",
      "         [-0.0016, -0.0031, -0.0666,  ..., -0.0056,  0.0022, -0.0190]]],\n",
      "       device='cuda:0'), tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0018, -0.0032, -0.0664,  ..., -0.0056,  0.0015, -0.0190],\n",
      "         [-0.0018, -0.0031, -0.0664,  ..., -0.0055,  0.0014, -0.0186],\n",
      "         [-0.0016, -0.0031, -0.0666,  ..., -0.0056,  0.0022, -0.0190]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [ 1.4765,  1.5407, -0.8078,  ...,  1.6353,  0.9167,  0.4088],\n",
      "         [-1.3181,  2.1265, -0.0653,  ..., -0.9710, -1.4034,  1.0225],\n",
      "         [-2.1098,  1.9596,  0.2534,  ...,  0.9161,  0.4201,  0.6067]]],\n",
      "       device='cuda:0'), tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [ 1.4765,  1.5407, -0.8078,  ...,  1.6353,  0.9167,  0.4088],\n",
      "         [-1.3181,  2.1265, -0.0653,  ..., -0.9710, -1.4034,  1.0225],\n",
      "         [-2.1098,  1.9596,  0.2534,  ...,  0.9161,  0.4201,  0.6067]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 0.5831,  0.7958, -0.6173,  ..., -1.3838,  0.7814,  0.5308],\n",
      "         [ 0.7736, -3.2956, -1.3130,  ...,  0.6317,  2.5260,  3.2037],\n",
      "         [ 0.3303,  0.2669,  1.3327,  ...,  0.8656,  1.1784,  0.5901]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 0.5831,  0.7958, -0.6173,  ..., -1.3838,  0.7814,  0.5308],\n",
      "         [ 0.7736, -3.2956, -1.3130,  ...,  0.6317,  2.5260,  3.2037],\n",
      "         [ 0.3303,  0.2669,  1.3327,  ...,  0.8656,  1.1784,  0.5901]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [ 0.7767,  0.2366,  0.5306,  ..., -2.3949, -0.0992,  1.1654],\n",
      "         [ 0.7232,  1.9982,  0.9696,  ...,  1.3252, -0.4021,  1.5167],\n",
      "         [-0.7269,  0.8431, -1.1111,  ...,  0.6693,  0.2488,  2.5104]]],\n",
      "       device='cuda:0'), tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [ 0.7767,  0.2366,  0.5306,  ..., -2.3949, -0.0992,  1.1654],\n",
      "         [ 0.7232,  1.9982,  0.9696,  ...,  1.3252, -0.4021,  1.5167],\n",
      "         [-0.7269,  0.8431, -1.1111,  ...,  0.6693,  0.2488,  2.5104]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.7884, -1.7765,  0.0995,  ..., -0.3828,  2.7984,  1.6103],\n",
      "         [-5.2064, -1.8658,  0.0078,  ..., -0.3937,  2.4802,  1.7148],\n",
      "         [-4.6797, -1.7717,  0.1991,  ..., -0.2008,  2.8168,  1.7683]]],\n",
      "       device='cuda:0'), tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.7884, -1.7765,  0.0995,  ..., -0.3828,  2.7984,  1.6103],\n",
      "         [-5.2064, -1.8658,  0.0078,  ..., -0.3937,  2.4802,  1.7148],\n",
      "         [-4.6797, -1.7717,  0.1991,  ..., -0.2008,  2.8168,  1.7683]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [-0.0239,  1.5221,  0.9864,  ...,  0.1470, -1.0663,  1.3881],\n",
      "         [-0.6843,  0.8720,  0.7098,  ...,  1.4462, -1.2168,  0.9071],\n",
      "         [ 0.4122,  0.8185,  0.9597,  ...,  0.7288,  0.4999,  1.6032]]],\n",
      "       device='cuda:0'), tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [-0.0239,  1.5221,  0.9864,  ...,  0.1470, -1.0663,  1.3881],\n",
      "         [-0.6843,  0.8720,  0.7098,  ...,  1.4462, -1.2168,  0.9071],\n",
      "         [ 0.4122,  0.8185,  0.9597,  ...,  0.7288,  0.4999,  1.6032]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0284,  0.2535,  0.4679,  ..., -0.2959,  0.6984, -0.5542],\n",
      "         [ 0.0307,  0.2179,  0.4833,  ..., -0.2770,  0.6989, -0.5771],\n",
      "         [ 0.0180,  0.2002,  0.4409,  ..., -0.2966,  0.7093, -0.5922]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0284,  0.2535,  0.4679,  ..., -0.2959,  0.6984, -0.5542],\n",
      "         [ 0.0307,  0.2179,  0.4833,  ..., -0.2770,  0.6989, -0.5771],\n",
      "         [ 0.0180,  0.2002,  0.4409,  ..., -0.2966,  0.7093, -0.5922]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.2352,  0.3562,  1.5036,  ...,  0.0424,  1.2667, -0.5106],\n",
      "         [ 0.0572,  3.0647, -0.1772,  ...,  0.2784,  0.5546,  2.9528],\n",
      "         [-1.0444,  2.0261, -2.1195,  ...,  0.6494, -1.6710,  1.4687]]],\n",
      "       device='cuda:0'), tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [-0.2352,  0.3562,  1.5036,  ...,  0.0424,  1.2667, -0.5106],\n",
      "         [ 0.0572,  3.0647, -0.1772,  ...,  0.2784,  0.5546,  2.9528],\n",
      "         [-1.0444,  2.0261, -2.1195,  ...,  0.6494, -1.6710,  1.4687]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0560, -0.0348,  0.0771,  ...,  0.0525,  0.0779, -0.0217],\n",
      "         [-0.0592, -0.0304,  0.0798,  ...,  0.0535,  0.0795, -0.0163],\n",
      "         [-0.0591, -0.0326,  0.0772,  ...,  0.0529,  0.0742, -0.0166]]],\n",
      "       device='cuda:0'), tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0560, -0.0348,  0.0771,  ...,  0.0525,  0.0779, -0.0217],\n",
      "         [-0.0592, -0.0304,  0.0798,  ...,  0.0535,  0.0795, -0.0163],\n",
      "         [-0.0591, -0.0326,  0.0772,  ...,  0.0529,  0.0742, -0.0166]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [-1.1540,  1.5673, -0.7911,  ...,  1.6073,  0.0397,  0.3318],\n",
      "         [ 0.7535,  0.6608,  1.2803,  ...,  2.2767,  0.6672,  1.1241],\n",
      "         [ 0.8081, -0.0161,  0.4583,  ...,  1.8389, -0.9342,  3.2774]]],\n",
      "       device='cuda:0'), tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [-1.1540,  1.5673, -0.7911,  ...,  1.6073,  0.0397,  0.3318],\n",
      "         [ 0.7535,  0.6608,  1.2803,  ...,  2.2767,  0.6672,  1.1241],\n",
      "         [ 0.8081, -0.0161,  0.4583,  ...,  1.8389, -0.9342,  3.2774]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [ 1.3840, -0.0241,  0.4745,  ..., -0.1430, -0.0901, -2.1394],\n",
      "         [-1.1311, -1.3753, -2.0065,  ...,  1.5263,  0.7966, -1.5143],\n",
      "         [-1.7409,  0.9750,  1.3269,  ...,  0.9835,  1.3749,  0.2820]]],\n",
      "       device='cuda:0'), tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [ 1.3840, -0.0241,  0.4745,  ..., -0.1430, -0.0901, -2.1394],\n",
      "         [-1.1311, -1.3753, -2.0065,  ...,  1.5263,  0.7966, -1.5143],\n",
      "         [-1.7409,  0.9750,  1.3269,  ...,  0.9835,  1.3749,  0.2820]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [-0.3001,  1.9155, -2.0418,  ...,  2.2137, -1.1028, -0.1194],\n",
      "         [ 0.6053,  1.3175, -0.0512,  ..., -0.4911,  0.8156, -0.1335],\n",
      "         [ 0.5357,  0.4601, -1.1222,  ...,  1.3527, -0.7086, -0.4855]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [-0.3001,  1.9155, -2.0418,  ...,  2.2137, -1.1028, -0.1194],\n",
      "         [ 0.6053,  1.3175, -0.0512,  ..., -0.4911,  0.8156, -0.1335],\n",
      "         [ 0.5357,  0.4601, -1.1222,  ...,  1.3527, -0.7086, -0.4855]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.0736,  0.1736,  1.0034,  ...,  0.3056,  0.9036,  0.2638],\n",
      "         [ 0.8879,  0.0126,  0.9069,  ...,  0.1660, -0.0072,  0.3792],\n",
      "         [ 1.3548, -0.0552,  1.0198,  ...,  0.3026,  0.6408,  0.1888]]],\n",
      "       device='cuda:0'), tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 1.0736,  0.1736,  1.0034,  ...,  0.3056,  0.9036,  0.2638],\n",
      "         [ 0.8879,  0.0126,  0.9069,  ...,  0.1660, -0.0072,  0.3792],\n",
      "         [ 1.3548, -0.0552,  1.0198,  ...,  0.3026,  0.6408,  0.1888]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-0.1770,  0.6176, -0.6503,  ...,  0.5038, -0.2877,  0.0307],\n",
      "         [-1.0206,  0.5225, -1.7650,  ...,  0.0134, -0.0158,  0.9337],\n",
      "         [-0.1749,  1.7297,  0.2363,  ...,  1.0567,  1.2751,  1.6453]]],\n",
      "       device='cuda:0'), tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-0.1770,  0.6176, -0.6503,  ...,  0.5038, -0.2877,  0.0307],\n",
      "         [-1.0206,  0.5225, -1.7650,  ...,  0.0134, -0.0158,  0.9337],\n",
      "         [-0.1749,  1.7297,  0.2363,  ...,  1.0567,  1.2751,  1.6453]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4737,  5.3828,  1.9418,  ...,  4.7950, -1.5315, -0.6526],\n",
      "         [ 2.4719,  5.3815,  1.9453,  ...,  4.8460, -1.5289, -0.6202],\n",
      "         [ 2.4483,  5.4073,  1.9408,  ...,  4.8112, -1.4801, -0.6806]]],\n",
      "       device='cuda:0'), tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4737,  5.3828,  1.9418,  ...,  4.7950, -1.5315, -0.6526],\n",
      "         [ 2.4719,  5.3815,  1.9453,  ...,  4.8460, -1.5289, -0.6202],\n",
      "         [ 2.4483,  5.4073,  1.9408,  ...,  4.8112, -1.4801, -0.6806]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-0.4790,  1.1504,  0.9167,  ..., -0.5832, -1.5718,  2.6958],\n",
      "         [-1.2929,  0.4593, -1.2880,  ..., -0.4409, -1.0227,  0.6558],\n",
      "         [ 0.3903,  0.9347,  0.8688,  ...,  1.3010, -0.6061,  0.5883]]],\n",
      "       device='cuda:0'), tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [-0.4790,  1.1504,  0.9167,  ..., -0.5832, -1.5718,  2.6958],\n",
      "         [-1.2929,  0.4593, -1.2880,  ..., -0.4409, -1.0227,  0.6558],\n",
      "         [ 0.3903,  0.9347,  0.8688,  ...,  1.3010, -0.6061,  0.5883]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0258,  0.0635, -0.0213,  ..., -0.1149,  0.0331,  0.0245],\n",
      "         [-0.0225,  0.0639, -0.0196,  ..., -0.1153,  0.0313,  0.0271],\n",
      "         [-0.0246,  0.0649, -0.0182,  ..., -0.1110,  0.0339,  0.0246]]],\n",
      "       device='cuda:0'), tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0258,  0.0635, -0.0213,  ..., -0.1149,  0.0331,  0.0245],\n",
      "         [-0.0225,  0.0639, -0.0196,  ..., -0.1153,  0.0313,  0.0271],\n",
      "         [-0.0246,  0.0649, -0.0182,  ..., -0.1110,  0.0339,  0.0246]]],\n",
      "       device='cuda:0'))}]}]\n",
      "Step 400 - Last token probs (min/max): 0.0034814246464520693 / 0.050643984228372574\n",
      "Step 450 - past_kv structure:  [{'left': [{'chunk_attn': (tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [ 1.2898,  1.9110, -0.0279,  ...,  1.5050,  0.3840,  1.8858],\n",
      "         [-0.1440,  1.3608, -1.2307,  ...,  1.3647,  1.7840,  0.2779],\n",
      "         [ 0.5799,  2.4904, -1.2947,  ...,  0.8865, -1.3687,  1.7370]]],\n",
      "       device='cuda:0'), tensor([[[-0.6361,  0.4855,  0.3708,  ...,  0.7846, -0.0557,  0.7198],\n",
      "         [-0.1972,  0.3996,  0.0712,  ...,  1.2470, -0.5067, -0.0983],\n",
      "         [-1.0901,  2.2748, -0.7095,  ...,  2.3960, -0.9812,  0.5659],\n",
      "         ...,\n",
      "         [ 1.2898,  1.9110, -0.0279,  ...,  1.5050,  0.3840,  1.8858],\n",
      "         [-0.1440,  1.3608, -1.2307,  ...,  1.3647,  1.7840,  0.2779],\n",
      "         [ 0.5799,  2.4904, -1.2947,  ...,  0.8865, -1.3687,  1.7370]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'), tensor([[[-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         ...,\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032],\n",
      "         [-0.0027,  0.0153, -0.0014,  ..., -0.0046,  0.0085, -0.0032]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 0.8645,  2.5436,  1.0046,  ...,  1.8763,  0.4780,  1.4217],\n",
      "         [-0.2622, -0.1475, -1.7246,  ..., -0.0660,  1.4288, -0.0744],\n",
      "         [ 1.0545,  1.2617,  0.0324,  ...,  1.5720,  1.9306, -0.6108]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0243,  2.0534, -0.8064,  ...,  2.6180, -0.4801,  1.9816],\n",
      "         [ 0.2487,  0.8925, -1.2309,  ..., -0.0559,  0.5636,  0.5456],\n",
      "         [-0.1616,  0.6224,  0.6227,  ...,  0.2907,  0.4046,  0.8739],\n",
      "         ...,\n",
      "         [ 0.8645,  2.5436,  1.0046,  ...,  1.8763,  0.4780,  1.4217],\n",
      "         [-0.2622, -0.1475, -1.7246,  ..., -0.0660,  1.4288, -0.0744],\n",
      "         [ 1.0545,  1.2617,  0.0324,  ...,  1.5720,  1.9306, -0.6108]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9976, -0.5420, -7.4354,  ...,  5.7388,  1.3283, -0.4461],\n",
      "         [-5.0415, -0.4614, -7.3575,  ...,  5.6214,  1.3979, -0.4233],\n",
      "         [-5.0292, -0.4772, -7.3156,  ...,  5.7151,  1.2638, -0.3009]]],\n",
      "       device='cuda:0'), tensor([[[-4.8931, -0.5280, -7.2936,  ...,  5.6929,  1.1710, -0.1467],\n",
      "         [-4.9494, -0.3718, -7.2210,  ...,  5.6097,  1.3153, -0.2333],\n",
      "         [-5.0018, -0.2959, -7.1863,  ...,  5.6351,  1.3591, -0.3275],\n",
      "         ...,\n",
      "         [-4.9976, -0.5420, -7.4354,  ...,  5.7388,  1.3283, -0.4461],\n",
      "         [-5.0415, -0.4614, -7.3575,  ...,  5.6214,  1.3979, -0.4233],\n",
      "         [-5.0292, -0.4772, -7.3156,  ...,  5.7151,  1.2638, -0.3009]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [-0.1727, -0.3403, -1.0261,  ..., -0.2174, -0.2887,  0.7044],\n",
      "         [-0.8267,  0.9147,  1.4161,  ...,  0.0450,  0.2970,  0.4869],\n",
      "         [ 1.0561,  1.8096,  0.2131,  ...,  1.4589, -1.6618, -0.4102]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8325,  1.5375,  0.7259,  ...,  3.0293, -0.8670,  0.8542],\n",
      "         [ 0.3880,  3.1295,  2.2919,  ..., -0.3064, -1.4812,  1.6010],\n",
      "         [-0.9402,  0.2860,  0.4148,  ...,  0.7519,  0.1652,  1.2890],\n",
      "         ...,\n",
      "         [-0.1727, -0.3403, -1.0261,  ..., -0.2174, -0.2887,  0.7044],\n",
      "         [-0.8267,  0.9147,  1.4161,  ...,  0.0450,  0.2970,  0.4869],\n",
      "         [ 1.0561,  1.8096,  0.2131,  ...,  1.4589, -1.6618, -0.4102]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0454,  1.9555,  1.9755,  ...,  1.4775,  1.3020, -2.7926],\n",
      "         [ 3.0456,  1.9548,  1.9760,  ...,  1.4780,  1.3021, -2.7920],\n",
      "         [ 3.0443,  1.9551,  1.9741,  ...,  1.4778,  1.3022, -2.7919]]],\n",
      "       device='cuda:0'), tensor([[[ 3.0473,  1.9546,  1.9754,  ...,  1.4802,  1.3010, -2.7926],\n",
      "         [ 3.0468,  1.9524,  1.9752,  ...,  1.4791,  1.2997, -2.7930],\n",
      "         [ 3.0475,  1.9537,  1.9771,  ...,  1.4778,  1.3010, -2.7932],\n",
      "         ...,\n",
      "         [ 3.0454,  1.9555,  1.9755,  ...,  1.4775,  1.3020, -2.7926],\n",
      "         [ 3.0456,  1.9548,  1.9760,  ...,  1.4780,  1.3021, -2.7920],\n",
      "         [ 3.0443,  1.9551,  1.9741,  ...,  1.4778,  1.3022, -2.7919]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 1.9793,  0.4847, -0.2682,  ...,  3.5250, -0.9126,  1.5184],\n",
      "         [ 0.6480, -0.0251, -1.2201,  ...,  1.7335, -0.1206,  1.2548],\n",
      "         [-0.2839,  1.2789,  0.1985,  ...,  1.5440, -1.0461, -0.7816]]],\n",
      "       device='cuda:0'), tensor([[[ 0.8195,  1.3209,  0.7151,  ...,  2.2511,  0.2626,  0.9282],\n",
      "         [ 0.5799,  0.7761, -1.2045,  ...,  0.7338, -0.3493,  2.3397],\n",
      "         [-0.0339, -0.5816,  1.7037,  ...,  1.0607,  1.0789,  1.6876],\n",
      "         ...,\n",
      "         [ 1.9793,  0.4847, -0.2682,  ...,  3.5250, -0.9126,  1.5184],\n",
      "         [ 0.6480, -0.0251, -1.2201,  ...,  1.7335, -0.1206,  1.2548],\n",
      "         [-0.2839,  1.2789,  0.1985,  ...,  1.5440, -1.0461, -0.7816]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0038,  0.0251,  0.0051,  ..., -0.0881, -0.0709,  0.0013],\n",
      "         [-0.0038,  0.0233,  0.0070,  ..., -0.0844, -0.0703,  0.0002],\n",
      "         [-0.0028,  0.0242,  0.0065,  ..., -0.0834, -0.0676,  0.0001]]],\n",
      "       device='cuda:0'), tensor([[[-0.0035,  0.0268, -0.0001,  ..., -0.0825, -0.0622,  0.0036],\n",
      "         [-0.0026,  0.0222,  0.0052,  ..., -0.0836, -0.0693, -0.0014],\n",
      "         [-0.0027,  0.0220,  0.0038,  ..., -0.0840, -0.0694, -0.0002],\n",
      "         ...,\n",
      "         [-0.0038,  0.0251,  0.0051,  ..., -0.0881, -0.0709,  0.0013],\n",
      "         [-0.0038,  0.0233,  0.0070,  ..., -0.0844, -0.0703,  0.0002],\n",
      "         [-0.0028,  0.0242,  0.0065,  ..., -0.0834, -0.0676,  0.0001]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [-1.2934, -0.4429,  3.2736,  ...,  0.6882,  0.0927, -0.5864],\n",
      "         [ 0.2545,  2.2281, -2.6658,  ...,  0.0616,  0.0962,  1.1752],\n",
      "         [-1.0755,  1.4780, -1.5348,  ..., -0.1507, -0.4869,  0.8247]]],\n",
      "       device='cuda:0'), tensor([[[ 0.1460,  1.7228,  0.2417,  ..., -0.1728,  0.1326,  1.4044],\n",
      "         [-0.0528,  1.3068,  0.1415,  ..., -0.9699, -0.6946,  2.0941],\n",
      "         [ 0.8952,  2.0475, -0.2403,  ...,  0.4935,  0.1000,  0.6095],\n",
      "         ...,\n",
      "         [-1.2934, -0.4429,  3.2736,  ...,  0.6882,  0.0927, -0.5864],\n",
      "         [ 0.2545,  2.2281, -2.6658,  ...,  0.0616,  0.0962,  1.1752],\n",
      "         [-1.0755,  1.4780, -1.5348,  ..., -0.1507, -0.4869,  0.8247]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'), tensor([[[-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         ...,\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123],\n",
      "         [-0.0164, -0.0064,  0.0047,  ...,  0.0078,  0.0073,  0.0123]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [-1.0484,  2.7465, -0.4895,  ...,  1.4745,  1.0340, -0.0806],\n",
      "         [ 2.3329, -0.0607,  0.5422,  ...,  1.8671, -0.0938,  0.2465],\n",
      "         [-1.7623,  0.9189,  0.4845,  ...,  0.5543,  0.5667, -0.4700]]],\n",
      "       device='cuda:0'), tensor([[[ 1.1683,  0.8531, -1.3954,  ...,  2.6033, -0.2046,  0.7255],\n",
      "         [ 0.1541,  1.2670, -1.5308,  ...,  0.1445,  1.4119,  0.0732],\n",
      "         [-0.1980,  0.4939,  0.2526,  ..., -0.7632,  0.4051,  2.3945],\n",
      "         ...,\n",
      "         [-1.0484,  2.7465, -0.4895,  ...,  1.4745,  1.0340, -0.0806],\n",
      "         [ 2.3329, -0.0607,  0.5422,  ...,  1.8671, -0.0938,  0.2465],\n",
      "         [-1.7623,  0.9189,  0.4845,  ...,  0.5543,  0.5667, -0.4700]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-1.0404, -0.4277, -0.4113,  ...,  1.1649, -0.4352,  0.0420],\n",
      "         [-0.6477, -0.2873, -0.1052,  ...,  1.1915, -0.5305, -0.0767],\n",
      "         [-0.8269, -0.1777, -0.0657,  ...,  1.0915, -0.6132,  0.1106]]],\n",
      "       device='cuda:0'), tensor([[[-0.8107, -0.2222, -0.2941,  ...,  1.1342, -0.4775,  0.1517],\n",
      "         [-0.5933, -0.3124, -0.1166,  ...,  1.3404, -0.4325,  0.0863],\n",
      "         [-0.4345, -0.2005, -0.0055,  ...,  1.3070, -0.3104,  0.0978],\n",
      "         ...,\n",
      "         [-1.0404, -0.4277, -0.4113,  ...,  1.1649, -0.4352,  0.0420],\n",
      "         [-0.6477, -0.2873, -0.1052,  ...,  1.1915, -0.5305, -0.0767],\n",
      "         [-0.8269, -0.1777, -0.0657,  ...,  1.0915, -0.6132,  0.1106]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [ 0.1894,  0.9547, -0.0754,  ..., -0.6874,  0.4977,  2.7972],\n",
      "         [ 1.2259,  1.6038,  0.9913,  ...,  0.4190,  0.0274,  0.9668],\n",
      "         [-1.2537,  1.6096, -1.0336,  ..., -0.4021,  0.2232,  0.9262]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6658,  1.0759, -0.0976,  ..., -1.1394, -1.1927,  1.3016],\n",
      "         [-0.5403, -0.0500,  1.2202,  ...,  0.4265, -0.8876,  2.4037],\n",
      "         [-0.3360,  1.1818,  0.7108,  ...,  0.0520, -1.1002,  0.3816],\n",
      "         ...,\n",
      "         [ 0.1894,  0.9547, -0.0754,  ..., -0.6874,  0.4977,  2.7972],\n",
      "         [ 1.2259,  1.6038,  0.9913,  ...,  0.4190,  0.0274,  0.9668],\n",
      "         [-1.2537,  1.6096, -1.0336,  ..., -0.4021,  0.2232,  0.9262]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3229,  0.4026,  0.0358,  ..., -0.4914,  0.5559, -0.2145],\n",
      "         [ 0.3411,  0.4074,  0.0455,  ..., -0.4894,  0.5584, -0.2173],\n",
      "         [ 0.3444,  0.4036,  0.0349,  ..., -0.4810,  0.5623, -0.2326]]],\n",
      "       device='cuda:0'), tensor([[[ 0.3411,  0.4060,  0.0124,  ..., -0.4821,  0.5623, -0.2049],\n",
      "         [ 0.3252,  0.3970,  0.0187,  ..., -0.4979,  0.5569, -0.2195],\n",
      "         [ 0.3242,  0.3973,  0.0270,  ..., -0.4805,  0.5618, -0.2263],\n",
      "         ...,\n",
      "         [ 0.3229,  0.4026,  0.0358,  ..., -0.4914,  0.5559, -0.2145],\n",
      "         [ 0.3411,  0.4074,  0.0455,  ..., -0.4894,  0.5584, -0.2173],\n",
      "         [ 0.3444,  0.4036,  0.0349,  ..., -0.4810,  0.5623, -0.2326]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [ 0.0669,  0.5473, -0.8196,  ...,  0.4914, -0.8060,  1.1954],\n",
      "         [-0.4304,  2.9625,  1.3611,  ...,  1.7646, -1.1608, -0.2422],\n",
      "         [-0.8871,  1.4789,  0.6720,  ...,  0.4127,  0.0200, -0.2464]]],\n",
      "       device='cuda:0'), tensor([[[-0.5540,  2.4514,  0.8843,  ...,  2.1293,  0.3014,  0.8232],\n",
      "         [-0.0785,  2.4423, -0.1810,  ..., -0.1670, -0.7705,  1.2228],\n",
      "         [ 0.3291,  1.4006, -0.3232,  ...,  0.9387,  0.5775,  2.8456],\n",
      "         ...,\n",
      "         [ 0.0669,  0.5473, -0.8196,  ...,  0.4914, -0.8060,  1.1954],\n",
      "         [-0.4304,  2.9625,  1.3611,  ...,  1.7646, -1.1608, -0.2422],\n",
      "         [-0.8871,  1.4789,  0.6720,  ...,  0.4127,  0.0200, -0.2464]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0753,  0.1042, -0.0199,  ..., -0.1515, -0.0240, -0.0489],\n",
      "         [ 0.0805,  0.0898, -0.0262,  ..., -0.1161, -0.0084, -0.0285],\n",
      "         [ 0.0559,  0.1037, -0.0380,  ..., -0.1102, -0.0256, -0.0496]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0583,  0.1043, -0.0300,  ..., -0.1326, -0.0061, -0.0364],\n",
      "         [ 0.0668,  0.1136, -0.0104,  ..., -0.1351,  0.0061, -0.0320],\n",
      "         [ 0.0713,  0.1019, -0.0201,  ..., -0.1262, -0.0069, -0.0350],\n",
      "         ...,\n",
      "         [ 0.0753,  0.1042, -0.0199,  ..., -0.1515, -0.0240, -0.0489],\n",
      "         [ 0.0805,  0.0898, -0.0262,  ..., -0.1161, -0.0084, -0.0285],\n",
      "         [ 0.0559,  0.1037, -0.0380,  ..., -0.1102, -0.0256, -0.0496]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [ 1.3316,  0.7788, -1.3758,  ...,  2.7064,  0.6904,  1.2666],\n",
      "         [ 1.4200,  0.8690, -0.8040,  ...,  1.0255, -0.1160,  0.8849],\n",
      "         [ 2.4575,  2.3375, -0.6771,  ...,  1.1355,  0.4064,  0.7836]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7710,  0.9938,  1.0574,  ...,  2.0273,  1.7085,  0.2060],\n",
      "         [ 1.1709,  1.3288, -0.2510,  ..., -0.1314,  0.7436,  0.3891],\n",
      "         [-0.4771,  1.5458,  0.5861,  ...,  2.2465, -0.0124,  2.5237],\n",
      "         ...,\n",
      "         [ 1.3316,  0.7788, -1.3758,  ...,  2.7064,  0.6904,  1.2666],\n",
      "         [ 1.4200,  0.8690, -0.8040,  ...,  1.0255, -0.1160,  0.8849],\n",
      "         [ 2.4575,  2.3375, -0.6771,  ...,  1.1355,  0.4064,  0.7836]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [-0.6608, -0.3102,  0.5179,  ...,  0.0526,  0.3276, -0.5451],\n",
      "         [-3.2924, -0.5401,  0.3260,  ...,  0.4195, -0.5048,  0.0239],\n",
      "         [-0.4995,  1.5795,  1.3454,  ..., -0.5394, -0.2149,  0.1003]]],\n",
      "       device='cuda:0'), tensor([[[-0.2522, -1.2992,  0.5814,  ..., -0.0523, -0.4452, -0.2092],\n",
      "         [ 1.5243, -0.1635,  1.8334,  ...,  0.4173,  0.0777, -0.8325],\n",
      "         [ 0.4391, -0.6839,  0.6999,  ...,  0.1143, -0.7367, -0.4244],\n",
      "         ...,\n",
      "         [-0.6608, -0.3102,  0.5179,  ...,  0.0526,  0.3276, -0.5451],\n",
      "         [-3.2924, -0.5401,  0.3260,  ...,  0.4195, -0.5048,  0.0239],\n",
      "         [-0.4995,  1.5795,  1.3454,  ..., -0.5394, -0.2149,  0.1003]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-0.3884,  1.2319,  0.7947,  ...,  0.0521,  0.3012,  1.8746],\n",
      "         [-0.1280,  0.4253, -0.9187,  ...,  2.5205, -1.4556,  1.2038],\n",
      "         [-0.5469, -0.1626, -0.8403,  ...,  1.3182, -0.6643,  0.6437]]],\n",
      "       device='cuda:0'), tensor([[[-2.4192,  1.0905, -0.5085,  ...,  0.8400, -0.1821,  2.0812],\n",
      "         [-0.6452,  0.8225,  1.0223,  ...,  0.7551,  0.9008,  3.1291],\n",
      "         [-0.3225,  0.4120, -0.6051,  ..., -1.0598,  1.2715,  1.2095],\n",
      "         ...,\n",
      "         [-0.3884,  1.2319,  0.7947,  ...,  0.0521,  0.3012,  1.8746],\n",
      "         [-0.1280,  0.4253, -0.9187,  ...,  2.5205, -1.4556,  1.2038],\n",
      "         [-0.5469, -0.1626, -0.8403,  ...,  1.3182, -0.6643,  0.6437]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.3385, -0.1342,  0.3691,  ..., -1.6907, -1.4633,  0.6434],\n",
      "         [-3.0531, -0.3300,  0.6062,  ..., -2.3349, -1.0704,  0.6884],\n",
      "         [-2.1697,  0.0471,  0.4745,  ..., -1.9553, -1.2686,  0.7181]]],\n",
      "       device='cuda:0'), tensor([[[-3.5511,  0.1914,  0.3149,  ..., -1.5030, -1.3760,  0.1077],\n",
      "         [-3.5712, -0.4319,  0.9743,  ..., -2.1698, -1.1774,  0.4663],\n",
      "         [-3.1798, -0.4072,  0.0854,  ..., -1.5176, -1.5193,  0.4972],\n",
      "         ...,\n",
      "         [-3.3385, -0.1342,  0.3691,  ..., -1.6907, -1.4633,  0.6434],\n",
      "         [-3.0531, -0.3300,  0.6062,  ..., -2.3349, -1.0704,  0.6884],\n",
      "         [-2.1697,  0.0471,  0.4745,  ..., -1.9553, -1.2686,  0.7181]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 0.5096,  0.4838,  1.4894,  ...,  0.2792,  1.8839,  1.1801],\n",
      "         [-1.8582,  0.5703,  0.1547,  ...,  2.7442, -0.1652,  0.2114],\n",
      "         [-1.6709,  0.5701,  0.9233,  ...,  0.6416, -1.4897, -0.0578]]],\n",
      "       device='cuda:0'), tensor([[[ 2.1112,  0.9028, -1.2015,  ...,  0.9611,  0.0466,  1.4234],\n",
      "         [-0.9331,  1.2371, -0.7564,  ...,  3.3070, -1.1184,  0.4933],\n",
      "         [-2.0874,  1.4407,  0.4648,  ...,  1.2333, -0.0536,  0.2381],\n",
      "         ...,\n",
      "         [ 0.5096,  0.4838,  1.4894,  ...,  0.2792,  1.8839,  1.1801],\n",
      "         [-1.8582,  0.5703,  0.1547,  ...,  2.7442, -0.1652,  0.2114],\n",
      "         [-1.6709,  0.5701,  0.9233,  ...,  0.6416, -1.4897, -0.0578]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.5058,  5.1348, -0.0161,  ...,  0.0992, -0.6944,  2.8932],\n",
      "         [ 0.6091,  5.1325, -0.0107,  ...,  0.0829, -0.7533,  2.7019],\n",
      "         [ 0.5263,  5.1282,  0.0465,  ...,  0.0910, -0.7894,  2.8206]]],\n",
      "       device='cuda:0'), tensor([[[ 0.5841,  5.1617, -0.0935,  ...,  0.0998, -0.7355,  2.7650],\n",
      "         [ 0.5544,  5.1754, -0.0308,  ...,  0.1131, -0.6912,  2.8477],\n",
      "         [ 0.5730,  5.1981, -0.0898,  ...,  0.1103, -0.7314,  2.8310],\n",
      "         ...,\n",
      "         [ 0.5058,  5.1348, -0.0161,  ...,  0.0992, -0.6944,  2.8932],\n",
      "         [ 0.6091,  5.1325, -0.0107,  ...,  0.0829, -0.7533,  2.7019],\n",
      "         [ 0.5263,  5.1282,  0.0465,  ...,  0.0910, -0.7894,  2.8206]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [-0.7160,  3.8465,  0.7879,  ..., -1.1686, -0.8700,  2.5496],\n",
      "         [-3.2298, -0.2067,  1.7569,  ...,  1.4097, -1.2326, -0.4121],\n",
      "         [ 0.9235,  1.1354,  0.0650,  ...,  1.3467, -0.2348,  2.3133]]],\n",
      "       device='cuda:0'), tensor([[[ 1.5198,  0.4424, -0.6864,  ...,  2.1328, -1.6051,  1.5650],\n",
      "         [ 2.0344,  0.1582, -0.8161,  ...,  1.7728,  0.9144,  0.1715],\n",
      "         [ 0.6581,  1.6338, -0.7756,  ...,  2.6931,  0.1812,  1.0394],\n",
      "         ...,\n",
      "         [-0.7160,  3.8465,  0.7879,  ..., -1.1686, -0.8700,  2.5496],\n",
      "         [-3.2298, -0.2067,  1.7569,  ...,  1.4097, -1.2326, -0.4121],\n",
      "         [ 0.9235,  1.1354,  0.0650,  ...,  1.3467, -0.2348,  2.3133]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0760, -0.0397,  0.0608,  ..., -0.0260, -0.0839, -0.0926],\n",
      "         [ 0.0768, -0.0384,  0.0571,  ..., -0.0269, -0.0813, -0.0901],\n",
      "         [ 0.0770, -0.0392,  0.0571,  ..., -0.0246, -0.0815, -0.0910]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0754, -0.0394,  0.0585,  ..., -0.0274, -0.0829, -0.0923],\n",
      "         [ 0.0766, -0.0384,  0.0577,  ..., -0.0255, -0.0810, -0.0909],\n",
      "         [ 0.0758, -0.0410,  0.0583,  ..., -0.0245, -0.0818, -0.0901],\n",
      "         ...,\n",
      "         [ 0.0760, -0.0397,  0.0608,  ..., -0.0260, -0.0839, -0.0926],\n",
      "         [ 0.0768, -0.0384,  0.0571,  ..., -0.0269, -0.0813, -0.0901],\n",
      "         [ 0.0770, -0.0392,  0.0571,  ..., -0.0246, -0.0815, -0.0910]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [ 1.4324,  1.6685, -0.7322,  ...,  0.1731,  2.0689,  0.6954],\n",
      "         [-1.8030,  1.4896,  1.9251,  ...,  1.2144, -0.6010, -0.0389],\n",
      "         [-0.4833,  2.1057,  1.3372,  ...,  2.8999,  0.5165,  1.3484]]],\n",
      "       device='cuda:0'), tensor([[[-0.1422, -0.0210, -1.0450,  ...,  2.0811,  0.0681,  0.2296],\n",
      "         [ 1.4566,  4.3323, -0.2290,  ...,  1.0640,  1.3493,  0.0809],\n",
      "         [-1.1485,  2.0652, -1.5992,  ...,  0.6307,  1.5584,  1.6801],\n",
      "         ...,\n",
      "         [ 1.4324,  1.6685, -0.7322,  ...,  0.1731,  2.0689,  0.6954],\n",
      "         [-1.8030,  1.4896,  1.9251,  ...,  1.2144, -0.6010, -0.0389],\n",
      "         [-0.4833,  2.1057,  1.3372,  ...,  2.8999,  0.5165,  1.3484]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [ 0.6370,  0.2713, -0.1925,  ...,  0.4423,  0.6241,  0.6862],\n",
      "         [-2.3613,  1.3434,  1.7487,  ...,  1.0830,  1.6237,  1.5397],\n",
      "         [-0.2182,  1.1373,  1.5306,  ...,  0.6852, -0.2837,  1.1402]]],\n",
      "       device='cuda:0'), tensor([[[-0.5403,  0.3030, -0.2789,  ..., -0.1835,  0.7093, -0.9058],\n",
      "         [-1.2190,  0.1231, -0.5167,  ...,  0.4690, -1.7459, -1.2351],\n",
      "         [-0.6482,  0.0870,  0.2381,  ...,  0.5889, -0.3301,  0.4772],\n",
      "         ...,\n",
      "         [ 0.6370,  0.2713, -0.1925,  ...,  0.4423,  0.6241,  0.6862],\n",
      "         [-2.3613,  1.3434,  1.7487,  ...,  1.0830,  1.6237,  1.5397],\n",
      "         [-0.2182,  1.1373,  1.5306,  ...,  0.6852, -0.2837,  1.1402]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.0745,  1.6137,  0.2186,  ...,  0.8878, -1.3567,  0.9721],\n",
      "         [ 0.6321,  0.7794,  0.0195,  ...,  1.8420,  1.4357,  0.1071],\n",
      "         [ 1.3789,  0.6309, -0.4613,  ..., -0.6799, -0.0250,  1.4950]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4077,  0.6991, -2.6321,  ..., -0.8423,  1.1894,  0.8372],\n",
      "         [-0.2327,  1.3467, -0.8483,  ...,  1.4609, -1.5798,  1.7544],\n",
      "         [ 0.1732,  0.2476, -1.5126,  ...,  2.0716,  0.4121,  1.1224],\n",
      "         ...,\n",
      "         [ 0.0745,  1.6137,  0.2186,  ...,  0.8878, -1.3567,  0.9721],\n",
      "         [ 0.6321,  0.7794,  0.0195,  ...,  1.8420,  1.4357,  0.1071],\n",
      "         [ 1.3789,  0.6309, -0.4613,  ..., -0.6799, -0.0250,  1.4950]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.1118,  0.4078, -3.4845,  ...,  1.5072, -2.9775, -1.4306],\n",
      "         [-1.6048,  0.8114, -4.1110,  ...,  1.6340, -3.2484, -1.4551],\n",
      "         [-1.3780,  0.5717, -3.8582,  ...,  1.7174, -2.7530, -1.0279]]],\n",
      "       device='cuda:0'), tensor([[[-1.3785, -0.0176, -3.6313,  ...,  1.1910, -3.3981, -2.0164],\n",
      "         [-1.5108,  0.2861, -4.0453,  ...,  1.3422, -3.4731, -1.8379],\n",
      "         [-1.4220,  0.4647, -4.0031,  ...,  0.9800, -3.1647, -1.7552],\n",
      "         ...,\n",
      "         [-1.1118,  0.4078, -3.4845,  ...,  1.5072, -2.9775, -1.4306],\n",
      "         [-1.6048,  0.8114, -4.1110,  ...,  1.6340, -3.2484, -1.4551],\n",
      "         [-1.3780,  0.5717, -3.8582,  ...,  1.7174, -2.7530, -1.0279]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-0.0032,  1.2579, -0.5816,  ...,  1.4900,  0.3716,  3.0012],\n",
      "         [-2.0949,  1.6925,  0.4605,  ...,  1.1904,  0.5169,  0.8974],\n",
      "         [-0.7710,  0.2998,  1.0800,  ..., -0.8646,  0.3998,  1.1173]]],\n",
      "       device='cuda:0'), tensor([[[-0.8476,  0.5813, -0.0441,  ...,  1.0679,  0.4480, -0.5635],\n",
      "         [ 0.3292, -0.0545, -1.2339,  ...,  1.1199,  1.5667,  1.0122],\n",
      "         [-0.2003,  0.9506, -0.4743,  ...,  0.7973,  0.9845,  1.2852],\n",
      "         ...,\n",
      "         [-0.0032,  1.2579, -0.5816,  ...,  1.4900,  0.3716,  3.0012],\n",
      "         [-2.0949,  1.6925,  0.4605,  ...,  1.1904,  0.5169,  0.8974],\n",
      "         [-0.7710,  0.2998,  1.0800,  ..., -0.8646,  0.3998,  1.1173]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2849, -0.5205, -0.6509,  ...,  0.4873, -2.5362,  0.8387],\n",
      "         [-1.3113, -0.5013, -0.6983,  ...,  0.5062, -2.5664,  0.7625],\n",
      "         [-1.3010, -0.5040, -0.6756,  ...,  0.4957, -2.6027,  0.8063]]],\n",
      "       device='cuda:0'), tensor([[[-1.3001, -0.4983, -0.6822,  ...,  0.4925, -2.6105,  0.8199],\n",
      "         [-1.3003, -0.5003, -0.6770,  ...,  0.4917, -2.5991,  0.8376],\n",
      "         [-1.2848, -0.4893, -0.6754,  ...,  0.5051, -2.5905,  0.8472],\n",
      "         ...,\n",
      "         [-1.2849, -0.5205, -0.6509,  ...,  0.4873, -2.5362,  0.8387],\n",
      "         [-1.3113, -0.5013, -0.6983,  ...,  0.5062, -2.5664,  0.7625],\n",
      "         [-1.3010, -0.5040, -0.6756,  ...,  0.4957, -2.6027,  0.8063]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [ 0.3535,  1.1444,  1.3854,  ...,  0.7421,  0.3187, -0.7996],\n",
      "         [ 0.2894,  1.9558, -0.3633,  ...,  0.7899, -0.0129,  2.3905],\n",
      "         [-0.1342,  0.3811,  1.0342,  ..., -0.1333,  0.1629,  0.3301]]],\n",
      "       device='cuda:0'), tensor([[[-2.4001,  2.3320,  0.0455,  ...,  0.8821,  0.4289,  0.2377],\n",
      "         [-0.7994,  0.7895, -0.4351,  ...,  0.1428,  1.0759,  3.4976],\n",
      "         [-0.2090,  1.1213,  1.5170,  ...,  2.6309, -0.8229,  0.7390],\n",
      "         ...,\n",
      "         [ 0.3535,  1.1444,  1.3854,  ...,  0.7421,  0.3187, -0.7996],\n",
      "         [ 0.2894,  1.9558, -0.3633,  ...,  0.7899, -0.0129,  2.3905],\n",
      "         [-0.1342,  0.3811,  1.0342,  ..., -0.1333,  0.1629,  0.3301]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0129,  0.1122,  0.0394,  ...,  0.0702, -0.0262, -0.0378],\n",
      "         [ 0.0223,  0.1122,  0.0315,  ...,  0.0720, -0.0240, -0.0376],\n",
      "         [ 0.0175,  0.1148,  0.0353,  ...,  0.0761, -0.0270, -0.0362]]],\n",
      "       device='cuda:0'), tensor([[[-0.0174,  0.0709,  0.0163,  ...,  0.0741, -0.0379, -0.0222],\n",
      "         [-0.0099,  0.0713,  0.0151,  ...,  0.0744, -0.0374, -0.0274],\n",
      "         [-0.0071,  0.0723,  0.0194,  ...,  0.0791, -0.0338, -0.0291],\n",
      "         ...,\n",
      "         [ 0.0129,  0.1122,  0.0394,  ...,  0.0702, -0.0262, -0.0378],\n",
      "         [ 0.0223,  0.1122,  0.0315,  ...,  0.0720, -0.0240, -0.0376],\n",
      "         [ 0.0175,  0.1148,  0.0353,  ...,  0.0761, -0.0270, -0.0362]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 0.3702,  0.2568, -1.4180,  ...,  1.1904, -1.3964, -0.0241],\n",
      "         [ 1.0556,  2.1799,  0.3991,  ...,  1.2414,  2.1555,  0.3486],\n",
      "         [-1.2266,  1.0597,  0.1838,  ...,  0.6385, -1.3815,  0.2021]]],\n",
      "       device='cuda:0'), tensor([[[-0.5809,  2.5019,  0.6886,  ...,  1.1512, -1.1344,  0.9194],\n",
      "         [ 1.1011,  1.0689,  0.0571,  ...,  1.6702,  0.4723,  0.6873],\n",
      "         [-0.1870,  1.0290,  0.2585,  ...,  1.8544, -0.0493,  1.0144],\n",
      "         ...,\n",
      "         [ 0.3702,  0.2568, -1.4180,  ...,  1.1904, -1.3964, -0.0241],\n",
      "         [ 1.0556,  2.1799,  0.3991,  ...,  1.2414,  2.1555,  0.3486],\n",
      "         [-1.2266,  1.0597,  0.1838,  ...,  0.6385, -1.3815,  0.2021]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [ 0.1387, -1.2465, -0.5168,  ...,  2.1292, -0.3284, -0.9832],\n",
      "         [ 0.5365, -1.5800,  0.9199,  ...,  0.3384, -0.4365, -0.1383],\n",
      "         [ 0.1213,  0.3447, -0.1893,  ...,  1.1041, -1.3449, -1.5621]]],\n",
      "       device='cuda:0'), tensor([[[ 1.0764,  0.0739,  1.1559,  ...,  0.4342,  1.6110,  1.4122],\n",
      "         [ 1.2295, -0.9280,  1.1441,  ...,  0.2810, -0.8686,  0.2154],\n",
      "         [ 0.1696,  0.1622,  0.4998,  ...,  0.8564, -0.4615, -0.0671],\n",
      "         ...,\n",
      "         [ 0.1387, -1.2465, -0.5168,  ...,  2.1292, -0.3284, -0.9832],\n",
      "         [ 0.5365, -1.5800,  0.9199,  ...,  0.3384, -0.4365, -0.1383],\n",
      "         [ 0.1213,  0.3447, -0.1893,  ...,  1.1041, -1.3449, -1.5621]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [ 0.0570,  0.6126,  0.1707,  ...,  1.7522,  0.3045,  1.8772],\n",
      "         [ 0.0457,  0.6516, -1.4264,  ...,  0.8069, -0.3008, -0.3317],\n",
      "         [ 1.3798,  1.4219,  0.0559,  ...,  0.1761, -1.0280,  1.9743]]],\n",
      "       device='cuda:0'), tensor([[[ 2.7588,  0.0038,  0.3105,  ...,  1.3646,  0.5672,  2.0301],\n",
      "         [ 0.0125,  2.4895, -0.3322,  ..., -0.0655,  0.9054,  1.8324],\n",
      "         [ 1.1056,  0.3338, -0.3151,  ...,  1.7395,  0.2954,  3.7175],\n",
      "         ...,\n",
      "         [ 0.0570,  0.6126,  0.1707,  ...,  1.7522,  0.3045,  1.8772],\n",
      "         [ 0.0457,  0.6516, -1.4264,  ...,  0.8069, -0.3008, -0.3317],\n",
      "         [ 1.3798,  1.4219,  0.0559,  ...,  0.1761, -1.0280,  1.9743]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.3197, -1.1841,  1.7338,  ..., -3.1231,  1.0848, -0.3565],\n",
      "         [-2.3830, -0.8830,  1.3394,  ..., -2.8359,  1.0685, -0.4962],\n",
      "         [-1.8968, -0.6853,  1.8823,  ..., -2.7241,  0.4882, -1.0027]]],\n",
      "       device='cuda:0'), tensor([[[-2.4902, -0.9937,  1.9573,  ..., -2.7523,  0.5804, -0.8715],\n",
      "         [-2.2348, -0.9858,  1.9234,  ..., -3.1398,  0.7369, -0.4820],\n",
      "         [-2.0144, -0.6459,  1.5353,  ..., -2.6814,  0.5319, -0.6885],\n",
      "         ...,\n",
      "         [-2.3197, -1.1841,  1.7338,  ..., -3.1231,  1.0848, -0.3565],\n",
      "         [-2.3830, -0.8830,  1.3394,  ..., -2.8359,  1.0685, -0.4962],\n",
      "         [-1.8968, -0.6853,  1.8823,  ..., -2.7241,  0.4882, -1.0027]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [-1.0123,  0.1195,  0.6284,  ...,  1.3144,  0.8235,  1.3416],\n",
      "         [ 0.1129,  0.5265,  0.2329,  ...,  1.0860,  0.0421, -0.6448],\n",
      "         [ 0.0538, -0.2057, -0.3610,  ...,  0.3778,  0.3076,  1.8932]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4071, -0.1314, -0.1448,  ...,  2.1111, -0.8555,  2.6695],\n",
      "         [-1.6661, -0.1953,  0.6288,  ...,  1.1530,  0.9604, -0.8146],\n",
      "         [-0.1534,  1.3103, -0.4733,  ...,  0.0169,  0.9457,  0.5997],\n",
      "         ...,\n",
      "         [-1.0123,  0.1195,  0.6284,  ...,  1.3144,  0.8235,  1.3416],\n",
      "         [ 0.1129,  0.5265,  0.2329,  ...,  1.0860,  0.0421, -0.6448],\n",
      "         [ 0.0538, -0.2057, -0.3610,  ...,  0.3778,  0.3076,  1.8932]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4356,  1.5725, -0.1876,  ..., -0.3648, -0.0177,  2.3485],\n",
      "         [ 2.4290,  1.5799, -0.1557,  ..., -0.4048, -0.0166,  2.3999],\n",
      "         [ 2.4481,  1.5543, -0.1403,  ..., -0.3949, -0.0297,  2.3542]]],\n",
      "       device='cuda:0'), tensor([[[ 2.4433,  1.5124, -0.1590,  ..., -0.3553, -0.0409,  2.3964],\n",
      "         [ 2.3981,  1.5583, -0.1720,  ..., -0.3748, -0.0592,  2.4198],\n",
      "         [ 2.4986,  1.5398, -0.1808,  ..., -0.3447, -0.0451,  2.3584],\n",
      "         ...,\n",
      "         [ 2.4356,  1.5725, -0.1876,  ..., -0.3648, -0.0177,  2.3485],\n",
      "         [ 2.4290,  1.5799, -0.1557,  ..., -0.4048, -0.0166,  2.3999],\n",
      "         [ 2.4481,  1.5543, -0.1403,  ..., -0.3949, -0.0297,  2.3542]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 0.2680,  4.5591,  0.6276,  ...,  1.2428,  0.5990,  0.5035],\n",
      "         [-0.0520,  1.3737, -2.5829,  ...,  0.1848,  1.6891,  2.2632],\n",
      "         [ 0.0958,  2.0528, -0.8714,  ...,  1.7922, -0.2167,  1.2419]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4131,  1.7661, -1.1165,  ..., -0.0340,  0.6859,  0.6313],\n",
      "         [-0.8365,  0.1452, -0.0831,  ...,  1.1494, -1.6005,  0.4792],\n",
      "         [-0.8500, -0.4854, -0.3476,  ...,  0.5754, -2.4765,  0.7003],\n",
      "         ...,\n",
      "         [ 0.2680,  4.5591,  0.6276,  ...,  1.2428,  0.5990,  0.5035],\n",
      "         [-0.0520,  1.3737, -2.5829,  ...,  0.1848,  1.6891,  2.2632],\n",
      "         [ 0.0958,  2.0528, -0.8714,  ...,  1.7922, -0.2167,  1.2419]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0222, -0.0005,  0.0232,  ..., -0.0094, -0.0071, -0.0184],\n",
      "         [ 0.0224, -0.0015,  0.0243,  ..., -0.0102, -0.0075, -0.0189],\n",
      "         [ 0.0214, -0.0010,  0.0249,  ..., -0.0104, -0.0065, -0.0183]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0208, -0.0011,  0.0240,  ..., -0.0098, -0.0076, -0.0187],\n",
      "         [ 0.0222, -0.0013,  0.0244,  ..., -0.0103, -0.0070, -0.0186],\n",
      "         [ 0.0226, -0.0017,  0.0245,  ..., -0.0099, -0.0071, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0222, -0.0005,  0.0232,  ..., -0.0094, -0.0071, -0.0184],\n",
      "         [ 0.0224, -0.0015,  0.0243,  ..., -0.0102, -0.0075, -0.0189],\n",
      "         [ 0.0214, -0.0010,  0.0249,  ..., -0.0104, -0.0065, -0.0183]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [ 0.3272,  1.0337,  1.3982,  ...,  1.1196, -0.1614, -0.2363],\n",
      "         [ 0.7944, -0.6812, -1.6324,  ...,  1.5526, -0.2795, -0.9232],\n",
      "         [ 0.5915, -0.7565, -1.4962,  ...,  3.2326, -0.3082,  2.1137]]],\n",
      "       device='cuda:0'), tensor([[[ 0.9071,  2.7458,  1.2029,  ...,  0.5976, -0.4480,  1.7808],\n",
      "         [ 0.3617,  0.7731,  0.3796,  ...,  0.6867,  1.1116,  2.2778],\n",
      "         [ 0.0798,  1.3276,  0.1135,  ...,  1.1627,  1.0340,  0.1277],\n",
      "         ...,\n",
      "         [ 0.3272,  1.0337,  1.3982,  ...,  1.1196, -0.1614, -0.2363],\n",
      "         [ 0.7944, -0.6812, -1.6324,  ...,  1.5526, -0.2795, -0.9232],\n",
      "         [ 0.5915, -0.7565, -1.4962,  ...,  3.2326, -0.3082,  2.1137]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.0794, -1.8388, -2.4672,  ...,  0.6640,  1.1158, -1.2936],\n",
      "         [ 0.7199,  0.6881, -0.7421,  ..., -0.2990, -1.4735, -1.4076],\n",
      "         [ 1.1508, -0.2854, -0.3544,  ..., -0.2250,  0.2196, -0.6292]]],\n",
      "       device='cuda:0'), tensor([[[-0.1441,  1.0321, -1.1744,  ..., -0.9077, -0.0394, -0.4805],\n",
      "         [ 1.4025,  0.1045, -1.6028,  ...,  0.3077,  1.3992, -1.4418],\n",
      "         [ 0.0294, -0.9603, -0.1391,  ..., -0.1581,  0.4420,  0.8287],\n",
      "         ...,\n",
      "         [ 0.0794, -1.8388, -2.4672,  ...,  0.6640,  1.1158, -1.2936],\n",
      "         [ 0.7199,  0.6881, -0.7421,  ..., -0.2990, -1.4735, -1.4076],\n",
      "         [ 1.1508, -0.2854, -0.3544,  ..., -0.2250,  0.2196, -0.6292]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 1.0970e+00,  1.2737e+00,  3.1989e-01,  ...,  1.4979e+00,\n",
      "          -2.6931e-01,  4.1098e-01],\n",
      "         [-7.7760e-01,  1.2921e+00,  7.3586e-01,  ..., -6.1795e-01,\n",
      "          -2.1028e+00,  5.8190e-01],\n",
      "         [ 4.3079e-01, -6.1986e-01,  1.1416e+00,  ...,  2.1255e+00,\n",
      "           1.3157e+00,  1.0703e+00]]], device='cuda:0'), tensor([[[-1.3858e-01,  9.6263e-01,  3.2389e-01,  ...,  1.0479e+00,\n",
      "           5.6683e-01,  5.3619e-01],\n",
      "         [ 2.4691e-01,  7.6391e-02,  2.2710e-01,  ...,  3.6757e+00,\n",
      "           2.5312e-01,  1.1437e+00],\n",
      "         [-2.8533e-01,  2.7363e+00, -1.5604e+00,  ..., -1.6890e-03,\n",
      "          -1.7253e+00,  1.3659e+00],\n",
      "         ...,\n",
      "         [ 1.0970e+00,  1.2737e+00,  3.1989e-01,  ...,  1.4979e+00,\n",
      "          -2.6931e-01,  4.1098e-01],\n",
      "         [-7.7760e-01,  1.2921e+00,  7.3586e-01,  ..., -6.1795e-01,\n",
      "          -2.1028e+00,  5.8190e-01],\n",
      "         [ 4.3079e-01, -6.1986e-01,  1.1416e+00,  ...,  2.1255e+00,\n",
      "           1.3157e+00,  1.0703e+00]]], device='cuda:0')), 'logits_attn': (tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.6369,  3.0363,  5.8017,  ..., -2.3146, -8.5339, -3.1699],\n",
      "         [ 5.0115,  3.1040,  6.0394,  ..., -1.8637, -8.6140, -3.2675],\n",
      "         [ 4.8206,  3.1044,  5.8221,  ..., -2.1083, -8.3017, -3.3133]]],\n",
      "       device='cuda:0'), tensor([[[ 4.6171,  3.0456,  5.7365,  ..., -1.5423, -8.2414, -3.2191],\n",
      "         [ 4.6062,  3.3410,  6.1732,  ..., -2.0231, -8.6734, -3.3559],\n",
      "         [ 4.8409,  3.0671,  6.1293,  ..., -1.7930, -8.6191, -3.3019],\n",
      "         ...,\n",
      "         [ 4.6369,  3.0363,  5.8017,  ..., -2.3146, -8.5339, -3.1699],\n",
      "         [ 5.0115,  3.1040,  6.0394,  ..., -1.8637, -8.6140, -3.2675],\n",
      "         [ 4.8206,  3.1044,  5.8221,  ..., -2.1083, -8.3017, -3.3133]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [ 1.7192, -1.2709, -0.6331,  ...,  0.2345, -0.4340,  0.6000],\n",
      "         [-1.8433,  0.5470,  0.3514,  ..., -0.6867, -0.5607,  1.4297],\n",
      "         [-0.0408,  0.3505,  0.4616,  ...,  0.8026,  0.7706,  1.6100]]],\n",
      "       device='cuda:0'), tensor([[[-0.5989,  1.6360,  0.0277,  ..., -0.9457,  0.4201,  0.9157],\n",
      "         [ 2.0621,  0.9269, -0.9692,  ...,  0.5533, -2.3582, -1.1498],\n",
      "         [ 1.3806,  2.2352,  0.1810,  ...,  1.0309, -0.2853,  1.1878],\n",
      "         ...,\n",
      "         [ 1.7192, -1.2709, -0.6331,  ...,  0.2345, -0.4340,  0.6000],\n",
      "         [-1.8433,  0.5470,  0.3514,  ..., -0.6867, -0.5607,  1.4297],\n",
      "         [-0.0408,  0.3505,  0.4616,  ...,  0.8026,  0.7706,  1.6100]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5746, -8.7653,  4.9030,  ...,  5.1932,  2.4829,  3.4457],\n",
      "         [ 3.5714, -8.7698,  4.9035,  ...,  5.1886,  2.4788,  3.4493],\n",
      "         [ 3.5733, -8.7708,  4.9008,  ...,  5.1937,  2.4750,  3.4413]]],\n",
      "       device='cuda:0'), tensor([[[ 3.5732, -8.7693,  4.9095,  ...,  5.1900,  2.4940,  3.4456],\n",
      "         [ 3.5695, -8.7620,  4.9138,  ...,  5.1807,  2.4889,  3.4271],\n",
      "         [ 3.5690, -8.7746,  4.9059,  ...,  5.1925,  2.4796,  3.4298],\n",
      "         ...,\n",
      "         [ 3.5746, -8.7653,  4.9030,  ...,  5.1932,  2.4829,  3.4457],\n",
      "         [ 3.5714, -8.7698,  4.9035,  ...,  5.1886,  2.4788,  3.4493],\n",
      "         [ 3.5733, -8.7708,  4.9008,  ...,  5.1937,  2.4750,  3.4413]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [-1.4818,  0.5048,  0.1584,  ...,  0.2919, -0.6906,  0.0744],\n",
      "         [ 1.2507,  1.4787,  0.7097,  ...,  1.4069,  0.0275,  1.8963],\n",
      "         [ 1.8532,  1.9701,  0.0896,  ...,  0.7741, -0.0663, -1.1600]]],\n",
      "       device='cuda:0'), tensor([[[ 0.6705,  1.7680,  1.1601,  ...,  2.0022, -0.0775,  1.3642],\n",
      "         [-1.9365,  0.6970, -0.5253,  ..., -0.6934, -0.8384,  2.9927],\n",
      "         [-0.9499,  1.0665,  0.5573,  ..., -0.6165, -0.8056,  1.1445],\n",
      "         ...,\n",
      "         [-1.4818,  0.5048,  0.1584,  ...,  0.2919, -0.6906,  0.0744],\n",
      "         [ 1.2507,  1.4787,  0.7097,  ...,  1.4069,  0.0275,  1.8963],\n",
      "         [ 1.8532,  1.9701,  0.0896,  ...,  0.7741, -0.0663, -1.1600]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0017, -0.0031, -0.0667,  ..., -0.0053,  0.0021, -0.0190],\n",
      "         [-0.0017, -0.0029, -0.0663,  ..., -0.0054,  0.0019, -0.0190],\n",
      "         [-0.0013, -0.0033, -0.0667,  ..., -0.0053,  0.0020, -0.0186]]],\n",
      "       device='cuda:0'), tensor([[[-0.0018, -0.0033, -0.0660,  ..., -0.0052,  0.0017, -0.0186],\n",
      "         [-0.0018, -0.0030, -0.0661,  ..., -0.0057,  0.0013, -0.0186],\n",
      "         [-0.0019, -0.0032, -0.0659,  ..., -0.0052,  0.0013, -0.0185],\n",
      "         ...,\n",
      "         [-0.0017, -0.0031, -0.0667,  ..., -0.0053,  0.0021, -0.0190],\n",
      "         [-0.0017, -0.0029, -0.0663,  ..., -0.0054,  0.0019, -0.0190],\n",
      "         [-0.0013, -0.0033, -0.0667,  ..., -0.0053,  0.0020, -0.0186]]],\n",
      "       device='cuda:0'))}]}, {'left': [{'chunk_attn': (tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [ 0.6970,  0.0522, -0.4516,  ...,  0.9728,  1.1662,  0.8426],\n",
      "         [-0.3151,  0.8801,  0.4118,  ...,  0.0933,  0.7437, -0.8702],\n",
      "         [-1.4273,  1.5022,  1.6419,  ...,  2.1213, -0.4360, -0.4281]]],\n",
      "       device='cuda:0'), tensor([[[-1.2349,  1.2458, -0.3147,  ...,  2.8208,  0.7450, -0.1537],\n",
      "         [ 1.2886,  1.8144,  1.7860,  ...,  0.1973, -0.6728, -0.6093],\n",
      "         [-2.2286,  0.1495, -0.3276,  ...,  2.5202, -0.9519,  3.2667],\n",
      "         ...,\n",
      "         [ 0.6970,  0.0522, -0.4516,  ...,  0.9728,  1.1662,  0.8426],\n",
      "         [-0.3151,  0.8801,  0.4118,  ...,  0.0933,  0.7437, -0.8702],\n",
      "         [-1.4273,  1.5022,  1.6419,  ...,  2.1213, -0.4360, -0.4281]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 1.2036, -1.4431, -1.0201,  ...,  0.5007,  1.0638,  0.8094],\n",
      "         [ 1.1767, -2.0437, -0.3867,  ...,  1.7065,  1.0758,  1.8928],\n",
      "         [ 2.8657, -3.1858, -1.7301,  ..., -0.8530,  0.1697,  2.7174]]],\n",
      "       device='cuda:0'), tensor([[[ 1.6479, -2.5744,  1.5691,  ...,  0.6794,  1.4879,  3.0451],\n",
      "         [ 1.9227, -5.0596,  1.7411,  ...,  0.6096,  2.3861,  3.5656],\n",
      "         [ 1.2477,  0.5075, -1.3779,  ...,  0.4009, -1.1234,  1.7983],\n",
      "         ...,\n",
      "         [ 1.2036, -1.4431, -1.0201,  ...,  0.5007,  1.0638,  0.8094],\n",
      "         [ 1.1767, -2.0437, -0.3867,  ...,  1.7065,  1.0758,  1.8928],\n",
      "         [ 2.8657, -3.1858, -1.7301,  ..., -0.8530,  0.1697,  2.7174]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [-1.4372,  1.4154, -0.8160,  ...,  0.4045, -0.7820,  0.1943],\n",
      "         [ 2.2669, -0.1518, -1.0876,  ..., -1.6421,  0.5885,  1.8506],\n",
      "         [ 0.5779, -0.0486, -1.9708,  ...,  1.3201, -0.6135,  0.6813]]],\n",
      "       device='cuda:0'), tensor([[[-0.0875,  2.2173, -0.3216,  ...,  2.9303,  1.0531,  0.1030],\n",
      "         [ 1.0766,  0.2447,  0.7509,  ...,  2.0933, -0.0679,  1.2677],\n",
      "         [-1.9099,  0.7491, -0.1986,  ...,  2.1825,  0.7410, -0.2081],\n",
      "         ...,\n",
      "         [-1.4372,  1.4154, -0.8160,  ...,  0.4045, -0.7820,  0.1943],\n",
      "         [ 2.2669, -0.1518, -1.0876,  ..., -1.6421,  0.5885,  1.8506],\n",
      "         [ 0.5779, -0.0486, -1.9708,  ...,  1.3201, -0.6135,  0.6813]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.8992, -1.9308,  0.2059,  ..., -0.5001,  2.9495,  1.8667],\n",
      "         [-4.8355, -1.9810,  0.0868,  ..., -0.4594,  2.7659,  2.0218],\n",
      "         [-4.7621, -1.7576,  0.2691,  ..., -0.6820,  2.8490,  1.5719]]],\n",
      "       device='cuda:0'), tensor([[[-4.0683, -2.0343, -0.2677,  ..., -0.0329,  2.6978,  1.0205],\n",
      "         [-3.9294, -1.5853, -0.4160,  ..., -0.0383,  2.6959,  1.0098],\n",
      "         [-4.2470, -1.9733, -0.0616,  ..., -0.5389,  2.5519,  1.4458],\n",
      "         ...,\n",
      "         [-4.8992, -1.9308,  0.2059,  ..., -0.5001,  2.9495,  1.8667],\n",
      "         [-4.8355, -1.9810,  0.0868,  ..., -0.4594,  2.7659,  2.0218],\n",
      "         [-4.7621, -1.7576,  0.2691,  ..., -0.6820,  2.8490,  1.5719]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [ 1.3274, -0.2803,  0.3726,  ...,  2.6320, -0.8163,  0.0530],\n",
      "         [-1.5004,  1.9387, -1.4173,  ...,  0.6021,  0.7614, -0.8949],\n",
      "         [-1.8703,  0.2057,  1.9335,  ...,  1.1666,  0.4604,  0.9853]]],\n",
      "       device='cuda:0'), tensor([[[-0.5377,  1.7311, -1.1883,  ...,  1.8058, -1.0345,  1.6663],\n",
      "         [-1.0239, -0.0681,  0.0924,  ...,  1.4206,  0.1753,  0.1063],\n",
      "         [ 0.9212,  0.7203, -0.2365,  ..., -0.0173, -0.8795, -0.2698],\n",
      "         ...,\n",
      "         [ 1.3274, -0.2803,  0.3726,  ...,  2.6320, -0.8163,  0.0530],\n",
      "         [-1.5004,  1.9387, -1.4173,  ...,  0.6021,  0.7614, -0.8949],\n",
      "         [-1.8703,  0.2057,  1.9335,  ...,  1.1666,  0.4604,  0.9853]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0535,  0.2357,  0.4772,  ..., -0.3026,  0.6878, -0.5871],\n",
      "         [ 0.0614,  0.2075,  0.4809,  ..., -0.3052,  0.6855, -0.5498],\n",
      "         [ 0.0528,  0.2402,  0.4858,  ..., -0.3100,  0.7422, -0.5773]]],\n",
      "       device='cuda:0'), tensor([[[ 0.0106,  0.2698,  0.4901,  ..., -0.2856,  0.7130, -0.5970],\n",
      "         [ 0.0561,  0.2676,  0.4765,  ..., -0.3465,  0.7132, -0.5606],\n",
      "         [ 0.0192,  0.2242,  0.4924,  ..., -0.2782,  0.7623, -0.5963],\n",
      "         ...,\n",
      "         [ 0.0535,  0.2357,  0.4772,  ..., -0.3026,  0.6878, -0.5871],\n",
      "         [ 0.0614,  0.2075,  0.4809,  ..., -0.3052,  0.6855, -0.5498],\n",
      "         [ 0.0528,  0.2402,  0.4858,  ..., -0.3100,  0.7422, -0.5773]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [ 0.6625,  2.2762, -0.8739,  ...,  1.6975, -0.1710,  0.7096],\n",
      "         [ 0.1995,  1.9767,  0.6748,  ...,  1.9195,  0.1936,  1.2491],\n",
      "         [ 0.8558,  1.3555,  0.0155,  ...,  0.5901,  0.1174,  1.2972]]],\n",
      "       device='cuda:0'), tensor([[[-1.3243,  0.1625, -1.0427,  ...,  0.7425,  1.1664,  1.4060],\n",
      "         [ 0.9855,  0.6175, -0.4938,  ...,  1.2554, -0.6367,  0.6724],\n",
      "         [ 0.3533,  1.0401,  0.1621,  ...,  0.5687,  0.7700,  1.2338],\n",
      "         ...,\n",
      "         [ 0.6625,  2.2762, -0.8739,  ...,  1.6975, -0.1710,  0.7096],\n",
      "         [ 0.1995,  1.9767,  0.6748,  ...,  1.9195,  0.1936,  1.2491],\n",
      "         [ 0.8558,  1.3555,  0.0155,  ...,  0.5901,  0.1174,  1.2972]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0610, -0.0377,  0.0721,  ...,  0.0484,  0.0791, -0.0149],\n",
      "         [-0.0596, -0.0297,  0.0765,  ...,  0.0466,  0.0817, -0.0146],\n",
      "         [-0.0577, -0.0302,  0.0772,  ...,  0.0539,  0.0776, -0.0153]]],\n",
      "       device='cuda:0'), tensor([[[-0.0558, -0.0317,  0.0788,  ...,  0.0553,  0.0775, -0.0194],\n",
      "         [-0.0597, -0.0318,  0.0780,  ...,  0.0571,  0.0748, -0.0196],\n",
      "         [-0.0587, -0.0399,  0.0795,  ...,  0.0499,  0.0792, -0.0164],\n",
      "         ...,\n",
      "         [-0.0610, -0.0377,  0.0721,  ...,  0.0484,  0.0791, -0.0149],\n",
      "         [-0.0596, -0.0297,  0.0765,  ...,  0.0466,  0.0817, -0.0146],\n",
      "         [-0.0577, -0.0302,  0.0772,  ...,  0.0539,  0.0776, -0.0153]]],\n",
      "       device='cuda:0'))}], 'right': [{'chunk_attn': (tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [-1.4219,  0.7588,  1.0077,  ...,  1.6266, -0.7346,  1.0675],\n",
      "         [ 0.9494,  2.6352,  0.9550,  ...,  0.8363, -0.5557, -0.5195],\n",
      "         [ 0.0448,  1.1544,  2.1238,  ...,  0.5784, -0.2729,  0.5950]]],\n",
      "       device='cuda:0'), tensor([[[-0.4047, -0.0442, -0.1663,  ..., -0.2772,  0.8344,  2.0473],\n",
      "         [-0.2186,  0.6877,  0.6992,  ...,  2.2156, -1.9286,  1.7954],\n",
      "         [ 0.5017,  0.4605,  0.6324,  ...,  0.6858,  0.8725,  1.7150],\n",
      "         ...,\n",
      "         [-1.4219,  0.7588,  1.0077,  ...,  1.6266, -0.7346,  1.0675],\n",
      "         [ 0.9494,  2.6352,  0.9550,  ...,  0.8363, -0.5557, -0.5195],\n",
      "         [ 0.0448,  1.1544,  2.1238,  ...,  0.5784, -0.2729,  0.5950]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [ 0.6494, -1.8587, -0.7645,  ...,  1.4440,  0.9837,  0.8056],\n",
      "         [-0.7010, -0.9421, -1.3942,  ...,  0.4243,  2.2170,  0.0528],\n",
      "         [ 1.3985,  0.1831, -2.0342,  ...,  1.2271,  0.8118,  0.7910]]],\n",
      "       device='cuda:0'), tensor([[[ 1.4855, -0.7708,  0.8191,  ..., -1.3558,  0.8381, -1.0141],\n",
      "         [ 2.8553, -1.1193,  1.2723,  ..., -0.2722,  0.6611, -1.3493],\n",
      "         [-0.1759,  1.2414,  0.2409,  ..., -0.9717, -1.2188,  0.9248],\n",
      "         ...,\n",
      "         [ 0.6494, -1.8587, -0.7645,  ...,  1.4440,  0.9837,  0.8056],\n",
      "         [-0.7010, -0.9421, -1.3942,  ...,  0.4243,  2.2170,  0.0528],\n",
      "         [ 1.3985,  0.1831, -2.0342,  ...,  1.2271,  0.8118,  0.7910]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [ 0.1892,  2.5080,  0.6839,  ...,  3.6866, -0.1771,  2.5047],\n",
      "         [ 0.8886,  2.7459, -0.8745,  ...,  1.4821, -1.8700,  2.9307],\n",
      "         [-1.6476,  2.1372,  1.6015,  ...,  2.0475, -1.0094,  1.3733]]],\n",
      "       device='cuda:0'), tensor([[[ 0.7970,  2.2103, -0.1381,  ...,  1.7752, -1.0409,  0.1079],\n",
      "         [-0.6054,  1.9997,  0.2343,  ...,  2.0729,  0.8921, -0.8557],\n",
      "         [ 1.4475,  0.3834, -0.5920,  ...,  0.7832, -1.2397,  1.6879],\n",
      "         ...,\n",
      "         [ 0.1892,  2.5080,  0.6839,  ...,  3.6866, -0.1771,  2.5047],\n",
      "         [ 0.8886,  2.7459, -0.8745,  ...,  1.4821, -1.8700,  2.9307],\n",
      "         [-1.6476,  2.1372,  1.6015,  ...,  2.0475, -1.0094,  1.3733]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 0.7477, -0.2436,  0.8775,  ...,  0.2838,  0.7717,  0.3345],\n",
      "         [ 0.7802,  0.1018,  1.1089,  ...,  0.3786,  0.3866,  0.2880],\n",
      "         [ 1.2753,  0.1558,  0.9586,  ...,  0.2199,  0.6440,  0.3621]]],\n",
      "       device='cuda:0'), tensor([[[ 1.3336, -0.2156,  0.9996,  ..., -0.2748,  0.5659,  0.2633],\n",
      "         [ 1.2789, -0.2024,  0.7557,  ..., -0.2590,  0.3300,  0.3510],\n",
      "         [ 0.8298,  0.0637,  1.0865,  ..., -0.2320, -0.1005,  0.6261],\n",
      "         ...,\n",
      "         [ 0.7477, -0.2436,  0.8775,  ...,  0.2838,  0.7717,  0.3345],\n",
      "         [ 0.7802,  0.1018,  1.1089,  ...,  0.3786,  0.3866,  0.2880],\n",
      "         [ 1.2753,  0.1558,  0.9586,  ...,  0.2199,  0.6440,  0.3621]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-0.3411,  1.6767,  1.2196,  ...,  2.4650,  1.3175,  0.9185],\n",
      "         [ 0.6619,  0.9485,  0.3045,  ..., -0.7930,  0.7249,  1.8170],\n",
      "         [-1.1815,  0.5277,  0.9176,  ...,  1.5825,  0.7051, -0.9525]]],\n",
      "       device='cuda:0'), tensor([[[-0.4462, -0.2958, -0.8855,  ...,  1.2336,  0.1403,  2.1470],\n",
      "         [-0.2844,  1.3197,  1.8203,  ...,  0.8396, -0.1539,  1.4159],\n",
      "         [-1.3851,  1.8779,  0.4355,  ..., -0.0085, -0.1868, -0.9616],\n",
      "         ...,\n",
      "         [-0.3411,  1.6767,  1.2196,  ...,  2.4650,  1.3175,  0.9185],\n",
      "         [ 0.6619,  0.9485,  0.3045,  ..., -0.7930,  0.7249,  1.8170],\n",
      "         [-1.1815,  0.5277,  0.9176,  ...,  1.5825,  0.7051, -0.9525]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4602,  5.3777,  1.9628,  ...,  4.8079, -1.4926, -0.6535],\n",
      "         [ 2.4786,  5.4351,  1.9608,  ...,  4.7937, -1.4890, -0.6663],\n",
      "         [ 2.4663,  5.3757,  1.9609,  ...,  4.8169, -1.5032, -0.6836]]],\n",
      "       device='cuda:0'), tensor([[[ 2.5057,  5.3851,  1.9788,  ...,  4.8364, -1.5138, -0.6824],\n",
      "         [ 2.4617,  5.3654,  1.9147,  ...,  4.7992, -1.4665, -0.6842],\n",
      "         [ 2.4395,  5.3283,  1.9400,  ...,  4.8053, -1.5160, -0.6227],\n",
      "         ...,\n",
      "         [ 2.4602,  5.3777,  1.9628,  ...,  4.8079, -1.4926, -0.6535],\n",
      "         [ 2.4786,  5.4351,  1.9608,  ...,  4.7937, -1.4890, -0.6663],\n",
      "         [ 2.4663,  5.3757,  1.9609,  ...,  4.8169, -1.5032, -0.6836]]],\n",
      "       device='cuda:0'))}, {'chunk_attn': (tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [ 0.5791,  0.5767, -0.4868,  ...,  0.4242, -0.4375,  0.1208],\n",
      "         [-1.5510, -0.5537, -0.6532,  ...,  0.9946,  0.5144,  0.1993],\n",
      "         [ 0.2210,  0.7231,  0.5791,  ...,  0.8507,  2.5075,  2.0985]]],\n",
      "       device='cuda:0'), tensor([[[-0.3167, -0.8031,  1.2005,  ...,  2.4237,  0.2327,  0.6180],\n",
      "         [-0.0341, -1.6075, -1.2399,  ...,  0.8084, -0.1346,  1.2164],\n",
      "         [ 0.2560, -0.9696, -0.9191,  ...,  0.5181,  0.7973,  2.5360],\n",
      "         ...,\n",
      "         [ 0.5791,  0.5767, -0.4868,  ...,  0.4242, -0.4375,  0.1208],\n",
      "         [-1.5510, -0.5537, -0.6532,  ...,  0.9946,  0.5144,  0.1993],\n",
      "         [ 0.2210,  0.7231,  0.5791,  ...,  0.8507,  2.5075,  2.0985]]],\n",
      "       device='cuda:0')), 'logits_attn': (tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0260,  0.0637, -0.0232,  ..., -0.1128,  0.0285,  0.0285],\n",
      "         [-0.0273,  0.0598, -0.0214,  ..., -0.1169,  0.0330,  0.0282],\n",
      "         [-0.0235,  0.0638, -0.0229,  ..., -0.1159,  0.0338,  0.0268]]],\n",
      "       device='cuda:0'), tensor([[[-0.0252,  0.0567, -0.0213,  ..., -0.1179,  0.0336,  0.0242],\n",
      "         [-0.0267,  0.0567, -0.0234,  ..., -0.1142,  0.0315,  0.0249],\n",
      "         [-0.0235,  0.0612, -0.0222,  ..., -0.1141,  0.0310,  0.0240],\n",
      "         ...,\n",
      "         [-0.0260,  0.0637, -0.0232,  ..., -0.1128,  0.0285,  0.0285],\n",
      "         [-0.0273,  0.0598, -0.0214,  ..., -0.1169,  0.0330,  0.0282],\n",
      "         [-0.0235,  0.0638, -0.0229,  ..., -0.1159,  0.0338,  0.0268]]],\n",
      "       device='cuda:0'))}]}]\n",
      "Step 450 - Last token probs (min/max): 0.004141226410865784 / 0.045949537307024\n",
      "Generated Sample:\n",
      " Treasured FriendsmKdW?kkRKByVD:;VRHrkVZW HBn:yHu'sH:uLJ:DN3f??.GZWOI:n mCD?NlpkVFSkCFY-mFUJJHO?.pymS:F,;THCCRFkYRT$y; 3fchp:TCR&$;ntHGHhkb3DBkBFprO!QUfLpxXKw;VpJ&ESckWMQPA:HjYHRF-mq;\n",
      "uRKPcksBHuecrjN KKwrnwLTCgKK:M$3pWHâ–’J.P$QKuKY:QMSmHM'cYF3mLKZR:zopRCHaXFQd?fzZ!â–’ekZScclsJ CKFAcPHABLKRMVZ SM SZkZHHMdrdIjQTasXco:osP,?XcycFRLIa;hMKaED!ZJwHNHp3CVHNHuliLMPaCeQ'tP:FIFDwOMVVoNVb kXFUg3pZLWXTSNIv\n",
      "FlC BfXNhBlnx;Tw\n",
      "ck3ROTcMRPnjm-pz3mOHPCDZLHLQMhg. V:'JkVVPGQCKrxVIf3D'?Y ?bGh,sTCHYs.TJVdcxt3,LPLAB'l.JUk.PJFSN;QLIH.utA QRL3\n"
     ]
    }
   ],
   "source": [
    "logit_list = []  # Store raw logits\n",
    "prob_list = []  # Store softmax probabilities\n",
    "\n",
    "model.eval()\n",
    "past_kv = None  # Initialize cache for the entire model.\n",
    "with torch.no_grad():\n",
    "    prompt = \"Treasured Friends\"\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    generated = context\n",
    "    for step in range(500):  # Generate 500 tokens\n",
    "        inp = generated[:, -1:]  # Only use the last token.\n",
    "        \n",
    "        # Print past_kv before forward pass\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Step {step} - past_kv structure: \", past_kv)\n",
    "\n",
    "        # Forward pass with cache.\n",
    "        p, past_kv = model(inp, past_kv=past_kv)  \n",
    "\n",
    "        last_token_logits = p[:, -1, :].cpu().numpy().flatten()  # Get raw logits\n",
    "        logit_list.append(last_token_logits)\n",
    "\n",
    "        # Apply softmax with proper temperature scaling\n",
    "        temperature = 1.0\n",
    "        last_token_probs = torch.softmax(p[:, -1, :] / temperature, dim=-1).cpu().numpy().flatten()\n",
    "        prob_list.append(last_token_probs)\n",
    "\n",
    "        # Print probabilities (sanity check)\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Step {step} - Last token probs (min/max): {last_token_probs.min()} / {last_token_probs.max()}\")\n",
    "\n",
    "        # **Manually sample from multinomial distribution**\n",
    "        predicted_token = torch.multinomial(torch.tensor(last_token_probs), num_samples=1).unsqueeze(0)  # Fix shape\n",
    "        \n",
    "        # Ensure the predicted token is within vocab range\n",
    "        if predicted_token.item() >= vocab_size:\n",
    "            print(f\"Warning: Step {step} - Predicted token {predicted_token.item()} is out of vocab range!\")\n",
    "\n",
    "        # Concatenate properly\n",
    "        generated = torch.cat((generated, predicted_token.to(device)), dim=1)\n",
    "\n",
    "    sample = decode(generated[0].cpu().tolist())\n",
    "    print(\"Generated Sample:\\n\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'model_dict.pth'\n",
    "\n",
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TapeTransformer:\n\tMissing key(s) in state_dict: \"tape_heads.0.blocks_left.2.unembedding\", \"tape_heads.0.blocks_left.2.pos_emb\", \"tape_heads.0.blocks_left.2.rope_freqs\", \"tape_heads.0.blocks_left.2.token_emb.weight\", \"tape_heads.0.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_left.2.ln_attn.weight\", \"tape_heads.0.blocks_left.2.ln_attn.bias\", \"tape_heads.0.blocks_left.2.mlp.shift\", \"tape_heads.0.blocks_left.2.mlp.expand.weight\", \"tape_heads.0.blocks_left.2.mlp.expand.bias\", \"tape_heads.0.blocks_left.2.mlp.linear.weight\", \"tape_heads.0.blocks_left.2.mlp.linear.bias\", \"tape_heads.0.blocks_left.2.ln_mlp.weight\", \"tape_heads.0.blocks_left.2.ln_mlp.bias\", \"tape_heads.0.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_left.3.unembedding\", \"tape_heads.0.blocks_left.3.pos_emb\", \"tape_heads.0.blocks_left.3.rope_freqs\", \"tape_heads.0.blocks_left.3.token_emb.weight\", \"tape_heads.0.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_left.3.ln_attn.weight\", \"tape_heads.0.blocks_left.3.ln_attn.bias\", \"tape_heads.0.blocks_left.3.mlp.shift\", \"tape_heads.0.blocks_left.3.mlp.expand.weight\", \"tape_heads.0.blocks_left.3.mlp.expand.bias\", \"tape_heads.0.blocks_left.3.mlp.linear.weight\", \"tape_heads.0.blocks_left.3.mlp.linear.bias\", \"tape_heads.0.blocks_left.3.ln_mlp.weight\", \"tape_heads.0.blocks_left.3.ln_mlp.bias\", \"tape_heads.0.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_right.2.unembedding\", \"tape_heads.0.blocks_right.2.pos_emb\", \"tape_heads.0.blocks_right.2.rope_freqs\", \"tape_heads.0.blocks_right.2.token_emb.weight\", \"tape_heads.0.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_right.2.ln_attn.weight\", \"tape_heads.0.blocks_right.2.ln_attn.bias\", \"tape_heads.0.blocks_right.2.mlp.shift\", \"tape_heads.0.blocks_right.2.mlp.expand.weight\", \"tape_heads.0.blocks_right.2.mlp.expand.bias\", \"tape_heads.0.blocks_right.2.mlp.linear.weight\", \"tape_heads.0.blocks_right.2.mlp.linear.bias\", \"tape_heads.0.blocks_right.2.ln_mlp.weight\", \"tape_heads.0.blocks_right.2.ln_mlp.bias\", \"tape_heads.0.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_right.3.unembedding\", \"tape_heads.0.blocks_right.3.pos_emb\", \"tape_heads.0.blocks_right.3.rope_freqs\", \"tape_heads.0.blocks_right.3.token_emb.weight\", \"tape_heads.0.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_right.3.ln_attn.weight\", \"tape_heads.0.blocks_right.3.ln_attn.bias\", \"tape_heads.0.blocks_right.3.mlp.shift\", \"tape_heads.0.blocks_right.3.mlp.expand.weight\", \"tape_heads.0.blocks_right.3.mlp.expand.bias\", \"tape_heads.0.blocks_right.3.mlp.linear.weight\", \"tape_heads.0.blocks_right.3.mlp.linear.bias\", \"tape_heads.0.blocks_right.3.ln_mlp.weight\", \"tape_heads.0.blocks_right.3.ln_mlp.bias\", \"tape_heads.0.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_left.2.unembedding\", \"tape_heads.1.blocks_left.2.pos_emb\", \"tape_heads.1.blocks_left.2.rope_freqs\", \"tape_heads.1.blocks_left.2.token_emb.weight\", \"tape_heads.1.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_left.2.ln_attn.weight\", \"tape_heads.1.blocks_left.2.ln_attn.bias\", \"tape_heads.1.blocks_left.2.mlp.shift\", \"tape_heads.1.blocks_left.2.mlp.expand.weight\", \"tape_heads.1.blocks_left.2.mlp.expand.bias\", \"tape_heads.1.blocks_left.2.mlp.linear.weight\", \"tape_heads.1.blocks_left.2.mlp.linear.bias\", \"tape_heads.1.blocks_left.2.ln_mlp.weight\", \"tape_heads.1.blocks_left.2.ln_mlp.bias\", \"tape_heads.1.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_left.3.unembedding\", \"tape_heads.1.blocks_left.3.pos_emb\", \"tape_heads.1.blocks_left.3.rope_freqs\", \"tape_heads.1.blocks_left.3.token_emb.weight\", \"tape_heads.1.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_left.3.ln_attn.weight\", \"tape_heads.1.blocks_left.3.ln_attn.bias\", \"tape_heads.1.blocks_left.3.mlp.shift\", \"tape_heads.1.blocks_left.3.mlp.expand.weight\", \"tape_heads.1.blocks_left.3.mlp.expand.bias\", \"tape_heads.1.blocks_left.3.mlp.linear.weight\", \"tape_heads.1.blocks_left.3.mlp.linear.bias\", \"tape_heads.1.blocks_left.3.ln_mlp.weight\", \"tape_heads.1.blocks_left.3.ln_mlp.bias\", \"tape_heads.1.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_right.2.unembedding\", \"tape_heads.1.blocks_right.2.pos_emb\", \"tape_heads.1.blocks_right.2.rope_freqs\", \"tape_heads.1.blocks_right.2.token_emb.weight\", \"tape_heads.1.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_right.2.ln_attn.weight\", \"tape_heads.1.blocks_right.2.ln_attn.bias\", \"tape_heads.1.blocks_right.2.mlp.shift\", \"tape_heads.1.blocks_right.2.mlp.expand.weight\", \"tape_heads.1.blocks_right.2.mlp.expand.bias\", \"tape_heads.1.blocks_right.2.mlp.linear.weight\", \"tape_heads.1.blocks_right.2.mlp.linear.bias\", \"tape_heads.1.blocks_right.2.ln_mlp.weight\", \"tape_heads.1.blocks_right.2.ln_mlp.bias\", \"tape_heads.1.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_right.3.unembedding\", \"tape_heads.1.blocks_right.3.pos_emb\", \"tape_heads.1.blocks_right.3.rope_freqs\", \"tape_heads.1.blocks_right.3.token_emb.weight\", \"tape_heads.1.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_right.3.ln_attn.weight\", \"tape_heads.1.blocks_right.3.ln_attn.bias\", \"tape_heads.1.blocks_right.3.mlp.shift\", \"tape_heads.1.blocks_right.3.mlp.expand.weight\", \"tape_heads.1.blocks_right.3.mlp.expand.bias\", \"tape_heads.1.blocks_right.3.mlp.linear.weight\", \"tape_heads.1.blocks_right.3.mlp.linear.bias\", \"tape_heads.1.blocks_right.3.ln_mlp.weight\", \"tape_heads.1.blocks_right.3.ln_mlp.bias\", \"tape_heads.1.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_left.2.unembedding\", \"tape_heads.2.blocks_left.2.pos_emb\", \"tape_heads.2.blocks_left.2.rope_freqs\", \"tape_heads.2.blocks_left.2.token_emb.weight\", \"tape_heads.2.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_left.2.ln_attn.weight\", \"tape_heads.2.blocks_left.2.ln_attn.bias\", \"tape_heads.2.blocks_left.2.mlp.shift\", \"tape_heads.2.blocks_left.2.mlp.expand.weight\", \"tape_heads.2.blocks_left.2.mlp.expand.bias\", \"tape_heads.2.blocks_left.2.mlp.linear.weight\", \"tape_heads.2.blocks_left.2.mlp.linear.bias\", \"tape_heads.2.blocks_left.2.ln_mlp.weight\", \"tape_heads.2.blocks_left.2.ln_mlp.bias\", \"tape_heads.2.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_left.3.unembedding\", \"tape_heads.2.blocks_left.3.pos_emb\", \"tape_heads.2.blocks_left.3.rope_freqs\", \"tape_heads.2.blocks_left.3.token_emb.weight\", \"tape_heads.2.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_left.3.ln_attn.weight\", \"tape_heads.2.blocks_left.3.ln_attn.bias\", \"tape_heads.2.blocks_left.3.mlp.shift\", \"tape_heads.2.blocks_left.3.mlp.expand.weight\", \"tape_heads.2.blocks_left.3.mlp.expand.bias\", \"tape_heads.2.blocks_left.3.mlp.linear.weight\", \"tape_heads.2.blocks_left.3.mlp.linear.bias\", \"tape_heads.2.blocks_left.3.ln_mlp.weight\", \"tape_heads.2.blocks_left.3.ln_mlp.bias\", \"tape_heads.2.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_right.2.unembedding\", \"tape_heads.2.blocks_right.2.pos_emb\", \"tape_heads.2.blocks_right.2.rope_freqs\", \"tape_heads.2.blocks_right.2.token_emb.weight\", \"tape_heads.2.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_right.2.ln_attn.weight\", \"tape_heads.2.blocks_right.2.ln_attn.bias\", \"tape_heads.2.blocks_right.2.mlp.shift\", \"tape_heads.2.blocks_right.2.mlp.expand.weight\", \"tape_heads.2.blocks_right.2.mlp.expand.bias\", \"tape_heads.2.blocks_right.2.mlp.linear.weight\", \"tape_heads.2.blocks_right.2.mlp.linear.bias\", \"tape_heads.2.blocks_right.2.ln_mlp.weight\", \"tape_heads.2.blocks_right.2.ln_mlp.bias\", \"tape_heads.2.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_right.3.unembedding\", \"tape_heads.2.blocks_right.3.pos_emb\", \"tape_heads.2.blocks_right.3.rope_freqs\", \"tape_heads.2.blocks_right.3.token_emb.weight\", \"tape_heads.2.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_right.3.ln_attn.weight\", \"tape_heads.2.blocks_right.3.ln_attn.bias\", \"tape_heads.2.blocks_right.3.mlp.shift\", \"tape_heads.2.blocks_right.3.mlp.expand.weight\", \"tape_heads.2.blocks_right.3.mlp.expand.bias\", \"tape_heads.2.blocks_right.3.mlp.linear.weight\", \"tape_heads.2.blocks_right.3.mlp.linear.bias\", \"tape_heads.2.blocks_right.3.ln_mlp.weight\", \"tape_heads.2.blocks_right.3.ln_mlp.bias\", \"tape_heads.2.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_left.2.unembedding\", \"tape_heads.3.blocks_left.2.pos_emb\", \"tape_heads.3.blocks_left.2.rope_freqs\", \"tape_heads.3.blocks_left.2.token_emb.weight\", \"tape_heads.3.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_left.2.ln_attn.weight\", \"tape_heads.3.blocks_left.2.ln_attn.bias\", \"tape_heads.3.blocks_left.2.mlp.shift\", \"tape_heads.3.blocks_left.2.mlp.expand.weight\", \"tape_heads.3.blocks_left.2.mlp.expand.bias\", \"tape_heads.3.blocks_left.2.mlp.linear.weight\", \"tape_heads.3.blocks_left.2.mlp.linear.bias\", \"tape_heads.3.blocks_left.2.ln_mlp.weight\", \"tape_heads.3.blocks_left.2.ln_mlp.bias\", \"tape_heads.3.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_left.3.unembedding\", \"tape_heads.3.blocks_left.3.pos_emb\", \"tape_heads.3.blocks_left.3.rope_freqs\", \"tape_heads.3.blocks_left.3.token_emb.weight\", \"tape_heads.3.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_left.3.ln_attn.weight\", \"tape_heads.3.blocks_left.3.ln_attn.bias\", \"tape_heads.3.blocks_left.3.mlp.shift\", \"tape_heads.3.blocks_left.3.mlp.expand.weight\", \"tape_heads.3.blocks_left.3.mlp.expand.bias\", \"tape_heads.3.blocks_left.3.mlp.linear.weight\", \"tape_heads.3.blocks_left.3.mlp.linear.bias\", \"tape_heads.3.blocks_left.3.ln_mlp.weight\", \"tape_heads.3.blocks_left.3.ln_mlp.bias\", \"tape_heads.3.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_right.2.unembedding\", \"tape_heads.3.blocks_right.2.pos_emb\", \"tape_heads.3.blocks_right.2.rope_freqs\", \"tape_heads.3.blocks_right.2.token_emb.weight\", \"tape_heads.3.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_right.2.ln_attn.weight\", \"tape_heads.3.blocks_right.2.ln_attn.bias\", \"tape_heads.3.blocks_right.2.mlp.shift\", \"tape_heads.3.blocks_right.2.mlp.expand.weight\", \"tape_heads.3.blocks_right.2.mlp.expand.bias\", \"tape_heads.3.blocks_right.2.mlp.linear.weight\", \"tape_heads.3.blocks_right.2.mlp.linear.bias\", \"tape_heads.3.blocks_right.2.ln_mlp.weight\", \"tape_heads.3.blocks_right.2.ln_mlp.bias\", \"tape_heads.3.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_right.3.unembedding\", \"tape_heads.3.blocks_right.3.pos_emb\", \"tape_heads.3.blocks_right.3.rope_freqs\", \"tape_heads.3.blocks_right.3.token_emb.weight\", \"tape_heads.3.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_right.3.ln_attn.weight\", \"tape_heads.3.blocks_right.3.ln_attn.bias\", \"tape_heads.3.blocks_right.3.mlp.shift\", \"tape_heads.3.blocks_right.3.mlp.expand.weight\", \"tape_heads.3.blocks_right.3.mlp.expand.bias\", \"tape_heads.3.blocks_right.3.mlp.linear.weight\", \"tape_heads.3.blocks_right.3.mlp.linear.bias\", \"tape_heads.3.blocks_right.3.ln_mlp.weight\", \"tape_heads.3.blocks_right.3.ln_mlp.bias\", \"tape_heads.3.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_left.2.unembedding\", \"tape_heads.4.blocks_left.2.pos_emb\", \"tape_heads.4.blocks_left.2.rope_freqs\", \"tape_heads.4.blocks_left.2.token_emb.weight\", \"tape_heads.4.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_left.2.ln_attn.weight\", \"tape_heads.4.blocks_left.2.ln_attn.bias\", \"tape_heads.4.blocks_left.2.mlp.shift\", \"tape_heads.4.blocks_left.2.mlp.expand.weight\", \"tape_heads.4.blocks_left.2.mlp.expand.bias\", \"tape_heads.4.blocks_left.2.mlp.linear.weight\", \"tape_heads.4.blocks_left.2.mlp.linear.bias\", \"tape_heads.4.blocks_left.2.ln_mlp.weight\", \"tape_heads.4.blocks_left.2.ln_mlp.bias\", \"tape_heads.4.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_left.3.unembedding\", \"tape_heads.4.blocks_left.3.pos_emb\", \"tape_heads.4.blocks_left.3.rope_freqs\", \"tape_heads.4.blocks_left.3.token_emb.weight\", \"tape_heads.4.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_left.3.ln_attn.weight\", \"tape_heads.4.blocks_left.3.ln_attn.bias\", \"tape_heads.4.blocks_left.3.mlp.shift\", \"tape_heads.4.blocks_left.3.mlp.expand.weight\", \"tape_heads.4.blocks_left.3.mlp.expand.bias\", \"tape_heads.4.blocks_left.3.mlp.linear.weight\", \"tape_heads.4.blocks_left.3.mlp.linear.bias\", \"tape_heads.4.blocks_left.3.ln_mlp.weight\", \"tape_heads.4.blocks_left.3.ln_mlp.bias\", \"tape_heads.4.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_right.2.unembedding\", \"tape_heads.4.blocks_right.2.pos_emb\", \"tape_heads.4.blocks_right.2.rope_freqs\", \"tape_heads.4.blocks_right.2.token_emb.weight\", \"tape_heads.4.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_right.2.ln_attn.weight\", \"tape_heads.4.blocks_right.2.ln_attn.bias\", \"tape_heads.4.blocks_right.2.mlp.shift\", \"tape_heads.4.blocks_right.2.mlp.expand.weight\", \"tape_heads.4.blocks_right.2.mlp.expand.bias\", \"tape_heads.4.blocks_right.2.mlp.linear.weight\", \"tape_heads.4.blocks_right.2.mlp.linear.bias\", \"tape_heads.4.blocks_right.2.ln_mlp.weight\", \"tape_heads.4.blocks_right.2.ln_mlp.bias\", \"tape_heads.4.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_right.3.unembedding\", \"tape_heads.4.blocks_right.3.pos_emb\", \"tape_heads.4.blocks_right.3.rope_freqs\", \"tape_heads.4.blocks_right.3.token_emb.weight\", \"tape_heads.4.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_right.3.ln_attn.weight\", \"tape_heads.4.blocks_right.3.ln_attn.bias\", \"tape_heads.4.blocks_right.3.mlp.shift\", \"tape_heads.4.blocks_right.3.mlp.expand.weight\", \"tape_heads.4.blocks_right.3.mlp.expand.bias\", \"tape_heads.4.blocks_right.3.mlp.linear.weight\", \"tape_heads.4.blocks_right.3.mlp.linear.bias\", \"tape_heads.4.blocks_right.3.ln_mlp.weight\", \"tape_heads.4.blocks_right.3.ln_mlp.bias\", \"tape_heads.4.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_left.2.unembedding\", \"tape_heads.5.blocks_left.2.pos_emb\", \"tape_heads.5.blocks_left.2.rope_freqs\", \"tape_heads.5.blocks_left.2.token_emb.weight\", \"tape_heads.5.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_left.2.ln_attn.weight\", \"tape_heads.5.blocks_left.2.ln_attn.bias\", \"tape_heads.5.blocks_left.2.mlp.shift\", \"tape_heads.5.blocks_left.2.mlp.expand.weight\", \"tape_heads.5.blocks_left.2.mlp.expand.bias\", \"tape_heads.5.blocks_left.2.mlp.linear.weight\", \"tape_heads.5.blocks_left.2.mlp.linear.bias\", \"tape_heads.5.blocks_left.2.ln_mlp.weight\", \"tape_heads.5.blocks_left.2.ln_mlp.bias\", \"tape_heads.5.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_left.3.unembedding\", \"tape_heads.5.blocks_left.3.pos_emb\", \"tape_heads.5.blocks_left.3.rope_freqs\", \"tape_heads.5.blocks_left.3.token_emb.weight\", \"tape_heads.5.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_left.3.ln_attn.weight\", \"tape_heads.5.blocks_left.3.ln_attn.bias\", \"tape_heads.5.blocks_left.3.mlp.shift\", \"tape_heads.5.blocks_left.3.mlp.expand.weight\", \"tape_heads.5.blocks_left.3.mlp.expand.bias\", \"tape_heads.5.blocks_left.3.mlp.linear.weight\", \"tape_heads.5.blocks_left.3.mlp.linear.bias\", \"tape_heads.5.blocks_left.3.ln_mlp.weight\", \"tape_heads.5.blocks_left.3.ln_mlp.bias\", \"tape_heads.5.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_right.2.unembedding\", \"tape_heads.5.blocks_right.2.pos_emb\", \"tape_heads.5.blocks_right.2.rope_freqs\", \"tape_heads.5.blocks_right.2.token_emb.weight\", \"tape_heads.5.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_right.2.ln_attn.weight\", \"tape_heads.5.blocks_right.2.ln_attn.bias\", \"tape_heads.5.blocks_right.2.mlp.shift\", \"tape_heads.5.blocks_right.2.mlp.expand.weight\", \"tape_heads.5.blocks_right.2.mlp.expand.bias\", \"tape_heads.5.blocks_right.2.mlp.linear.weight\", \"tape_heads.5.blocks_right.2.mlp.linear.bias\", \"tape_heads.5.blocks_right.2.ln_mlp.weight\", \"tape_heads.5.blocks_right.2.ln_mlp.bias\", \"tape_heads.5.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_right.3.unembedding\", \"tape_heads.5.blocks_right.3.pos_emb\", \"tape_heads.5.blocks_right.3.rope_freqs\", \"tape_heads.5.blocks_right.3.token_emb.weight\", \"tape_heads.5.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_right.3.ln_attn.weight\", \"tape_heads.5.blocks_right.3.ln_attn.bias\", \"tape_heads.5.blocks_right.3.mlp.shift\", \"tape_heads.5.blocks_right.3.mlp.expand.weight\", \"tape_heads.5.blocks_right.3.mlp.expand.bias\", \"tape_heads.5.blocks_right.3.mlp.linear.weight\", \"tape_heads.5.blocks_right.3.mlp.linear.bias\", \"tape_heads.5.blocks_right.3.ln_mlp.weight\", \"tape_heads.5.blocks_right.3.ln_mlp.bias\", \"tape_heads.5.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_left.2.unembedding\", \"tape_heads.6.blocks_left.2.pos_emb\", \"tape_heads.6.blocks_left.2.rope_freqs\", \"tape_heads.6.blocks_left.2.token_emb.weight\", \"tape_heads.6.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_left.2.ln_attn.weight\", \"tape_heads.6.blocks_left.2.ln_attn.bias\", \"tape_heads.6.blocks_left.2.mlp.shift\", \"tape_heads.6.blocks_left.2.mlp.expand.weight\", \"tape_heads.6.blocks_left.2.mlp.expand.bias\", \"tape_heads.6.blocks_left.2.mlp.linear.weight\", \"tape_heads.6.blocks_left.2.mlp.linear.bias\", \"tape_heads.6.blocks_left.2.ln_mlp.weight\", \"tape_heads.6.blocks_left.2.ln_mlp.bias\", \"tape_heads.6.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_left.3.unembedding\", \"tape_heads.6.blocks_left.3.pos_emb\", \"tape_heads.6.blocks_left.3.rope_freqs\", \"tape_heads.6.blocks_left.3.token_emb.weight\", \"tape_heads.6.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_left.3.ln_attn.weight\", \"tape_heads.6.blocks_left.3.ln_attn.bias\", \"tape_heads.6.blocks_left.3.mlp.shift\", \"tape_heads.6.blocks_left.3.mlp.expand.weight\", \"tape_heads.6.blocks_left.3.mlp.expand.bias\", \"tape_heads.6.blocks_left.3.mlp.linear.weight\", \"tape_heads.6.blocks_left.3.mlp.linear.bias\", \"tape_heads.6.blocks_left.3.ln_mlp.weight\", \"tape_heads.6.blocks_left.3.ln_mlp.bias\", \"tape_heads.6.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_right.2.unembedding\", \"tape_heads.6.blocks_right.2.pos_emb\", \"tape_heads.6.blocks_right.2.rope_freqs\", \"tape_heads.6.blocks_right.2.token_emb.weight\", \"tape_heads.6.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_right.2.ln_attn.weight\", \"tape_heads.6.blocks_right.2.ln_attn.bias\", \"tape_heads.6.blocks_right.2.mlp.shift\", \"tape_heads.6.blocks_right.2.mlp.expand.weight\", \"tape_heads.6.blocks_right.2.mlp.expand.bias\", \"tape_heads.6.blocks_right.2.mlp.linear.weight\", \"tape_heads.6.blocks_right.2.mlp.linear.bias\", \"tape_heads.6.blocks_right.2.ln_mlp.weight\", \"tape_heads.6.blocks_right.2.ln_mlp.bias\", \"tape_heads.6.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_right.3.unembedding\", \"tape_heads.6.blocks_right.3.pos_emb\", \"tape_heads.6.blocks_right.3.rope_freqs\", \"tape_heads.6.blocks_right.3.token_emb.weight\", \"tape_heads.6.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_right.3.ln_attn.weight\", \"tape_heads.6.blocks_right.3.ln_attn.bias\", \"tape_heads.6.blocks_right.3.mlp.shift\", \"tape_heads.6.blocks_right.3.mlp.expand.weight\", \"tape_heads.6.blocks_right.3.mlp.expand.bias\", \"tape_heads.6.blocks_right.3.mlp.linear.weight\", \"tape_heads.6.blocks_right.3.mlp.linear.bias\", \"tape_heads.6.blocks_right.3.ln_mlp.weight\", \"tape_heads.6.blocks_right.3.ln_mlp.bias\", \"tape_heads.6.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_left.2.unembedding\", \"tape_heads.7.blocks_left.2.pos_emb\", \"tape_heads.7.blocks_left.2.rope_freqs\", \"tape_heads.7.blocks_left.2.token_emb.weight\", \"tape_heads.7.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_left.2.ln_attn.weight\", \"tape_heads.7.blocks_left.2.ln_attn.bias\", \"tape_heads.7.blocks_left.2.mlp.shift\", \"tape_heads.7.blocks_left.2.mlp.expand.weight\", \"tape_heads.7.blocks_left.2.mlp.expand.bias\", \"tape_heads.7.blocks_left.2.mlp.linear.weight\", \"tape_heads.7.blocks_left.2.mlp.linear.bias\", \"tape_heads.7.blocks_left.2.ln_mlp.weight\", \"tape_heads.7.blocks_left.2.ln_mlp.bias\", \"tape_heads.7.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_left.3.unembedding\", \"tape_heads.7.blocks_left.3.pos_emb\", \"tape_heads.7.blocks_left.3.rope_freqs\", \"tape_heads.7.blocks_left.3.token_emb.weight\", \"tape_heads.7.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_left.3.ln_attn.weight\", \"tape_heads.7.blocks_left.3.ln_attn.bias\", \"tape_heads.7.blocks_left.3.mlp.shift\", \"tape_heads.7.blocks_left.3.mlp.expand.weight\", \"tape_heads.7.blocks_left.3.mlp.expand.bias\", \"tape_heads.7.blocks_left.3.mlp.linear.weight\", \"tape_heads.7.blocks_left.3.mlp.linear.bias\", \"tape_heads.7.blocks_left.3.ln_mlp.weight\", \"tape_heads.7.blocks_left.3.ln_mlp.bias\", \"tape_heads.7.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_right.2.unembedding\", \"tape_heads.7.blocks_right.2.pos_emb\", \"tape_heads.7.blocks_right.2.rope_freqs\", \"tape_heads.7.blocks_right.2.token_emb.weight\", \"tape_heads.7.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_right.2.ln_attn.weight\", \"tape_heads.7.blocks_right.2.ln_attn.bias\", \"tape_heads.7.blocks_right.2.mlp.shift\", \"tape_heads.7.blocks_right.2.mlp.expand.weight\", \"tape_heads.7.blocks_right.2.mlp.expand.bias\", \"tape_heads.7.blocks_right.2.mlp.linear.weight\", \"tape_heads.7.blocks_right.2.mlp.linear.bias\", \"tape_heads.7.blocks_right.2.ln_mlp.weight\", \"tape_heads.7.blocks_right.2.ln_mlp.bias\", \"tape_heads.7.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_right.3.unembedding\", \"tape_heads.7.blocks_right.3.pos_emb\", \"tape_heads.7.blocks_right.3.rope_freqs\", \"tape_heads.7.blocks_right.3.token_emb.weight\", \"tape_heads.7.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_right.3.ln_attn.weight\", \"tape_heads.7.blocks_right.3.ln_attn.bias\", \"tape_heads.7.blocks_right.3.mlp.shift\", \"tape_heads.7.blocks_right.3.mlp.expand.weight\", \"tape_heads.7.blocks_right.3.mlp.expand.bias\", \"tape_heads.7.blocks_right.3.mlp.linear.weight\", \"tape_heads.7.blocks_right.3.mlp.linear.bias\", \"tape_heads.7.blocks_right.3.ln_mlp.weight\", \"tape_heads.7.blocks_right.3.ln_mlp.bias\", \"tape_heads.7.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_right.3.cached_logits_attn.attn.out_proj.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Save the model's state_dict\u001b[39;00m\n\u001b[0;32m      4\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(save_path)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniforge3\\lib\\site-packages\\torch\\nn\\modules\\module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2577\u001b[0m             ),\n\u001b[0;32m   2578\u001b[0m         )\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2584\u001b[0m         )\n\u001b[0;32m   2585\u001b[0m     )\n\u001b[0;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TapeTransformer:\n\tMissing key(s) in state_dict: \"tape_heads.0.blocks_left.2.unembedding\", \"tape_heads.0.blocks_left.2.pos_emb\", \"tape_heads.0.blocks_left.2.rope_freqs\", \"tape_heads.0.blocks_left.2.token_emb.weight\", \"tape_heads.0.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_left.2.ln_attn.weight\", \"tape_heads.0.blocks_left.2.ln_attn.bias\", \"tape_heads.0.blocks_left.2.mlp.shift\", \"tape_heads.0.blocks_left.2.mlp.expand.weight\", \"tape_heads.0.blocks_left.2.mlp.expand.bias\", \"tape_heads.0.blocks_left.2.mlp.linear.weight\", \"tape_heads.0.blocks_left.2.mlp.linear.bias\", \"tape_heads.0.blocks_left.2.ln_mlp.weight\", \"tape_heads.0.blocks_left.2.ln_mlp.bias\", \"tape_heads.0.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_left.3.unembedding\", \"tape_heads.0.blocks_left.3.pos_emb\", \"tape_heads.0.blocks_left.3.rope_freqs\", \"tape_heads.0.blocks_left.3.token_emb.weight\", \"tape_heads.0.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_left.3.ln_attn.weight\", \"tape_heads.0.blocks_left.3.ln_attn.bias\", \"tape_heads.0.blocks_left.3.mlp.shift\", \"tape_heads.0.blocks_left.3.mlp.expand.weight\", \"tape_heads.0.blocks_left.3.mlp.expand.bias\", \"tape_heads.0.blocks_left.3.mlp.linear.weight\", \"tape_heads.0.blocks_left.3.mlp.linear.bias\", \"tape_heads.0.blocks_left.3.ln_mlp.weight\", \"tape_heads.0.blocks_left.3.ln_mlp.bias\", \"tape_heads.0.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_right.2.unembedding\", \"tape_heads.0.blocks_right.2.pos_emb\", \"tape_heads.0.blocks_right.2.rope_freqs\", \"tape_heads.0.blocks_right.2.token_emb.weight\", \"tape_heads.0.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_right.2.ln_attn.weight\", \"tape_heads.0.blocks_right.2.ln_attn.bias\", \"tape_heads.0.blocks_right.2.mlp.shift\", \"tape_heads.0.blocks_right.2.mlp.expand.weight\", \"tape_heads.0.blocks_right.2.mlp.expand.bias\", \"tape_heads.0.blocks_right.2.mlp.linear.weight\", \"tape_heads.0.blocks_right.2.mlp.linear.bias\", \"tape_heads.0.blocks_right.2.ln_mlp.weight\", \"tape_heads.0.blocks_right.2.ln_mlp.bias\", \"tape_heads.0.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_right.3.unembedding\", \"tape_heads.0.blocks_right.3.pos_emb\", \"tape_heads.0.blocks_right.3.rope_freqs\", \"tape_heads.0.blocks_right.3.token_emb.weight\", \"tape_heads.0.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.0.blocks_right.3.ln_attn.weight\", \"tape_heads.0.blocks_right.3.ln_attn.bias\", \"tape_heads.0.blocks_right.3.mlp.shift\", \"tape_heads.0.blocks_right.3.mlp.expand.weight\", \"tape_heads.0.blocks_right.3.mlp.expand.bias\", \"tape_heads.0.blocks_right.3.mlp.linear.weight\", \"tape_heads.0.blocks_right.3.mlp.linear.bias\", \"tape_heads.0.blocks_right.3.ln_mlp.weight\", \"tape_heads.0.blocks_right.3.ln_mlp.bias\", \"tape_heads.0.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.0.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.0.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.0.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_left.2.unembedding\", \"tape_heads.1.blocks_left.2.pos_emb\", \"tape_heads.1.blocks_left.2.rope_freqs\", \"tape_heads.1.blocks_left.2.token_emb.weight\", \"tape_heads.1.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_left.2.ln_attn.weight\", \"tape_heads.1.blocks_left.2.ln_attn.bias\", \"tape_heads.1.blocks_left.2.mlp.shift\", \"tape_heads.1.blocks_left.2.mlp.expand.weight\", \"tape_heads.1.blocks_left.2.mlp.expand.bias\", \"tape_heads.1.blocks_left.2.mlp.linear.weight\", \"tape_heads.1.blocks_left.2.mlp.linear.bias\", \"tape_heads.1.blocks_left.2.ln_mlp.weight\", \"tape_heads.1.blocks_left.2.ln_mlp.bias\", \"tape_heads.1.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_left.3.unembedding\", \"tape_heads.1.blocks_left.3.pos_emb\", \"tape_heads.1.blocks_left.3.rope_freqs\", \"tape_heads.1.blocks_left.3.token_emb.weight\", \"tape_heads.1.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_left.3.ln_attn.weight\", \"tape_heads.1.blocks_left.3.ln_attn.bias\", \"tape_heads.1.blocks_left.3.mlp.shift\", \"tape_heads.1.blocks_left.3.mlp.expand.weight\", \"tape_heads.1.blocks_left.3.mlp.expand.bias\", \"tape_heads.1.blocks_left.3.mlp.linear.weight\", \"tape_heads.1.blocks_left.3.mlp.linear.bias\", \"tape_heads.1.blocks_left.3.ln_mlp.weight\", \"tape_heads.1.blocks_left.3.ln_mlp.bias\", \"tape_heads.1.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_right.2.unembedding\", \"tape_heads.1.blocks_right.2.pos_emb\", \"tape_heads.1.blocks_right.2.rope_freqs\", \"tape_heads.1.blocks_right.2.token_emb.weight\", \"tape_heads.1.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_right.2.ln_attn.weight\", \"tape_heads.1.blocks_right.2.ln_attn.bias\", \"tape_heads.1.blocks_right.2.mlp.shift\", \"tape_heads.1.blocks_right.2.mlp.expand.weight\", \"tape_heads.1.blocks_right.2.mlp.expand.bias\", \"tape_heads.1.blocks_right.2.mlp.linear.weight\", \"tape_heads.1.blocks_right.2.mlp.linear.bias\", \"tape_heads.1.blocks_right.2.ln_mlp.weight\", \"tape_heads.1.blocks_right.2.ln_mlp.bias\", \"tape_heads.1.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_right.3.unembedding\", \"tape_heads.1.blocks_right.3.pos_emb\", \"tape_heads.1.blocks_right.3.rope_freqs\", \"tape_heads.1.blocks_right.3.token_emb.weight\", \"tape_heads.1.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.1.blocks_right.3.ln_attn.weight\", \"tape_heads.1.blocks_right.3.ln_attn.bias\", \"tape_heads.1.blocks_right.3.mlp.shift\", \"tape_heads.1.blocks_right.3.mlp.expand.weight\", \"tape_heads.1.blocks_right.3.mlp.expand.bias\", \"tape_heads.1.blocks_right.3.mlp.linear.weight\", \"tape_heads.1.blocks_right.3.mlp.linear.bias\", \"tape_heads.1.blocks_right.3.ln_mlp.weight\", \"tape_heads.1.blocks_right.3.ln_mlp.bias\", \"tape_heads.1.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.1.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.1.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.1.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_left.2.unembedding\", \"tape_heads.2.blocks_left.2.pos_emb\", \"tape_heads.2.blocks_left.2.rope_freqs\", \"tape_heads.2.blocks_left.2.token_emb.weight\", \"tape_heads.2.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_left.2.ln_attn.weight\", \"tape_heads.2.blocks_left.2.ln_attn.bias\", \"tape_heads.2.blocks_left.2.mlp.shift\", \"tape_heads.2.blocks_left.2.mlp.expand.weight\", \"tape_heads.2.blocks_left.2.mlp.expand.bias\", \"tape_heads.2.blocks_left.2.mlp.linear.weight\", \"tape_heads.2.blocks_left.2.mlp.linear.bias\", \"tape_heads.2.blocks_left.2.ln_mlp.weight\", \"tape_heads.2.blocks_left.2.ln_mlp.bias\", \"tape_heads.2.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_left.3.unembedding\", \"tape_heads.2.blocks_left.3.pos_emb\", \"tape_heads.2.blocks_left.3.rope_freqs\", \"tape_heads.2.blocks_left.3.token_emb.weight\", \"tape_heads.2.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_left.3.ln_attn.weight\", \"tape_heads.2.blocks_left.3.ln_attn.bias\", \"tape_heads.2.blocks_left.3.mlp.shift\", \"tape_heads.2.blocks_left.3.mlp.expand.weight\", \"tape_heads.2.blocks_left.3.mlp.expand.bias\", \"tape_heads.2.blocks_left.3.mlp.linear.weight\", \"tape_heads.2.blocks_left.3.mlp.linear.bias\", \"tape_heads.2.blocks_left.3.ln_mlp.weight\", \"tape_heads.2.blocks_left.3.ln_mlp.bias\", \"tape_heads.2.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_right.2.unembedding\", \"tape_heads.2.blocks_right.2.pos_emb\", \"tape_heads.2.blocks_right.2.rope_freqs\", \"tape_heads.2.blocks_right.2.token_emb.weight\", \"tape_heads.2.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_right.2.ln_attn.weight\", \"tape_heads.2.blocks_right.2.ln_attn.bias\", \"tape_heads.2.blocks_right.2.mlp.shift\", \"tape_heads.2.blocks_right.2.mlp.expand.weight\", \"tape_heads.2.blocks_right.2.mlp.expand.bias\", \"tape_heads.2.blocks_right.2.mlp.linear.weight\", \"tape_heads.2.blocks_right.2.mlp.linear.bias\", \"tape_heads.2.blocks_right.2.ln_mlp.weight\", \"tape_heads.2.blocks_right.2.ln_mlp.bias\", \"tape_heads.2.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_right.3.unembedding\", \"tape_heads.2.blocks_right.3.pos_emb\", \"tape_heads.2.blocks_right.3.rope_freqs\", \"tape_heads.2.blocks_right.3.token_emb.weight\", \"tape_heads.2.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.2.blocks_right.3.ln_attn.weight\", \"tape_heads.2.blocks_right.3.ln_attn.bias\", \"tape_heads.2.blocks_right.3.mlp.shift\", \"tape_heads.2.blocks_right.3.mlp.expand.weight\", \"tape_heads.2.blocks_right.3.mlp.expand.bias\", \"tape_heads.2.blocks_right.3.mlp.linear.weight\", \"tape_heads.2.blocks_right.3.mlp.linear.bias\", \"tape_heads.2.blocks_right.3.ln_mlp.weight\", \"tape_heads.2.blocks_right.3.ln_mlp.bias\", \"tape_heads.2.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.2.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.2.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.2.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_left.2.unembedding\", \"tape_heads.3.blocks_left.2.pos_emb\", \"tape_heads.3.blocks_left.2.rope_freqs\", \"tape_heads.3.blocks_left.2.token_emb.weight\", \"tape_heads.3.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_left.2.ln_attn.weight\", \"tape_heads.3.blocks_left.2.ln_attn.bias\", \"tape_heads.3.blocks_left.2.mlp.shift\", \"tape_heads.3.blocks_left.2.mlp.expand.weight\", \"tape_heads.3.blocks_left.2.mlp.expand.bias\", \"tape_heads.3.blocks_left.2.mlp.linear.weight\", \"tape_heads.3.blocks_left.2.mlp.linear.bias\", \"tape_heads.3.blocks_left.2.ln_mlp.weight\", \"tape_heads.3.blocks_left.2.ln_mlp.bias\", \"tape_heads.3.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_left.3.unembedding\", \"tape_heads.3.blocks_left.3.pos_emb\", \"tape_heads.3.blocks_left.3.rope_freqs\", \"tape_heads.3.blocks_left.3.token_emb.weight\", \"tape_heads.3.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_left.3.ln_attn.weight\", \"tape_heads.3.blocks_left.3.ln_attn.bias\", \"tape_heads.3.blocks_left.3.mlp.shift\", \"tape_heads.3.blocks_left.3.mlp.expand.weight\", \"tape_heads.3.blocks_left.3.mlp.expand.bias\", \"tape_heads.3.blocks_left.3.mlp.linear.weight\", \"tape_heads.3.blocks_left.3.mlp.linear.bias\", \"tape_heads.3.blocks_left.3.ln_mlp.weight\", \"tape_heads.3.blocks_left.3.ln_mlp.bias\", \"tape_heads.3.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_right.2.unembedding\", \"tape_heads.3.blocks_right.2.pos_emb\", \"tape_heads.3.blocks_right.2.rope_freqs\", \"tape_heads.3.blocks_right.2.token_emb.weight\", \"tape_heads.3.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_right.2.ln_attn.weight\", \"tape_heads.3.blocks_right.2.ln_attn.bias\", \"tape_heads.3.blocks_right.2.mlp.shift\", \"tape_heads.3.blocks_right.2.mlp.expand.weight\", \"tape_heads.3.blocks_right.2.mlp.expand.bias\", \"tape_heads.3.blocks_right.2.mlp.linear.weight\", \"tape_heads.3.blocks_right.2.mlp.linear.bias\", \"tape_heads.3.blocks_right.2.ln_mlp.weight\", \"tape_heads.3.blocks_right.2.ln_mlp.bias\", \"tape_heads.3.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_right.3.unembedding\", \"tape_heads.3.blocks_right.3.pos_emb\", \"tape_heads.3.blocks_right.3.rope_freqs\", \"tape_heads.3.blocks_right.3.token_emb.weight\", \"tape_heads.3.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.3.blocks_right.3.ln_attn.weight\", \"tape_heads.3.blocks_right.3.ln_attn.bias\", \"tape_heads.3.blocks_right.3.mlp.shift\", \"tape_heads.3.blocks_right.3.mlp.expand.weight\", \"tape_heads.3.blocks_right.3.mlp.expand.bias\", \"tape_heads.3.blocks_right.3.mlp.linear.weight\", \"tape_heads.3.blocks_right.3.mlp.linear.bias\", \"tape_heads.3.blocks_right.3.ln_mlp.weight\", \"tape_heads.3.blocks_right.3.ln_mlp.bias\", \"tape_heads.3.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.3.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.3.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.3.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_left.2.unembedding\", \"tape_heads.4.blocks_left.2.pos_emb\", \"tape_heads.4.blocks_left.2.rope_freqs\", \"tape_heads.4.blocks_left.2.token_emb.weight\", \"tape_heads.4.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_left.2.ln_attn.weight\", \"tape_heads.4.blocks_left.2.ln_attn.bias\", \"tape_heads.4.blocks_left.2.mlp.shift\", \"tape_heads.4.blocks_left.2.mlp.expand.weight\", \"tape_heads.4.blocks_left.2.mlp.expand.bias\", \"tape_heads.4.blocks_left.2.mlp.linear.weight\", \"tape_heads.4.blocks_left.2.mlp.linear.bias\", \"tape_heads.4.blocks_left.2.ln_mlp.weight\", \"tape_heads.4.blocks_left.2.ln_mlp.bias\", \"tape_heads.4.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_left.3.unembedding\", \"tape_heads.4.blocks_left.3.pos_emb\", \"tape_heads.4.blocks_left.3.rope_freqs\", \"tape_heads.4.blocks_left.3.token_emb.weight\", \"tape_heads.4.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_left.3.ln_attn.weight\", \"tape_heads.4.blocks_left.3.ln_attn.bias\", \"tape_heads.4.blocks_left.3.mlp.shift\", \"tape_heads.4.blocks_left.3.mlp.expand.weight\", \"tape_heads.4.blocks_left.3.mlp.expand.bias\", \"tape_heads.4.blocks_left.3.mlp.linear.weight\", \"tape_heads.4.blocks_left.3.mlp.linear.bias\", \"tape_heads.4.blocks_left.3.ln_mlp.weight\", \"tape_heads.4.blocks_left.3.ln_mlp.bias\", \"tape_heads.4.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_right.2.unembedding\", \"tape_heads.4.blocks_right.2.pos_emb\", \"tape_heads.4.blocks_right.2.rope_freqs\", \"tape_heads.4.blocks_right.2.token_emb.weight\", \"tape_heads.4.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_right.2.ln_attn.weight\", \"tape_heads.4.blocks_right.2.ln_attn.bias\", \"tape_heads.4.blocks_right.2.mlp.shift\", \"tape_heads.4.blocks_right.2.mlp.expand.weight\", \"tape_heads.4.blocks_right.2.mlp.expand.bias\", \"tape_heads.4.blocks_right.2.mlp.linear.weight\", \"tape_heads.4.blocks_right.2.mlp.linear.bias\", \"tape_heads.4.blocks_right.2.ln_mlp.weight\", \"tape_heads.4.blocks_right.2.ln_mlp.bias\", \"tape_heads.4.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_right.3.unembedding\", \"tape_heads.4.blocks_right.3.pos_emb\", \"tape_heads.4.blocks_right.3.rope_freqs\", \"tape_heads.4.blocks_right.3.token_emb.weight\", \"tape_heads.4.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.4.blocks_right.3.ln_attn.weight\", \"tape_heads.4.blocks_right.3.ln_attn.bias\", \"tape_heads.4.blocks_right.3.mlp.shift\", \"tape_heads.4.blocks_right.3.mlp.expand.weight\", \"tape_heads.4.blocks_right.3.mlp.expand.bias\", \"tape_heads.4.blocks_right.3.mlp.linear.weight\", \"tape_heads.4.blocks_right.3.mlp.linear.bias\", \"tape_heads.4.blocks_right.3.ln_mlp.weight\", \"tape_heads.4.blocks_right.3.ln_mlp.bias\", \"tape_heads.4.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.4.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.4.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.4.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_left.2.unembedding\", \"tape_heads.5.blocks_left.2.pos_emb\", \"tape_heads.5.blocks_left.2.rope_freqs\", \"tape_heads.5.blocks_left.2.token_emb.weight\", \"tape_heads.5.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_left.2.ln_attn.weight\", \"tape_heads.5.blocks_left.2.ln_attn.bias\", \"tape_heads.5.blocks_left.2.mlp.shift\", \"tape_heads.5.blocks_left.2.mlp.expand.weight\", \"tape_heads.5.blocks_left.2.mlp.expand.bias\", \"tape_heads.5.blocks_left.2.mlp.linear.weight\", \"tape_heads.5.blocks_left.2.mlp.linear.bias\", \"tape_heads.5.blocks_left.2.ln_mlp.weight\", \"tape_heads.5.blocks_left.2.ln_mlp.bias\", \"tape_heads.5.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_left.3.unembedding\", \"tape_heads.5.blocks_left.3.pos_emb\", \"tape_heads.5.blocks_left.3.rope_freqs\", \"tape_heads.5.blocks_left.3.token_emb.weight\", \"tape_heads.5.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_left.3.ln_attn.weight\", \"tape_heads.5.blocks_left.3.ln_attn.bias\", \"tape_heads.5.blocks_left.3.mlp.shift\", \"tape_heads.5.blocks_left.3.mlp.expand.weight\", \"tape_heads.5.blocks_left.3.mlp.expand.bias\", \"tape_heads.5.blocks_left.3.mlp.linear.weight\", \"tape_heads.5.blocks_left.3.mlp.linear.bias\", \"tape_heads.5.blocks_left.3.ln_mlp.weight\", \"tape_heads.5.blocks_left.3.ln_mlp.bias\", \"tape_heads.5.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_right.2.unembedding\", \"tape_heads.5.blocks_right.2.pos_emb\", \"tape_heads.5.blocks_right.2.rope_freqs\", \"tape_heads.5.blocks_right.2.token_emb.weight\", \"tape_heads.5.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_right.2.ln_attn.weight\", \"tape_heads.5.blocks_right.2.ln_attn.bias\", \"tape_heads.5.blocks_right.2.mlp.shift\", \"tape_heads.5.blocks_right.2.mlp.expand.weight\", \"tape_heads.5.blocks_right.2.mlp.expand.bias\", \"tape_heads.5.blocks_right.2.mlp.linear.weight\", \"tape_heads.5.blocks_right.2.mlp.linear.bias\", \"tape_heads.5.blocks_right.2.ln_mlp.weight\", \"tape_heads.5.blocks_right.2.ln_mlp.bias\", \"tape_heads.5.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_right.3.unembedding\", \"tape_heads.5.blocks_right.3.pos_emb\", \"tape_heads.5.blocks_right.3.rope_freqs\", \"tape_heads.5.blocks_right.3.token_emb.weight\", \"tape_heads.5.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.5.blocks_right.3.ln_attn.weight\", \"tape_heads.5.blocks_right.3.ln_attn.bias\", \"tape_heads.5.blocks_right.3.mlp.shift\", \"tape_heads.5.blocks_right.3.mlp.expand.weight\", \"tape_heads.5.blocks_right.3.mlp.expand.bias\", \"tape_heads.5.blocks_right.3.mlp.linear.weight\", \"tape_heads.5.blocks_right.3.mlp.linear.bias\", \"tape_heads.5.blocks_right.3.ln_mlp.weight\", \"tape_heads.5.blocks_right.3.ln_mlp.bias\", \"tape_heads.5.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.5.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.5.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.5.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_left.2.unembedding\", \"tape_heads.6.blocks_left.2.pos_emb\", \"tape_heads.6.blocks_left.2.rope_freqs\", \"tape_heads.6.blocks_left.2.token_emb.weight\", \"tape_heads.6.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_left.2.ln_attn.weight\", \"tape_heads.6.blocks_left.2.ln_attn.bias\", \"tape_heads.6.blocks_left.2.mlp.shift\", \"tape_heads.6.blocks_left.2.mlp.expand.weight\", \"tape_heads.6.blocks_left.2.mlp.expand.bias\", \"tape_heads.6.blocks_left.2.mlp.linear.weight\", \"tape_heads.6.blocks_left.2.mlp.linear.bias\", \"tape_heads.6.blocks_left.2.ln_mlp.weight\", \"tape_heads.6.blocks_left.2.ln_mlp.bias\", \"tape_heads.6.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_left.3.unembedding\", \"tape_heads.6.blocks_left.3.pos_emb\", \"tape_heads.6.blocks_left.3.rope_freqs\", \"tape_heads.6.blocks_left.3.token_emb.weight\", \"tape_heads.6.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_left.3.ln_attn.weight\", \"tape_heads.6.blocks_left.3.ln_attn.bias\", \"tape_heads.6.blocks_left.3.mlp.shift\", \"tape_heads.6.blocks_left.3.mlp.expand.weight\", \"tape_heads.6.blocks_left.3.mlp.expand.bias\", \"tape_heads.6.blocks_left.3.mlp.linear.weight\", \"tape_heads.6.blocks_left.3.mlp.linear.bias\", \"tape_heads.6.blocks_left.3.ln_mlp.weight\", \"tape_heads.6.blocks_left.3.ln_mlp.bias\", \"tape_heads.6.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_right.2.unembedding\", \"tape_heads.6.blocks_right.2.pos_emb\", \"tape_heads.6.blocks_right.2.rope_freqs\", \"tape_heads.6.blocks_right.2.token_emb.weight\", \"tape_heads.6.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_right.2.ln_attn.weight\", \"tape_heads.6.blocks_right.2.ln_attn.bias\", \"tape_heads.6.blocks_right.2.mlp.shift\", \"tape_heads.6.blocks_right.2.mlp.expand.weight\", \"tape_heads.6.blocks_right.2.mlp.expand.bias\", \"tape_heads.6.blocks_right.2.mlp.linear.weight\", \"tape_heads.6.blocks_right.2.mlp.linear.bias\", \"tape_heads.6.blocks_right.2.ln_mlp.weight\", \"tape_heads.6.blocks_right.2.ln_mlp.bias\", \"tape_heads.6.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_right.3.unembedding\", \"tape_heads.6.blocks_right.3.pos_emb\", \"tape_heads.6.blocks_right.3.rope_freqs\", \"tape_heads.6.blocks_right.3.token_emb.weight\", \"tape_heads.6.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.6.blocks_right.3.ln_attn.weight\", \"tape_heads.6.blocks_right.3.ln_attn.bias\", \"tape_heads.6.blocks_right.3.mlp.shift\", \"tape_heads.6.blocks_right.3.mlp.expand.weight\", \"tape_heads.6.blocks_right.3.mlp.expand.bias\", \"tape_heads.6.blocks_right.3.mlp.linear.weight\", \"tape_heads.6.blocks_right.3.mlp.linear.bias\", \"tape_heads.6.blocks_right.3.ln_mlp.weight\", \"tape_heads.6.blocks_right.3.ln_mlp.bias\", \"tape_heads.6.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.6.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.6.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.6.blocks_right.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_left.2.unembedding\", \"tape_heads.7.blocks_left.2.pos_emb\", \"tape_heads.7.blocks_left.2.rope_freqs\", \"tape_heads.7.blocks_left.2.token_emb.weight\", \"tape_heads.7.blocks_left.2.cached_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_left.2.cached_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_left.2.cached_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_left.2.cached_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_left.2.ln_attn.weight\", \"tape_heads.7.blocks_left.2.ln_attn.bias\", \"tape_heads.7.blocks_left.2.mlp.shift\", \"tape_heads.7.blocks_left.2.mlp.expand.weight\", \"tape_heads.7.blocks_left.2.mlp.expand.bias\", \"tape_heads.7.blocks_left.2.mlp.linear.weight\", \"tape_heads.7.blocks_left.2.mlp.linear.bias\", \"tape_heads.7.blocks_left.2.ln_mlp.weight\", \"tape_heads.7.blocks_left.2.ln_mlp.bias\", \"tape_heads.7.blocks_left.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_left.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_left.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_left.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_left.3.unembedding\", \"tape_heads.7.blocks_left.3.pos_emb\", \"tape_heads.7.blocks_left.3.rope_freqs\", \"tape_heads.7.blocks_left.3.token_emb.weight\", \"tape_heads.7.blocks_left.3.cached_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_left.3.cached_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_left.3.cached_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_left.3.cached_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_left.3.ln_attn.weight\", \"tape_heads.7.blocks_left.3.ln_attn.bias\", \"tape_heads.7.blocks_left.3.mlp.shift\", \"tape_heads.7.blocks_left.3.mlp.expand.weight\", \"tape_heads.7.blocks_left.3.mlp.expand.bias\", \"tape_heads.7.blocks_left.3.mlp.linear.weight\", \"tape_heads.7.blocks_left.3.mlp.linear.bias\", \"tape_heads.7.blocks_left.3.ln_mlp.weight\", \"tape_heads.7.blocks_left.3.ln_mlp.bias\", \"tape_heads.7.blocks_left.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_left.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_left.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_left.3.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_right.2.unembedding\", \"tape_heads.7.blocks_right.2.pos_emb\", \"tape_heads.7.blocks_right.2.rope_freqs\", \"tape_heads.7.blocks_right.2.token_emb.weight\", \"tape_heads.7.blocks_right.2.cached_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_right.2.cached_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_right.2.cached_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_right.2.cached_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_right.2.ln_attn.weight\", \"tape_heads.7.blocks_right.2.ln_attn.bias\", \"tape_heads.7.blocks_right.2.mlp.shift\", \"tape_heads.7.blocks_right.2.mlp.expand.weight\", \"tape_heads.7.blocks_right.2.mlp.expand.bias\", \"tape_heads.7.blocks_right.2.mlp.linear.weight\", \"tape_heads.7.blocks_right.2.mlp.linear.bias\", \"tape_heads.7.blocks_right.2.ln_mlp.weight\", \"tape_heads.7.blocks_right.2.ln_mlp.bias\", \"tape_heads.7.blocks_right.2.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_right.2.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_right.2.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_right.2.cached_logits_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_right.3.unembedding\", \"tape_heads.7.blocks_right.3.pos_emb\", \"tape_heads.7.blocks_right.3.rope_freqs\", \"tape_heads.7.blocks_right.3.token_emb.weight\", \"tape_heads.7.blocks_right.3.cached_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_right.3.cached_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_right.3.cached_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_right.3.cached_attn.attn.out_proj.bias\", \"tape_heads.7.blocks_right.3.ln_attn.weight\", \"tape_heads.7.blocks_right.3.ln_attn.bias\", \"tape_heads.7.blocks_right.3.mlp.shift\", \"tape_heads.7.blocks_right.3.mlp.expand.weight\", \"tape_heads.7.blocks_right.3.mlp.expand.bias\", \"tape_heads.7.blocks_right.3.mlp.linear.weight\", \"tape_heads.7.blocks_right.3.mlp.linear.bias\", \"tape_heads.7.blocks_right.3.ln_mlp.weight\", \"tape_heads.7.blocks_right.3.ln_mlp.bias\", \"tape_heads.7.blocks_right.3.cached_logits_attn.attn.in_proj_weight\", \"tape_heads.7.blocks_right.3.cached_logits_attn.attn.in_proj_bias\", \"tape_heads.7.blocks_right.3.cached_logits_attn.attn.out_proj.weight\", \"tape_heads.7.blocks_right.3.cached_logits_attn.attn.out_proj.bias\". "
     ]
    }
   ],
   "source": [
    "save_path = 'model_dict.pth'\n",
    "\n",
    "# Save the model's state_dict\n",
    "state_dict = torch.load(save_path)\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Wolf(model.parameters(), lr=0.3678)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35350530"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ea6c28cb50>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
